<!DOCTYPE html><html lang="zh-CN" data-theme="dark"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Coding-Zuo - Coding And Studying</title><meta name="keywords" content="NLP zuoyuhui"><meta name="author" content="Coding-Zuo"><meta name="copyright" content="Coding-Zuo"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#0d0d0d"><meta name="description" content="我的建议是看开点、、、">
<meta property="og:type" content="website">
<meta property="og:title" content="Coding-Zuo">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="Coding-Zuo">
<meta property="og:description" content="我的建议是看开点、、、">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://i.loli.net/2021/03/22/YP2oqk7lOAfceTD.jpg">
<meta property="article:author" content="Coding-Zuo">
<meta property="article:tag" content="NLP zuoyuhui">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.loli.net/2021/03/22/YP2oqk7lOAfceTD.jpg"><link rel="shortcut icon" href="https://i.loli.net/2021/03/22/reFlcYOnP3dSuJX.png"><link rel="canonical" href="http://example.com/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.json","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = { 
  isPost: false,
  isHome: true,
  isHighlightShrink: false,
  isToc: false,
  postUpdate: '2022-02-21 10:01:53'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
          const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
          const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
          const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

          if (t === undefined) {
            if (isLightMode) activateLightMode()
            else if (isDarkMode) activateDarkMode()
            else if (isNotSpecified || hasNoSupport) {
              const now = new Date()
              const hour = now.getHours()
              const isNight = hour <= 6 || hour >= 18
              isNight ? activateDarkMode() : activateLightMode()
            }
            window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
              if (saveToLocal.get('theme') === undefined) {
                e.matches ? activateDarkMode() : activateLightMode()
              }
            })
          } else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const fontSizeVal = saveToLocal.get('global-font-size')
    if (fontSizeVal !== undefined) {
      document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
    }
    })(window)</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/sviptzk/HexoStaticFile@latest/Hexo/css/footer.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css"><meta name="generator" content="Hexo 5.3.0"><link rel="alternate" href="/atom.xml" title="Coding-Zuo" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="https://i.loli.net/2021/03/22/YP2oqk7lOAfceTD.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">134</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">16</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https:www.baidu.com"><i class="fa-fw fas fa-heart"></i><span> 我的简历</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 清单</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/%E9%9F%B3%E4%B9%90"><i class="fa-fw /music/"></i><span> 0</span></a></li><li><a class="site-page child" href="/%E7%94%B5%E5%BD%B1"><i class="fa-fw /movies/"></i><span> 1</span></a></li><li><a class="site-page child" href="/%E7%85%A7%E7%89%87"><i class="fa-fw /Gallery/"></i><span> 2</span></a></li></ul></div></div></div></div><div class="page" id="body-wrap"><header class="full_page" id="page-header" style="background-image: url('https://i.loli.net/2021/03/22/Td23imqYWsLGcJA.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Coding-Zuo</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https:www.baidu.com"><i class="fa-fw fas fa-heart"></i><span> 我的简历</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 清单</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/%E9%9F%B3%E4%B9%90"><i class="fa-fw /music/"></i><span> 0</span></a></li><li><a class="site-page child" href="/%E7%94%B5%E5%BD%B1"><i class="fa-fw /movies/"></i><span> 1</span></a></li><li><a class="site-page child" href="/%E7%85%A7%E7%89%87"><i class="fa-fw /Gallery/"></i><span> 2</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="site-info"><h1 id="site-title">Coding-Zuo</h1><div id="site-subtitle"><span id="subtitle"></span></div><div id="site_social_icons"><a class="social-icon" href="https://github.com/Coding-Zuo" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="/zzuuoo666@sina.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div id="scroll-down"><i class="fas fa-angle-down scroll-down-effects"></i></div></header><main class="layout" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2021/10/01/%E7%AC%AC%E4%BA%94%E5%B1%8A%E8%BE%BE%E8%A7%82%E6%9D%AF%E2%80%94%E2%80%94%E9%A3%8E%E9%99%A9%E4%BA%8B%E4%BB%B6%E6%A0%87%E7%AD%BE%E8%AF%86%E5%88%AB%E6%AF%94%E8%B5%9B%E5%A4%8D%E7%9B%98/" title="第五届达观杯——风险事件标签识别比赛复盘">     <img class="post_bg" src="https://z3.ax1x.com/2021/10/01/47nQm9.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="第五届达观杯——风险事件标签识别比赛复盘"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/10/01/%E7%AC%AC%E4%BA%94%E5%B1%8A%E8%BE%BE%E8%A7%82%E6%9D%AF%E2%80%94%E2%80%94%E9%A3%8E%E9%99%A9%E4%BA%8B%E4%BB%B6%E6%A0%87%E7%AD%BE%E8%AF%86%E5%88%AB%E6%AF%94%E8%B5%9B%E5%A4%8D%E7%9B%98/" title="第五届达观杯——风险事件标签识别比赛复盘">第五届达观杯——风险事件标签识别比赛复盘</a><div class="article-meta-wrap"><span class="article-meta"><i class="fas fa-thumbtack sticky"></i><span class="sticky">置顶</span><span class="article-meta__separator">|</span></span><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-10-01T07:25:41.000Z" title="发表于 2021-10-01 15:25:41">2021-10-01</time></span></div><div class="content">第五届达观杯Rank4——风险事件标签识别比赛复盘成绩：A榜第5，B榜第4，最终分数分别为：0.62411600、0.58140504
比赛链接：https://www.datafountain.cn/competitions/512
代码：https://github.com/Coding-Zuo/DaguanFengxian
赛题任务这个比赛的全名是叫：基于大规模预训练模型的风险事件标签识别，在技术层面上可以提取为两个任务，一个是预训练一个是文本分类。
针对预训练赛题方给了一个70g的无标注预训练文本，训练集有14009条，测试集6004条（包含AB榜数据）
赛题全部为脱敏数据（所有文字都转换成了数字表达）脱敏前的数据样例为：




资讯文本
风险事件标签




新冠肺炎疫情给美国劳动力市场造成巨大冲击，首次申请失业救济人数已经连续19周超过100万人，约为疫情暴发前平均水平的6倍
宏观_经济数据下滑


石化公司双苯厂发生爆炸事故，造成大量苯类污染物进入江河水体，造成重大环境污染
事故_生产设施


市场监管局执法人员对5家品牌奶茶店进行了检查，发现多家门店存在工作人员健康证 ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2022/02/21/ZeroPrompt-Scaling-Prompt-Based-Pretraining-to-1-000-Tasks-Improves-Zero-Shot-Generalization/" title="ZeroPrompt- Scaling Prompt-Based Pretraining to 1,000 Tasks Improves Zero-Shot Generalization">     <img class="post_bg" src="https://s4.ax1x.com/2022/02/21/HXcFxA.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="ZeroPrompt- Scaling Prompt-Based Pretraining to 1,000 Tasks Improves Zero-Shot Generalization"></a></div><div class="recent-post-info"><a class="article-title" href="/2022/02/21/ZeroPrompt-Scaling-Prompt-Based-Pretraining-to-1-000-Tasks-Improves-Zero-Shot-Generalization/" title="ZeroPrompt- Scaling Prompt-Based Pretraining to 1,000 Tasks Improves Zero-Shot Generalization">ZeroPrompt- Scaling Prompt-Based Pretraining to 1,000 Tasks Improves Zero-Shot Generalization</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2022-02-21T01:56:43.000Z" title="发表于 2022-02-21 09:56:43">2022-02-21</time></span></div><div class="content">ZeroPrompt: Scaling Prompt-Based Pretraining to 1,000 Tasks Improves Zero-Shot Generalization任务数量极大的情况下，模型大小对性能的影响很小…

论文地址: https://arxiv.org/pdf/2201.06910.pdf

XLNet作者杨植麟团队发布了首个中文多任务Prompt统一模型：ZeroPrompt。研究的重点是 【任务的规模】 和 【zero-shot】 的 prompting。
以前的模型只在几十个任务上进行训练，ZeroPrompt 使用真实世界的数据将其扩展到1000个任务（中文数据）。这导致了一个重要的发现，即任务规模可以成为模型尺寸的有效替代方案； 即，模型尺寸对大量任务的性能影响很小。
此外，该文还提出了一种结合了遗传算法来自动搜索 unseen 任务的最佳 prompt。 
Introduction众所周知，prompt 可以激发语言模型的潜力，避免预训练和Fine tuning 之间的gap，并且是一个非常 Parameter-Efficient 的调整方法 ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2022/02/10/Prompt-Guided-Few-Shot-Event-Detection/" title="Prompt-Guided Few-Shot Event Detection">     <img class="post_bg" src="https://i.loli.net/2021/10/28/DjK6qxmT9cA7Ov3.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Prompt-Guided Few-Shot Event Detection"></a></div><div class="recent-post-info"><a class="article-title" href="/2022/02/10/Prompt-Guided-Few-Shot-Event-Detection/" title="Prompt-Guided Few-Shot Event Detection">Prompt-Guided Few-Shot Event Detection</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2022-02-10T01:39:09.000Z" title="发表于 2022-02-10 09:39:09">2022-02-10</time></span></div><div class="content">Prompt-Guided Few-Shot Event Detection</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2022/02/10/MetaPrompting-Learning-to-Learn-Better-Prompts/" title="MetaPrompting: Learning to Learn Better Prompts">     <img class="post_bg" src="https://s4.ax1x.com/2022/01/22/7fJ3lV.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="MetaPrompting: Learning to Learn Better Prompts"></a></div><div class="recent-post-info"><a class="article-title" href="/2022/02/10/MetaPrompting-Learning-to-Learn-Better-Prompts/" title="MetaPrompting: Learning to Learn Better Prompts">MetaPrompting: Learning to Learn Better Prompts</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2022-02-10T01:25:14.000Z" title="发表于 2022-02-10 09:25:14">2022-02-10</time></span></div><div class="content">MetaPrompting: Learning to Learn Better Prompts</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2022/01/08/28%E5%AE%9E%E7%8E%B0strStr-%E2%80%94%E2%80%94KMP/" title="28实现strStr()——KMP">     <img class="post_bg" src="https://s2.loli.net/2022/01/08/wBiRIsTqb97Ygzj.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="28实现strStr()——KMP"></a></div><div class="recent-post-info"><a class="article-title" href="/2022/01/08/28%E5%AE%9E%E7%8E%B0strStr-%E2%80%94%E2%80%94KMP/" title="28实现strStr()——KMP">28实现strStr()——KMP</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2022-01-08T14:20:11.000Z" title="发表于 2022-01-08 22:20:11">2022-01-08</time></span></div><div class="content">28实现strStr()——KMP28. 实现 strStr()朴素解法枚举原串 ss 中的每个字符作为【发起点】，每次从原串中的【发起点】和匹配串的首位，开始尝试匹配：

匹配成功：返回本次匹配的原串【发起点】
匹配失败：枚举原串的下一个【发起点】，重新尝试匹配

12345678910111213141516public int Strstr(String haystack, String needle)&#123;	 int n = haystack.length(), m = needle.length();   for(int i=0;i&lt;n;i++)&#123;     	boolean flag = true;      for(int j=0; j&lt;m ; j++)&#123;         if(haystack.charAt(i+j) != needle.charAt(j))&#123;            flag = false;            break;         &#125;      &#125;      if(flag) ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2022/01/04/Exploring-Low-dimensional-Intrinsic-Task-Subspace-via-Prompt-Tuning/" title="Exploring Low-dimensional Intrinsic Task Subspace via Prompt Tuning">     <img class="post_bg" src="https://i.loli.net/2021/08/29/7pyGPBNQZRmv3Tr.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Exploring Low-dimensional Intrinsic Task Subspace via Prompt Tuning"></a></div><div class="recent-post-info"><a class="article-title" href="/2022/01/04/Exploring-Low-dimensional-Intrinsic-Task-Subspace-via-Prompt-Tuning/" title="Exploring Low-dimensional Intrinsic Task Subspace via Prompt Tuning">Exploring Low-dimensional Intrinsic Task Subspace via Prompt Tuning</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2022-01-04T07:04:20.000Z" title="发表于 2022-01-04 15:04:20">2022-01-04</time></span></div><div class="content">Exploring Low-dimensional Intrinsic Task Subspace via Prompt Tuning预训练的语言模型（PLM）如何学习通用的表征，并有效地适应广泛的NLP任务的差异很大的表面上？
在这项工作中，我们从经验上发现了一些证据，表明PLM对各种任务的适应性可以被重新参数化，即在一个共同的低维内在任务子空间中只优化几个自由参数。这可能有助于我们理解为什么PLMs 可以帮助我们理解为什么PLM可以很容易地适应各种NLP任务的 小规模的数据。
具体来说，为了找到这样一个子空间并考察其普遍性，我们借助最近在prompt tuning方面的成功经验，将多个NLP任务的软提示分解到同一个低维非线性子空间中，然后我们只通过调谐子空间中的参数来学习使PLM适应未见的任务或数据。
我们把这个管道称为 intrinsic prompt tuning（IPT）。在实验中，我们研究了不同的少量NLP任务，并令人惊讶地发现，在用100个随机任务找到的5维子空间中，只需调整5个自由参数，我们就可以对100个看过的任务（使用不同的训练数据）和20个未看过的任务分别恢复87 ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2021/12/27/Unsupervised-Domain-Adaptation-of-a-Pretrained-Cross-Lingual-Language-Model/" title="Unsupervised Domain Adaptation of a Pretrained Cross-Lingual Language Model">     <img class="post_bg" src="https://i.loli.net/2021/11/17/hMK8qF4Jne6sTYC.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Unsupervised Domain Adaptation of a Pretrained Cross-Lingual Language Model"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/12/27/Unsupervised-Domain-Adaptation-of-a-Pretrained-Cross-Lingual-Language-Model/" title="Unsupervised Domain Adaptation of a Pretrained Cross-Lingual Language Model">Unsupervised Domain Adaptation of a Pretrained Cross-Lingual Language Model</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-12-27T11:39:54.000Z" title="发表于 2021-12-27 19:39:54">2021-12-27</time></span></div><div class="content">Unsupervised Domain Adaptation of a Pretrained Cross-Lingual Language Model最近的研究表明，在大规模的无标签文本上预训练跨语言语言模型，可以在各种跨语言和低资源任务中产生明显的性能改进。通过对一百种语言和TB级文本的训练，跨语言模型已被证明能有效地利用高资源语言来提高低资源语言的处理能力，并超过了单语言模型。在本文中，我们进一步研究了当预训练的跨语言模型需要适应新领域时的跨语言和跨领域（CLCD）设置。具体来说，我们提出了一种新的无监督的特征分解方法，该方法可以从纠缠在一起的预训练的跨语言表征中自动提取特定领域的特征和领域不变的特征，给定源语言中未标记的原始文本。我们提出的模型利用相互信息估计，将跨语言模型计算的表征分解为领域变量和领域特定部分。实验结果表明，我们提出的方法比最先进的预训练的跨语言模型在CLCD环境中取得了明显的性能改进。本文的源代码可在https://github.com/lijuntaopku/UFD。
Introduction深度学习的最新进展使各种NLP任务受益，并在大规模注释数据集可用时 ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2021/12/22/Contrastive-Representation-Distillation/" title="Contrastive Representation Distillation">     <img class="post_bg" src="https://s2.loli.net/2021/12/22/aCcIO7GKrPo5DV3.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Contrastive Representation Distillation"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/12/22/Contrastive-Representation-Distillation/" title="Contrastive Representation Distillation">Contrastive Representation Distillation</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-12-22T15:50:39.000Z" title="发表于 2021-12-22 23:50:39">2021-12-22</time></span></div><div class="content">Contrastive Representation Distillation我们经常希望将表征性知识从一个神经网络转移到另一个神经网络。这方面的例子包括将一个大型网络提炼成一个较小的网络，将知识从一种感觉模式转移到另一种感觉模式，或者将一系列模型集合成一个单一的估计器。知识提炼是解决这些问题的标准方法，它使教师和学生网络的概率输出之间的KL散度最小。我们证明这个目标忽略了教师网络的重要结构知识。
这促使我们提出了另一个目标，即训练学生在教师的数据表述中捕捉到更多的信息。我们把这个目标表述为对比学习。
实验证明，我们所产生的新目标在各种知识迁移任务上优于知识蒸馏和其他尖端的蒸馏器，包括单一模型压缩、集合蒸馏和跨modal转移。我们的方法在许多迁移任务中创造了新的最先进的技术，当与知识蒸馏相结合时，有时甚至超过了教师网络。
INTRODUCTION知识蒸馏（KD）将知识从一个深度学习模型（教师）转移到另一个（学生）。最初由Hinton等人（2015）提出的目标是最小化教师和学生输出之间的KL散度。当输出是一个分布时，这种表述具有直观的意义，例如，在类上的概率质量函数。然而，我们经常希望迁 ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2021/12/22/Achieving-Forgetting-Prevention-and-Knowledge-Transfer-in-Continual-Learning/" title="Achieving Forgetting Prevention and Knowledge Transfer in Continual Learning">     <img class="post_bg" src="https://s2.loli.net/2021/12/22/OG4tHAZ7uEoJTfh.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Achieving Forgetting Prevention and Knowledge Transfer in Continual Learning"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/12/22/Achieving-Forgetting-Prevention-and-Knowledge-Transfer-in-Continual-Learning/" title="Achieving Forgetting Prevention and Knowledge Transfer in Continual Learning">Achieving Forgetting Prevention and Knowledge Transfer in Continual Learning</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-12-22T06:09:05.000Z" title="发表于 2021-12-22 14:09:05">2021-12-22</time></span></div><div class="content">Achieving Forgetting Prevention and Knowledge Transfer in Continual LearningAbstract持续学习（CL）是指逐步学习一连串的任务，目的是实现两个主要目标：克服灾难性遗忘（CF）和鼓励跨任务的知识转移（KT）。然而，大多数现有的技术只注重克服CF，没有鼓励KT的机制，因此在KT中表现不佳。尽管有几篇论文试图同时处理CF和KT，但我们的实验表明，当任务没有太多的共享知识时，它们受到严重的CF影响。
另一个观察结果是，目前大多数CL方法没有使用预训练的模型，但事实证明，这种模型可以大大改善最终的任务表现。例如，在自然语言处理中，对类似BERT的预训练语言模型进行微调是最有效的方法之一。
 然而，对于CL来说，这种方法受到了严重的CF的影响。一个有趣的问题是如何将预训练的模型最好地用于CL。本文提出了一个名为CTR的新模型来解决这些问题。我们的实验结果证明了CTR的有效性。
Introduction本文研究了在任务持续学习（Task-CL）环境下的自然语言处理（NLP）任务序列的持续学习（CL）。它的目的是 

( ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2021/12/21/On-Transferability-of-Prompt-Tuning-for-Natural-Language-Understanding/" title="On Transferability of Prompt Tuning for Natural Language Understanding">     <img class="post_bg" src="https://i.loli.net/2021/12/02/MVzbTiL5glWvtj4.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="On Transferability of Prompt Tuning for Natural Language Understanding"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/12/21/On-Transferability-of-Prompt-Tuning-for-Natural-Language-Understanding/" title="On Transferability of Prompt Tuning for Natural Language Understanding">On Transferability of Prompt Tuning for Natural Language Understanding</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-12-21T07:44:25.000Z" title="发表于 2021-12-21 15:44:25">2021-12-21</time></span></div><div class="content">On Transferability of Prompt Tuning for Natural Language UnderstandingPrompt tuning（PT）是一种很有前途的参数高效方法，可以利用极其庞大的预训练语言模型（PLM），只需 tuning 几个软提示，就可以达到与全参数微调相当的性能。
然而，与微调相比，经验上PT需要更多的训练步骤。为了探索是否可以通过重复使用训练好的 soft prompts 和分享学到的知识来提高 PT 的效率，我们从经验上研究了 soft prompts 在不同任务和模型中的可迁移性。

在跨任务迁移中，发现经过训练的  soft prompts  可以很好地迁移到类似的任务中，并为它们初始化PT，以加速训练和提高性能。此外，为了探索哪些因素会影响 prompts 的跨任务转移性，我们研究了如何测量 prompt 的相似性，发现激活的神经元的重叠率与迁移性高度相关。
在跨模型迁移中，我们探索了如何将一个PLM的 prompt 投射到另一个PLM上，并成功地训练了一种 projector，该projector 可以在类似的任务上实现非微 ...</div></div></div><nav id="pagination"><div class="pagination"><span class="page-number current">1</span><a class="page-number" href="/page/2/#content-inner">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/14/#content-inner">14</a><a class="extend next" rel="next" href="/page/2/#content-inner"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-info-avatar is-center"><img class="avatar-img" src="https://i.loli.net/2021/03/22/YP2oqk7lOAfceTD.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">Coding-Zuo</div><div class="author-info__description">我的建议是看开点、、、</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">134</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">16</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/Coding-Zuo"><i class="fab fa-github"></i><span>Let's Github</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/Coding-Zuo" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="/zzuuoo666@sina.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">用力去思考🤔</div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/02/21/ZeroPrompt-Scaling-Prompt-Based-Pretraining-to-1-000-Tasks-Improves-Zero-Shot-Generalization/" title="ZeroPrompt- Scaling Prompt-Based Pretraining to 1,000 Tasks Improves Zero-Shot Generalization"><img src="https://s4.ax1x.com/2022/02/21/HXcFxA.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="ZeroPrompt- Scaling Prompt-Based Pretraining to 1,000 Tasks Improves Zero-Shot Generalization"/></a><div class="content"><a class="title" href="/2022/02/21/ZeroPrompt-Scaling-Prompt-Based-Pretraining-to-1-000-Tasks-Improves-Zero-Shot-Generalization/" title="ZeroPrompt- Scaling Prompt-Based Pretraining to 1,000 Tasks Improves Zero-Shot Generalization">ZeroPrompt- Scaling Prompt-Based Pretraining to 1,000 Tasks Improves Zero-Shot Generalization</a><time datetime="2022-02-21T01:56:43.000Z" title="发表于 2022-02-21 09:56:43">2022-02-21</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/02/10/Prompt-Guided-Few-Shot-Event-Detection/" title="Prompt-Guided Few-Shot Event Detection"><img src="https://i.loli.net/2021/10/28/DjK6qxmT9cA7Ov3.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Prompt-Guided Few-Shot Event Detection"/></a><div class="content"><a class="title" href="/2022/02/10/Prompt-Guided-Few-Shot-Event-Detection/" title="Prompt-Guided Few-Shot Event Detection">Prompt-Guided Few-Shot Event Detection</a><time datetime="2022-02-10T01:39:09.000Z" title="发表于 2022-02-10 09:39:09">2022-02-10</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/02/10/MetaPrompting-Learning-to-Learn-Better-Prompts/" title="MetaPrompting: Learning to Learn Better Prompts"><img src="https://s4.ax1x.com/2022/01/22/7fJ3lV.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="MetaPrompting: Learning to Learn Better Prompts"/></a><div class="content"><a class="title" href="/2022/02/10/MetaPrompting-Learning-to-Learn-Better-Prompts/" title="MetaPrompting: Learning to Learn Better Prompts">MetaPrompting: Learning to Learn Better Prompts</a><time datetime="2022-02-10T01:25:14.000Z" title="发表于 2022-02-10 09:25:14">2022-02-10</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/01/08/28%E5%AE%9E%E7%8E%B0strStr-%E2%80%94%E2%80%94KMP/" title="28实现strStr()——KMP"><img src="https://s2.loli.net/2022/01/08/wBiRIsTqb97Ygzj.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="28实现strStr()——KMP"/></a><div class="content"><a class="title" href="/2022/01/08/28%E5%AE%9E%E7%8E%B0strStr-%E2%80%94%E2%80%94KMP/" title="28实现strStr()——KMP">28实现strStr()——KMP</a><time datetime="2022-01-08T14:20:11.000Z" title="发表于 2022-01-08 22:20:11">2022-01-08</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/01/04/Exploring-Low-dimensional-Intrinsic-Task-Subspace-via-Prompt-Tuning/" title="Exploring Low-dimensional Intrinsic Task Subspace via Prompt Tuning"><img src="https://i.loli.net/2021/08/29/7pyGPBNQZRmv3Tr.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Exploring Low-dimensional Intrinsic Task Subspace via Prompt Tuning"/></a><div class="content"><a class="title" href="/2022/01/04/Exploring-Low-dimensional-Intrinsic-Task-Subspace-via-Prompt-Tuning/" title="Exploring Low-dimensional Intrinsic Task Subspace via Prompt Tuning">Exploring Low-dimensional Intrinsic Task Subspace via Prompt Tuning</a><time datetime="2022-01-04T07:04:20.000Z" title="发表于 2022-01-04 15:04:20">2022-01-04</time></div></div></div></div><div class="card-widget card-tags"><div class="item-headline"><i class="fas fa-tags"></i><span>标签</span></div><div class="card-tag-cloud"><a href="/tags/Convex-optimization/" style="font-size: 1.1em; color: #999">Convex optimization</a> <a href="/tags/DP/" style="font-size: 1.26em; color: #999fa8">DP</a> <a href="/tags/DataGame/" style="font-size: 1.26em; color: #999fa8">DataGame</a> <a href="/tags/Docker/" style="font-size: 1.22em; color: #999ea4">Docker</a> <a href="/tags/GNN/" style="font-size: 1.34em; color: #99a3b0">GNN</a> <a href="/tags/GNN-cv/" style="font-size: 1.14em; color: #999b9d">GNN&cv</a> <a href="/tags/GNN-nlp/" style="font-size: 1.46em; color: #99a7bb">GNN&nlp</a> <a href="/tags/LeetCode/" style="font-size: 1.42em; color: #99a6b7">LeetCode</a> <a href="/tags/ML-DL/" style="font-size: 1.22em; color: #999ea4">ML&DL</a> <a href="/tags/NLP/" style="font-size: 1.1em; color: #999">NLP</a> <a href="/tags/context-detection/" style="font-size: 1.5em; color: #99a9bf">context detection</a> <a href="/tags/nlp/" style="font-size: 1.38em; color: #99a4b4">nlp</a> <a href="/tags/pytorch/" style="font-size: 1.1em; color: #999">pytorch</a> <a href="/tags/%E5%88%B7%E9%A2%98/" style="font-size: 1.3em; color: #99a1ac">刷题</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" style="font-size: 1.14em; color: #999b9d">数据结构</a> <a href="/tags/%E9%85%8D%E7%BD%AE%E8%AE%B0%E5%BD%95/" style="font-size: 1.18em; color: #999ca1">配置记录</a></div></div><div class="card-widget card-archives"><div class="item-headline"><i class="fas fa-archive"></i><span>归档</span><a class="card-more-btn" href="/archives/" title="查看更多">
    <i class="fas fa-angle-right"></i></a></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2022/02/"><span class="card-archive-list-date">二月 2022</span><span class="card-archive-list-count">3</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2022/01/"><span class="card-archive-list-date">一月 2022</span><span class="card-archive-list-count">2</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/12/"><span class="card-archive-list-date">十二月 2021</span><span class="card-archive-list-count">8</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/11/"><span class="card-archive-list-date">十一月 2021</span><span class="card-archive-list-count">12</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/10/"><span class="card-archive-list-date">十月 2021</span><span class="card-archive-list-count">13</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/09/"><span class="card-archive-list-date">九月 2021</span><span class="card-archive-list-count">20</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/08/"><span class="card-archive-list-date">八月 2021</span><span class="card-archive-list-count">10</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/07/"><span class="card-archive-list-date">七月 2021</span><span class="card-archive-list-count">7</span></a></li></ul></div><div class="card-widget card-map"><div class="card-content"><div class="item-headline"><i class="fa fa-globe-asia" aria-hidden="true"></i><span>aside.card_map</span></div><script id="clstr_globe" type="text/javascript" defer="defer" src="//clustrmaps.com/globe.js?d=dw5ySwxQc209v5eDdMmMLhW4-aHUt-vE_XaC-6nRPAA"></script></div></div><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>网站资讯</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">文章数目 :</div><div class="item-count">134</div></div><div class="webinfo-item"><div class="item-name">本站访客数 :</div><div class="item-count" id="busuanzi_value_site_uv"></div></div><div class="webinfo-item"><div class="item-name">本站总访问量 :</div><div class="item-count" id="busuanzi_value_site_pv"></div></div><div class="webinfo-item"><div class="item-name">最后更新时间 :</div><div class="item-count" id="last-push-date" data-lastPushDate="2022-02-21T02:01:52.993Z"></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2022 By Coding-Zuo</div><div class="footer_custom_text">Hi, welcome to my BLOG</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="font-plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>function subtitleType () {
  if (true) { 
    var typed = new Typed("#subtitle", {
      strings: "今日事&#44;今日畢,Never put off till tomorrow what you can do today".split(","),
      startDelay: 300,
      typeSpeed: 150,
      loop: true,
      backSpeed: 50
    })
  } else {
    document.getElementById("subtitle").innerHTML = '今日事&#44;今日畢'
  }
}

if (true) {
  if (typeof Typed === 'function') {
    subtitleType()
  } else {
    getScript('https://cdn.jsdelivr.net/npm/typed.js/lib/typed.min.js').then(subtitleType)
  }
} else {
  subtitleType()
}</script><script>if (document.getElementsByClassName('mermaid').length) {
  if (window.mermaidJsLoad) mermaid.init()
  else {
    getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(() => {
      window.mermaidJsLoad = true
      mermaid.initialize({
        theme: 'default',
      })
      false && mermaid.init()
    })
  }
}</script></div><script src="/js/custom.js"></script><script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script><script defer="defer" id="fluttering_ribbon" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-fluttering-ribbon.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script src="//code.tidio.co/mak6nokafytw9mgrsuzglwzfxiy3fpdl.js" async="async"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>