<!DOCTYPE html><html lang="zh-CN" data-theme="dark"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Coding-Zuo - Coding And Studying</title><meta name="keywords" content="NLP zuoyuhui"><meta name="author" content="Coding-Zuo"><meta name="copyright" content="Coding-Zuo"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#0d0d0d"><meta name="description" content="我的建议是看开点、、、">
<meta property="og:type" content="website">
<meta property="og:title" content="Coding-Zuo">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="Coding-Zuo">
<meta property="og:description" content="我的建议是看开点、、、">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://i.loli.net/2021/03/22/YP2oqk7lOAfceTD.jpg">
<meta property="article:author" content="Coding-Zuo">
<meta property="article:tag" content="NLP zuoyuhui">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.loli.net/2021/03/22/YP2oqk7lOAfceTD.jpg"><link rel="shortcut icon" href="https://i.loli.net/2021/03/22/reFlcYOnP3dSuJX.png"><link rel="canonical" href="http://example.com/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.json","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = { 
  isPost: false,
  isHome: true,
  isHighlightShrink: false,
  isToc: false,
  postUpdate: '2022-01-21 19:01:27'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
          const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
          const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
          const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

          if (t === undefined) {
            if (isLightMode) activateLightMode()
            else if (isDarkMode) activateDarkMode()
            else if (isNotSpecified || hasNoSupport) {
              const now = new Date()
              const hour = now.getHours()
              const isNight = hour <= 6 || hour >= 18
              isNight ? activateDarkMode() : activateLightMode()
            }
            window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
              if (saveToLocal.get('theme') === undefined) {
                e.matches ? activateDarkMode() : activateLightMode()
              }
            })
          } else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const fontSizeVal = saveToLocal.get('global-font-size')
    if (fontSizeVal !== undefined) {
      document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
    }
    })(window)</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/sviptzk/HexoStaticFile@latest/Hexo/css/footer.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css"><meta name="generator" content="Hexo 5.3.0"><link rel="alternate" href="/atom.xml" title="Coding-Zuo" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="https://i.loli.net/2021/03/22/YP2oqk7lOAfceTD.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">131</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">16</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https:www.baidu.com"><i class="fa-fw fas fa-heart"></i><span> 我的简历</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 清单</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/%E9%9F%B3%E4%B9%90"><i class="fa-fw /music/"></i><span> 0</span></a></li><li><a class="site-page child" href="/%E7%94%B5%E5%BD%B1"><i class="fa-fw /movies/"></i><span> 1</span></a></li><li><a class="site-page child" href="/%E7%85%A7%E7%89%87"><i class="fa-fw /Gallery/"></i><span> 2</span></a></li></ul></div></div></div></div><div class="page" id="body-wrap"><header class="full_page" id="page-header" style="background-image: url('https://i.loli.net/2021/03/22/Td23imqYWsLGcJA.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Coding-Zuo</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https:www.baidu.com"><i class="fa-fw fas fa-heart"></i><span> 我的简历</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 清单</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/%E9%9F%B3%E4%B9%90"><i class="fa-fw /music/"></i><span> 0</span></a></li><li><a class="site-page child" href="/%E7%94%B5%E5%BD%B1"><i class="fa-fw /movies/"></i><span> 1</span></a></li><li><a class="site-page child" href="/%E7%85%A7%E7%89%87"><i class="fa-fw /Gallery/"></i><span> 2</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="site-info"><h1 id="site-title">Coding-Zuo</h1><div id="site-subtitle"><span id="subtitle"></span></div><div id="site_social_icons"><a class="social-icon" href="https://github.com/Coding-Zuo" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="/zzuuoo666@sina.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div id="scroll-down"><i class="fas fa-angle-down scroll-down-effects"></i></div></header><main class="layout" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2021/10/01/%E7%AC%AC%E4%BA%94%E5%B1%8A%E8%BE%BE%E8%A7%82%E6%9D%AF%E2%80%94%E2%80%94%E9%A3%8E%E9%99%A9%E4%BA%8B%E4%BB%B6%E6%A0%87%E7%AD%BE%E8%AF%86%E5%88%AB%E6%AF%94%E8%B5%9B%E5%A4%8D%E7%9B%98/" title="第五届达观杯——风险事件标签识别比赛复盘">     <img class="post_bg" src="https://z3.ax1x.com/2021/10/01/47nQm9.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="第五届达观杯——风险事件标签识别比赛复盘"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/10/01/%E7%AC%AC%E4%BA%94%E5%B1%8A%E8%BE%BE%E8%A7%82%E6%9D%AF%E2%80%94%E2%80%94%E9%A3%8E%E9%99%A9%E4%BA%8B%E4%BB%B6%E6%A0%87%E7%AD%BE%E8%AF%86%E5%88%AB%E6%AF%94%E8%B5%9B%E5%A4%8D%E7%9B%98/" title="第五届达观杯——风险事件标签识别比赛复盘">第五届达观杯——风险事件标签识别比赛复盘</a><div class="article-meta-wrap"><span class="article-meta"><i class="fas fa-thumbtack sticky"></i><span class="sticky">置顶</span><span class="article-meta__separator">|</span></span><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-10-01T07:25:41.000Z" title="发表于 2021-10-01 15:25:41">2021-10-01</time></span></div><div class="content">第五届达观杯Rank4——风险事件标签识别比赛复盘成绩：A榜第5，B榜第4，最终分数分别为：0.62411600、0.58140504
比赛链接：https://www.datafountain.cn/competitions/512
代码：https://github.com/Coding-Zuo/DaguanFengxian
赛题任务这个比赛的全名是叫：基于大规模预训练模型的风险事件标签识别，在技术层面上可以提取为两个任务，一个是预训练一个是文本分类。
针对预训练赛题方给了一个70g的无标注预训练文本，训练集有14009条，测试集6004条（包含AB榜数据）
赛题全部为脱敏数据（所有文字都转换成了数字表达）脱敏前的数据样例为：




资讯文本
风险事件标签




新冠肺炎疫情给美国劳动力市场造成巨大冲击，首次申请失业救济人数已经连续19周超过100万人，约为疫情暴发前平均水平的6倍
宏观_经济数据下滑


石化公司双苯厂发生爆炸事故，造成大量苯类污染物进入江河水体，造成重大环境污染
事故_生产设施


市场监管局执法人员对5家品牌奶茶店进行了检查，发现多家门店存在工作人员健康证 ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2022/01/08/28%E5%AE%9E%E7%8E%B0strStr-%E2%80%94%E2%80%94KMP/" title="28实现strStr()——KMP">     <img class="post_bg" src="https://s2.loli.net/2022/01/08/wBiRIsTqb97Ygzj.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="28实现strStr()——KMP"></a></div><div class="recent-post-info"><a class="article-title" href="/2022/01/08/28%E5%AE%9E%E7%8E%B0strStr-%E2%80%94%E2%80%94KMP/" title="28实现strStr()——KMP">28实现strStr()——KMP</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2022-01-08T14:20:11.000Z" title="发表于 2022-01-08 22:20:11">2022-01-08</time></span></div><div class="content">28实现strStr()——KMP28. 实现 strStr()朴素解法枚举原串 ss 中的每个字符作为【发起点】，每次从原串中的【发起点】和匹配串的首位，开始尝试匹配：

匹配成功：返回本次匹配的原串【发起点】
匹配失败：枚举原串的下一个【发起点】，重新尝试匹配

12345678910111213141516public int Strstr(String haystack, String needle)&#123;	 int n = haystack.length(), m = needle.length();   for(int i=0;i&lt;n;i++)&#123;     	boolean flag = true;      for(int j=0; j&lt;m ; j++)&#123;         if(haystack.charAt(i+j) != needle.charAt(j))&#123;            flag = false;            break;         &#125;      &#125;      if(flag) ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2022/01/04/Exploring-Low-dimensional-Intrinsic-Task-Subspace-via-Prompt-Tuning/" title="Exploring Low-dimensional Intrinsic Task Subspace via Prompt Tuning">     <img class="post_bg" src="https://i.loli.net/2021/08/29/7pyGPBNQZRmv3Tr.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Exploring Low-dimensional Intrinsic Task Subspace via Prompt Tuning"></a></div><div class="recent-post-info"><a class="article-title" href="/2022/01/04/Exploring-Low-dimensional-Intrinsic-Task-Subspace-via-Prompt-Tuning/" title="Exploring Low-dimensional Intrinsic Task Subspace via Prompt Tuning">Exploring Low-dimensional Intrinsic Task Subspace via Prompt Tuning</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2022-01-04T07:04:20.000Z" title="发表于 2022-01-04 15:04:20">2022-01-04</time></span></div><div class="content">Exploring Low-dimensional Intrinsic Task Subspace via Prompt Tuning预训练的语言模型（PLM）如何学习通用的表征，并有效地适应广泛的NLP任务的差异很大的表面上？
在这项工作中，我们从经验上发现了一些证据，表明PLM对各种任务的适应性可以被重新参数化，即在一个共同的低维内在任务子空间中只优化几个自由参数。这可能有助于我们理解为什么PLMs 可以帮助我们理解为什么PLM可以很容易地适应各种NLP任务的 小规模的数据。
具体来说，为了找到这样一个子空间并考察其普遍性，我们借助最近在prompt tuning方面的成功经验，将多个NLP任务的软提示分解到同一个低维非线性子空间中，然后我们只通过调谐子空间中的参数来学习使PLM适应未见的任务或数据。
我们把这个管道称为 intrinsic prompt tuning（IPT）。在实验中，我们研究了不同的少量NLP任务，并令人惊讶地发现，在用100个随机任务找到的5维子空间中，只需调整5个自由参数，我们就可以对100个看过的任务（使用不同的训练数据）和20个未看过的任务分别恢复87 ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2021/12/27/Unsupervised-Domain-Adaptation-of-a-Pretrained-Cross-Lingual-Language-Model/" title="Unsupervised Domain Adaptation of a Pretrained Cross-Lingual Language Model">     <img class="post_bg" src="https://i.loli.net/2021/11/17/hMK8qF4Jne6sTYC.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Unsupervised Domain Adaptation of a Pretrained Cross-Lingual Language Model"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/12/27/Unsupervised-Domain-Adaptation-of-a-Pretrained-Cross-Lingual-Language-Model/" title="Unsupervised Domain Adaptation of a Pretrained Cross-Lingual Language Model">Unsupervised Domain Adaptation of a Pretrained Cross-Lingual Language Model</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-12-27T11:39:54.000Z" title="发表于 2021-12-27 19:39:54">2021-12-27</time></span></div><div class="content">Unsupervised Domain Adaptation of a Pretrained Cross-Lingual Language Model最近的研究表明，在大规模的无标签文本上预训练跨语言语言模型，可以在各种跨语言和低资源任务中产生明显的性能改进。通过对一百种语言和TB级文本的训练，跨语言模型已被证明能有效地利用高资源语言来提高低资源语言的处理能力，并超过了单语言模型。在本文中，我们进一步研究了当预训练的跨语言模型需要适应新领域时的跨语言和跨领域（CLCD）设置。具体来说，我们提出了一种新的无监督的特征分解方法，该方法可以从纠缠在一起的预训练的跨语言表征中自动提取特定领域的特征和领域不变的特征，给定源语言中未标记的原始文本。我们提出的模型利用相互信息估计，将跨语言模型计算的表征分解为领域变量和领域特定部分。实验结果表明，我们提出的方法比最先进的预训练的跨语言模型在CLCD环境中取得了明显的性能改进。本文的源代码可在https://github.com/lijuntaopku/UFD。
Introduction深度学习的最新进展使各种NLP任务受益，并在大规模注释数据集可用时 ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2021/12/22/Contrastive-Representation-Distillation/" title="Contrastive Representation Distillation">     <img class="post_bg" src="https://s2.loli.net/2021/12/22/aCcIO7GKrPo5DV3.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Contrastive Representation Distillation"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/12/22/Contrastive-Representation-Distillation/" title="Contrastive Representation Distillation">Contrastive Representation Distillation</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-12-22T15:50:39.000Z" title="发表于 2021-12-22 23:50:39">2021-12-22</time></span></div><div class="content">Contrastive Representation Distillation我们经常希望将表征性知识从一个神经网络转移到另一个神经网络。这方面的例子包括将一个大型网络提炼成一个较小的网络，将知识从一种感觉模式转移到另一种感觉模式，或者将一系列模型集合成一个单一的估计器。知识提炼是解决这些问题的标准方法，它使教师和学生网络的概率输出之间的KL散度最小。我们证明这个目标忽略了教师网络的重要结构知识。
这促使我们提出了另一个目标，即训练学生在教师的数据表述中捕捉到更多的信息。我们把这个目标表述为对比学习。
实验证明，我们所产生的新目标在各种知识迁移任务上优于知识蒸馏和其他尖端的蒸馏器，包括单一模型压缩、集合蒸馏和跨modal转移。我们的方法在许多迁移任务中创造了新的最先进的技术，当与知识蒸馏相结合时，有时甚至超过了教师网络。
INTRODUCTION知识蒸馏（KD）将知识从一个深度学习模型（教师）转移到另一个（学生）。最初由Hinton等人（2015）提出的目标是最小化教师和学生输出之间的KL散度。当输出是一个分布时，这种表述具有直观的意义，例如，在类上的概率质量函数。然而，我们经常希望迁 ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2021/12/22/Achieving-Forgetting-Prevention-and-Knowledge-Transfer-in-Continual-Learning/" title="Achieving Forgetting Prevention and Knowledge Transfer in Continual Learning">     <img class="post_bg" src="https://s2.loli.net/2021/12/22/OG4tHAZ7uEoJTfh.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Achieving Forgetting Prevention and Knowledge Transfer in Continual Learning"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/12/22/Achieving-Forgetting-Prevention-and-Knowledge-Transfer-in-Continual-Learning/" title="Achieving Forgetting Prevention and Knowledge Transfer in Continual Learning">Achieving Forgetting Prevention and Knowledge Transfer in Continual Learning</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-12-22T06:09:05.000Z" title="发表于 2021-12-22 14:09:05">2021-12-22</time></span></div><div class="content">Achieving Forgetting Prevention and Knowledge Transfer in Continual LearningAbstract持续学习（CL）是指逐步学习一连串的任务，目的是实现两个主要目标：克服灾难性遗忘（CF）和鼓励跨任务的知识转移（KT）。然而，大多数现有的技术只注重克服CF，没有鼓励KT的机制，因此在KT中表现不佳。尽管有几篇论文试图同时处理CF和KT，但我们的实验表明，当任务没有太多的共享知识时，它们受到严重的CF影响。
另一个观察结果是，目前大多数CL方法没有使用预训练的模型，但事实证明，这种模型可以大大改善最终的任务表现。例如，在自然语言处理中，对类似BERT的预训练语言模型进行微调是最有效的方法之一。
 然而，对于CL来说，这种方法受到了严重的CF的影响。一个有趣的问题是如何将预训练的模型最好地用于CL。本文提出了一个名为CTR的新模型来解决这些问题。我们的实验结果证明了CTR的有效性。
Introduction本文研究了在任务持续学习（Task-CL）环境下的自然语言处理（NLP）任务序列的持续学习（CL）。它的目的是 

( ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2021/12/21/On-Transferability-of-Prompt-Tuning-for-Natural-Language-Understanding/" title="On Transferability of Prompt Tuning for Natural Language Understanding">     <img class="post_bg" src="https://i.loli.net/2021/12/02/MVzbTiL5glWvtj4.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="On Transferability of Prompt Tuning for Natural Language Understanding"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/12/21/On-Transferability-of-Prompt-Tuning-for-Natural-Language-Understanding/" title="On Transferability of Prompt Tuning for Natural Language Understanding">On Transferability of Prompt Tuning for Natural Language Understanding</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-12-21T07:44:25.000Z" title="发表于 2021-12-21 15:44:25">2021-12-21</time></span></div><div class="content">On Transferability of Prompt Tuning for Natural Language UnderstandingPrompt tuning（PT）是一种很有前途的参数高效方法，可以利用极其庞大的预训练语言模型（PLM），只需 tuning 几个软提示，就可以达到与全参数微调相当的性能。
然而，与微调相比，经验上PT需要更多的训练步骤。为了探索是否可以通过重复使用训练好的 soft prompts 和分享学到的知识来提高 PT 的效率，我们从经验上研究了 soft prompts 在不同任务和模型中的可迁移性。

在跨任务迁移中，发现经过训练的  soft prompts  可以很好地迁移到类似的任务中，并为它们初始化PT，以加速训练和提高性能。此外，为了探索哪些因素会影响 prompts 的跨任务转移性，我们研究了如何测量 prompt 的相似性，发现激活的神经元的重叠率与迁移性高度相关。
在跨模型迁移中，我们探索了如何将一个PLM的 prompt 投射到另一个PLM上，并成功地训练了一种 projector，该projector 可以在类似的任务上实现非微 ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2021/12/19/TransPrompt-Towards-an-Automatic-Transferable-Prompting-Framework-for-Few-shot-Text-Classification/" title="TransPrompt Towards an Automatic Transferable Prompting Framework for Few-shot Text Classification">     <img class="post_bg" src="https://s2.loli.net/2021/12/19/hTNkCw9jpLiZRWV.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="TransPrompt Towards an Automatic Transferable Prompting Framework for Few-shot Text Classification"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/12/19/TransPrompt-Towards-an-Automatic-Transferable-Prompting-Framework-for-Few-shot-Text-Classification/" title="TransPrompt Towards an Automatic Transferable Prompting Framework for Few-shot Text Classification">TransPrompt Towards an Automatic Transferable Prompting Framework for Few-shot Text Classification</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-12-19T13:59:11.000Z" title="发表于 2021-12-19 21:59:11">2021-12-19</time></span></div><div class="content">TransPrompt: Towards an Automatic Transferable Prompting Framework for Few-shot Text ClassificationAbstract最近的研究表明，prompts 可以提高大型预训练语言模型在 few-shot 文本分类中的表现。然而，目前还不清楚如何在类似的NLP任务中迁移 prompts 知识以达到相互强化的目的。基于连续的 prompts 嵌入，我们提出了TransPrompt，一个可迁移的 prompt 框架，用于在类似的任务中进行 few-shot 的学习。
 在TransPrompt中，我们采用了一个多任务元知识获取程序来训练一个元学习者，以捕获跨任务的可迁移知识。我们进一步设计了两种去偏技术，使其对任何任务都更具有任务无关性和无偏性。
之后，元学习器可以以高精确度适应目标任务。大量的实验表明，TransPrompt在多个NLP任务和数据集上的表现优于单任务和跨任务的强基线。我们进一步表明，元学习器可以有效地提高以前未见过的任务的性能。当用完整的训练集学习时，TransPrompt也优于强大的 ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2021/12/07/Iterative-Network-Pruning-with-Uncertainty-Regularization-for-Lifelong-Sentiment-Classification/" title="Iterative Network Pruning with Uncertainty Regularization for Lifelong Sentiment Classification">     <img class="post_bg" src="https://s2.loli.net/2021/12/07/YiNu7IOeRfMjyUX.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Iterative Network Pruning with Uncertainty Regularization for Lifelong Sentiment Classification"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/12/07/Iterative-Network-Pruning-with-Uncertainty-Regularization-for-Lifelong-Sentiment-Classification/" title="Iterative Network Pruning with Uncertainty Regularization for Lifelong Sentiment Classification">Iterative Network Pruning with Uncertainty Regularization for Lifelong Sentiment Classification</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-12-07T13:20:14.000Z" title="发表于 2021-12-07 21:20:14">2021-12-07</time></span></div><div class="content">Iterative Network Pruning with Uncertainty Regularization for Lifelong Sentiment Classification提出了一种新的具有不确定性正则化的迭代网络修剪方法，用于终身情感分类（IPRLS），它利用了网络修剪和权重正则化的原则。通过以迭代的方式进行网络修剪和不确定性正则化，IPRLS可以使一个单一的BERT模型适应来自多个领域的连续到达的数据，同时避免灾难性的遗忘和相互影响。
具体来说，利用迭代修剪方法来去除大型深度网络中的冗余参数，这样释放出来的空间就可以用来学习新的任务，解决灾难性遗忘的问题。
在学习新任务时，我们也使用基于贝叶斯在线学习框架的不确定性正则化来约束BERT中旧任务权重的更新，这使得正向转移成为可能，即学习新任务可以提高过去任务的表现，同时保护旧知识不被丢失。
此外，我们提出了一个与BERT各层并行的特定任务的低维残差函数，这使得IPRLS在学习新任务时不容易丢失保存在基础BERT网络中的知识。
INTRODUCTION随着网络上大量富含观点的文档的增加，人们对情感分类给予了极大的关注， ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2021/12/03/Continual-Learning-with-Hypernetworks/" title="Continual Learning with Hypernetworks">     <img class="post_bg" src="https://i.loli.net/2021/12/03/HXDsvWIFemhG37V.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Continual Learning with Hypernetworks"></a></div><div class="recent-post-info"><a class="article-title" href="/2021/12/03/Continual-Learning-with-Hypernetworks/" title="Continual Learning with Hypernetworks">Continual Learning with Hypernetworks</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2021-12-03T12:18:00.000Z" title="发表于 2021-12-03 20:18:00">2021-12-03</time></span></div><div class="content">Continual Learning with Hypernetworks当人工神经网络在多个任务上进行顺序训练时，它们会遭受灾难性的遗忘。 为了克服这个问题，我们提出了一种基于任务条件超网络的新方法，即基于任务身份生成目标模型权重的网络。
由于一个简单的关键特征，此类模型的持续学习 (CL) 难度较小：任务条件超网络不需要回忆所有先前看到的数据的输入-输出关系，只需要排练特定于任务的权重实现，这可以 使用简单的正则化器在内存中维护。
除了在标准的CL基准上取得最先进的性能外，对长任务序列的额外实验显示，任务条件下的超网络显示出非常大的能力来保留以前的记忆。
值得注意的是，当可训练的超网络权重数量与目标网络大小相当或小于目标网络大小时，如此长的记忆寿命是在一个压缩制度下实现的。我们对低维任务嵌入空间（超网络的输入空间）的结构进行了深入研究，并表明任务条件下的超网络展示了迁移学习。最后，基于CIFAR-10/100图像数据集的挑战性CL基准的经验结果进一步支持了前向信息迁移。
INTRODUCTION我们假设一个具有可训练权重 $Θ$ 的神经网络 $f(x,Θ)$ 被赋予来自一组任务的数 ...</div></div></div><nav id="pagination"><div class="pagination"><span class="page-number current">1</span><a class="page-number" href="/page/2/#content-inner">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/14/#content-inner">14</a><a class="extend next" rel="next" href="/page/2/#content-inner"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-info-avatar is-center"><img class="avatar-img" src="https://i.loli.net/2021/03/22/YP2oqk7lOAfceTD.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">Coding-Zuo</div><div class="author-info__description">我的建议是看开点、、、</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">131</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">16</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/Coding-Zuo"><i class="fab fa-github"></i><span>Let's Github</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/Coding-Zuo" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="/zzuuoo666@sina.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">用力去思考🤔</div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/01/08/28%E5%AE%9E%E7%8E%B0strStr-%E2%80%94%E2%80%94KMP/" title="28实现strStr()——KMP"><img src="https://s2.loli.net/2022/01/08/wBiRIsTqb97Ygzj.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="28实现strStr()——KMP"/></a><div class="content"><a class="title" href="/2022/01/08/28%E5%AE%9E%E7%8E%B0strStr-%E2%80%94%E2%80%94KMP/" title="28实现strStr()——KMP">28实现strStr()——KMP</a><time datetime="2022-01-08T14:20:11.000Z" title="发表于 2022-01-08 22:20:11">2022-01-08</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/01/04/Exploring-Low-dimensional-Intrinsic-Task-Subspace-via-Prompt-Tuning/" title="Exploring Low-dimensional Intrinsic Task Subspace via Prompt Tuning"><img src="https://i.loli.net/2021/08/29/7pyGPBNQZRmv3Tr.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Exploring Low-dimensional Intrinsic Task Subspace via Prompt Tuning"/></a><div class="content"><a class="title" href="/2022/01/04/Exploring-Low-dimensional-Intrinsic-Task-Subspace-via-Prompt-Tuning/" title="Exploring Low-dimensional Intrinsic Task Subspace via Prompt Tuning">Exploring Low-dimensional Intrinsic Task Subspace via Prompt Tuning</a><time datetime="2022-01-04T07:04:20.000Z" title="发表于 2022-01-04 15:04:20">2022-01-04</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/12/27/Unsupervised-Domain-Adaptation-of-a-Pretrained-Cross-Lingual-Language-Model/" title="Unsupervised Domain Adaptation of a Pretrained Cross-Lingual Language Model"><img src="https://i.loli.net/2021/11/17/hMK8qF4Jne6sTYC.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Unsupervised Domain Adaptation of a Pretrained Cross-Lingual Language Model"/></a><div class="content"><a class="title" href="/2021/12/27/Unsupervised-Domain-Adaptation-of-a-Pretrained-Cross-Lingual-Language-Model/" title="Unsupervised Domain Adaptation of a Pretrained Cross-Lingual Language Model">Unsupervised Domain Adaptation of a Pretrained Cross-Lingual Language Model</a><time datetime="2021-12-27T11:39:54.000Z" title="发表于 2021-12-27 19:39:54">2021-12-27</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/12/22/Contrastive-Representation-Distillation/" title="Contrastive Representation Distillation"><img src="https://s2.loli.net/2021/12/22/aCcIO7GKrPo5DV3.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Contrastive Representation Distillation"/></a><div class="content"><a class="title" href="/2021/12/22/Contrastive-Representation-Distillation/" title="Contrastive Representation Distillation">Contrastive Representation Distillation</a><time datetime="2021-12-22T15:50:39.000Z" title="发表于 2021-12-22 23:50:39">2021-12-22</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/12/22/Achieving-Forgetting-Prevention-and-Knowledge-Transfer-in-Continual-Learning/" title="Achieving Forgetting Prevention and Knowledge Transfer in Continual Learning"><img src="https://s2.loli.net/2021/12/22/OG4tHAZ7uEoJTfh.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Achieving Forgetting Prevention and Knowledge Transfer in Continual Learning"/></a><div class="content"><a class="title" href="/2021/12/22/Achieving-Forgetting-Prevention-and-Knowledge-Transfer-in-Continual-Learning/" title="Achieving Forgetting Prevention and Knowledge Transfer in Continual Learning">Achieving Forgetting Prevention and Knowledge Transfer in Continual Learning</a><time datetime="2021-12-22T06:09:05.000Z" title="发表于 2021-12-22 14:09:05">2021-12-22</time></div></div></div></div><div class="card-widget card-tags"><div class="item-headline"><i class="fas fa-tags"></i><span>标签</span></div><div class="card-tag-cloud"><a href="/tags/Convex-optimization/" style="font-size: 1.1em; color: #999">Convex optimization</a> <a href="/tags/DP/" style="font-size: 1.26em; color: #999fa8">DP</a> <a href="/tags/DataGame/" style="font-size: 1.26em; color: #999fa8">DataGame</a> <a href="/tags/Docker/" style="font-size: 1.22em; color: #999ea4">Docker</a> <a href="/tags/GNN/" style="font-size: 1.34em; color: #99a3b0">GNN</a> <a href="/tags/GNN-cv/" style="font-size: 1.14em; color: #999b9d">GNN&cv</a> <a href="/tags/GNN-nlp/" style="font-size: 1.46em; color: #99a7bb">GNN&nlp</a> <a href="/tags/LeetCode/" style="font-size: 1.42em; color: #99a6b7">LeetCode</a> <a href="/tags/ML-DL/" style="font-size: 1.22em; color: #999ea4">ML&DL</a> <a href="/tags/NLP/" style="font-size: 1.1em; color: #999">NLP</a> <a href="/tags/context-detection/" style="font-size: 1.5em; color: #99a9bf">context detection</a> <a href="/tags/nlp/" style="font-size: 1.38em; color: #99a4b4">nlp</a> <a href="/tags/pytorch/" style="font-size: 1.1em; color: #999">pytorch</a> <a href="/tags/%E5%88%B7%E9%A2%98/" style="font-size: 1.3em; color: #99a1ac">刷题</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" style="font-size: 1.14em; color: #999b9d">数据结构</a> <a href="/tags/%E9%85%8D%E7%BD%AE%E8%AE%B0%E5%BD%95/" style="font-size: 1.18em; color: #999ca1">配置记录</a></div></div><div class="card-widget card-archives"><div class="item-headline"><i class="fas fa-archive"></i><span>归档</span><a class="card-more-btn" href="/archives/" title="查看更多">
    <i class="fas fa-angle-right"></i></a></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2022/01/"><span class="card-archive-list-date">一月 2022</span><span class="card-archive-list-count">2</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/12/"><span class="card-archive-list-date">十二月 2021</span><span class="card-archive-list-count">8</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/11/"><span class="card-archive-list-date">十一月 2021</span><span class="card-archive-list-count">12</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/10/"><span class="card-archive-list-date">十月 2021</span><span class="card-archive-list-count">13</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/09/"><span class="card-archive-list-date">九月 2021</span><span class="card-archive-list-count">20</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/08/"><span class="card-archive-list-date">八月 2021</span><span class="card-archive-list-count">10</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/07/"><span class="card-archive-list-date">七月 2021</span><span class="card-archive-list-count">7</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/06/"><span class="card-archive-list-date">六月 2021</span><span class="card-archive-list-count">6</span></a></li></ul></div><div class="card-widget card-map"><div class="card-content"><div class="item-headline"><i class="fa fa-globe-asia" aria-hidden="true"></i><span>aside.card_map</span></div><script id="clstr_globe" type="text/javascript" defer="defer" src="//clustrmaps.com/globe.js?d=dw5ySwxQc209v5eDdMmMLhW4-aHUt-vE_XaC-6nRPAA"></script></div></div><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>网站资讯</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">文章数目 :</div><div class="item-count">131</div></div><div class="webinfo-item"><div class="item-name">本站访客数 :</div><div class="item-count" id="busuanzi_value_site_uv"></div></div><div class="webinfo-item"><div class="item-name">本站总访问量 :</div><div class="item-count" id="busuanzi_value_site_pv"></div></div><div class="webinfo-item"><div class="item-name">最后更新时间 :</div><div class="item-count" id="last-push-date" data-lastPushDate="2022-01-21T11:01:27.072Z"></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2022 By Coding-Zuo</div><div class="footer_custom_text">Hi, welcome to my BLOG</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="font-plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>function subtitleType () {
  if (true) { 
    var typed = new Typed("#subtitle", {
      strings: "今日事&#44;今日畢,Never put off till tomorrow what you can do today".split(","),
      startDelay: 300,
      typeSpeed: 150,
      loop: true,
      backSpeed: 50
    })
  } else {
    document.getElementById("subtitle").innerHTML = '今日事&#44;今日畢'
  }
}

if (true) {
  if (typeof Typed === 'function') {
    subtitleType()
  } else {
    getScript('https://cdn.jsdelivr.net/npm/typed.js/lib/typed.min.js').then(subtitleType)
  }
} else {
  subtitleType()
}</script><script>if (document.getElementsByClassName('mermaid').length) {
  if (window.mermaidJsLoad) mermaid.init()
  else {
    getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(() => {
      window.mermaidJsLoad = true
      mermaid.initialize({
        theme: 'default',
      })
      false && mermaid.init()
    })
  }
}</script></div><script src="/js/custom.js"></script><script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script><script defer="defer" id="fluttering_ribbon" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-fluttering-ribbon.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script src="//code.tidio.co/mak6nokafytw9mgrsuzglwzfxiy3fpdl.js" async="async"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>