<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Coding-Zuo</title>
  
  <subtitle>Coding And Studying</subtitle>
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2022-02-21T02:10:21.631Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>Coding-Zuo</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Prompt tuning 基础</title>
    <link href="http://example.com/2022/02/21/Prompt-tuning-%E5%9F%BA%E7%A1%80/"/>
    <id>http://example.com/2022/02/21/Prompt-tuning-%E5%9F%BA%E7%A1%80/</id>
    <published>2022-02-21T02:08:56.000Z</published>
    <updated>2022-02-21T02:10:21.631Z</updated>
    
    <content type="html"><![CDATA[<p>[TOC]</p><h1 id="Prompt-tuning调研"><a href="#Prompt-tuning调研" class="headerlink" title="Prompt tuning调研"></a>Prompt tuning调研</h1><h2 id="基本介绍"><a href="#基本介绍" class="headerlink" title="基本介绍"></a>基本介绍</h2><p>在海量数据上预训练 PLM，将其调整为下游任务，这已经成为NLP的典型范式（Fine tuning/微调/精调）。传统上，它通过特定任务的监督，优化PLM的所有参数。</p><p>然而，随着 PLM 参数的持续增长，全参数微调对于典型的范式和模型存储都变得难以承受。为了弥补这一缺陷，人们提出了许多参数高效的 tuning 方法，这些方法只调整几个参数，而保持大部分PLM参数的冻结。</p><p>在这些具有参数效率的微调变体中，Prompt Tuning 得到了广泛的关注，这是由 GPT-3 激发的。 它通过在输入文本之前给每个任务预留一个文本提示，并让 PLM 直接生成答案，从而展示了显著的【少样本】与【跨任务/domain迁移】性能。</p><p>Prompt 的突然兴起，主要是因为学者们把任务扩展到了NLU，之前大部分是做生成和信息抽取，而在统一了方法之后，<strong>现在可以做分类任务和匹配任务了，同时在少样本甚至全样本，能追上微调的效果</strong>。</p><p>Prompt的思想：<strong>设计不同的输入形态，激发语言模型的潜力，得到任务相关的输出，从而避免微调模式带来的灾难性遗忘问题</strong>。引用刘鹏飞博士放在<a href="https://zhuanlan.zhihu.com/p/395115779">博客</a>里的图：</p><p><img src="https://s4.ax1x.com/2022/02/18/H7YIdU.png" alt=""></p><p>Prompt兴起之前做NLP任务的大致流程，即”Pre-train, Fine-tune”，如上图，可看做是由预训练模型（PLM）迁就下游任务。Prompt的模式大致可以归纳成”Pre-train, Prompt, and Predict”。在该模式中，可看成由下游任务迁就 PLM，下游任务被重新调整成类似预训练任务的形式。例如，MLM（Masked Language Model），在文本情感分类任务中，对于”I love this movie”这句输入，可以在后面加上Prompt：”the movie is <em>_</em>“，组成如下这样一句话：</p><blockquote><p>I love this movie, the movie is <em>_</em></p></blockquote><p>然后让 PLM 用表示情感的答案（例如”great”、”terrible”等）做完形填空，最后再将该答案转换为情感分类的标签。这样一来，我们就可以通过构造合适的【模板】，控制模型的输出空间，从而训练 PLM 来解决各种各样的下游任务。</p><p>Prompt 更严谨的定义如下：</p><blockquote><p>Prompt is the technique of <strong>making better use of the knowledge</strong> from the pre-trained model by <strong>adding additional texts to the input</strong>.</p><p>Prompt 是一种<strong>为了更好的使用预训练语言模型的知识</strong>，采用在输入段<strong>添加额外的文本</strong>的技术。</p></blockquote><ul><li>目的：更好挖掘预训练语言模型的能力</li><li>手段：在输入端添加文本，即重新定义任务（task reformulation）</li></ul><h2 id="Prompt-优势是什么"><a href="#Prompt-优势是什么" class="headerlink" title="Prompt 优势是什么"></a>Prompt 优势是什么</h2><p>从四个角度进行分析：Level 1. Prompt Learning 角度；Level 2. Prompt Learning 和 Fine-tuning 的区别；Level 3. 现代 NLP 历史；Level 4. 超越NLP</p><h3 id="Level-1-Prompt-tuning-使得所有的NLP任务成为一个语言模型的问题"><a href="#Level-1-Prompt-tuning-使得所有的NLP任务成为一个语言模型的问题" class="headerlink" title="Level 1. Prompt tuning 使得所有的NLP任务成为一个语言模型的问题"></a>Level 1. Prompt tuning 使得所有的NLP任务成为一个语言模型的问题</h3><ul><li><p>Prompt tuning 可以将所有的任务归化为预训练语言模型的任务</p></li><li><p>避免了预训练和Fine tuning 之间的gap，几乎所有 NLP 任务都可以直接使用，不需要训练数据。</p></li><li><p>更少的调整参数、提升参数效率</p></li><li><p>在少样本的数据集上，能取得超过微调的效果，未来也有希望在全方位超过微调。</p></li><li><p>使得所有的任务在方法上变得一致，在<strong>多任务、多领域场景下使得迁移学习变得更加自然且容易</strong>，如下图：</p><p><img src="https://s4.ax1x.com/2022/02/19/HH79mR.png" alt=""></p><p>左边是传统的 Model Tuning(Fine tuning) 的范式：对于不同的任务，都需要将整个预训练语言模型进行精调，每个任务都有自己的一整套参数。右边是Prompt Tuning，对于不同的任务，仅需要插入不同的prompt 参数，每个任务都单独训练Prompt 参s数，不训练预训练语言模型，这样子可以大大缩短训练时间，也极大的提升了模型的使用率。</p></li></ul><h3 id="Level-2-Prompt-tuning-和-Fine-tuning-的范式区别"><a href="#Level-2-Prompt-tuning-和-Fine-tuning-的范式区别" class="headerlink" title="Level 2. Prompt tuning 和 Fine tuning 的范式区别"></a>Level 2. Prompt tuning 和 Fine tuning 的范式区别</h3><ul><li>Fine tuning 是使得预训练语言模型<strong>适配下游任务</strong></li><li>Prompting 是将下游任务进行任务重定义，使得其利用预训练语言模型的能力，即<strong>适配语言模型</strong></li></ul><h3 id="Level-3-现代-NLP-第四范式"><a href="#Level-3-现代-NLP-第四范式" class="headerlink" title="Level 3. 现代 NLP 第四范式"></a>Level 3. 现代 NLP 第四范式</h3><p>Prompting 方法是现在NLP的第四范式。其中现在NLP的发展史包含</p><ol><li>Feature Engineering：即使用文本特征，例如词性，长度等，在使用机器学习的方法进行模型训练。（无预训练语言模型）</li><li>Architecture Engineering：在W2V基础上，利用深度模型，加上固定的embedding。（有固定预训练embedding，但与下游任务无直接关系）</li><li>Objective Engineering：在bert 的基础上，使用动态的embedding，在加上Fine tuning。（有预训练语言模型，但与下游任务有gap）</li><li>Prompt Engineering：直接利用与训练语言模型辅以特定的prompt。（有预训练语言模型，但与下游任务无gap）</li></ol><p>我们可以发现，在四个范式中，预训练语言模型，和下游任务之间的距离，变得越来越近，直到最后Prompt Learning是直接完全利用LM的能力。</p><p><img src="https://s4.ax1x.com/2022/02/19/HH5YeP.png" alt=""></p><h3 id="Level-4-超越NLP的角度"><a href="#Level-4-超越NLP的角度" class="headerlink" title="Level 4. 超越NLP的角度"></a>Level 4. 超越NLP的角度</h3><p>Prompt 可以作为连接多模态的一个契机，例如 CLIP 模型，连接了文本和图片。相信在未来，可以连接声音和视频，这是一个广大的待探索的领域。</p><p><img src="https://s4.ax1x.com/2022/02/19/HHIAfg.png" alt=""></p><h2 id="Prompt-的工作流"><a href="#Prompt-的工作流" class="headerlink" title="Prompt 的工作流"></a>Prompt 的工作流</h2><p>Prompt 的工作流包含以下4部分：</p><ol><li>Prompt 模版（Template）的构造</li><li>Prompt 答案空间映射（Verbalizer）的构造</li><li>文本代入template，并且使用预训练语言模型进行预测</li><li>将预测的结果映射回label。</li></ol><p>具体的步骤如下图，接下来将一步步进行拆解分析。</p><p><img src="https://s4.ax1x.com/2022/02/19/HHqT3T.png" alt=""></p><h3 id="Step-1-prompt-construction【Template】"><a href="#Step-1-prompt-construction【Template】" class="headerlink" title="Step 1: prompt construction【Template】"></a>Step 1: prompt construction【Template】</h3><p>首先我们需要构建一个模版Template，模版的作用是将输入和输出进行重新构造，变成一个新的带有mask slots的文本，具体如下：</p><ul><li>定义一个模版，包含了2处代填入的slots：[x] 和 [z]</li><li>将 [x] 用输入文本代入</li></ul><p>例如：</p><ul><li>输入：x = 我喜欢这个电影。</li><li>模版：[x] 总而言之，它是一个 [z] 电影。</li><li>代入（Prompt）：我喜欢这个电影。总而言之，它是一个[z]电影。</li></ul><p><img src="https://s4.ax1x.com/2022/02/19/HHvnoj.png" alt=""></p><p>以上介绍的为离散的Prompt（手工构造Prompt），这浪费人力并且往往是次优的性能。目前普遍采用的是连续的Prompt 将Prompt 向量化进行调优，在经典工作中将会涉及此类工作。</p><h3 id="Step-2-answer-construction【Verbalizer】"><a href="#Step-2-answer-construction【Verbalizer】" class="headerlink" title="Step 2: answer construction【Verbalizer】"></a>Step 2: answer construction【Verbalizer】</h3><p>对于我们构造的prompt，我们需要知道我们的预测词和我们的label 之间的关系，并且我们也不可能让 z 是任意词，这边我们就需要一个映射函数（mapping function）将输出的词与label进行映射。</p><p>例如，输出的 label 有两个，一个【是】 ，一个【不是】 ，我们可以限定，【是】这个预测词是<code>fantastic</code> 对应 ，【不是】则对应  <code>boring</code>  。</p><p><img src="https://s4.ax1x.com/2022/02/19/HHxy3q.png" alt=""></p><h3 id="Step-3-answer-prediction【Prediction】"><a href="#Step-3-answer-prediction【Prediction】" class="headerlink" title="Step 3: answer prediction【Prediction】"></a>Step 3: answer prediction【Prediction】</h3><p>选择<a href="https://link.zhihu.com/?target=https%3A//huggingface.co/docs/transformers/model_summary">合适的预训练语言模型</a>，然后进行mask slots [z] 的预测。例如下图，得到了结果 <code>fantastic</code>, 我们需要将其代入 [z] 中。</p><p><img src="https://s4.ax1x.com/2022/02/19/HHx4UJ.png" alt=""></p><h3 id="Step-4-answer-label-mapping【Mapping】"><a href="#Step-4-answer-label-mapping【Mapping】" class="headerlink" title="Step 4: answer-label mapping【Mapping】"></a>Step 4: answer-label mapping【Mapping】</h3><p>第四步骤，对于得到的 <code>answer</code>，我们需要使用 <code>Verbalizer</code> 将其映射回原本的label。</p><p>例如：fantastic 映射回 label：</p><p><img src="https://s4.ax1x.com/2022/02/19/HHzEVg.png" alt=""></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p><img src="https://s4.ax1x.com/2022/02/19/HHz8ZF.png" alt=""></p><h2 id="经典工作与方法（持续更新…）"><a href="#经典工作与方法（持续更新…）" class="headerlink" title="经典工作与方法（持续更新…）"></a>经典工作与方法（持续更新…）</h2><h3 id="Parameter-Efficient-Transfer-Learning-for-NLP-（ICML-2019-2019-2-2"><a href="#Parameter-Efficient-Transfer-Learning-for-NLP-（ICML-2019-2019-2-2" class="headerlink" title="Parameter-Efficient Transfer Learning for NLP （ICML 2019) -2019.2.2"></a>Parameter-Efficient Transfer Learning for NLP （ICML 2019) -2019.2.2</h3><ul><li>motivation: 将 adapter 加入到 transformer 中，在针对某个下游任务微调时，改变的仅仅是 adapter 的参数。</li><li>method:<img src="https://s4.ax1x.com/2022/02/19/HbATTP.png" alt=""></li></ul><h3 id="Language-Models-as-Knowledge-Bases-ACL-2019-2019-9-3"><a href="#Language-Models-as-Knowledge-Bases-ACL-2019-2019-9-3" class="headerlink" title="Language Models as Knowledge Bases?  (ACL 2019) -2019.9.3"></a>Language Models as Knowledge Bases?  (ACL 2019) -2019.9.3</h3><ul><li><p>motivation : 语言模型可以作为关系知识的潜在表示形式，对预先训练的现成语言模型（例如 ELMo 和 BERT）中已经存在的关系知识提取。在 kownledge-base complete 任务上利用语言模型预测的分数，完成知识提取，相比 elmo 等模型表现要好。需要人工标注 query 也就是模板。 </p></li><li><p>method:</p><p><img src="https://s4.ax1x.com/2022/02/19/HbeN7R.png" alt=""></p></li></ul><h3 id="Exploiting-Cloze-Questions-for-Few-Shot-Text-Classification-and-Natural-Language-Inference-EACL-2021-2020-1-21"><a href="#Exploiting-Cloze-Questions-for-Few-Shot-Text-Classification-and-Natural-Language-Inference-EACL-2021-2020-1-21" class="headerlink" title="Exploiting Cloze Questions for Few Shot Text Classification and Natural Language Inference (EACL 2021) - 2020.1.21"></a>Exploiting Cloze Questions for Few Shot Text Classification and Natural Language Inference (EACL 2021) - 2020.1.21</h3><ul><li><p>motivation:  如何用较小的预训练模型充分发挥预训练模型作为语言模型的作用，做 few shot learning，做法是分类转化为完形填空 </p></li><li><p>method:</p><p><img src="https://s4.ax1x.com/2022/02/19/HbmPb9.png" alt=""></p></li></ul><h3 id="It’s-Not-Just-Size-That-Matters-Small-Language-Models-Are-Also-Few-Shot-Learners-NAACL-2021-2020-9-15"><a href="#It’s-Not-Just-Size-That-Matters-Small-Language-Models-Are-Also-Few-Shot-Learners-NAACL-2021-2020-9-15" class="headerlink" title="It’s Not Just Size That Matters: Small Language Models Are Also Few-Shot Learners (NAACL 2021) -2020.9.15"></a>It’s Not Just Size That Matters: Small Language Models Are Also Few-Shot Learners (NAACL 2021) -2020.9.15</h3><ul><li>motivation: 解决 label mask 预测多 token 问题。</li><li>method: 选择分数最高的一个 token 为基准计算，替代多个 token 完形填空的分数计算</li></ul><h3 id="Parameter-Efficient-Transfer-Learning-with-Diff-Pruning-2020-12-14"><a href="#Parameter-Efficient-Transfer-Learning-with-Diff-Pruning-2020-12-14" class="headerlink" title="Parameter-Efficient Transfer Learning with Diff Pruning -2020.12.14"></a>Parameter-Efficient Transfer Learning with Diff Pruning -2020.12.14</h3><ul><li>motivation : adapter 的延续，将原来的参数上增加新参数（L0 正则约束稀疏性）</li></ul><h3 id="Prefix-Tuning-Optimizing-Continuous-Prompts-for-Generation-ACL-2021-2021-1-1"><a href="#Prefix-Tuning-Optimizing-Continuous-Prompts-for-Generation-ACL-2021-2021-1-1" class="headerlink" title="Prefix-Tuning: Optimizing Continuous Prompts for Generation (ACL 2021) -2021.1.1"></a>Prefix-Tuning: Optimizing Continuous Prompts for Generation (ACL 2021) -2021.1.1</h3><ul><li><p>motivation : 提出了 Prefix-Tuning，一种轻量级 fintune 替代方法，用于对 NLG 任务进行微调，在使语言模型参数冻结的同时，去优化一个参数量少的 continuous task-specific vector（称为 prefix），用词表中的词初始化较好，并且和类别相关。在大多数任务上比 finetune 好。  </p></li><li><p>method: 根据不同的模型结构定义了不同的 Prompt 拼接方式，在 GPT 类的自回归模型上采用 [PREFIX, x, y]，在 T5 类的 encoder-decoder 模型上采用 [PREFIX, x, PREFIX’, y]。</p><ol><li><p>把预训练大模型 freeze 住，因为大模型参数量大，精调起来效率低，毕竟 prompt 的出现就是要解决大模型少样本的适配。</p></li><li><p>直接优化 Prompt 参数不太稳定，加了个更大的 MLP，训练完只保存 MLP 变换后的参数就行了。</p></li><li>实验证实只加到 embedding 上的效果不太好，因此作者在每层都加了 prompt 的参数，改动较大。</li></ol></li></ul><h3 id="PADA-A-Prompt-based-Autoregressive-Approach-for-Adaptation-to-Unseen-Domains-2021-2-24"><a href="#PADA-A-Prompt-based-Autoregressive-Approach-for-Adaptation-to-Unseen-Domains-2021-2-24" class="headerlink" title="PADA: A Prompt-based Autoregressive Approach for Adaptation to Unseen Domains  -2021.2.24"></a>PADA: A Prompt-based Autoregressive Approach for Adaptation to Unseen Domains  -2021.2.24</h3><ul><li>motivation: 利用 t5 的 embedding，选择领域的代表关键词（利用互信息），然后进行领域迁移（挖掘领域共现关键）</li></ul><h3 id="GPT-Understands-Too-2021-3-18"><a href="#GPT-Understands-Too-2021-3-18" class="headerlink" title="GPT Understands, Too  -2021.3.18"></a>GPT Understands, Too  -2021.3.18</h3><ul><li><p>motivation: P-tuning 重新审视了关于模版的定义，放弃了“模版由自然语言构成”这一常规要求，从而将模版的构建转化为连续参数优化问题，虽然简单，但却有效。</p><p><img src="https://s4.ax1x.com/2022/02/19/Hbnowj.png" alt=""></p></li></ul><h3 id="KnowPrompt-Knowledge-aware-Prompt-tuning-with-Synergistic-Optimization-for-Relation-Extraction-2021-4-15"><a href="#KnowPrompt-Knowledge-aware-Prompt-tuning-with-Synergistic-Optimization-for-Relation-Extraction-2021-4-15" class="headerlink" title="KnowPrompt: Knowledge-aware Prompt-tuning with Synergistic Optimization for Relation Extraction  -2021.4.15"></a>KnowPrompt: Knowledge-aware Prompt-tuning with Synergistic Optimization for Relation Extraction  -2021.4.15</h3><ul><li><p>motivation: 融入外部知识（实体，关系）的 embedding 当做参数，将关系分类设置成模板，采用 MASK 的方式训练，同时增 KE 的 loss 。</p><p><img src="https://s4.ax1x.com/2022/02/19/HbuN7j.png" alt=""></p></li></ul><h3 id="The-Power-of-Scale-for-Parameter-Efficient-Prompt-Tuning-2021-4-18"><a href="#The-Power-of-Scale-for-Parameter-Efficient-Prompt-Tuning-2021-4-18" class="headerlink" title="The Power of Scale for Parameter-Efficient Prompt Tuning  (2021.4.18)"></a>The Power of Scale for Parameter-Efficient Prompt Tuning  (2021.4.18)</h3><ul><li><p>motivation: 对 prefix tuning 的进一步简化 : prefix tuning 会训练所有与 prefix prompt 相关的层。而这篇文章 : 针对每个下游任务，只调输入文本前面的一些 tokens (soft prompt)。另外，这篇文章还提出了 Prompt Ensembling。</p></li><li><p>method: 总体上 Prompt Tuning 与 P-Tuning （ P-tuning-GPT Understands, Too） 较为相似。但 Prompt Tuning 的 prompt 参数全部置于左侧，并且论文将注意力集中在了冻结模型权重的一系列实验上，更好的验证了 prompt 的效果。初始化prompt: sampled vocab：从 5000 个 T5 字典最常用的 token 中提取。</p><p>class label：从任务 label 对应的 token 中提取。由于任务 label 通常数量较少，当任务 label 不够满足 prompt 参数长度时，使用 sampled vocab 进行填充。当一个 label 存在 multi-token 时，取其平均值。简单的 ensemble 能提升 prompt-tuning 的效果。</p><p><img src="https://s4.ax1x.com/2022/02/19/HbuLEd.png" alt=""></p></li></ul><h3 id="Multimodal-Few-Shot-Learning-with-Frozen-Language-Model-2021-7-3"><a href="#Multimodal-Few-Shot-Learning-with-Frozen-Language-Model-2021-7-3" class="headerlink" title="Multimodal Few-Shot Learning with Frozen Language Model -2021.7.3"></a>Multimodal Few-Shot Learning with Frozen Language Model -2021.7.3</h3><ul><li><p>motivation: 如何使用冻结参数的语言模型进行多模态任务</p></li><li><p>method: 冻结 LM 参数，只调输出以及视觉的 Vision Encoder（图中粉色部分）。LM 使用的是自回归的语言模型。视觉编码器基于 NF-ResNet-50，但是在视觉编码器之上套了一层线性映射，让其变成 Vision Prefix，类似于 Prefix Tuning [1] 的 Prefix (不过这里的 Prefix 是可以训练的)。这样，Image 就可以转变成 LM 可以理解的形式。</p><p><img src="https://s4.ax1x.com/2022/02/19/HbQx81.png" alt=""></p></li></ul><h3 id="Knowledgeable-Prompt-tuning-Incorporating-Knowledge-into-Prompt-Verbalizer-for-Text-Classification-2021-8-4"><a href="#Knowledgeable-Prompt-tuning-Incorporating-Knowledge-into-Prompt-Verbalizer-for-Text-Classification-2021-8-4" class="headerlink" title="Knowledgeable Prompt-tuning: Incorporating Knowledge into Prompt Verbalizer for Text Classification  (2021.8.4)"></a>Knowledgeable Prompt-tuning: Incorporating Knowledge into Prompt Verbalizer for Text Classification  (2021.8.4)</h3><ul><li>motivation: 对标签词进行扩展，相当于引入外部知识。</li></ul><h3 id="Finetuned-Language-Models-Are-Zero-Shot-Learners-2021-9-3"><a href="#Finetuned-Language-Models-Are-Zero-Shot-Learners-2021-9-3" class="headerlink" title="Finetuned Language Models Are Zero-Shot Learners -2021.9.3"></a>Finetuned Language Models Are Zero-Shot Learners -2021.9.3</h3><ul><li><p>motivation: 简称FLAN， 另称 : Instruction Tuning。改善语言模型的 zero-shot 学习的能力。</p></li><li><p>method：作者先收集整理了一系列任务集合(task cluster)，每个任务集合包含若干特定的数据集，有 NLU，也有 NLG，之后的 instruction tuning 就是在若干 task clusters 上训练的。tuning 方法有点像 GPT-3 的那种 prompting, 但是又有区别：</p><p><img src="https://s4.ax1x.com/2022/02/19/Hb1ly6.png" alt=""></p><p><img src="https://s4.ax1x.com/2022/02/19/HbM2f1.png" alt=""></p></li></ul><p>众所周知，GPT-3 不做进一步地精调，只是在 inference 时候，在开头提供一些 examples (instructions) 和 prompt，称作 in-context learning；但是这篇工作是要做精调的，把类似的 instruction 作为 tuning 时候的训练数据。</p><p>GPT-3 是单任务的，而这篇工作在 tuning 阶段使用多任务，每个任务都人工设计了一个 instruction template，把 template 填充之后就变成了 tuning 时候用的训练 examples。tuning 完成之后，把模型用于全新的 (unseen) 任务进行 inference, 这一次，不用 instructions (GPT-3), 就能达到很好的效果。</p><h3 id="PPT-Pre-trained-Prompt-Tuning-for-Few-shot-Learning-2021-9-9"><a href="#PPT-Pre-trained-Prompt-Tuning-for-Few-shot-Learning-2021-9-9" class="headerlink" title="PPT: Pre-trained Prompt Tuning for Few-shot Learning -2021.9.9"></a>PPT: Pre-trained Prompt Tuning for Few-shot Learning -2021.9.9</h3><ul><li>motivation: 通过预训练将 prompt tuning 用于下游任务，提供好的初始化 prompt，使得效果更稳定</li></ul><h3 id="Multitask-Prompted-Training-Enables-Zero-Shot-Task-Generalization-（EMNLP-2021）-2021-9-15"><a href="#Multitask-Prompted-Training-Enables-Zero-Shot-Task-Generalization-（EMNLP-2021）-2021-9-15" class="headerlink" title="Multitask Prompted Training Enables Zero-Shot Task Generalization （EMNLP 2021） -2021.9.15"></a>Multitask Prompted Training Enables Zero-Shot Task Generalization （EMNLP 2021） -2021.9.15</h3><ul><li><p>motivation: 大模型具有很好的零样本泛化能力 (zero-shot generalization)，这取决于它隐式的多任务学习机制(也就是 GPT-3 的那种外循环机制)。那么能不能通过显式的多任务学习机制 (即带有 prompt engineering) 来激发大模型的零样本泛化能力呢？</p></li><li><p>粗暴、协作：多任务数据集达 171 个，Prompt 达 1939 个，模型也是超大的（T5, 11B）。和 FLAN 工作整体相似，区别是增加了任务和 prompt 数量，减小了模型参数，效果超过 FLAN，证明了多任务 prompt 学习能使模型更加鲁棒、泛化能力更强。</p><p><img src="https://s4.ax1x.com/2022/02/19/HbQIg0.png" alt=""></p></li></ul><h3 id="P-Tuning-v2-Prompt-Tuning-Can-Be-Comparable-to-Finetuning-Universally-Across-Scales-and-Tasks-2021-10-14"><a href="#P-Tuning-v2-Prompt-Tuning-Can-Be-Comparable-to-Finetuning-Universally-Across-Scales-and-Tasks-2021-10-14" class="headerlink" title="P-Tuning v2: Prompt Tuning Can Be Comparable to Finetuning Universally Across Scales and Tasks  -2021.10.14"></a>P-Tuning v2: Prompt Tuning Can Be Comparable to Finetuning Universally Across Scales and Tasks  -2021.10.14</h3><ul><li><p>motivation: 之前的 soft prompt (google) 和 P-tuning 只对大模型有效，而且也仅仅用于解决一些简单的 NLU 任务。因此这个工作主要是扩展之前的 P-Tuning：适配小模型，适配复杂的 NLU 任务 (如序列标注等)。</p></li><li><p>method: 其实比起 P-tuning 或者 Google 的 soft prompt 的方式，这个更类似于 prefix tuning, 即和 prefix prompt 相关联的一系列层都能调。</p><p><img src="https://s4.ax1x.com/2022/02/19/Hb3S0O.png" alt=""></p><p>另外几点考虑是：</p><p>去掉了重参数化：比如 prefix tuning [1] 中的 MLP 以及 P-tuning 中的 LSTM，都不要了，因为这东西对效果提升不大。</p><p>多任务学习：这个挺有必要的，一方面可以减小 prompt 随机初始化的压力，另一方面可以更好地搞到跨任务/数据集的知识。</p><p>不用 verbalizer 了 : 其实对于复杂的 NLU 任务来说，verbalizer 的设计很不直观，那么就返璞归真，沿用原始的 [CLS]/token (hidden state) + MLP 就好。</p></li></ul><h3 id="SPoT-Better-Frozen-Model-Adaptation-through-Soft-Prompt-Transfer-2021-10-15"><a href="#SPoT-Better-Frozen-Model-Adaptation-through-Soft-Prompt-Transfer-2021-10-15" class="headerlink" title="SPoT: Better Frozen Model Adaptation through Soft Prompt Transfer  -2021.10.15"></a>SPoT: Better Frozen Model Adaptation through Soft Prompt Transfer  -2021.10.15</h3><ul><li><p>motivation: 还是为了增强模型在不同任务上的泛化性能，不过是基于 Prompt Tuning。换句话说：Transfer Learning + Prompt Tuning.</p></li><li><p>method:  Task-Agnostic Approach : 先使用 multi-task training 得到一个 soft prompt, 用其作为目标任务的初始化。Task-Specific Approach : 为了进一步提高效率，作者做了一个 prompt library. 先在一系列源任务上进行学习，取早期的 embedding 作为键，相应的最优 soft prompt 作为值。当我们需要解决目标任务时，把目标任务的早期 embedding 作为 query，与库中的键计算余弦相似度，从而检索到相应的值 (soft prompt) 作为初始化，再对 target prompt 进行进一步的优化。</p><p><img src="https://s4.ax1x.com/2022/02/19/Hb3nHS.png" alt=""></p></li></ul><h3 id="ZeroPrompt-Scaling-Prompt-Based-Pretraining-to-1-000-Tasks-Improves-Zero-Shot-Generalization-2022-1-18"><a href="#ZeroPrompt-Scaling-Prompt-Based-Pretraining-to-1-000-Tasks-Improves-Zero-Shot-Generalization-2022-1-18" class="headerlink" title="ZeroPrompt: Scaling Prompt-Based Pretraining to 1,000 Tasks Improves Zero-Shot Generalization -2022 1.18"></a>ZeroPrompt: Scaling Prompt-Based Pretraining to 1,000 Tasks Improves Zero-Shot Generalization -2022 1.18</h3><ul><li><p>motivation : 继FLAN和T0之后，ZeroPrompt[9]实现了大规模多任务学习在中文领域“零的突破”。ZeroPrompt来自于XLNet作者杨植麟团队，共收集了1000个中文任务数据，整个测试任务上平均只相差4.7个点，而在部分测试任务上Zero-shot性能比有监督fine tuning还要好。</p></li><li><p>ZeroPrompt虽然数据规模庞大，但也证明一点：<strong>任务数据规模的拓展是模型缩放的一种有效替代手段,任务数量极大的情况下，模型大小对性能的影响很小</strong>。正如下图所示：随着多任务训练任务的增加，不同大小模型之间的Zero-shot性能趋近一致。</p><p><img src="https://s4.ax1x.com/2022/02/19/HbY6RH.png" alt=""></p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;[TOC]&lt;/p&gt;
&lt;h1 id=&quot;Prompt-tuning调研&quot;&gt;&lt;a href=&quot;#Prompt-tuning调研&quot; class=&quot;headerlink&quot; title=&quot;Prompt tuning调研&quot;&gt;&lt;/a&gt;Prompt tuning调研&lt;/h1&gt;&lt;h2 id=&quot;</summary>
      
    
    
    
    
    <category term="Active Learning" scheme="http://example.com/tags/Active-Learning/"/>
    
  </entry>
  
  <entry>
    <title>Auto-Encoding Variational Bayes</title>
    <link href="http://example.com/2022/02/21/Auto-Encoding-Variational-Bayes/"/>
    <id>http://example.com/2022/02/21/Auto-Encoding-Variational-Bayes/</id>
    <published>2022-02-21T02:06:21.000Z</published>
    <updated>2022-02-21T02:08:07.951Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Auto-Encoding-Variational-Bayes"><a href="#Auto-Encoding-Variational-Bayes" class="headerlink" title="Auto-Encoding Variational Bayes"></a>Auto-Encoding Variational Bayes</h1><p>在存在后验分布难以处理的连续隐变量和大数据集的情况下，我们如何在有向概率模型中进行有效的推理和学习？我们介绍了一种随机变分推理和学习算法，该算法可以扩展到大型数据集，在一些温和的可分性条件下，甚至可以在难以解决的情况下工作。</p><p>我们的贡献有两个方面。首先，我们表明，变分下限的重新参数化产生了一个下限估计器，可以使用标准的随机梯度方法直接优化。其次，我们表明，对于每个数据点具有连续潜变量的i.i.d.数据集，通过使用提议的下限估计器将近似推理模型（也称为识别模型）拟合到难以解决的后验中，可以使后验推理特别有效。理论上的优势反映在实验结果中。</p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>如何才能对连续隐变量和/或参数具有难以处理的后验分布的有向概率模型进行有效的近似推理和学习？</p><p>变分贝叶斯(VB)方法涉及对难以处理的后验的近似进行优化。不幸的是，常见的均值场方法需要对近似后验的期望值进行分析解，这在一般情况下也是难以解决的。</p><p>我们展示了变分下限的重新参数化如何产生一个简单的可微分的无偏估计器；这个SGVB（随机梯度变分贝叶斯）估计器可用于几乎任何具有连续隐变量和/或参数的模型中的有效近似后验推断，并且使用标准随机梯度上升技术直接优化。</p><p>对于一个独立的数据集和每个数据点的连续隐变量的情况，我们提出了自编码VB（AEVB）算法。在AEVB算法中，我们通过使用SGVB估计器来优化识别模型，使推理和学习特别有效，这使我们能够使用简单的祖先采样进行非常有效的近似后验推理，这反过来又使我们能够有效地学习模型参数，而不需要每个数据点的昂贵迭代推理方案（如MCMC）。学习到的近似后验推理模型也可以用于一系列的任务，如识别、去噪、表示和可视化的目的。当一个神经网络被用于识别模型时，我们就得到了变量自编码器。</p><h2 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h2><p>本节中的策略可用于为具有连续隐变量的各种有向图模型推导下界估计量（随机目标函数）。我们将在这里限制自己具有 i.i.d 的常见情况。 每个数据点具有潜在变量的数据集，我们喜欢对（全局）参数执行最大似然（ML）或最大后验（MAP）推断，以及对潜在变量进行变分推断。</p><p>例如，可以直接将此场景扩展到我们还对全局参数执行变分推理的情况； 该算法放在附录中，但该案例的实验留给未来的工作。请注意，我们的方法可以应用于在线的非静态设置，例如 流数据，但这里为了简单起见，我们假设一个固定的数据集。</p><h3 id="Problem-scenario"><a href="#Problem-scenario" class="headerlink" title="Problem scenario"></a>Problem scenario</h3><p>让我们考虑一些数据集 $X={x^{(i)}}_{i=1}^N$ , 由一些连续或离散变量 $x$ 的 N 个 i.i.d 样本组成。我们假设数据是由某个随机过程产生的，涉及一个未观测到的连续随机变量 $z$。</p><p><img src="https://s4.ax1x.com/2022/02/17/H44DgK.png" alt=""></p><p>图1.正在考虑的有向图模型的类型。实线表示生成模型 $p<em>θ(z)p</em>θ(x|z)$，虚线表示变分逼近 $q<em>{\phi}(z|x)$ 到难以处理的后验 $p</em>θ(z|x)$。 变分参数 $\phi$ 与生成模型参数 $θ$ 共同学习。</p><p>该过程由两个步骤组成：</p><ul><li>从某个先验分布 $p_{θ^*}(z)$生成值 $z^{(i)}$；</li><li>从某个条件分布 $p_{θ^*}(x|z)$ 生成值 $x^{(i)}$。</li></ul><p>我们假设先验 $p<em>{θ^∗}(z)$ 和似然 $p</em>{θ^∗}(x|z)$ 来自分布 $p<em>θ(z)$ 和 $p</em>θ(x|z)$ 的参数族，并且它们的 PDFs 几乎在任何地方都是可微的 w.r.t. $θ$ 和 $z$。不幸的是，很多这个过程在我们看来是隐藏的：我们不知道真正的参数 $θ^∗$ 以及隐变量 $z^{(i)}$ 的值。</p><p>非常重要的是，我们不对边际或后验概率做出常见的简化假设。 相反，我们在这里对一种通用算法感兴趣，该算法甚至在以下情况下也能有效工作：</p><ol><li>难处理性：边际似然  $p<em>{\theta} = \int p</em>{\theta}(z)p<em>{\theta}(x|z)dz$ 的积分难以处理的情况（因此我们无法评估或区分边际似然），其中真实的后验密度 $p</em>{\theta}(z|x) = p<em>{\theta}(x|z)p</em>{\theta}(z)/p<em>{\theta}(x)$ 是难以处理的（因此不能使用 EM 算法），并且任何合理的平均场 VB 算法所需的积分也是难以处理的。这些难以处理的问题非常普遍，并且出现在中等复杂的似然函数 $p</em>{\theta}(x|z)$ 的情况下，例如 具有非线性隐藏层的神经网络。</li><li>大型数据集：我们有太多的数据，以至于批量优化成本太高； 我们希望使用小批量甚至单个数据点进行参数更新。 基于采样的解决方案，例如 Monte Carlo EM 通常会太慢，因为它涉及每个数据点通常昂贵的采样循环。</li></ol><p>我们对上述场景中的三个相关问题感兴趣，并提出解决方案：</p><ol><li>参数 $θ$ 的有效近似 ML 或 MAP 估计。 参数本身可能是感兴趣的，例如 如果我们正在分析一些自然过程。 它们还允许我们模拟隐藏的随机过程并生成类似于真实数据的人工数据。</li><li>给定观察值 $x$ 以选择参数 $θ$，对隐变量 $z$ 进行有效的近似后验推断。 这对于编码或数据表示任务很有用。</li><li>变量 $x$ 的有效近似边际推断。 这使我们能够执行需要先验 $x$ 的各种推理任务。 计算机视觉中的常见应用包括图像去噪、修复和超分辨率。</li></ol><p>为了解决上述问题，让我们引入一个识别模型 $q<em>{\phi }(z|x)$：一个对难以解决的真实后验 $p</em>{θ}(z|x)$的近似。请注意，与均值场变分推理中的近似后验相比，它不一定是因果关系，它的参数 $\phi $ 也不是由某种闭合形式的期望值计算出来的。相反，我们将引入一种方法来学习识别模型参数 $\phi$ 和生成模型参数 $\theta$。</p><p>从编码理论的角度来看，未观察到的变量 $z$ 可以解释为一种潜在的表示或代码。因此，在本文中，我们也将把识别模型 $q<em>{\phi }(z|x)$ 称为概率编码器，因为给定一个数据点 $x$ ，它产生一个关于编码 $z$ 的可能值的分布（例如高斯），数据点 $x$ 可能是由此产生的。类似地，我们将把 $p</em>θ(x|z)$ 称为概率解码器，因为给定一个编码 $z$，它产生一个关于 $x$ 的可能对应值的分布。</p><h3 id="The-variational-bound"><a href="#The-variational-bound" class="headerlink" title="The variational bound"></a>The variational bound</h3><p>边际似然由单个数据点的边际似然之和 $\log p<em>{\theta}(x^{(1)},…,x^{(N)}) = \sum</em>{i=1}^{N} \log p_{\theta}(x^{(i)})$ 组成，每个数据点可以改写为：</p><script type="math/tex; mode=display">\log p_{\theta}(x^{(i)}) = D_{KL}(q_{\phi}(z|x^{(i)}) || p_{\theta}(z|x^{(i)})) + L(\theta,\phi;x^{(i)})</script><p>第一个 RHS 项是近似值与真实后验的 KL 散度。 由于这个 KL 散度是非负的，第二个 RHS 项 $L(\theta,\phi,x^{(i)})$ 被称为数据点 $i$ 的边际似然的（变分）下界，可以写成：</p><script type="math/tex; mode=display">log p_{\theta}(x^{(i)}) \ge L(\theta,\phi;x^{(i)}) = E_{q_{\phi}(z|x^{(i)})}[\log p_{\theta}(x^{(i)}|z)]</script><p>也可以写成：</p><script type="math/tex; mode=display">L(\theta,\phi;x^{(i)}) = - D_{KL}(q_{\phi}(z|x^{(i)}) || p_{\theta}(z)) + E_{q_{\phi}(z|x^{(i)})}[\log p_{\theta}(x^{(i)}|z)]</script><p>我们想要区分和优化下界 $L(θ,\phi;x(i))$ w.r.t 变分参数 $\phi $ 和生成参数 $θ$。然而，下界 w.r.t $\phi$ 的梯度有点问题。 这类问题的常用（näıve）蒙特卡洛梯度估计器是：$\nabla<em>{\phi} E</em>{q<em>{\phi}(z)}[f(z)] = E</em>{q<em>{\phi}(z)}[f(z)\nabla</em>{q<em>{\phi}(z)}\log q</em>{\phi}(z)] \simeq \frac{1}{L}\sum<em>{l=1}^{L} f(z) \nabla</em>{q<em>{\phi}(z^{(l)}) }\log q</em>{\phi}(z^{(l)})$ 其中 $z^{(l)}\sim q_{\phi}(z|x^{(i)})$ 这个梯度估计器表现出非常高的方差（参见例如 [BJP12]），对于我们的目的来说是不切实际的。</p><h3 id="The-SGVB-estimator-and-AEVB-algorithm"><a href="#The-SGVB-estimator-and-AEVB-algorithm" class="headerlink" title="The SGVB estimator and AEVB algorithm"></a>The SGVB estimator and AEVB algorithm</h3><p>在这一节中，我们将介绍一个实用的下限及其导数（相对于参数）的估计器。我们假设 $q<em>{\phi }(z|x)$ 形式的近似后验，但请注意，该技术也可以应用于 $q</em>{\phi}(z)$ 的情况，即我们不以 $x$ 为条件。用于推断参数后验的完全变异贝叶斯方法在附录中给出。</p><p>在第 2.4 节中概述的某些温和条件下，对于选择的近似后验 $q<em>{\phi }(z|x)$，我们可以使用（辅助）噪声的可微变换 $g</em>{\phi}(ε, x)$ 重新参数化随机变量 $\hat z \sim q_{\phi}(z|x)$ 变量 $ε$：</p><script type="math/tex; mode=display">\hat z = g_{\phi}(\epsilon , x) \ with \epsilon \sim p(\epsilon)</script><p>关于选择这种合适的分布 $p(\epsilon)$ 和函数 $g<em>{\phi}(ε,x)$ 的一般策略，见2.4节。现在我们可以对一些函数 $f(z)$ 的期望值进行蒙特卡洛估计，即 $q</em>{\phi}(z|x)$，具体如下:</p><script type="math/tex; mode=display">E_{q_{\phi}(z|x^{(i)})} [f(z)] = E_{p(\epsilon)}[f(g_{\phi}(\epsilon, x^{(i)}))] \simeq \frac{1}{L} \sum_{l=1}^{L} f(g_{\phi}(\epsilon^{(l)}, x^{(i)})) \ \ where \ \ \epsilon^{(l)}\sim p(\epsilon)</script><p>我们将这一技术应用于变分下限（公式（2）），产生我们的通用随机梯度变分贝叶斯（SGVB）估计器 $\hat L^A(\theta, \phi; x^{(i)}) \simeq L(\theta, \phi;x^{(i)})$:</p><script type="math/tex; mode=display">\hat L^A(\theta, \phi; x^{(i)}) = \frac{1}{L}\sum_{l=1}^L\log p_{\theta}(x^{(i)}, z^{(i,l)} ) - \log q_{\phi}(z^{(i,l)}| x^{(i)}) \\where \ \ z^{(i,l)} = g_{\phi}(\epsilon^{i,l}, x^{(i)}) \ and \ \epsilon^{(l)} \sim p(\epsilon)</script><p>通常，公式(3)的 KL散度 $D<em>{KL}(q</em>{\phi}(z|x^{(i)})||p<em>{\theta}(z))$ 可以用分析法进行积分(见附录B)，这样，只有预期重建误差$E</em>{q<em>{\phi}(z|x^{(i)})}\log p</em>{\theta}(x^{(i)}|z)$ 需要通过抽样进行估计。<br>然后可以将 KL 散度项解释为正则化 $\phi$ ，鼓励近似后验接近先验 $p_{\theta}(z)$。这产生了 SGVB 估计器的第二个版本 $\hat L^B(\theta,\phi;x^{(i)}) \simeq L(\theta,\phi;x^{(i)})$，对应于等式(3)，它的方差通常比通用估计量小：</p><script type="math/tex; mode=display">\hat L^B(\theta, \phi; x^{(i)}) = -D_{KL}(q_{\phi}(z|x^{(i)}) || p_{\theta}(z)) + \frac{1}{L}\sum_{l=1}^L(\log p_{\theta}(x^{(i)}|z^{(i,l)}))\\where \ \ \ z^{(i,l)} = g_{\phi} (\epsilon^{(i,l)}, x^{(i)}) \ and \ \epsilon^{(l)}\sim p(\epsilon)</script><p>给定来自具有 $N$ 个数据点的数据集 $X$ 的多个数据点，我们可以基于小批量构建完整数据集的边际似然下限的估计器：</p><script type="math/tex; mode=display">L(\theta,\phi; X) \simeq \hat L^M(\theta, \phi;X^M) = \frac{N}{M} \sum_{i=1}^M\hat L(\theta,\phi;x^{(i)})</script><p>其中 minibatch $X^M = {x^{(i)}}^M_{i=1}$ 是从具有 $N$ 个数据点的完整数据集 $X$ 中随机抽取的 $M$ 个数据点样本。</p><p>在我们的实验中，我们发现每个数据点的样本数量 $L$ 可以设置为 1，只要 minibatch 大小 $M$ 足够大，例如 $M = 100$。可以取导数 $∇_{θ,\phi}\hat L(\theta;X^M)$，得到的梯度可以与 SGD 或 Adagrad [DHS10] 等随机优化方法结合使用。 有关计算随机梯度的基本方法，请参见算法 1。</p><p><img src="https://s4.ax1x.com/2022/02/17/HIt6KK.png" alt=""></p><p>查看等式给出的目标函数时，与自编码器的联系变得清晰。 (7)。 第一项是（近似后验与先验的 KL 散度）充当正则化项，而第二项是预期的负重构误差。选择函数 $g<em>{\phi}(.)$ 使其将数据点 $x^{(i)}$ 和随机噪声向量 $ε^{(l)}$ 映射到来自该数据点的近似后验的样本：$z^{(i,l)} = g</em>{\phi}(ε^{(l)}, x^{(i)})$ 其中 $z^{(i,l)} \sim q<em>{\phi}(z|x^{(i)})$。随后，样本 $z^{(i,l)}$ 被输入到函数 $\log p</em>{\theta}(x^{(i)}|z^{(i,l)})$，它等于生成条件下数据点 $x^{(i)}$ 的概率密度（或质量） 模型，给定 $z^{(i,l)}$。 该术语是自编码器用语中的负重构误差。</p><h3 id="The-reparameterization-trick"><a href="#The-reparameterization-trick" class="headerlink" title="The reparameterization trick"></a>The reparameterization trick</h3><p>为了解决我们的问题，我们调用了另一种方法来从 $q_{\phi}(z|x)$ 生成样本。 基本的参数化技巧非常简单。</p><p>令 $z$ 为连续随机变量，$z \sim q<em>{\phi}(z|x)$ 为某个条件分布。 然后通常可以将随机变量 $z$ 表示为确定性变量 $z = g</em>{\phi}(ε,x)$，其中 $\epsilon$ 是具有独立边际 $p(\epsilon) $ 的辅助变量，而 $g<em>{\phi}(.)$ 是由$\phi$参数化的某个向量值函数 。这种重新参数化对我们的情况很有用，因为它可以用来重写期望 w.r.t $q</em>{\phi}(z|x)$，使得期望的蒙特卡罗估计值是可微的 w.r.t φ。 证明如下。</p><p>这种重新参数化对我们的情况很有用，因为它可以用来重写期望 w.r.t $q_{\phi }(z|x)$，使得期望的蒙特卡罗估计值是可微的 w.r.t φ。</p><p>证明如下。 给定确定性映射 $z = g<em>{\phi} (\epsilon, x)$ 我们知道 $z = g</em>{\phi}(z|x)\prod_i dz_i =p(\epsilon)\prod_i d\epsilon_i$。</p><p>因此，$\int q<em>{\phi}(z|x)f(z) dz = \int p(\epsilon)f(z)d{\epsilon} = \int p(\epsilon) f(g</em>{\phi}(\epsilon,x)) d\epsilon$ 。因此可以构造一个可微的估计量：$\int q<em>{\phi}(z|x)f(z)dz \simeq \frac{1}{L}f(g</em>{\phi}(x,\epsilon^{(l)}))$ 其中 $\epsilon^{(l)}\sim p(\epsilon)$ 。在第2.3节中，我们应用这个技巧得到了变分下界的一个可微估计。</p><p>以单变量高斯情况为例：令 $z\sim p(z|x) = N(\mu, \sigma^2)$ 。在这种情况下，有效的重新参数化是 $z=μ+σ\epsilon$，其中ε是辅助噪声变量 $ε\sim N(0,1)$。因此 $E<em>{N(z;\mu,\epsilon^2)} [f(z)] = E</em>{N(\epsilon;0,1)}[f(\mu +\sigma\epsilon )] \simeq \frac{1}{L}\sum<em>{l=1}^L f(\mu+\sigma\epsilon^{(l)})$, 其中 $\epsilon^{(l)}\sim N(0,1)$。对于其中的 $q</em>{\phi }(z|x)$，我们可以选择这样的可微变换 $g_{\phi }(.)$ 和辅助变量 $\epsilon \sim p(\epsilon)$？三种基本方法是：</p><ol><li>易处理的逆 CDF。 在这种情况下，令 $\epsilon \sim U(0,I)$ ，令 $g<em>{\phi }(ε,x)$ 为 $q</em>{\phi }(z|x)$ 的逆 CDF。 示例：指数、Cauchy、Logistic、Rayleigh、Pareto、Weibull、倒数、Gompertz、Gumbel 和 Erlang 分布。</li><li>与高斯示例类似，对于任何“location-scale”分布族，我们可以选择标准分布（位置 = 0，尺度 = 1）作为辅助变量 $ε$，并令 $g(.) = local + scale·ε$ . 示例：拉普拉斯分布、椭圆分布、学生 t 分布、逻辑分布、均匀分布、三角分布和高斯分布。</li><li>组合：通常可以将随机变量表示为辅助变量的不同变换。 示例：Log-Normal（正态分布变量的取幂）、Gamma（指数分布变量的总和）、Dirichlet（Gamma 变量的加权和）、Beta、卡方和 F 分布。</li></ol><p>当所有三种方法都失败时，存在对逆 CDF 的良好近似，需要计算的时间复杂度与 PDF 相当（参见例如 [Dev86] 中的某些方法）。</p><h2 id="Example-Variational-Auto-Encoder"><a href="#Example-Variational-Auto-Encoder" class="headerlink" title="Example: Variational Auto-Encoder"></a>Example: Variational Auto-Encoder</h2><p>在本节中，我们将给出一个示例，其中我们将神经网络用于概率编码器 $q<em>{\phi} (z|x)$（生成模型 $p</em>{\theta}(x, z)$ 的后验近似），其中参数 $\phi $ 和 $\theta $ 为 与AEVB算法联合优化。</p><p>让隐变量的先验为中心各向同性多元高斯 $p<em>{\theta}(z) = N(z;0,I)$。请注意，在这种情况下，先验缺少参数。 我们让 $p</em>{\theta} (x|z)$ 是一个多元高斯（在实值数据的情况下）或伯努利（在二进制数据的情况下），其分布参数是使用 MLP（一个全连接的神经网络 单个隐藏层，见附录 C)。</p><p>请注意，在这种情况下，真正的后验 $p<em>{\theta}(z|x)$ 是难以处理的。 虽然 $q</em>{\phi }(z|x)$ 的形式有很大的自由度，但我们将假设真实的（但难以处理的）后验采用具有近似对角协方差的近似高斯形式。 在这种情况下，我们可以让变分近似后验为具有对角协方差结构的多元高斯：</p><script type="math/tex; mode=display">\log q_{\phi}(z|x^{(i)}) = \log N(z;\mu^{(i)}, \epsilon^{2(i)}I)</script><p>其中，近似后验值 $μ^{(i)}$和 $σ^{(i)} $的平均值和s.d.是编码MLP的输出，即数据点 $x^{(i)}$和变分参数 $\phi $ 的非线性函数（见附录C）。</p><p>如第2.4节所述，我们从后验 $z^{(i，l)} \sim q<em>{\phi}(z|x^{(i)})$ 中采样，使用 $z^{(i,l)}=g</em>{\phi}(x^{(i)}，ε^{(l)})=μ^{(i)}+σ^{(i)}\odot \epsilon ^{(l)}$，其中$ε^{(l)} \sim N(0,I)$。$\odot$ 表示元素乘积。 在这个模型中，$p<em>{\theta }(z)$（先验）和 $q</em>{\phi }(z|x)$ 都是高斯的； 在这种情况下，我们可以使用 eq.(7) 的估计器，其中 KL 散度可以在没有估计的情况下计算和微分（参见附录 B）。 该模型和数据点 $x^{(i)}$ 的结果估计量为：</p><script type="math/tex; mode=display">L(\theta,\phi; x^{(i)}) \simeq \frac{1}{2}\sum_{j=1}^{J}(1+\log( (\sigma^{(i)}_j)^2 ) - (\mu_j^{(i)})^2 - (\sigma^{(i)}_j)^2)\\where \ \ z^{(i,l)} = \mu^{(i)} + \sigma^{(i)} \odot \epsilon^{(l)} \ and \ \epsilon^{(l)}\sim N(0,I)</script><p>如上文和附录 C 所述，解码项 $\log p_{\theta} (x^{(i)} |z^{(i,l)} )$ 是伯努利或高斯 MLP，具体取决于我们建模的数据类型。</p><h2 id="Related-work"><a href="#Related-work" class="headerlink" title="Related work"></a>Related work</h2><p>据我们所知，唤醒-睡眠算法 [HDFN95] 是文献中唯一适用于同一类连续潜变量模型的其他在线学习方法。 与我们的方法一样，wake-sleep 算法采用近似真实后验的识别模型。 唤醒睡眠算法的一个缺点是它需要同时优化两个目标函数，这两个目标函数一起不对应于边际似然的优化。 唤醒睡眠的一个优点是它也适用于具有离散隐变量的模型。 Wake-Sleep 与每个数据点的 AEVB 具有相同的计算复杂性。</p><p>随机变分推断 [HBWP13] 最近受到越来越多的关注。 最近，[BJP12] 引入了一种控制变量方案，以减少 2.1 节中讨论的朴素梯度估计器的高方差，并应用于后验的指数族近似。 在 [RGB13] 中，引入了一些通用方法，即控制变量方案，以减少原始梯度估计器的方差。 在 [SK13] 中，与本文类似的重新参数化被用于随机变分推理算法的有效版本中，用于学习指数族近似分布的自然参数。</p><p>AEVB 算法揭示了有向概率模型（用变分目标训练）和自动编码器之间的联系。 线性自编码器和某类生成线性高斯模型之间的联系早已为人所知。 在 [Row98] 中表明，PCA 对应于线性高斯模型特例的最大似然 (ML) 解，其中先验 $p(z) = N (0, I)$ 和条件分布 $p(x |z) = N (x; Wz, \epsilon I)$，特别是 ε 无限小的情况。</p><p>在最近关于自编码器 [VLL+10] 的相关工作中，表明非正则化自编码器的训练标准对应于输入 $X$ 和潜在之间的互信息的下限（参见 infomax 原则 [Lin89]）的最大化 表示 $Z$ 。互信息最大化（wrt参数）等价于最大化条件熵，其下限为自编码模型[VLL+10]下数据的预期对数似然，即负重构误差 .然而，众所周知，这种重建标准本身不足以学习有用的表示[BCV13]。已经提出了正则化技术来使自编码器学习有用的表示，例如去噪、收缩和稀疏自编码器变体 [BCV13]。 SGVB 目标包含一个由变分界规定的正则化项（例如 eq. (10)），缺少学习有用表示所需的通常令人讨厌的正则化超参数。相关的还有编码器-解码器架构，例如预测稀疏分解 (PSD) [KRL08]，我们从中汲取了一些灵感。同样相关的是最近引入的生成随机网络 [BTL13]，其中嘈杂的自动编码器学习从数据分布中采样的马尔可夫链的转换算子。在 [SL10] 中，一个识别模型被用于使用深度玻尔兹曼机器进行高效学习。这些方法要么针对非归一化模型（即像玻尔兹曼机这样的无向模型），要么仅限于稀疏编码模型，这与我们提出的用于学习一类有向概率模型的通用算法相反。</p><p>最近提出的 DARN 方法 [GMW13] 也使用自编码结构学习有向概率模型，但是他们的方法适用于二进制隐变量。 甚至最近，[RMW14] 还使用我们在本文中描述的重新参数化技巧在自动编码器、定向概率模型和随机变分推理之间建立了联系。 他们的工作是独立于我们开发的，并为 AEVB 提供了额外的视角。</p><h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><p>我们训练了来自 MNIST 和 Frey Face 数据集的图像生成模型，并在变分下限和估计的边际似然方面比较了学习算法。</p><p>使用了第 3 节中的生成模型（编码器）和变分近似（解码器），其中描述的编码器和解码器具有相同数量的隐藏单元。 由于 Frey Face 数据是连续的，我们使用了具有高斯输出的解码器，与编码器相同，只是在解码器输出处使用 sigmoidal 激活函数将均值限制在区间 (0, 1)。 请注意，对于隐藏单元，我们指的是编码器和解码器的神经网络的隐藏层。</p><p>使用随机梯度上升更新参数，其中梯度是通过区分下界估计量 $∇_{\theta,\phi} L(θ, \phi; X)$ 计算的（参见算法 1），加上对应于先验 $p(θ) = N(0,I)$ 的小权重衰减项 。 该目标的优化等效于近似 MAP 估计，其中似然梯度由下限的梯度近似。</p><p>我们将 AEVB 的性能与唤醒睡眠算法 [HDFN95] 进行了比较。 我们为唤醒睡眠算法和变分自编码器采用了相同的编码器（也称为识别模型）。 所有参数，无论是变分参数还是生成参数，都通过从 $N(0,0.01)$ 中随机抽样进行初始化，并使用 MAP 标准进行联合随机优化。 使用 Adagrad [DHS10] 调整步长； Adagrad 全局步长参数是根据前几次迭代中训练集的性能从 {0.01, 0.02, 0.1} 中选择的。 使用大小为 M = 100 的小批量，每个数据点 L = 1 个样本。</p><p><img src="https://s4.ax1x.com/2022/02/18/Ho0z1H.png" alt=""></p><p><strong>Likelihood lower bound</strong> 我们训练了生成模型（解码器）和相应的编码器（又名识别模型），在 MNIST 的情况下具有 500 个隐藏单元，在 Frey Face 数据集的情况下具有 200 个隐藏单元（以防止过度拟合，因为它是一个相当小的数据集）。 隐藏单元的选择数量是基于先前关于自编码器的文献，不同算法的相对性能对这些选择不是很敏感。 图 2 显示了比较下限时的结果。 有趣的是，多余的隐变量不会导致过拟合，这可以通过变分界的正则化性质来解释。</p><p><strong>Marginal likelihood</strong> 对于非常低维的隐空间，可以使用 MCMC 估计器估计学习生成模型的边际似然。 有关边际似然估计量的更多信息，请参见附录。 对于编码器和解码器，我们再次使用了神经网络，这次有 100 个隐藏单元和 3 个隐变量； 对于更高维的潜在空间，估计变得不可靠。 同样，使用了 MNIST 数据集。 将 AEVB 和 Wake-Sleep 方法与具有混合蒙特卡罗 (HMC) [DKPR87] 采样器的蒙特卡罗 EM (MCEM) 进行了比较； 详细信息在附录中。 我们比较了三种算法的收敛速度，分别用于小型和大型训练集。 结果如图 3 所示。</p><p><img src="https://s4.ax1x.com/2022/02/18/HoDZa6.png" alt=""></p><p><strong>Visualisation of high-dimensional data</strong> 如果我们选择低维潜在空间（例如 2D），我们可以使用学习到的编码器（识别模型）将高维数据投影到低维流形。 有关 MNIST 和 Frey Face 数据集的 2D 潜在流形的可视化，请参见附录 A。</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>我们引入了一种新的变分下界估计器，随机梯度 VB (SGVB)，用于使用连续潜在变量进行有效的近似推断。 所提出的估计器可以使用标准随机梯度方法直接区分和优化。 对于 i.i.d. 数据集和每个数据点的连续潜在变量 我们引入了一种高效的推理和学习算法，即自编码 VB (AEVB)，它使用 SGVB 估计器学习近似推理模型。 理论优势体现在实验结果中。</p><h2 id="Future-work"><a href="#Future-work" class="headerlink" title="Future work"></a>Future work</h2><p>由于 SGVB 估计器和 AEVB 算法可以应用于几乎任何具有连续隐变量的推理和学习问题，因此有很多未来方向：</p><ul><li>使用用于编码器的深度神经网络（例如卷积网络）学习分层生成架构 和解码器，与 AEVB 联合训练； </li><li>时间序列模型（即动态贝叶斯网络）；</li><li>将 SGVB 应用于全局参数； </li><li>具有隐变量的监督模型，可用于学习复杂的噪声分布。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Auto-Encoding-Variational-Bayes&quot;&gt;&lt;a href=&quot;#Auto-Encoding-Variational-Bayes&quot; class=&quot;headerlink&quot; title=&quot;Auto-Encoding Variational Baye</summary>
      
    
    
    
    
    <category term="Active Learning" scheme="http://example.com/tags/Active-Learning/"/>
    
  </entry>
  
  <entry>
    <title>A Survey of Active Learning for Text Classification Using Deep Neural Networks</title>
    <link href="http://example.com/2022/02/21/A-Survey-of-Active-Learning-for-Text-Classification-Using-Deep-Neural-Networks/"/>
    <id>http://example.com/2022/02/21/A-Survey-of-Active-Learning-for-Text-Classification-Using-Deep-Neural-Networks/</id>
    <published>2022-02-21T02:03:15.000Z</published>
    <updated>2022-02-21T02:05:10.504Z</updated>
    
    <content type="html"><![CDATA[<h1 id="A-Survey-of-dy-for-Text-Classification-Using-Deep-Neural-Networks"><a href="#A-Survey-of-dy-for-Text-Classification-Using-Deep-Neural-Networks" class="headerlink" title="A Survey of dy for Text Classification Using Deep Neural Networks"></a>A Survey of dy for Text Classification Using Deep Neural Networks</h1><p>通过利用NN的卓越文本分类性能进行Active Learning (AL)，我们可以使用相同数量的数据提高模型的性能，或者减少数据，从而减少所需的注释工作，同时保持相同的性能。</p><p>我们回顾了使用深度神经网络(DNNs)进行文本分类的AL，并阐述了阻碍其采用的两个主要原因：</p><ul><li>NNs无法提供可靠的不确定性估计，这是最常用的查询策略所依赖的</li><li>在小数据上训练DNN的挑战。</li></ul><p>为了研究前者，我们构建了一个查询策略分类，区分了<strong>基于数据、基于模型和基于预测</strong>的实例选择，并调查了这些类别在最近的研究中的流行情况。</p><p>通过利用NN的卓越文本分类性能进行AL，我们可以使用相同数量的数据提高模型的性能，或者减少数据，从而减少所需的注释工作，同时保持相同的性能。</p><p>最后，我们分析了AL在文本分类方面的最新工作，将各自的查询策略与分类法联系起来，并概述了它们的共性和不足。因此，我们强调了当前研究中的差距，并提出了开放的研究问题。</p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>数据是机器学习应用的燃料，因此其价值一直在稳步增长。在许多设置中，产生了大量的未标记数据，但是为了在有监督的机器学习中使用这些数据，除了提供标记之外别无选择。这通常需要手动标记过程，这通常不是微不足道的，甚至可能需要领域专家，例如在专利分类[52，23]或临床文本分类[75，24，28]中。</p><p>此外，这很耗时，并且迅速增加了货币成本，因此很快就使这种方法变得不可行。即使有专家，由于现代数据集的巨大规模，通常也不可能标记每个数据。这尤其阻碍了自然语言处理(NLP)领域，在自然语言处理领域，每个文档中的数据集和文本量都可能是巨大的，导致人类专家无法承受大量的注释工作。</p><p>主动学习(AL)旨在减少人类专家标注的数据量。这是一个 oracle (通常是人工注释者)和 active learner 之间的迭代循环过程。<strong>与被动学习不同的是，在被动学习中，数据被简单地馈送到算法中，主动学习者选择下一步要标记哪些样本。</strong>然而，标签本身是由人类专家完成的，也就是所谓的圈中人。在收到新标签后，active learner 训练一个新模型，这个过程从头开始。使用主动学习者这个术语，我们指的是一个模型、一个查询策略和一个停止标准的组成。</p><p>在这项工作中，模型是w.l.o.g.文本分类模型，<strong>查询策略决定哪些实例应该被贴上标签</strong>，而<strong>停止标准定义了何时停止AL循环</strong>。根据Settles[85]的说法，AL有三种主要情况。</p><ul><li>Pool-based : 在这种情况下，学习者可以访问封闭的未标记的实例集，称为池。</li><li>Stream-based : 学习者一次收到一个实例，可以选择保留或丢弃。</li><li>membership query synthesis : 学习者创建新的人工实例来进行标记。</li></ul><p>如果基于池的方案不是在单个实例上操作，而是在一批实例上操作，这被称为批模式batch-model AL[85]。在整个工作中，我们假设了一个基于池的批处理方案，因为在文本分类设置中，数据集通常是一个封闭的集合，而批处理操作减少了再训练操作的数量，这将导致用户的等待时间。</p><p><strong>AL的基本思想是，少数有代表性的实例可以作为完整数据集的代用品。</strong>不仅较小的数据子集可以降低计算成本，而且已经证明，与在完整数据集上学习相比，AL甚至可以提高所产生模型的质量[83, 24]。因此，AL已经被用于许多NLP任务中，例如文本分类[95, 39]，命名实体识别[88, 94, 89]，或机器翻译[35]，并且仍然是一个活跃的研究领域。</p><p>对于AL从业者来说，这意味着用更少的样本达到相同的性能，或者用相同的数据量提高性能。</p><p>一个有利的发展是，迁移学习，特别是微调预训练的语言模型（LMs）的范式，已经在NLP中流行。在AL的背景下，这尤其有助于小数据情况下的训练，在这种情况下，可以利用预训练的模型，只用很少的数据进行微调来训练一个模型，否则是不可行的。最后，通过对子词单元的操作，LM还可以处理词汇外的标记，这比许多传统方法更有优势。</p><p>尽管NN目前很受欢迎，但在NLP的背景下，关于基于NN的主动学习的研究却很少，在文本分类的背景下就更少了。这是由于以下原因造成的。</p><ul><li>许多DL模型都需要大量的数据[103]，这与旨在需要尽可能少的数据的AL形成了强烈的对比；</li><li>有一个基于人工数据生成的整体AL方案，不幸的是，这对于文本来说更具挑战性，而对于图像来说，数据增强通常用于分类任务[100]；</li><li>NNs缺乏关于其预测的不确定性信息（如第3.2节所述），这使得使用整个突出类别的查询策略变得复杂。</li></ul><p>本文旨在总结现有的基于(D)NN的AL文本分类方法。我们的主要贡献如下：</p><ul><li>我们提供了一个查询策略的分类法，并对与文本分类的AL相关的策略进行分类。</li><li>我们调查了在AL、文本分类和（D）NN的交叉点上的现有工作。</li><li>文本分类的最新进展被总结出来并与AL过程相关。然后调查了它们是否以及在多大程度上被应用于AL。</li><li>在数据集、模型和查询策略方面，对以往研究的实验设置进行了集体分析，以确定实验中的最新趋势、共性和不足之处。</li><li>我们确定了研究差距并概述了未来的研究方向。</li></ul><p>因此，我们对基于NN的主动文本分类的最新进展进行了全面调查。在回顾了这些最新进展之后，我们阐明了需要重新评估的领域，或者尚未在最近的背景下进行评估的领域。作为最后的结果，我们提出了研究问题，概述了未来的研究范围。</p><h2 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h2><p>Settles[85]提供了一个一般的主动学习综述，总结了普遍的AL场景类型和查询策略。他们介绍了基本的AL设置的变化，如可变的标签成本或替代的查询类型，最值得一提的是，他们讨论了调查AL有效性的经验和理论研究 :他们提到的研究表明，AL在实践中是有效的，并在现实世界的应用中越来越多地得到了采用。然而，有人指出，实证研究也报告了AL比被动学习表现更差的案例，而且对AL的理论分析也不完整。最后，说明了与相关研究领域的关系，从而将AL与强化学习和半监督学习等联系起来。</p><p>Fu, Zhu, and Li[25]的综述主要围绕着对基于不确定性的查询策略的全面分析，这些策略被归类为一个分类法。这个分类法在最顶层<strong>区分了i.i.d.实例的不确定性和实例的关联性。后者是前者的超集，旨在通过在查询时考虑特征、标签和结构的相关性来减少实例间的冗余</strong>。此外，他们对每种查询策略进行了算法分析，并按各自的时间复杂度对策略进行排序，强调了基于相关性的策略的复杂度增加。</p><p>Aggarwal等人[1]进行了另一项涵盖广泛主题的一般性调查。他们提供了一个查询策略的平面分类，这与Fu, Zhu, and Li[25]的分类法大相径庭，将其分为以下三类：</p><ul><li>“基于异质性”，通过预测的不确定性或与现有标记实例的不相似性对实例进行采样。</li><li>“基于性能”，根据模型损失的预测变化来选择实例</li><li>“基于代表性”，选择数据点以反映更大的集合的属性，通常通过分布密度的手段实现[1]。</li></ul><p>与[85]类似，他们提出并讨论了许多非标准的主动学习场景的变化。</p><p>Olsson[71]进行了一项以NLP为重点的主动学习综述。这项工作的主要贡献是对基于分歧的查询策略的调查，该策略使用多个分类器之间的分歧来选择实例。此外，Olsson回顾了一些实际的考虑，例如，选择初始种子集，决定基于流和基于池的方案，以及决定何时终止学习过程。</p><p>虽然提到了一些基于NN的应用，但上述调查都没有深入地涵盖基于NN的AL。此外，没有一个是最近才涵盖NN架构的，这些架构最近才被成功地适应于文本分类问题，例如KimCNN[48]。NLP的最新进展也是如此，如词嵌入、上下文语言模型（在第4.1节中解释），或由此产生的文本分类的进展（在第4.1节和第4.2节中讨论）。我们打算在本调查的剩余部分填补这些空白。</p><h2 id="Active-Learning"><a href="#Active-Learning" class="headerlink" title="Active Learning"></a>Active Learning</h2><p><strong>AL的目标是使用尽可能少的标记实例来创建一个模型，即最大限度地减少 oracle 和主动学习者之间的相互作用。</strong>AL的过程（如图1所示）如下：</p><p><img src="https://s4.ax1x.com/2022/02/11/Hagr3d.png" alt="img"></p><p>oracle 从主动学习者那里请求未标记的实例（查询，见图1：步骤1），然后由主动学习者（根据选定的查询策略）选择这些实例并传递给oracle（见图1：步骤2）。随后，这些实例被 oracle 标记并返回给主动学习者（更新，见图1：步骤3）。在每个更新步骤之后，主动学习者的模型被重新训练，这使得这个操作至少和基础模型的训练一样昂贵。这个过程不断重复，直到达到停止标准（例如，最大的迭代次数或分类精度变化的最小阈值）。</p><p><strong>AL最重要的组成部分是查询策略。</strong>在介绍中，我们声称很大一部分的查询策略是基于不确定性的。为了分析这一点，我们在下面的章节中提供了一个查询策略的分类，并强调了涉及不确定性的部分。关于AL的一般和更详细的介绍，请参考Settles[85]和Aggarwal等人[1]的调查。</p><h3 id="Query-Strategies"><a href="#Query-Strategies" class="headerlink" title="Query Strategies"></a>Query Strategies</h3><p>在图2中，我们根据策略的输入信息对最常见的AL查询策略进行了分类，输入信息表示一个策略所操作的数字值。在我们的分类法中，输入信息可以是随机的，也可以是数据、模型和预测中的一种。</p><p><img src="https://s4.ax1x.com/2022/02/11/HahnFf.png" alt="img"></p><p>这些类别是按照复杂性的增加来排序的，并不是相互排斥的。显然，模型是数据的一个函数，而预测也是模型和数据的一个函数，此外，在许多情况下，一个策略会使用这些标准中的多个标准。在这种情况下，我们将查询策略归入最具体的类别（即基于预测的先于基于模型的，而基于模型的又先于基于数据的）。</p><ul><li>Random: 传统上，随机性被用作许多任务的基线。在这种情况下，随机抽样是随机选择实例，是AL实例选择的一个强有力的基线[55, 83, 81]。它的表现往往比更复杂的策略更有竞争力，特别是当标签池变得更大时[84, 22]。</li><li>Data-based : 基于数据的策略具有最低水平的知识，即它们只对原始输入数据和可选的标签池的标签进行操作。我们把它们进一步分为：（1）依靠数据不确定性的策略，它可能使用关于数据分布、标签分布和标签相关性的信息，以及（2）代表性，它试图通过使用较少的代表性实例来代表整体的属性，来几何地压缩一组点。</li><li>Model-based ：基于模型的策略类具有关于数据和模型的知识。这些策略根据模型给定的实例所提供的措施来查询实例。这方面的一个例子是对模型解释给定实例的信心的衡量[26]，例如，模型对遇到的特征的可靠程度。这也可以是一个预期的量，例如在梯度的大小方面[86]。虽然仍然可以从模型中获得预测，但我们施加了一个限制，即目标度量必须是模型的一个（观察到的或预期的）数量，不包括最终预测。基于模型的不确定性是这里值得注意的一个子类，它利用模型的权重的不确定性来操作[26]。Sharma和Bilgic[87]描述了一个类似的类别，其中的不确定性源于在训练数据中没有找到足够的证据，也就是说，在训练时未能分离出类别。他们把这种不确定性称为证据不足的不确定性。</li><li>Prediction-based ： 基于预测的策略通过对预测输出的评分来选择实例。这一类中最突出的成员是基于预测不确定性和基于分歧的方法。Sharma和Bilgic[87]用冲突证据不确定性来表示基于预测的不确定性，他们与这项工作相反，将其视为基于模型的不确定性的另一种形式。基于模型的不确定性和基于预测的不确定性这两个概念之间有时只有一线之隔。粗略地说，基于预测的不确定性在分类环境中对应于类间不确定性，而基于模型的不确定性则对应于类内不确定性。在文献中，不确定性采样[55]通常指的是基于预测的不确定性，除非另有说明。</li><li>Ensembles ：当一个查询策略结合了其他多个策略的输出时，这被称为集成。由于一些原因，我们只在分类法中对集合策略的概念进行了分类（见图2中基于分歧的子类），而没有详细说明。(1) 集合体又是由原始的查询策略组成，可以用我们的分类法进行分类。(2) 组合体可以是混合体，即它们可以是不同类别的查询策略的混合体。此外，集合体的输出通常是单个分类器之间分歧的函数，这在Olsson[71]和Fu, Zhu, and Li[25]以前的调查中已经涉及。</li></ul><p>我们并不是第一个提供查询策略分类的人。Aggarwal等人[1]提供了另一种分类，将查询策略分为基于异质性的模型、基于性能的模型和基于代表性的模型。基于异质性的模型试图对不同的数据点进行采样，而不是对当前的标签库进行采样。这类模型包括不确定性抽样和合集，也就是说，合集和单一模型策略之间没有区别。基于性能的模型旨在以提高模型性能为目标进行数据采样，例如减少模型的误差。这与我们的基于模型的类别有交叉，然而，它缺乏关注参数变化（例如，预期梯度长度[86]）而不是指标变化的策略。最后，基于代表性的策略对实例进行抽样，使子样本的分布与训练集尽可能地相似。尽管与我们基于数据的类别相似，但它们总是假设存在一个模型，而基于数据的策略则不然。</p><p>Fu, Zhu和Li[25]将查询策略分为基于不确定性和基于多样性两类。基于不确定性的策略假设实例的i.i.d.分布；他们为每个实例计算单独的分数，这是选择实例的基础。基于多样性的策略是其超集，还考虑了实例之间的相关性。因此，他们将不确定性和相关性作为查询策略的关键组成部分。这种分类法通过完全考虑不确定性和相关性，成功地区分了查询策略。然而，它在输入信息方面不太透明，而我们的分类法强调了这一点。然而，相关性是一个与我们的分类法正交的因素，可以作为一个额外的标准加入。</p><p>在创建了我们的分类法之后，我们发现了最近对深度学习中的不确定性的分类[26]，它区分了数据-、模型-和预测-的不确定性，类似于分类法的第一个层次（基于数据、模型、预测的查询策略）。虽然这种分类自然来自于数据的处理程度，但我们强调，我们不是第一个提出这种抽象概念的人。</p><p>通过使用输入信息作为决定性的标准，这个分类法提供了一个以信息为导向的查询策略观点。它强调了在现有的查询策略中，哪些部分以及如何涉及到不确定性。然而，如第3.2节所述，就NN而言，不确定性是具有挑战性的。此外，我们在第4.3节中使用分类法对最近在文本分类方面的AL工作进行了分类。</p><h3 id="Neural-Network-Based-Active-Learning"><a href="#Neural-Network-Based-Active-Learning" class="headerlink" title="Neural-Network-Based Active Learning"></a>Neural-Network-Based Active Learning</h3><p>在这一节中，我们调查了这样一个问题：为什么神经网络在AL应用中没有更普遍的应用。这可以归结为两个中心议题。<strong>神经网络的不确定性估计</strong>，以及<strong>需要大数据的神经网络和处理小数据的AL之间的对比</strong>。我们从NN的角度来研究这些问题，缓解NLP的焦点。</p><p><strong>Previous Work</strong></p><p>基于NN的AL的早期研究可以分为基于不确定性的[16]，和基于集合的[50, 63]策略。前者通常使用预测熵[62, 81]作为不确定性的衡量标准，而后者则利用单个分类器之间的分歧。Settles, Craven和Ray[86]提出了预期梯度长度（EGL）查询策略，该策略通过模型权重的预期变化来选择实例。Zhang, Lease和Wallace [104]是第一个将CNN用于AL的人。他们提出了一个预期梯度长度策略的变种[86]，在这个策略中，他们选择了预期会导致嵌入空间最大变化的实例，从而训练了高度鉴别性的表示。Sener和Savarese[84]观察到基于不确定性的查询策略对基于CNN的批处理模式AL并不有效，并提出了核心集选择，即对一个小的子集进行采样以代表整个数据集。Ash等人[5]提出了BADGE，一种用于DNN的查询策略，它在最后一层的梯度上使用k-means++播种[4]，以便通过不确定性和多样性来查询。</p><p>最后，生成对抗网络（GANs; [30]）也被成功应用于AL任务。Zhu和Bento[106]使用GANs在一个使用SVM模型的主动学习器中对图像进行查询合成。实例被合成，因此它们将被分类为具有高度不确定性。作者报告说，这种方法优于随机抽样、使用SVM的基于池的不确定性抽样[95]，在某些情况下也优于被动学习，但其弱点是产生的实例过于相似。该方法本身既不是纯粹的基于NN的方法，也不属于基于池的方案，然而，它是第一个报道的将GANs用于AL的方法。Ducoffe和Precioso[22]使用对抗性攻击来寻找跨越决策边界的实例，目的是提高模型的稳健性。他们训练了两种CNN架构，并报告了在图像分类任务上优于核心集[84]策略的结果。很明显，GANs本质上属于成员查询综合的场景。因此，它们的性能与人工数据合成的质量相关，也就是说，它们通常对NLP任务不是那么有效。这一点已经被认识到了，并且已经对更好的文本生成进行了首次改进[105]。</p><p><strong>Uncertainty in Neural Networks</strong></p><p>最早并在许多变化中采用的一类策略是不确定性采样[83, 95]。不幸的是，这个被广泛使用的概念并不能直接应用于NN，因为它们并不提供固有的不确定性指标。在过去，这个问题已经通过集合[50, 36, 12]，或通过学习误差估计[70]来解决。最近的方法进一步使用贝叶斯扩展[11]，使用dropout获得不确定性估计[91，27]，或使用概率NN来估计预测的不确定性[51]。然而，在较大的数据集上，集合和贝叶斯方法很快就变得不可行了，而且众所周知，NN架构对其预测过于自信[33, 51]。因此，NN的不确定性只是没有得到充分的解决，因此仍然是一个高度相关的研究领域。</p><p><strong>Contrasting Paradigms</strong></p><p>众所周知，DNN尤其在大规模数据集方面表现出色，但往往拥有大量的数据是对其表现的严格要求（例如，[103]）。另一方面，AL试图最小化标记的数据。小的标记数据集对DNN来说是一个问题，因为它们在小的数据集上已知会过度拟合（例如，[93，100]），这导致测试集上的泛化性能不好。此外，DNN在使用小数据集进行训练时，往往比浅层模型没有什么优势[89]，因此缺乏对其较高计算成本的证明。另一方面，我们显然不能要求AL来标记更多的数据，因为这将违背它的目的。因此，已经有关于使用小数据集处理（D）NN的研究，然而，这只是一个稀缺的数量，特别是相对于一般的NN文献的大量内容而言。处理小数据集大多是通过使用预训练[37, 97]或其他转移学习方法[13, 8, 97]来规避的。最后，对最佳超参数的搜索常常被忽视，而是使用相关工作的超参数，这些参数是为大数据集优化的，如果有的话。</p><h2 id="Active-Learning-for-Text-Classification"><a href="#Active-Learning-for-Text-Classification" class="headerlink" title="Active Learning for Text Classification"></a>Active Learning for Text Classification</h2><p>在第4.1和4.2节中，我们首先总结了最近的文本分类和NNs的方法。我们阐述了每种方法在AL背景下的重要性，并分析了最近的研究对其的采用情况。对于未被充分采用的方法，我们介绍了它们如何能够推动文本分类的AL。最重要的是，我们概述了最近在文本分类方面的AL实验，并分析了共同点和缺点。</p><h3 id="Recent-Advances-in-Text-Classification"><a href="#Recent-Advances-in-Text-Classification" class="headerlink" title="Recent Advances in Text Classification"></a>Recent Advances in Text Classification</h3><p><strong>Representations</strong> 传统的方法使用词袋（BoW）表示，它是稀疏和高维的。然而，随着word2vec[66, 65]、GloVe[74]或fastText[46]等词嵌入的引入，词嵌入在许多情况下已经取代了BoW表示。这是由几个原因造成的。</p><ul><li>(1)它们在向量空间中表示语义关系，避免了例如由于同义词造成的特征不匹配问题；</li><li>(2)纳入词嵌入后，在许多下游任务中表现出色[66, 74, 46] 。</li><li>(3) 与词袋不同，词向量是密集的、低维的表示，这使得它们适用于更广泛的算法—特别是在有利于固定大小输入的NN的背景下。为了获得类似的固定大小的词序列表示，即句子、段落或文件，已经提出了各种方法[53]。</li></ul><p>词嵌入是一种表征，它为每个词提供一个向量，因此也提供一个含义。这使得它们也不知道当前单词的上下文，因此无法检测和处理歧义。与词嵌入不同，语言模型（LMs）使用单词和周围的语境来计算单词向量[76]。这就产生了一个上下文表示法，它继承了词嵌入的优点，同时允许针对具体语境的表示（与静态嵌入相反）[76]。ELMo是第一个获得广泛采用的LM，并在几个NLP任务上超过了最先进的模型[76]。此后不久，BERT[20]被引入，提供了基于双向预训练的语言建模。创建基于BERT的模型的过程包括一个预训练和一个微调步骤，与ELMO的直接基于特征的方法相反，在这种方法中，从预训练的模型中获得上下文向量并直接作为特征使用[20]。通过屏蔽，即在训练过程中随机删除一部分标记，训练被调整为预测被屏蔽的单词。这使得双向训练成为可能，否则会受到阻碍，因为在计算给定上下文的出现概率时，一个词可以 “看到自己”[20]。在此之后，XLNet[102]引入了类似的使用自回归语言模型进行预训练和微调的方法，然而，它克服了BERT的局限性，因为它在预训练过程中不依赖屏蔽数据[102]，而且，成功地整合了最近的TransformerXL架构[17]。此后，各种LM相继发表，它们进一步优化了以前LM架构的预训练（如RoBERTa[59]和ELECTRA[15]），或者将知识提炼成一个较小的模型（如DistilBERT[82]）。与词嵌入类似，也有使用LM的方法，以便从LM中获得句子表示[80]。</p><p>所有提到的表示法都比传统的BoW表示法提供了更丰富的表现力，因此非常适合主动学习的目的。</p><p><strong>Neural-Network-Based Text Classification</strong> Kim[48]提出的一个著名的CNN架构（KimCNN）在预先训练好的单词向量上运行，并且只用一个简单而优雅的架构就取得了当时最先进的结果。所调查的CNN设置不需要太多的超参数调整，并证实了dropout[91]作为基于CNN的文本分类的正则器的有效性。</p><p>fastText[46]的词嵌入与其他词嵌入不同，因为该方法（1）有监督，（2）专门为文本分类设计。作为一个浅层神经网络，它仍然非常有效，同时仍然获得了与当时的深度学习方法相当的性能。</p><p>Howard和Ruder[41]开发了通用语言模型微调（ULMFiT），这是一种使用AWD-LSTM架构的LM转移学习方法[64]，在几个文本分类数据集上，当只对100个标记的例子进行训练时，其表现优于目前的技术水平，从而取得了明显优于以前工作中更复杂架构的结果。像BERT[20]和XLNet[102]这样的特定语境的LM为每个标记产生一个与语境相关的向量，从而有力地改善了基于NN的文本分类[20, 102, 92]。在基于NN的文本分类中，最先进的是基于LM的XLNet微调，它在测试错误率方面比BERT略胜一筹[102, 92]。ULMFiT紧随其后，而KimCNN仍然是一个强有力的竞争者。值得注意的是，ULMFiT、BERT和XLNet都进行转移学习，其目的是将知识从一个模型转移到另一个模型[79, 13]，从而大量减少所需的数据量。</p><h3 id="Text-Classification-for-Active-Learning"><a href="#Text-Classification-for-Active-Learning" class="headerlink" title="Text Classification for Active Learning"></a>Text Classification for Active Learning</h3><p>传统的文本分类的AL严重依赖于基于预测-不确定性的查询策略[55]和集合[58]。常见的模型选择包括支持向量机（SVMs；[95]）、朴素贝叶斯[69]、逻辑回归[39]和神经网络[50]。据我们所知，以前的调查没有涵盖用于文本分类的传统AL，然而，Olsson[71]已经深入介绍了用于NLP的基于集合的AL。</p><p>关于现代基于NN的文本分类的AL，相关模型主要是基于CNN和LSTM的深度架构。Zhang, Lease和Wallace[104]声称他们是第一个考虑使用DNN进行文本分类的AL。他们使用CNN并贡献了一个查询策略，该策略根据单词嵌入的预期变化和模型给定的不确定性来选择实例，从而学习用于文本分类的判别性嵌入。An, Wu和Han[2]评估了SVM、LSTM和门控递归单元（GRU; Cho等人[14]）模型，并报告说后两者在中国新闻数据集ThucNews上的表现明显优于SVM基线。Lu和MacNamee[61]研究了不同文本表示法在基于池的AL场景中的表现。此外，他们使用这一策略获得了一个代理数据集（包括总数据的5%到40%），在此基础上使用ULMFiT[41]训练基于LSTM的LM，达到了接近于在完整数据集上训练的准确性。与过去的出版物不同，他们报告说这种<strong>基于不确定性的策略是有效的、稳健的，同时在计算上也很便宜</strong>。这是文本分类、NN和DL之间的交叉点方面最相关的工作。</p><h3 id="Commonalities-and-Limitations-of-Previous-Experiments"><a href="#Commonalities-and-Limitations-of-Previous-Experiments" class="headerlink" title="Commonalities and Limitations of Previous Experiments"></a>Commonalities and Limitations of Previous Experiments</h3><p>表1显示了最新的文本分类实验的AL，它们都比Settles[85]和Olsson[71]的调查要新。对于每个出版物，我们列出了所使用的数据集、模型和查询策略的类别（关于第3.1节中的分类法）。我们提出这个表格是为了了解最近喜欢的分类模型和查询策略类别。</p><p><img src="https://s4.ax1x.com/2022/02/15/HcO9Yt.png" alt="img"></p><p>我们可以从表1中得出多个结论：很明显，这些查询策略中的绝大多数属于基于预测的查询策略，更具体地说，属于基于预测的不确定性和基于分歧的子类。除此之外，我们还可以发现一些不足之处。首先，在许多实验中，有两个或更多的标准数据集被评估，但很多时候，这些实验在数据集方面几乎没有交集。因此，我们失去了与以往研究的可比性。</p><p>我们可以从表1中得出多个结论：很明显，这些查询策略中的绝大多数属于基于预测的查询策略，更具体地说，属于基于预测的不确定性和基于分歧的子类。除此之外，我们还可以发现一些不足之处。首先，在许多实验中，有两个或更多的标准数据集被评估，但很多时候，这些实验在数据集方面几乎没有交集。因此，我们失去了与以往研究的可比性。对于最近的研究，可以从表1中看出，唯一较大的交集是Zhang, Lease, and Wallace [104] 和Lowell, Lipton, and Wallace [60] 的作品之间。Siddhant和Lipton[90]通过各自的一个数据集，至少提供了与Zhang, Lease, and Wallace[104]和Lowell, Lipton, and Wallace[60]的一些可比性。此外，RMA[3]是R21[54]的一个子集，Bloodgood[10]和Hu, Mac Namee, and Delany[44]都使用了R21，所以它们在某种程度上可能具有可比性。[78]是唯一在较新的大规模文本分类数据集[103]上进行评估的，虽然这些数据集在规模上更真实，但作者省略了经典数据集，所以很难将他们的贡献与之前的工作联系起来。此外，由于这个原因，我们不知道过去的实验是否以及在何种程度上可以推广到DNN[78]。</p><p>最后，尚不清楚最近的（D）NN是否从相同的查询策略中受益，也就是说，过去的研究结果可能不适用于现代NN架构。Prabhu, Dognin和Singh[78]在最近的文献中发现了关于使用预测不确定性与NN结合的有效性的相互矛盾的说法。他们使用FastText.zip（FTZ）模型和预测不确定性查询策略取得了有竞争力的结果，事实证明，尽管所有报道的关于NN和不确定性估计的弱点，但在只需要少量数据的情况下，还是非常有效。</p><h2 id="Open-Research-Questions"><a href="#Open-Research-Questions" class="headerlink" title="Open Research Questions"></a>Open Research Questions</h2><p><strong>Uncertainty Estimates in Neural Networks</strong> 在第3节中，说明了基于不确定性的策略已经成功地与非NN模型结合使用，在第4.3节中，说明了它们在最近基于NN的AL中也占了查询策略的最大部分。<strong>不幸的是，由于不确定性估计不准确，或者可扩展性有限</strong>（如第3.2节所述），NN的不确定性仍然是一个挑战。</p><p><strong>Representations</strong> 正如第4.1节所概述的，NLP中文本表示法的使用已经从词包转向静态和上下文的词嵌入。这些表示法显然提供了许多优势，如消歧义能力、非稀疏向量，以及许多任务的性能提高。尽管已经有一些应用[104, 78, 61]，但还没有专门针对AL的系统评估来比较使用NN的词嵌入和LMs。此外，它们目前只是很少被使用，这暗示着要么采用得很慢，要么是一些没有被调查的实际问题。</p><p><strong>Small Data DNNs</strong> DL方法通常是在大数据集的背景下应用的。然而，AL的目的是使（标记的）数据集尽可能的小。在第3节中，我们概述了为什么小数据集对DNN来说是个挑战，以及基于DNN的AL的一个直接后果。使用预训练的语言模型，这个问题在一定程度上得到了缓解，因为微调允许使用相当小的数据集训练模型。然而，要想成功地微调一个模型，还需要调查有多少数据是必要的。</p><p><strong>Comparable Evaluations</strong> 在第4.3节中，我们对文本分类中最常见的AL策略进行了概述。不幸的是，实验中使用的数据集的组合往往是完全不相干的，例如Siddhant和Lipton[90]，Lowell, Lipton和Wallace[60]，以及Prabhu, Dognin和Singh[78]。因此，可比性降低甚至丧失，特别是在最近和过去的工作之间。然而，可比性对于验证过去关于基于浅层NN的AL的见解是否仍然适用于基于DNN的AL[78]至关重要。</p><p><strong>Learning to Learn</strong> 有大量的查询策略可供选择，我们在第3.1节中对这些策略进行了（非详尽的）分类。这就引入了选择最优策略的问题。正确的选择取决于许多因素，如数据、模型或任务，甚至在AL过程中的不同迭代中也会有所不同。因此，学习学习(或元学习)已经变得很流行，可以用来学习最优选择[42]，甚至可以学习整个查询策略[6, 49]。</p><h2 id="Conclusions"><a href="#Conclusions" class="headerlink" title="Conclusions"></a>Conclusions</h2><p>在这项调查中，我们调查了基于(D)NN的文本分类的AL，并检查了阻碍其采用的因素。我们创建了一个分类法，通过它们对基于数据、基于模型和基于预测的输入信息的依赖来区分查询策略。我们分析了用于文本分类的AL的查询策略，并将它们归入各自的分类法类别。我们提出了AL、文本分类和DNN之间的交集，就我们所知，这是这个主题的第一次调查。此外，我们回顾了基于(D)NN的AL，确定了当前的挑战和技术状态，并指出它的研究不足，而且经常缺乏可比性。除此之外，我们还介绍了NLP的相关最新进展，将其与AL联系起来，并指出其应用的差距和限制。我们的主要发现之一是，无论分析是否限于NN，基于不确定性的查询策略仍然是使用最广泛的一类。基于LM的表征提供了更细粒度的上下文特定表征，同时也处理了词汇外的词汇。此外，我们发现基于微调的迁移学习在一定程度上缓解了小数据问题，但缺乏采用。最重要的是，DNN在许多任务上都有很强的性能，在AL中的首次采用也显示了很好的效果[104, 90]。所有这些成果对AL来说都是非常理想的。所有这些收益对AL来说都是非常理想的。因此，在AL中改进DNN的采用是至关重要的，特别是由于预期的性能提高可以在使用相同数量的数据时用于提高分类结果，或者通过减少数据和标签工作来提高标签过程的效率。基于这些发现，我们确定了未来工作的研究方向，以进一步推进基于（D）NN的AL。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;A-Survey-of-dy-for-Text-Classification-Using-Deep-Neural-Networks&quot;&gt;&lt;a href=&quot;#A-Survey-of-dy-for-Text-Classification-Using-Deep-Neura</summary>
      
    
    
    
    
    <category term="Active Learning" scheme="http://example.com/tags/Active-Learning/"/>
    
  </entry>
  
  <entry>
    <title>ZeroPrompt- Scaling Prompt-Based Pretraining to 1,000 Tasks Improves Zero-Shot Generalization</title>
    <link href="http://example.com/2022/02/21/ZeroPrompt-Scaling-Prompt-Based-Pretraining-to-1-000-Tasks-Improves-Zero-Shot-Generalization/"/>
    <id>http://example.com/2022/02/21/ZeroPrompt-Scaling-Prompt-Based-Pretraining-to-1-000-Tasks-Improves-Zero-Shot-Generalization/</id>
    <published>2022-02-21T01:56:43.000Z</published>
    <updated>2022-02-21T02:01:42.902Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ZeroPrompt-Scaling-Prompt-Based-Pretraining-to-1-000-Tasks-Improves-Zero-Shot-Generalization"><a href="#ZeroPrompt-Scaling-Prompt-Based-Pretraining-to-1-000-Tasks-Improves-Zero-Shot-Generalization" class="headerlink" title="ZeroPrompt: Scaling Prompt-Based Pretraining to 1,000 Tasks Improves Zero-Shot Generalization"></a>ZeroPrompt: Scaling Prompt-Based Pretraining to 1,000 Tasks Improves Zero-Shot Generalization</h1><p><strong>任务数量极大的情况下，模型大小对性能的影响很小…</strong></p><blockquote><p>论文地址: <em><a href="https://arxiv.org/pdf/2201.06910.pdf">https://arxiv.org/pdf/2201.06910.pdf</a></em></p></blockquote><p>XLNet作者杨植麟团队发布了首个中文多任务Prompt统一模型：ZeroPrompt。研究的重点是 【任务的规模】 和 【zero-shot】 的 prompting。</p><p>以前的模型只在几十个任务上进行训练，ZeroPrompt 使用真实世界的数据将其扩展到1000个任务（中文数据）。这导致了一个重要的发现，即<strong>任务规模可以成为模型尺寸的有效替代方案</strong>； 即，<strong>模型尺寸对大量任务的性能影响很小</strong>。</p><p>此外，该文还提出了一种结合了遗传算法来自动搜索 unseen 任务的最佳 prompt。 </p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>众所周知，prompt 可以激发语言模型的潜力，避免预训练和Fine tuning 之间的gap，并且是一个非常 Parameter-Efficient 的调整方法。不仅如此，Prompt 还可以对不同的NLP任务进行范式统一，统一为相同的数据形式。同时，受益于预训练语言模型的强大，就对多任务、多领域进行统一建模。</p><p> 最初，GPT-3 证明了通过在更大规模模型上使用 prompt 来实现零样本和少样本学习的可能性。 然而，与全监督微调相比，zero-shot 和 few-shot 泛化的性能在许多任务上仍然不足。</p><p>之前 FLAN 与 T0 分别探索了模型大小与 prompt数量对多任务预训练的性能和效率，但目前还不清楚扩展训练任务的数量的影响如何。</p><p>如图 1 所示，实证研究表明，任务扩展可以成为模型尺寸的有效替代方案：</p><p><img src="https://s4.ax1x.com/2022/02/17/H5ISCn.png" alt=""></p><p>由于训练任务非常多，模型大小对性能的影响很小。 此外，任务规模可以提高各种模型规模的性能。 对于参考基线，RoBERTa-Large 以完全监督的方式进行微调，而 Pangu Alpha 和 CPM-2 是 zero-shot prompted。 所有模型都用中文训练和评估。</p><p>除此之外，ZeroPrompt 还探索了，在多任务训练时：</p><ul><li>如何对不同任务类型更好地统一建模，Prompt如何设计？</li><li>应该选择哪些任务数据进行多任务训练呢？</li><li>对unseen domain的新任务如何获得高性能，如何自动构建Prompt？</li></ul><h2 id="ZeroPrompt"><a href="#ZeroPrompt" class="headerlink" title="ZeroPrompt"></a>ZeroPrompt</h2><h3 id="Zero-shot-Adaptation-with-Few-shot-Validation"><a href="#Zero-shot-Adaptation-with-Few-shot-Validation" class="headerlink" title="Zero-shot Adaptation with Few-shot Validation"></a>Zero-shot Adaptation with Few-shot Validation</h3><p>为了验证Prompt的效果，需要标注一些样本做验证集，论文将这一设置称为，“Zero-shot Adaptation with Few-shot Validation”，设置总结在下图:</p><p><img src="https://s4.ax1x.com/2022/02/18/HTVtW4.png" alt=""></p><h3 id="Datasets-for-scaling-to-1-000-tasks"><a href="#Datasets-for-scaling-to-1-000-tasks" class="headerlink" title="Datasets for scaling to 1,000+ tasks"></a>Datasets for scaling to 1,000+ tasks</h3><p>数据来源主要是学术界公开的数据集和工业生产数据，包括情感分析、新闻分类、推断、NER、MRC、摘要等多个任务。其中，公开数据集共80个。下图列出了每种任务类型中的任务数量：</p><p><img src="https://s4.ax1x.com/2022/02/18/HTmcfU.png" alt=""></p><p>一共的1110个任务数据上，有824个用作多任务预训练，剩余的286个数据是进行zero-shot测试的unseen任务。</p><h3 id="ZeroPrompt-的pipeline"><a href="#ZeroPrompt-的pipeline" class="headerlink" title="ZeroPrompt 的pipeline"></a>ZeroPrompt 的pipeline</h3><p><img src="https://s4.ax1x.com/2022/02/20/HLVtKg.png" alt=""></p><p>与传统的预训练-微调范式相比， ZeroPrompt 引入了两个关键差异：</p><ul><li>为所有下游任务提供通用模型，而不是为每个特定下游任务提供多个不同的微调模型。 </li><li>其次，使用 Genetic Prompt Search （GPS）在我们的“Zero-shot Adaptation with Few-shot Validation”设置中自动生成高性能prompt。 此外，我们的 ZeroPrompt 使用混合 prompt 形式，包括 soft prompt 和 hard prompt。</li></ul><h3 id="Genetic-Prompt-Search"><a href="#Genetic-Prompt-Search" class="headerlink" title="Genetic Prompt Search"></a>Genetic Prompt Search</h3><p>目标在不更新模型参数的情况下自动获得高性能prompts，提出了 GPS 以进一步提高 ZeroPrompt 的 zero-shot性能。</p><p>遵循更现实的零样本学习设置，采样少量数据作为下游任务的开发集 $D_{dev}$——“Zero-shot Adaptation with Few-shot Validation”。</p><p>GPS 的过程在算法1中进-行了描述，其中 $f<em>{GPS}$是决定保留或消除哪个 prompt 的度量函数，$g</em>{GPS}$表示生成新 prompt 的遗传函数。 对于下游任务，算法首先使用一组手工 prompt $G_0$ 进行初始化。</p><p>在实践中，通过 3 次初始化来实现良好的性能。 对于每次迭代，使用 $f<em>{GPS}$ 计算 $G^t$ 中 prompt 的分数，并选择前 K 个提示作为 $G^t</em><em>$。 然后我们使用基于 $G^t_</em>$ 的 $g_{GPS}$ 生成 $G^{t+1}$。最后，我们从整个生成的 prompt 集中选择前 K 个 prompts。 </p><p><img src="https://s4.ax1x.com/2022/02/18/HT8ETJ.png" alt=""></p><h3 id="Prompt-Design"><a href="#Prompt-Design" class="headerlink" title="Prompt Design"></a>Prompt Design</h3><p>尽管带有 prompt 的大规模预训练模型，例如 GPT-3  在没有任何标记数据的情况下对看不见的任务进行零样本泛化，显示出可喜的结果，快速设计对其性能至关重要。在本小节中，描述了我们选择的 prompt 设计和其他一些经过测试的变体。</p><p>在 prompt 模板 $T$ 的最简单形式中，提示方法通过手工提示 $P$ 和文本输入序列 $X$ 构造 $T$：</p><script type="math/tex; mode=display">T = \{P,X,[MASK]\}</script><p>其中 $[MASK]$ 是应填写答案以完成句子的空白。 这被称为句子填充。</p><p>如图 4 所示，优化后的prompt $P$ 进一步分解为 $\Epsilon$、$V$ 和 $D$ 三个部分，其中有任务特定的 soft prompt $E$、verbalizer prompt $V$ 和任务描述prompt $D$。结果， 我们的提示模板 $T$ 可以表示为：</p><script type="math/tex; mode=display">T = \{\Epsilon,V,D,X, [MASK]\}</script><p><img src="https://s4.ax1x.com/2022/02/20/HLNF3D.png" alt=""></p><p>与 PET  类似，使用生成任务的 prompt 和用于分类任务的 prompt-verbalizer对 (PVPs)。 </p><p>对于每种任务类型，我们首先设计一个基本 prompts 集合，然后通过添加特定任务的关键字或表达式来修改基本 prompts，以获得最终的任务描述 prompt。 强制每个任务类型中的任务具有相同或相似的 verbalizer 以保持一致性。</p><h3 id="Prompts-with-Verbalizer-Candidates"><a href="#Prompts-with-Verbalizer-Candidates" class="headerlink" title="Prompts with Verbalizer Candidates"></a>Prompts with Verbalizer Candidates</h3><p>对于 unseen 的任务的零样本学习，在这种情况下微调不是一种选择，从大量候选词汇中找到表现最好的verbalizer v ∈ V 是一个难题。为了解决这个问题，我们将所有可能的 verbalizer 候选者 $V = {v_1 , v_2 , …}$ 连接起来，并将候选者放在任务描述提示之前，如图 4 所示。</p><h3 id="Disentangled-Task-Representations"><a href="#Disentangled-Task-Representations" class="headerlink" title="Disentangled Task Representations"></a>Disentangled Task Representations</h3><p>如上所述，我们强制执行直观相似的任务以具有相似的 prompts 或 PVPs，以便与任务无关的知识已经以这种方式正确建模。 同时，特定于任务的知识也应该有助于零样本泛化。</p><p>为了在多任务预训练中 解耦 特定于任务和与任务无关的知识，安装了一个连续 prompt 嵌入作为前缀，这被称为图 4 中所示的特定于任务的 soft prompt。</p><p>对于 unseen 的任务，需要冷启动 并在没有标记数据的情况下从头开始初始化 prompt 嵌入。 一种直觉是直接使用来自具有相似数据分布的训练任务的soft prompt。 </p><h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><h3 id="Experiment-Setups"><a href="#Experiment-Setups" class="headerlink" title="Experiment Setups"></a>Experiment Setups</h3><h4 id="Baseline-Models"><a href="#Baseline-Models" class="headerlink" title="Baseline Models"></a>Baseline Models</h4><ul><li>Pangu-α : 具有多达 2000 亿个参数的预训练解码器模型。 在计算资源有限的情况下，以 130 亿版本的 Pangu-α 作为基准。</li><li>CPM-2 : 具有 110 亿个参数的预训练编码器-解码器模型。 以中文版的 CPM-2 为基准。</li><li>RoBERTa : 与强基线、微调的 RoBERTa-large 模型进行比较。</li></ul><h3 id="Main-Results"><a href="#Main-Results" class="headerlink" title="Main Results"></a>Main Results</h3><h4 id="Results-of-Task-Scaling"><a href="#Results-of-Task-Scaling" class="headerlink" title="Results of Task Scaling"></a>Results of Task Scaling</h4><p><img src="https://s4.ax1x.com/2022/02/18/H7k9j1.png" alt=""></p><p>有上图可以看出：随着任务数量从20升至800个，不同参数大小模型间的差距变得很小，FLOPs提升30倍。</p><h4 id="Results-Compared-with-Other-Approaches"><a href="#Results-Compared-with-Other-Approaches" class="headerlink" title="Results Compared with Other Approaches"></a>Results Compared with Other Approaches</h4><p>在unseen的测试数据集上将 ZeroPrompt 与其他强大的零样本和完全监督的方法进行比较。 由于篇幅有限，表 3 中仅包含部分保留的测试任务（ 17 个学术数据集和 10 个生产数据集以进行比较）。</p><p><img src="https://s4.ax1x.com/2022/02/18/H7AJZ6.png" alt=""></p><p>主要结论是：</p><ul><li>ZeroPrompt显著提升T5的zero-shot性能，从37.8提升到68.76，一共提升近31个点；</li><li>ZeroPrompt显著提升CPM2和盘古的zero-shot性能，提升近28个点；</li><li>ZeroPrompt的zero-shot性能与RoBERTa-large有监督finetune可比或更好（如上图红色标识）；</li><li>ZeroPrompt与finetuned的RoBERTa-large相比，整体只差4.7个点，而ZeroPrompt没有使用任何标记数据进行微调。原论文表示：这是“令人欣喜”的结果。</li></ul><h3 id="Ablation-Studies"><a href="#Ablation-Studies" class="headerlink" title="Ablation Studies"></a>Ablation Studies</h3><h4 id="Effect-of-Prompt-Design"><a href="#Effect-of-Prompt-Design" class="headerlink" title="Effect of Prompt Design"></a>Effect of Prompt Design</h4><p><img src="https://s4.ax1x.com/2022/02/18/H7mjqs.png" alt=""></p><p>【特定任务的soft prompt】 和 【候选标签verbalizer prompt】对最终结果有正向收益。</p><h4 id="Effect-of-Genetic-Prompt-Search"><a href="#Effect-of-Genetic-Prompt-Search" class="headerlink" title="Effect of Genetic Prompt Search"></a>Effect of Genetic Prompt Search</h4><p><img src="https://s4.ax1x.com/2022/02/18/H7QZ6O.png" alt=""></p><p>【Prompt遗传搜索算法】好于之前的LM-BFF、翻译等方式。</p><h4 id="Effect-of-Cross-Task-Type-Transfer"><a href="#Effect-of-Cross-Task-Type-Transfer" class="headerlink" title="Effect of Cross Task Type Transfer"></a>Effect of Cross Task Type Transfer</h4><p><img src="https://s4.ax1x.com/2022/02/18/H7QYjS.png" alt=""></p><p>在跨任务类型的zero-shot性能测试上，只能从某些任务类型中受益，而利用其他任务的更多标记数据并没有持续提升。</p><h2 id="Limitations-and-Future-Work"><a href="#Limitations-and-Future-Work" class="headerlink" title="Limitations and Future Work"></a>Limitations and Future Work</h2><p>虽然可以将任务缩放视为模型缩放的替代方案，它提高了零样本学习的效率和性能。然而，仍一些局限性，未来通过研究这些问题可能会进一步提高零样本性能。</p><ul><li>跨任务迁移的zero-shot性能，并不总是随着任务规模的增加而持续提升</li><li>在多任务训练中，如何选择更好的训练任务分布。 </li><li>如何收集更多多样的任务数据，而当前的任务数据规模仍然是受限的。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;ZeroPrompt-Scaling-Prompt-Based-Pretraining-to-1-000-Tasks-Improves-Zero-Shot-Generalization&quot;&gt;&lt;a href=&quot;#ZeroPrompt-Scaling-Prompt-Ba</summary>
      
    
    
    
    
    <category term="context detection" scheme="http://example.com/tags/context-detection/"/>
    
  </entry>
  
  <entry>
    <title>Prompt-Guided Few-Shot Event Detection</title>
    <link href="http://example.com/2022/02/10/Prompt-Guided-Few-Shot-Event-Detection/"/>
    <id>http://example.com/2022/02/10/Prompt-Guided-Few-Shot-Event-Detection/</id>
    <published>2022-02-10T01:39:09.000Z</published>
    <updated>2022-02-10T01:40:03.355Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Prompt-Guided-Few-Shot-Event-Detection"><a href="#Prompt-Guided-Few-Shot-Event-Detection" class="headerlink" title="Prompt-Guided Few-Shot Event Detection"></a>Prompt-Guided Few-Shot Event Detection</h1>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Prompt-Guided-Few-Shot-Event-Detection&quot;&gt;&lt;a href=&quot;#Prompt-Guided-Few-Shot-Event-Detection&quot; class=&quot;headerlink&quot; title=&quot;Prompt-Guided Fe</summary>
      
    
    
    
    
    <category term="context detection" scheme="http://example.com/tags/context-detection/"/>
    
  </entry>
  
  <entry>
    <title>MetaPrompting: Learning to Learn Better Prompts</title>
    <link href="http://example.com/2022/02/10/MetaPrompting-Learning-to-Learn-Better-Prompts/"/>
    <id>http://example.com/2022/02/10/MetaPrompting-Learning-to-Learn-Better-Prompts/</id>
    <published>2022-02-10T01:25:14.000Z</published>
    <updated>2022-02-10T01:29:16.040Z</updated>
    
    <content type="html"><![CDATA[<h1 id="MetaPrompting-Learning-to-Learn-Better-Prompts"><a href="#MetaPrompting-Learning-to-Learn-Better-Prompts" class="headerlink" title="MetaPrompting: Learning to Learn Better Prompts"></a>MetaPrompting: Learning to Learn Better Prompts</h1>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;MetaPrompting-Learning-to-Learn-Better-Prompts&quot;&gt;&lt;a href=&quot;#MetaPrompting-Learning-to-Learn-Better-Prompts&quot; class=&quot;headerlink&quot; title=&quot;</summary>
      
    
    
    
    
    <category term="context detection" scheme="http://example.com/tags/context-detection/"/>
    
  </entry>
  
  <entry>
    <title>28实现strStr()——KMP</title>
    <link href="http://example.com/2022/01/08/28%E5%AE%9E%E7%8E%B0strStr-%E2%80%94%E2%80%94KMP/"/>
    <id>http://example.com/2022/01/08/28%E5%AE%9E%E7%8E%B0strStr-%E2%80%94%E2%80%94KMP/</id>
    <published>2022-01-08T14:20:11.000Z</published>
    <updated>2022-01-08T16:01:57.610Z</updated>
    
    <content type="html"><![CDATA[<h1 id="28实现strStr-——KMP"><a href="#28实现strStr-——KMP" class="headerlink" title="28实现strStr()——KMP"></a>28实现strStr()——KMP</h1><h4 id="28-实现-strStr"><a href="#28-实现-strStr" class="headerlink" title="28. 实现 strStr()"></a><a href="https://leetcode-cn.com/problems/implement-strstr/">28. 实现 strStr()</a></h4><h2 id="朴素解法"><a href="#朴素解法" class="headerlink" title="朴素解法"></a>朴素解法</h2><p>枚举原串 ss 中的每个字符作为【发起点】，每次从原串中的【发起点】和匹配串的首位，开始尝试匹配：</p><ul><li>匹配成功：返回本次匹配的原串【发起点】</li><li>匹配失败：枚举原串的下一个【发起点】，重新尝试匹配</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">Strstr</span><span class="params">(String haystack, String needle)</span></span>&#123;</span><br><span class="line"> <span class="keyword">int</span> n = haystack.length(), m = needle.length();</span><br><span class="line">   <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;n;i++)&#123;</span><br><span class="line">     <span class="keyword">boolean</span> flag = <span class="keyword">true</span>;</span><br><span class="line">      <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>; j&lt;m ; j++)&#123;</span><br><span class="line">         <span class="keyword">if</span>(haystack.charAt(i+j) != needle.charAt(j))&#123;</span><br><span class="line">            flag = <span class="keyword">false</span>;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">         &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span>(flag)&#123;</span><br><span class="line">         <span class="keyword">return</span> i;</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>时间复杂度： 枚举复杂度为 $O(n-m)$ , 构造比较时间复杂度为 $O(m)$,  整体复杂度 $O((n-m)*m)$</p><h2 id="KMP"><a href="#KMP" class="headerlink" title="KMP"></a>KMP</h2><p>KMP 算法是一个快速查找匹配串的算法，他的作用是：如何快速在【原字符串】中找到【匹配字符串】。</p><p>上述的朴素解法，不考虑剪枝的话是 $O(m*n)$ 的，而KMP算法的复杂度为 $O(m+n)$</p><p>KMP 之所以能够在 $O(m+n)$ 复杂度内完成查找，是因为其能在【非完全匹配】的过程中提取到有效信息进行复用，以减少【重复匹配】的消耗。</p><h3 id="1-匹配过程"><a href="#1-匹配过程" class="headerlink" title="1. 匹配过程"></a>1. 匹配过程</h3><p>在模拟KMP匹配过程之前，先建立两个概念：</p><ul><li>前缀：对于字符串 【abcxxxxefg】，我们称abc属于abcxxxefg的某个前缀</li><li>后缀：对于字符串【abcxxxxefg】，我们称efg属于abcxxxefg的某个后缀</li></ul><p>然后我们假设原串为 【abeababeabf】，匹配串为【abeabf】：</p><p><img src="https://s2.loli.net/2022/01/08/yCL6O3uYGrhkXQD.png" alt=""></p><p>我们可以先看看如果不使用KMP，会如何进行匹配（不使用substring函数的情况下）</p><p>首先在【原串】和【匹配串】分别各有一个指针指向当前匹配的位置。</p><p>首次匹配的【发起点】是一个字符 a。显然，后面的【abeab】都是匹配的，两个指针会同时往右移动（黑标）</p><p>在都能匹配上【abeab】的部分，【朴素匹配】和【KMP】并无不同。</p><p>知道出现第一个不同位置（红标）：</p><p><img src="https://s2.loli.net/2022/01/08/wDoqETL34KWGxAk.png" alt=""></p><p>接下来，是【朴素匹配】和【KMP】出现不同的地方：</p><p>朴素匹配的逻辑：</p><ul><li>将原串的指针移动至本次【发起点】的下一个位置（b字符处）；匹配串的指针移动至起始位置。</li><li>尝试匹配，发现对不上，原串的指针会一直往后移动，直到能够匹配串对上位置</li></ul><p><img src="https://s2.loli.net/2022/01/08/uaIlOkmJLrXvgZB.png" alt=""></p><p>也就是说，对于【朴素匹配】而言，一旦匹配失败，将会将原串指针调整至下一个【发起点】，匹配串的指针调整至起始位置，然后重新尝试匹配。</p><p>这也就不难理解为什么【朴素匹配】的复杂度是 $O(m*n)$ 了</p><p>然后看看KMP匹配过程：</p><p>首先匹配串会坚持已经匹配成功的部分中是否存相同的【前缀】和【后缀】。如果存在，则跳转到【前缀】的下一个位置继续往下匹配：</p><p><img src="https://s2.loli.net/2022/01/08/kRogifeQTH61vbV.png" alt=""></p><p>跳转到下一匹配位置后，尝试匹配，发现两个指针的字符对不上，并且此时匹配串指针前面不存在相同的【前缀】和【后缀】，这个时候只能回到匹配串的起始位置重新开始：</p><p><img src="https://s2.loli.net/2022/01/08/1yzKgLvdOjqGm4k.png" alt=""></p><p><strong>到这里，你应该清楚 KMP 为什么相比于朴素解法更快：</strong></p><ul><li>因为KMP利益已匹配的部分中相同的【前缀】和【后缀】来加速下一次匹配</li><li>因为KMP的原串指针不会进行回溯（没有朴素匹配中回到下一个【起发点】的过程）</li></ul><p>第一点很直观，也很好理解。</p><p>我们可以把重点放在第二点上，原串不回溯至「发起点」意味着什么？</p><p>其实是意味着：随着匹配过程的进行，原串指针不断的右移，我们本质上是不断地在否决一些【不可能】的方案。</p><p>当我们的原串指针从 $i$ 位置后移到 $j$ 位置，不仅仅代表这【原串】下标范围 $[i,j)$ 的字符与【匹配串】匹配或者不匹配，更是在否决那些以【原串】下标范围为 $[i,j)$ 为【匹配发起点】的子集。</p><h3 id="2-分析实现"><a href="#2-分析实现" class="headerlink" title="2. 分析实现"></a>2. 分析实现</h3><p>先分析一下复杂度，如果严格按照上述解法的话，最坏情况下我们需要扫描整个原串，</p><p>复杂度为$O(n)$，同时在每一次匹配失败时，去检查已匹配部分的相同【前缀】和【后缀】，跳转到对应的位置，如果不匹配则再检查前面部分是否有相同【前缀】和【后缀】，再跳转到相应的位置。。。这部分的复杂度是$O(m^2)$，因此整体的复杂度是 $O(n<em>m^2)$，而我们的朴素解法是 $O(m</em>n)$ 的</p><p>说明还有些性质我们没有用到。</p><p>显然，扫描完整原串操作是不可避免的，我们可以优化的只能是【检测已匹配部分的相同前缀和后缀】这一过程。</p><p>再进一步，我们检测【前缀】和【后缀】的目的其实是【为了确定匹配串中的下一段开始匹配的位置】。</p><p>同时，我们发现对于匹配串的任意一个位置而言，由该位置发起的下一个匹配点位置其实与原串无关。</p><p>举个例子，对于匹配串【abcabd】的字符 d 而言，由它发起的下一个匹配点跳转必然是字符 c 的位置。因为字符d位置的相同【前缀】和【后缀】字符ab的下一位置就是字符 c</p><p>可见从匹配串某个位置跳转到下一个匹配位置这一过程是与原串无关的，我们将这一过程称为找 next 点。</p><p>显然我们可以预处理出 next 数组，数组中每个位置的值就是该下标应该跳转的目标位置（next 点）</p><p>当我们进行了这一步优化后，复杂度是多少？</p><p>预处理next数组的复杂度未知，匹配过程最多扫描完整个原串，复杂度为 $O(n)$</p><p>因此如果我们希望整个KMP过程是 $O(m+n)$ 的话，那么我们需要再 $O(m)$ 的复杂度内预处理出 next数组</p><p>所以我们的重点在于如何在 $O(m)$ 复杂度内处理next数组</p><h3 id="3-next数组的构建"><a href="#3-next数组的构建" class="headerlink" title="3.next数组的构建"></a>3.next数组的构建</h3><p>如何用 $O(m)$ 的复杂度内被预处理处理的</p><p>假设有匹配串 【aaabbab】，我们来看看对应的next 是如何被构建出来的。</p><p><img src="https://s2.loli.net/2022/01/08/sqSABkMG5FCDpg6.png" alt=""></p><p><img src="https://s2.loli.net/2022/01/08/cz6heiI8jwYflEF.png" alt=""></p><p><img src="https://s2.loli.net/2022/01/08/kbvGnaBTPiFxjEC.png" alt=""></p><p><img src="https://s2.loli.net/2022/01/08/Dx1ZiwKHc9Rh3T6.png" alt=""></p><p>这就是整个 <code>next</code> 数组的构建过程，时空复杂度均为 O(m)。</p><p>至此整个 KMP 匹配过程复杂度是 O(m + n) 的。</p><h3 id="4-代码实现"><a href="#4-代码实现" class="headerlink" title="4.代码实现"></a>4.代码实现</h3><p>在实际编码时，通常我会往原串和匹配串头部追加一个空格（哨兵）。</p><p>目的是让 j 下标从 0 开始，省去 j 从 -1 开始的麻烦。</p><p>整个过程与上述分析完全一致，一些相关的注释我已经写到代码里。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">strStr</span><span class="params">(String ss, String pp)</span></span>&#123;</span><br><span class="line">     <span class="keyword">if</span>(pp.isEmpty()) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">     <span class="comment">// 分别读取原串和匹配串的长度</span></span><br><span class="line">     <span class="keyword">int</span> n = ss.length(), m = pp.length();</span><br><span class="line">     <span class="comment">// 原串和匹配串前面都加空格，使其下标从 1 开始</span></span><br><span class="line">     ss = <span class="string">&quot; &quot;</span> + ss;</span><br><span class="line">     pp = <span class="string">&quot; &quot;</span> + pp;</span><br><span class="line"></span><br><span class="line">     <span class="keyword">char</span>[] s = ss.toCharArray();</span><br><span class="line">     <span class="keyword">char</span>[] p = pp.toCharArray();</span><br><span class="line"></span><br><span class="line">     <span class="comment">// 构建 next 数组，数组长度为匹配串的长度 （next数组是和匹配串相关的）</span></span><br><span class="line">     <span class="keyword">int</span>[] next = <span class="keyword">new</span> <span class="keyword">int</span>[m+<span class="number">1</span>];</span><br><span class="line">     <span class="comment">// 构建过程 i=2，j=0 开始，i小于等于匹配串长度【构造 i 从 2 开始】</span></span><br><span class="line">     <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">2</span>, j=<span class="number">0</span>; i&lt;=m; i++)&#123;</span><br><span class="line">         <span class="comment">// 匹配不成功的话，j=next(j)</span></span><br><span class="line">         <span class="keyword">while</span>(j&gt;<span class="number">0</span> &amp;&amp; p[i]!=p[j+<span class="number">1</span>])&#123;</span><br><span class="line">             j = next[j];</span><br><span class="line">         &#125;</span><br><span class="line">         <span class="comment">// 匹配成功的话，先让j++</span></span><br><span class="line">         <span class="keyword">if</span>(p[i] == p[j+<span class="number">1</span>])&#123;</span><br><span class="line">             j++;</span><br><span class="line">         &#125;</span><br><span class="line">         <span class="comment">// 更新next[i]，结束本次循环，i++</span></span><br><span class="line">         next[i] = j;</span><br><span class="line">     &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">     <span class="comment">// 匹配过程，i=1,j=0开始，i小于等于原串长度，【匹配i从1开始】</span></span><br><span class="line">     <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>,j=<span class="number">0</span>; i &lt;= n; i++)&#123;</span><br><span class="line">         <span class="comment">//匹配不成功 j=next(j)</span></span><br><span class="line">         <span class="keyword">while</span>(j&gt;<span class="number">0</span> &amp;&amp; s[i]!=p[j+<span class="number">1</span>])&#123;</span><br><span class="line">             j=next[j];</span><br><span class="line">         &#125;</span><br><span class="line">         <span class="comment">//匹配成功的话，先让j++,结束本次循环后i++</span></span><br><span class="line">         <span class="keyword">if</span>(s[i] == p[j+<span class="number">1</span>])&#123;</span><br><span class="line">             j++;</span><br><span class="line">         &#125;</span><br><span class="line">         <span class="comment">// 整一段匹配成功直接返回下标</span></span><br><span class="line">         <span class="keyword">if</span>(j==m)&#123;</span><br><span class="line">             <span class="keyword">return</span> i-m;</span><br><span class="line">         &#125;</span><br><span class="line">     &#125;</span><br><span class="line">     <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;28实现strStr-——KMP&quot;&gt;&lt;a href=&quot;#28实现strStr-——KMP&quot; class=&quot;headerlink&quot; title=&quot;28实现strStr()——KMP&quot;&gt;&lt;/a&gt;28实现strStr()——KMP&lt;/h1&gt;&lt;h4 id=&quot;28-实现-s</summary>
      
    
    
    
    
    <category term="LeetCode" scheme="http://example.com/tags/LeetCode/"/>
    
  </entry>
  
  <entry>
    <title>Exploring Low-dimensional Intrinsic Task Subspace via Prompt Tuning</title>
    <link href="http://example.com/2022/01/04/Exploring-Low-dimensional-Intrinsic-Task-Subspace-via-Prompt-Tuning/"/>
    <id>http://example.com/2022/01/04/Exploring-Low-dimensional-Intrinsic-Task-Subspace-via-Prompt-Tuning/</id>
    <published>2022-01-04T07:04:20.000Z</published>
    <updated>2022-01-04T14:00:34.654Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Exploring-Low-dimensional-Intrinsic-Task-Subspace-via-Prompt-Tuning"><a href="#Exploring-Low-dimensional-Intrinsic-Task-Subspace-via-Prompt-Tuning" class="headerlink" title="Exploring Low-dimensional Intrinsic Task Subspace via Prompt Tuning"></a>Exploring Low-dimensional Intrinsic Task Subspace via Prompt Tuning</h1><p>预训练的语言模型（PLM）如何学习通用的表征，并有效地适应广泛的NLP任务的差异很大的表面上？</p><p>在这项工作中，我们从经验上发现了一些证据，表明PLM对各种任务的适应性可以被重新参数化，即在一个共同的低维内在任务子空间中只优化几个自由参数。这可能有助于我们理解为什么PLMs 可以帮助我们理解为什么PLM可以很容易地适应各种NLP任务的 小规模的数据。</p><p>具体来说，为了找到这样一个子空间并考察其普遍性，我们借助最近在prompt tuning方面的成功经验，将多个NLP任务的软提示分解到同一个低维非线性子空间中，然后我们只通过调谐子空间中的参数来学习使PLM适应未见的任务或数据。</p><p>我们把这个管道称为 <em>intrinsic prompt tuning</em>（IPT）。在实验中，我们研究了不同的少量NLP任务，并令人惊讶地发现，在用100个随机任务找到的5维子空间中，只需调整5个自由参数，我们就可以对100个看过的任务（使用不同的训练数据）和20个未看过的任务分别恢复87%和65%的完整提示调谐性能，显示了所发现的内在任务子空间的巨大通用能力。</p><p>除了作为一种分析工具，IPT还可以进一步带来实际的好处，如提高提示调谐的稳定性。</p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>预训练的语言模型（PLMs）在各种自然语言处理（NLP）任务中表现出了优势（Han等人，2021a；Qiu等人，2020）。</p><p>在海量数据上预训练巨大的参数后，PLM可以通过全参数微调甚至参数高效的调谐方法，有效地适应不同的下游NLP任务，与模型规模相比，数据规模较小。然而，这种适应背后的机制仍然不清楚。PLM如何通过与任务无关的预训练目标来学习普遍的表征，并轻松适应差异很大的不同NLP任务？为了理解PLM如何能以较小的代价普遍地进行适应，在本文中，我们假设PLM适应各种下游任务的优化问题可以被重新参数化，即在同一个低维参数子空间中只优化几个自由参数，我们称之为内在任务子空间（图1）。</p><p><img src="https://s2.loli.net/2022/01/04/xGiLDu9VXqZPfsh.png" alt=""></p><p>具体来说，这里的适应性是指优化可调整的适应性参数，使PLM能够适应某个下游任务，这通常是一个非常高维的优化问题。例如，在传统的微调中，自适应参数是所有的PLM参数和分类头，其数量超过了数亿。然而，Aghajanyan等人（2021）表明，对PLM单一任务的适应可以重新参数化，只需在低维子空间中优化数百个自由参数，然后将调整后的参数随机投射回全部参数空间。这激发了我们的假设，即对多个任务的适应可以被重新参数化为同一低维内在任务子空间的优化。如果这个假设成立，特定任务优化子空间的存在解释了PLMs的普遍性，而低维度解释了为什么适应性可以用相对较小的数据完成。从这个角度来看，PLMs是一个通用的压缩框架，它将各种任务的学习复杂性从非常高的维度压缩到低维度。如果这个假设成立，特定任务的优化子空间的存在解释了PLMs的普遍性，而低维度解释了为什么适应性可以用相对较小的数据完成。从这个角度来看，PLMs是一个通用的压缩框架，它将各种任务的学习复杂性从非常高的维度压缩到低维度。</p><p>为了找到该假设的证据，我们需要开发寻找PLM的内在任务子空间的方法。自然，子空间应该包含各种任务的适应性解决方案（即可调整的适应性参数），因此我们可以通过使用多个任务训练适应性参数的低维分解来近似子空间，然后考察我们是否能在找到的子空间中学习未见过的任务。然而，训练所有PLM参数的分解（微调的情况）在计算上是难以实现的，因为投影到子空间的参数将是数百个PLM。</p><p>Prompt tuning（PT）提供了一个参数高效的替代方案，其适应性参数，即软提示，只有几万个。然而，PT可以在理解（Lester等人，2021；Liu等人，2021b）和生成（Li和Liang，2021）任务上达到接近微调的性能。此外，PT没有结构上的偏差，因为调整后的软提示仅限于输入嵌入，因此与其他参数有效的调整方法如适配器（Houlsby等人，2019）相比，分解它们在直觉上更容易。</p><p>在实验中，我们通过PT在 few-shot 学习设置下探索共同的内在子空间，这保证了各种任务的数据规模是平衡的。我们将本文使用的经验方法命名为IPT，由两个阶段组成：multi-task subspace finding（MSF）和 intrinsic subspace tuning（IST）。在MSF阶段，<strong>我们首先为多个任务获得优化的软提示，然后通过首先将它们投射到低维子空间，然后用反向投射重建它们来学习一个自动编码器。</strong>优化的自动编码器定义了所需的内在子空间。在IST期间，我们只在MSF通过反投影找到的低维子空间中为未见过的数据和任务训练少数自由参数。</p><p>令人惊讶的是，我们发现内在的任务子空间可能不仅存在，而且维度极低。我们研究了不同的few-shot NLP任务，发现在一个由100个随机任务用MSF找到的5维子空间中，对于100个看过的任务（使用不同的训练数据）和20个未看过的任务，我们可以用IST分别恢复87%和65%的完整PT性能。此外，我们研究了IPT在不同任务类型以及训练任务和数据数量下的有效性。我们还表明，发现的内在任务子空间和IPT有一些实际用途，如分析任务差异和提高提示调谐稳定性。我们鼓励未来的工作探索如何更好地找到内在任务子空间，并从PLM适应性的低维重新参数化中获得灵感，开发先进的技术。</p><h2 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h2><h3 id="PLM-Fine-tuning-and-Prompt-tuning"><a href="#PLM-Fine-tuning-and-Prompt-tuning" class="headerlink" title="PLM, Fine-tuning and Prompt tuning."></a>PLM, Fine-tuning and Prompt tuning.</h3><p>随着BERT以来的成功（Devlin等，2019），预训练的语言模型（Radford等，2018；Yang等，2019；Liu等，2019；Raffel等，2019）给NLP带来了新的范式，即预训练一个大规模的模型作为通用骨干，然后将PLM适应特定的下游任务。下游适应的主流方式是微调，即增加特定任务的分类头，用下游任务的监督数据调整所有PLM参数。</p><p>最近，研究人员发现，通过将下游任务铸造成预训练任务的形式，并在输入中加入一些提示标记，包括人类设计的可解释提示（Brown等人，2020；Schick和Schütze，2021a，b；Han等人，2021b；Ding等人，2021；Hu等人，2021）和自动搜索的提示（Jiang等人，2020；Shin等人，2020；Gao等人，2021），也可以取得很好的效果。按照这一研究思路，提示被从词汇表中的标记扩展到可训练的嵌入，即软提示（Li and Liang, 2021; Hambardzumyan et al., 2021; Zhong et al., 2021; Qin and Eisner, 2021; Liu et al., 2021b; Lester et al., 2021）。此外，一些工作（Li and Liang, 2021; Qin and Eisner, 2021; Lester et al., 2021）证明，只有调整软提示并保持PLM参数冻结，才能在各种任务中取得良好的表现。特别是，Lester等人（2021）表明，随着PLM规模的增长，提示调整和微调之间的差距越来越小，最后消失了。</p><p>在这项工作中，我们试图朝着解开这些现象的方向迈出一步，即PLM如何能够学习通用能力，以适应各种任务的少量数据和可调整的参数。</p><h3 id="Intrinsic-Dimensionality"><a href="#Intrinsic-Dimensionality" class="headerlink" title="Intrinsic Dimensionality"></a>Intrinsic Dimensionality</h3><p>本质维度（ID）是表示某些数据或近似函数所需的最小变量数。Li等人（2018）提出通过将神经网络的所有可训练参数随机投射到线性子空间来测量神经网络优化的目标函数的ID，并找到满意的解决方案（如可以达到90%的性能）出现的最小尺寸。在此之后，Aghajanyan等人（2021）表明，PLM微调在许多NLP任务上的ID可以低于数千，而且预训练隐含地优化了下游任务的ID，这也是这项工作的动机。他们的方法中使用的随机线性投影不涉及生成低维子空间的任何额外训练，因此，在子空间中成功找到解决方案为有效的低维重参数化的存在提供了充分的证据。</p><p>随机线性投影不可避免地引入了多余的任务相关信息，并使生成的子空间在重新参数化任务适应方面不紧凑。考虑到存在性已经给出，而我们要研究的假设是低维子空间是否是普遍的，我们采用更强的子空间寻找方法，并使用来自不同下游任务的监督来训练适应性参数的非线性低维分解。</p><h3 id="Unifying-Different-NLP-Tasks"><a href="#Unifying-Different-NLP-Tasks" class="headerlink" title="Unifying Different NLP Tasks."></a>Unifying Different NLP Tasks.</h3><p>尽管各种NLP任务在表面上差别很大，但长期以来，人们一直试图将不同的NLP任务统一为相同的形式（Sun等人，2021），从而用类似的技术来处理它们，特别是在提示方法（Liu等人，2021a）成功地将各种任务投向PLM的预训练任务的形式之后。本文的分析可能有助于我们理解如何能做到这一点，以及如何从内在任务子空间的角度更好地统一不同的任务。</p><h2 id="Methodology"><a href="#Methodology" class="headerlink" title="Methodology"></a>Methodology</h2><p>我们首先在第3.1节中介绍了微调和软提示调谐的基本前提，然后在第3.2节中介绍了我们提出的分析管道本征提示调谐（IPT），包括两个训练阶段。(1）多任务子空间查找（MSF）和（2）内在子空间调整（IST）。在图2中，我们将微调、提示调谐和我们的IPT的范式可视化。</p><p><img src="https://s2.loli.net/2022/01/04/N3dlADSeVj5c8BE.png" alt=""></p><h3 id="Preliminaries"><a href="#Preliminaries" class="headerlink" title="Preliminaries"></a>Preliminaries</h3><p>假设我们得到一系列 NLP任务 ${T<em>1, T_2, …, T</em>{|T|}}$，在不丧失一般性的情况下，按照Raffel等人（2019）的做法，我们假设每个任务 $T<em>i$ 都被投射为统一格式的条件生成。$T_i = {X_i, Y_i}$ 其中输入 $X_i$ 和目标 $Y_i$都由一系列token组成，$X_i = {w_1,w_2,…,w</em>{|X|}}$， $Y<em>i = {y_1,y_2,…,y</em>{|Y<em>i|}}$ 。目标是学习一个映射函数 $F：X_i→Y_i$，事实上的方法是用PLM $M$ 对 $F$ 进行建模，它首先将输入$X_i = {w_1, w_2, …, w</em>{|X<em>i|}}$转换为嵌入$E_i = {w_1, w_2, …, w</em>{|X<em>i|}}∈R^{|X_i|\times d}$，其中去掉了隐藏的大小，然后将 $E_i$ 编码为隐藏的表示 $H_i = {h_1, h_2, …, h</em>{|X_i|}}∈R^{|Xi|×d}$，最后以 $H_i$ 为条件对 $Y_i$进行解码。 目标是优化以下目标:</p><script type="math/tex; mode=display">L_{LM}^i = -\frac{1}{Y_i} \prod_{j=1}^{|Y_i|} p(y_j |w_1,...,w_{|X_i|}, y_1,...,y_{j-1})</script><p>在传统的微调中，$M$ 的所有参数（$θ<em>M$）都参与了优化。最近，及时调谐（Lester等人，2021年）作为一种有效的替代方法出现了，它的调谐参数非常少。是一种有效的替代方法，其可调谐的参数非常少。从形式上看，提示调谐通过在 $H_i$之前添加一系列由 $θ_P$ 参数化的可调谐向量 $P_i = {p_1, p_2, …, p_n}$，将额外的信息引入输入$X_i$，即修改后的输入嵌入 $E* = {p_1,p_2,…,p_n;w_1,w_2,…,w</em>{|X_i|} }\in R^{n+|X_i|\times d} $。在提示调谐过程中，$θ_M$保持固定，只有 $θ_P$被更新，满足 $|θ_P| = n\times d &lt;&lt; |\theta_M|$的条件。</p><h3 id="Intrinsic-Prompt-Tuning"><a href="#Intrinsic-Prompt-Tuning" class="headerlink" title="Intrinsic Prompt Tuning"></a>Intrinsic Prompt Tuning</h3><p>为了验证我们的假设，即PLM对各种下游任务的适应可以被重新参数化为低维内在任务子空间内的优化，我们提出了一个名为内在提示调谐（IPT）的两阶段管道。第一阶段是多任务子空间寻找（MSF），旨在寻找具有多任务 prompts 的内在任务子空间，这些 prompts 是由一个具有投影函数和反投影函数的自动编码器定义的。第二个内在子空间调整（IST）阶段是只在子空间中调整参数，然后用反投影函数将其恢复到 soft prompts 中。</p><h4 id="Multi-task-Subspace-Finding"><a href="#Multi-task-Subspace-Finding" class="headerlink" title="Multi-task Subspace Finding"></a>Multi-task Subspace Finding</h4><p>在MSF期间，我们试图通过学习矩阵 $P_i\in R^{n×d}$的分解，找到一个低维度 $d_I$ 的令人满意的内在任务子空间，这是下游任务 $T_i$ 的训练 soft-prompt。受文本自动编码器的启发（Bowman等人，2016），该分解包括一个投影函数 $Proj(-)$将$P_i$投射到 $d_I$维的子空间，以及一个反投影函数$Proj_b(-)$将 $d_I$ 维的向量投射回 soft-prompt 中以处理 $T_i$，我们重建 $P_i$如下:</p><script type="math/tex; mode=display">p*_i = Proj_b(Proj(P_i)),  L^i_{AE} = ||P^*_i - P_i||_2^2</script><p>其中，$Proj(-)$用单层FFN实现，$Projb(-)$用两层感知器实现，参数如下:</p><script type="math/tex; mode=display">Proj_b(d_i) = W_2(tanh(W_1d_i + b_1)) + b_2</script><p>其中 $W<em>1\in R^{d’_I\times d_I}, b_1\in R^{d_I’},W_2\in R^{N\times d\times d’_I}, b_2\in R^{n\times d}$ 是可训练的参数。此外，为某项任务的 prompt $P_i$ 找到分解，本质上是一个矩阵，这在某种程度上是微不足道的。由于我们想在MSF中找到的理想的内在任务子空间应该适用于广泛的任务，所以我们引入了多任务训练，同时将训练任务的重构 soft-prompt 的任务导向语言建模损失 $L</em>{LM}$作为目标函数。通过联合优化重建损失和面向任务的损失，子空间可以获得重新参数化各种任务适应的能力。MSF的总体训练目标显示如下:</p><script type="math/tex; mode=display">L_{\theta_{proj}} = \frac{1}{T_{train}} \sum_{i=1}^{|T_{train}|}(L_{LM}^i + \alpha L_{AE}^i)</script><p>其中 $α$ 表示控制两个损失之间比例的超参数，$θ_{proj}$表示 $Proj$ 和 $Proj_b$的参数。在MSF期间，我们只对 Proj 和 Projb 进行优化，而对其他参数保持固定。通过引入下游任务监督和非线性，我们可以有效地找到比随机线性子空间更多的不冗余和更强的子空间。</p><h3 id="Intrinsic-Subspace-Tuning"><a href="#Intrinsic-Subspace-Tuning" class="headerlink" title="Intrinsic Subspace Tuning."></a>Intrinsic Subspace Tuning.</h3><p>在这个阶段，我们要评估MSF找到的子空间是否可以推广到未见过的训练数据或未见过的任务。如果答案是肯定的，我们可以说，我们成功地找到了内在的任务子空间，在一定程度上重新参数化了PLM对各种任务的适应性。具体来说，我们只保留在MSF期间学到的Projb，并保持 Projb 和 M 都是固定的，然后对于每个任务，我们不进行香草prompt tuning，而只tune 子空间中的 $d_I$ 自由参数（$θ_d$），并将 $d_I$ 参数与 Projb 投影到 soft-prompt 中，目标函数可以表述为：</p><script type="math/tex; mode=display">L_{\theta_d}^i = L_{LM}^i</script><h2 id="Experiment-and-Analysis"><a href="#Experiment-and-Analysis" class="headerlink" title="Experiment and Analysis"></a>Experiment and Analysis</h2><p>在本节中，我们首先在第4.1节中描述了实验设置，包括任务和相应的数据集、评价指标和本文的训练细节。然后，我们在第4.2节和第4.3节介绍实验结果和分析。</p><h3 id="Experimental-Settings"><a href="#Experimental-Settings" class="headerlink" title="Experimental Settings"></a>Experimental Settings</h3><p><strong>Tasks and Datasets.</strong> 为了在实验中覆盖广泛而多样的NLP任务，我们从CrossFit Gym（Ye等人，2021年）的数据库中随机选择了各种各样的 few-shot NLP任务T（共120个）。<strong>few-shot 的设置确保了各种任务的数据规模是平衡的，因此MSF发现的子空间不会轻易偏向数据丰富的任务。</strong></p><p>简单介绍一下，CrossFit Gym由各种类型的少数NLP任务组成，包括文本分类（如情感分析和自然语言推理）、问题回答（如机器阅读理解和多选题回答）、条件生成（如总结和对话）等等。如第3.1节所述，所有任务都按照Raffel等人（2019）和Khashabi等人（2020）的做法处理成统一的序列到序列的格式，以便于用统一的文本到文本的PLM处理它们。例如，一个多选QA任务的输入被表述为: $Question: <question> Context: <context> Candidates:<candidates>$ 而PLM预计将从<candidates>生成正确的答案跨度。每个任务 $T<em>i\in T$可以 表示为一个 $(D^i</em>{train} , D^i<em>{train} , D^i</em>{train})$的元组，其中 $D<em>{train}/D</em>{dev}$ 的大小被设置为K，以确保 few-shot 设置。对于分类和回归任务，K=16，而对于其他类别的任务，K=32。我们在第6节中列出任务细节。</p><p><strong>Evaluation Metrics.</strong> 由于不同的任务有不同的评估协议（例如，通常判别性任务的F1分数和生成性任务的BLEU），我们引入平均绝对性能（$E<em>{abs}$）和平均相对性能（$E</em>{rel}$）作为主要评估指标。具体来说，让$T = {T<em>1, …, T</em>{|T|}}$是要评估的任务，让 $E<em>{T_i}$ 表示 $T_i$ 对 IPT 的测试得分, $E</em>{abs} =\frac{1}{T}\sum<em>{T_i\in T} E</em>{T<em>i} , E</em>{rel} = \frac{1}{|T|} \sum<em>{T_i\in T} \frac{E</em>{T<em>i}}{E^*</em>{T<em>i}}$ ，其中 $E^*</em>{T<em>i}$ 定义为 prompt tuning$E</em>{T<em>i}^{PT}$或微调 $E</em>{T<em>i}^{FT}$后的性能。在本文中。我们使用 $E</em>{rel}$作为主要评价标准，选择 $E<em>{abs} $作为辅助标准。为了正确评估IPT实现的泛化能力，我们从T中随机抽取训练任务 $T</em>{train}$ 和测试任务$T<em>{test}$，满足 $T</em>{Train} \cap T_{test} = ∅$。</p><p>在多任务子空间查找（MSF）阶段，PLMs只在 $T<em>{train}$ 上进行训练，我们在 $T</em>{train}$ 上评估 $E<em>{abs}$ 和 $E</em>{rel}$，看看重建压缩到 $d<em>I $维子空间的提示会损失多少性能，这将为泛化到未见过的数据和任务提供一个经验上界。我们还用在MSF中学到的自动编码器重新构建 $T</em>{test}$ 的训练过的 soft-prompt，并测试其性能，以研究学到的自动编码器对未见过的 soft-prompt 的重建能力。</p><p>对于本征子空间调谐（IST）阶段，我们 首先对 $T<em>{train}$ 进行IST，使用与MSF中使用的 $D^i</em>{train} /D^i_{dev}$完全相同的方法，研究只在子空间中进行优化可以在多大程度上恢复性能。</p><p>之后，我们通过两个泛化挑战来评估IPT的泛化能力，看对各种任务的适应是否在很大程度上被重新参数化为所发现的子空间。(1) 未见过的数据挑战和 (2) 未见过的任务挑战。</p><ul><li>对于未见过的数据挑战，我们在 $T<em>{train}$ 上进行IST，使用不同的K-shot $D^{i’}</em>{train}/D^{i’}<em>{dev}$ 训练数据进行重新采样，同时保持 $D^i</em>{test}$ 保持不变。注意 $D^{i’}<em>{train}/D^{i’}</em>{dev} $ 和 $D^i<em>{train}/D^{i}</em>{dev}$ 形成的，符合i.i.d.假设。未见过的数据挑战是为了测试所学的子空间是否能推广到未见过的数据，这将导致不同的优化轨迹。</li><li>对于未见过的任务挑战，我们对通过IPT在 $T_{test}$上获得的 soft-prompt 进行评估，看看在发现的子空间中的优化能在多大程度上恢复PLM对未见过的任务的适应性，这将为我们的假设提供证据，即PLM的不同任务适应性的重新参数化子空间并不独立。                                                                      </li></ul><h3 id="Main-Results"><a href="#Main-Results" class="headerlink" title="Main Results"></a>Main Results</h3><p><img src="https://s2.loli.net/2022/01/04/R6cqt8gHLTFyVaS.png" alt=""></p><p>评估了三种任务拆分：随机、非cls和cls，详情列于表1。实验结果显示在图3（$E<em>{rel}$）、表2（$E</em>{abs}$）和表3（$E<em>{abs}$）。如前所述，我们选择 $E</em>{rel}$ 作为分析的主要标准。基于这些结果，我们研究了以下研究问题。</p><h4 id="Q1-PLM是否真的将各种任务适应性重新参数化，使之成为一个低维的任务子空间？"><a href="#Q1-PLM是否真的将各种任务适应性重新参数化，使之成为一个低维的任务子空间？" class="headerlink" title="Q1. PLM是否真的将各种任务适应性重新参数化，使之成为一个低维的任务子空间？"></a>Q1. PLM是否真的将各种任务适应性重新参数化，使之成为一个低维的任务子空间？</h4><p>从图3（a）的结果，我们可以看到。(1)对于未见过的数据挑战（$T<em>{train}^{diff}(IST)$），选择 训练 dI ≥ 5可以恢复80%以上的全 对于100个训练任务，在未见过的独立数据上使用IST的 prompt tuning 性能，可以恢复80%以上。 (2）对于未见过的任务挑战（$T</em>{test}(IST)$），我们只需调整5∼100个参数，也可以达到约60%的性能。从这些结果来看，我们可以说MSF发现的子空间中的低维重新参数化成功地恢复了 $T_{train}$ 的PLM适应性，并且在一定程度上也可以推广到未见过的任务，因此只需在这些子空间中调整几个自由参数就可以实现非微不足道的性能。</p><p>这为我们的假设提供了证据，即PLM将各种任务适应性重新参数化为同一个低维子空间，或者至少各种任务适应性的低维重新参数化子空间（Aghajanyan等人，2021）应该有一个实质性的交集，否则 $T<em>{train}$发现的子空间对 $T</em>{test}$来说几乎不可能起作用。</p><p>此外，在随机拆分中，我们可以看到，当 dI≥5 时，$T<em>{train}^{diff}(IST)$和 $T</em>{test}(IST)$ 的 $E^{(PT)}_{rel}$总是在同一水平上，这表明内在任务子空间的维度应该在 5 左右，这对于有上亿个参数的PLM来说是非常低的。</p><h4 id="Q2-What-limits-IPT"><a href="#Q2-What-limits-IPT" class="headerlink" title="Q2. What limits IPT?"></a>Q2. What limits IPT?</h4><p>虽然观察到了积极的证据，但考虑到对于未见过的任务只能恢复60%左右的表现，IPT的有效性仍然有限。从图3（a）和（b）的结果中，我们讨论了哪些因素可能会限制IPT的有效性，并为改进分析管道提供见解。</p><ol><li>当我们使用MSF的自动编码器（$T<em>{train}(MSF)$）直接重建软提示时，Ttrain的性能甚至优于虚构的 soft-prompt tuning，这表明：(1)MSF的管道可以通过在极低的维度上强制执行多任务技能共享来帮助改善 soft-prompt 的调谐。极低的维度，和 (2) 在子空间中至少存在足够好的解决方案，这些解决方案是由MSF找到的。足够好的解决方案，这些解决方案已经被MSF发现。然而，即使使用完全相同的训练数据，IST也不能找到这些好的解决方案，从而导致 $T</em>{train}(MSF)$ 和 $T_{train}^{same}(IST)$之间的差距，这表明所采用的优化算法的局限性会影响IST的性能。</li><li>从 $T<em>{train}(MSF)$ 和 $T</em>{test}(MSF)$ 的比较中，我们可以看出，直接重建未见过的任务的 soft prompt 的性能很差。这表明在MSF中训练的自动编码器的重构能力不能很好地推广到未见过的输入（soft-prompt），这可能在一定程度上限制了IPT。尽管如此，IST仍然可以在MSF找到的子空间内找到更好的解决方案。</li><li>从图3（a）和（b）的结果比较中，我们可以看到，fine-tuning( $E^{FT}<em>{rel}$)的相对性能总是比 prompt tuning（$E^{PT}</em>{rel}$）要差。这是因为 soft prompt 略逊于 few-shot 设置下的微调，而IPT的性能受 soft prompt 调谐的约束，因为MSF被设计为重构 soft prompt。理想情况下，$E^{FT}_{rel}$可以通过设计更先进的 prompt tuning算法来进一步改进。</li></ol><h4 id="Q3-How-is-the-influence-of-task-types"><a href="#Q3-How-is-the-influence-of-task-types" class="headerlink" title="Q3. How is the influence of task types?"></a>Q3. How is the influence of task types?</h4><p>按照CrossFit（Ye et al. 研究的任务分为两部分：cls（分类）。属于判别性任务，而Non-cls（非 分类），它们往往是生成性任务。从图3（c）-（f）的结果中，我们发现。与常识一致，它们之间存在着巨大的 它们之间的差异。(1) 在分类任务和非分类任务之间存在着巨大的概括性差距。当在MSF中只使用一种任务（cls或non-cls）时，发现的子空间对同种任务（$T^{in}<em>{test} (IST)$）工作良好，但对其他种类的任务（$T^{out}</em>{test}(IST)$）的概括性很差。(2) 当增加d时，非cls任务（图3(c)和(d)）在所有设置中的表现趋于下降，但cls表现（图3(e)和(f)）趋于增加。合理地讲，对于各种NLP任务来说，理想的内在子空间维度设置至少应该达到一个阈值（内在维度），以确保子空间可以被大幅描述，但也不应该太大，因为这可能导致过度参数化。因此，我们认为这表明，尽管是反直觉的，但对于非cls任务来说，最合适的内在子空间维度要远远小于cls任务。我们假设这可能来自于 few-shot 的设置，并将在未来进行探索。</p><h3 id="Analyses-and-Properties"><a href="#Analyses-and-Properties" class="headerlink" title="Analyses and Properties"></a>Analyses and Properties</h3><p><strong>Visualization of the Found Intrinsic Subspace</strong> 我们在图4中用PCA可视化了内在向量（由IST在发现的子空间中学习的自由参数组成的向量），从中我们可以看到：(1）分类任务群和非分类任务群之间存在着明显的分界线，表明它们是高度独立的，这与常识是一致的。这也解释了为什么在任何一个簇上学到的子空间对另一个簇的概括性很差。(2）未见过的任务 $T<em>{test}$ 的点与 $T</em>{train}$的点混合在一起，这表明发现的子空间普遍地对各种任务进行了重新参数化，因此PLM可以泛化到未见过的任务。(3) 从(c)和(d)中还可以看出，属于同一类别的点呈现出紧凑的集群。我们认为，学到的内在向量可以被看作是低维的任务表征，有助于分析各种NLP任务的相似性和差异性。</p><p><img src="https://s2.loli.net/2022/01/04/KnFhqdHP7LSrAcX.png" alt=""></p><p><strong>Impacts of the Number of Training Tasks.</strong></p><p>在MSF期间，自动编码器被优化，以重建各种训练任务的适应性参数，将其重新参数化为低维任务子空间。理想情况下，$T<em>{train}$的覆盖率会大大影响IPT在未见任务 $T</em>{test}$ 上的泛化能力。为了证明这一点，我们随机选择任务分区，在原始 $T<em>{train}$中只随机抽取 {20%、40%、60%、80%} 的任务来训练自动编码器，然后在相同的 $T</em>{test}$上评估未见过的任务挑战。结果如图5所示，从图中我们可以看出，随着训练任务数量的增加，发现的任务子空间的泛化能力普遍提高。这反映出，增加所见任务的覆盖面和多样性可以帮助IPT找到更多的通用子空间。</p><p><img src="https://s2.loli.net/2022/01/04/9orPjdyLE4lZDea.png" alt=""></p><p><strong>Impacts of the Number of Shots</strong> 虽然在本文中，我们主要研究的是 few-shot 的设置，以控制数据量的影响，但研究当有更多的训练数据时，IPT的能力是否会更强，也是很有意思的。在这里，我们通过将任务分区cls的 few-shot 增加一倍来进行初始试验，并进行实验，看看MSF和IST在T上的性能（$E^{PT}_{rel }$）。注意计算EPT时，K-shot和2K-shot实验的分母是不同的。</p><p>结果在图6中得到了体现。从中我们可以看到，在2K拍摄的情况下，MSF 和 IST 之间的差距在 2K-shot 设置中迅速缩小 当dI增长时，MSF和IST之间的差距迅速缩小，而在K-shot设置中则明显放缓。而在K-shot设置中则明显缓慢。这表明，涉及更多的监督可能有利于IST的优化。我们还发现，当增加dI时，2K-shot的$T^{same}_{ train}$ 增长非常接近100%，但从来没有超过它，这表明当有更多的数据可用时，联合重建多个任务的提示不会带来额外的好处，因为在K-shot设置中观察到。一般来说，我们认为探索IPT在数据丰富的情况下发现的子空间会有多强是很有意义的。</p><p><strong>Improving Prompt Tuning Stability with IPT</strong> 在表4中，我们显示了在10次运行中120个任务的测试分数的平均标准偏差（std），比较了IPT（dI=10）、微调和及时调整。我们观察到，prompt tuning是最不稳定的策略，具有最高的标准，而精调则表现得更为稳定。soft prompt tuning的不稳定性可能会影响这一技术的实际使用。直观地说，IPT试图找到低维的内在子空间，只用几个自由参数来学习新任务，这将有助于提高稳定性，IPT肯定会成为表4中最稳定的方法。</p><p><img src="https://s2.loli.net/2022/01/04/zpoeKD2Yf8q6mOM.png" alt=""></p><p>为了使IPT带来的稳定性优势实用化，我们建议使用IPT找到的解决方案作为香草 prompt tuning的初始化。具体来说，我们在 $T_{test}$上继续进行随机分区的实验，选择 $d_I=10$，并通过在IST期间在子空间中反推来初始化软提示。在IST期间在子空间中找到的解决方案进行初始化。与 prompt tuning 基线相比，其他细节保持不变。</p><p>我们观察到，以这种方式实现的标准方差明显低于香草 prompt tuning（1.65 v.s. 4.19) 而在这种方式下，我们可以实现103.4%的EPT，也就是说，性能也可以从59%（IST）提高。这表明，IPT和 prompt tuning可以进一步以两阶段的方式结合。这个实验还表明，尽管我们的IPT管道在本文中主要作为一个分析框架，但它也能带来实际的好处。我们将在未来探索IPT的更多实际用途。</p><h2 id="Discussion"><a href="#Discussion" class="headerlink" title="Discussion"></a>Discussion</h2><p>NLP任务是否可以被重新参数化到同一个子空间？</p><p>在本文中，我们发现了强有力的证据，通过压缩各种任务的适应性参数与下游监督，我们有可能找到一个极低维的子空间，其中包含次优但非琐碎的解决方案，以适应PLM的未见任务。尽管在MSF期间 $E^{PT}_{rel}$超过了100%，但我们注意到在IST期间，对看到的和未看到的任务的概括仍然远非完美（87%对EPT的65%），而且增加 $d_I $并没有明显改善性能。</p><p>尽管这可能与目前优化算法的不足有关，但基于目前的结果，我们不能直接得出结论，PLM的各种NLP任务改编可以在完全相同的子空间内进行重新参数化优化。然而，至少我们找到了有希望的经验结果，表明各种任务的低维重新参数化子空间有很大的交集，这可以通过MSF找到。而在这个交集子空间进行IST可以恢复每个任务的大部分性能。因此，我们鼓励未来的工作探索（1）是否存在在极低维的子空间中进行IST的更高效和有效的优化算法，以及（2）各种任务的内在子空间的联合是否也是低维的。</p><p>此外，还应该注意的是，通过IPT实现的极低维度（约5∼100）不应该被完全视为Aghajanyan等人（2021）和Li等人（2018）的内在维度，因为内在维度应该确保整个训练过程可以在该低维度上完成。用IPT实现的维度有可能作为内在维度的一个粗略下限。</p><p><strong>Relation to the scaling law.</strong> 最近，越来越多关于规模力量的案例被展示出来。人们发现，极其庞大的PLM往往更具有样本效率（Kaplan等人，2020年）、参数效率（Lester等人，2021年）和跨任务的可概括性（Wei等人，2021年）。我们认为这可以用本文的假设来解释：更大的或训练得更好的PLM的适应性可以更好地重新参数化到相同的低维子空间，这样跨任务的泛化应该更容易，更好的预训练带来更低的重新参数化尺寸（Aghajanyan等人，2021），因此更大的PLM应该需要更少的数据和可调整参数。</p><p>如果这个假设成立，我们认为应该开发类似于IPT的调整方法。较大的PLM提供了更强大的压缩框架，我们可以找到低维的内在任务子空间，并在这些子空间中训练各种下游任务，这将避免过度参数化造成的不稳定和巨大的泛化差距，而且对环境也更环保。</p><h2 id="Conclusion-and-Future-work"><a href="#Conclusion-and-Future-work" class="headerlink" title="Conclusion and Future work"></a>Conclusion and Future work</h2><p>在本文中，我们研究了这样一个假设：<strong>PLM对各种任务的适应性可以被重新参数化为同一低维内在任务子空间中的几个自由参数的优化。</strong>我们开发了一个名为IPT的分析管道，它首先通过联合压缩多个任务的适应性参数找到一个子空间，然后只在子空间中对未见过的数据和任务进行参数调整。IPT在极低维度上取得的非微妙的表现为该假设提供了积极的证据。我们还讨论了影响结果的因素和IPT的潜在实际用途。未来，我们将改进IPT框架，以更好地验证普遍的低维重参数化假设，并开发更多的实用技术，在低维子空间进行更有效的优化。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Exploring-Low-dimensional-Intrinsic-Task-Subspace-via-Prompt-Tuning&quot;&gt;&lt;a href=&quot;#Exploring-Low-dimensional-Intrinsic-Task-Subspace-via</summary>
      
    
    
    
    
    <category term="context detection" scheme="http://example.com/tags/context-detection/"/>
    
  </entry>
  
  <entry>
    <title>Unsupervised Domain Adaptation of a Pretrained Cross-Lingual Language Model</title>
    <link href="http://example.com/2021/12/27/Unsupervised-Domain-Adaptation-of-a-Pretrained-Cross-Lingual-Language-Model/"/>
    <id>http://example.com/2021/12/27/Unsupervised-Domain-Adaptation-of-a-Pretrained-Cross-Lingual-Language-Model/</id>
    <published>2021-12-27T11:39:54.000Z</published>
    <updated>2021-12-27T12:34:43.107Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Unsupervised-Domain-Adaptation-of-a-Pretrained-Cross-Lingual-Language-Model"><a href="#Unsupervised-Domain-Adaptation-of-a-Pretrained-Cross-Lingual-Language-Model" class="headerlink" title="Unsupervised Domain Adaptation of a Pretrained Cross-Lingual Language Model"></a>Unsupervised Domain Adaptation of a Pretrained Cross-Lingual Language Model</h1><p>最近的研究表明，在大规模的无标签文本上预训练跨语言语言模型，可以在各种跨语言和低资源任务中产生明显的性能改进。通过对一百种语言和TB级文本的训练，<strong>跨语言模型已被证明能有效地利用高资源语言来提高低资源语言的处理能力</strong>，并超过了单语言模型。在本文中，我们进一步研究了当预训练的跨语言模型需要适应新领域时的跨语言和跨领域（CLCD）设置。具体来说，我们提出了一种新的无监督的特征分解方法，该方法可以<strong>从纠缠在一起的预训练的跨语言表征中自动提取特定领域的特征和领域不变的特征</strong>，<strong>给定源语言中未标记的原始文本。我们提出的模型利用相互信息估计，将跨语言模型计算的表征分解为领域变量和领域特定部分</strong>。实验结果表明，我们提出的方法比最先进的预训练的跨语言模型在CLCD环境中取得了明显的性能改进。本文的源代码可在<a href="https://github.com/lijuntaopku/UFD。">https://github.com/lijuntaopku/UFD。</a></p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>深度学习的最新进展使各种NLP任务受益，并在大规模注释数据集可用时导致性能的显著改善。对于高资源语言，例如英语，许多任务收集足够的标记数据来建立深度神经模型是可行的。然而，对于许多语言来说，在大多数情况下可能不存在足够的数据来充分利用深度神经模型的进步。因此，人们提出了各种跨语言迁移学习方法，以利用高资源语言的标记数据来构建低资源语言的深度模型[Kim等人，2019；Lin等人，2019；He等人，2019；Vulic ́等人，2019]。尽管如此，大多数跨语言迁移学习研究的重点是减轻语言的歧视，而对领域差距的探索较少。在这项研究中，我们专注于一个更具挑战性的环境，即跨语言和跨领域（CLCD）转移，其中源语言的领域内标签数据不可用。</p><p>传统上，<strong>跨语言方法主要依靠从数据中提取语言不变的特征，将从源语言学到的知识转移到目标语言中</strong>。<strong>一种直接的方法是权重共享，它通过事先将输入文本映射到一个共享的嵌入空间</strong>，直接将在源语言上训练的<strong>模型参数重用</strong>到目标语言。然而，之前的重新搜索[Chen等人，2018]显示，<strong>权重共享不足以提取语言不变的特征</strong>，而这些特征可以在不同的语言中很好地通用。因此，我们提出了一种语言对抗训练策略，利用每种语言的非平行无标签文本，提取跨语言的不变特征。这样的策略在双语转换环境中表现良好，但<strong>不适合从多种语言中提取语言不变量特征</strong>，因为<strong>所有源语言共享的特征可能过于稀疏，无法保留有用的信息。</strong></p><p>最近，规模化的预训练跨语言模型，例如多语言的BERT[Devlin等人，2019]和XLM[Conneau和Lample，2019；Conneau等人，2019]，在各种跨语言任务中表现出非常有竞争力的性能，甚至在低资源语言上超过了预训练的单语言模型。通过采用平行文本（未为任何特定任务标记）和所有语言共享的子词词汇，这些预训练的跨语言模型可以有效地将来自多种语言的输入文本编码到一个单一的表示空间，这是一个由多种语言（超过一百种）共享的特征空间。虽然在提取语言不变的特征方面有很好的通用性，但跨语言的预训练方法在<strong>提取领域不变的特征方面没有具体的策略</strong>。在我们的CLCD设置中，<strong>语言不变量和领域不变量的特征都需要被提取</strong>。</p><p>为了解决上述跨语言预训练模型[Conneau等，2019]在CLCD场景中的局限性，我们提出了一种无监督的特征分解（UFD）方法，它只利用源语言中的未标记数据。具体来说，我们提出的方法受到最近提出的无监督表示学习方法[Hjelm等人，2019]的启发，<strong>通过结合互信息最大化和最小化</strong>，<strong>可以同时提取领域不变的特征和领域特定的特征</strong>。与以往的跨语言迁移学习方法相比，我们提出的模型保持了跨语言预训练模型的优点，即对百余种语言具有良好的泛化能力，并且只需要源语言中的未标记数据进行领域适应，适用于更多的跨语言迁移场景。</p><p>我们在一个基准的跨语言感官分类数据集上评估了我们的模型，即亚马逊评论[Pretten- hofer and Stein, 2010]，它涉及多种语言和领域。实验结果表明，随着预训练的XLM跨语言模型的增强，我们提出的UFD模型（在源语言的一些未标记的原始文本上训练）和一个简单的Lin-ear分类器（在源语言和源领域的小型标记数据集上训练）胜过那些能够获得强大的跨语言监督（如商业MT系统）或多尖端源语言的标记数据集的最先进模型。此外，将我们提出的UFD策略与源语言中未标记的15万个实例集结合起来，可以持续获得超过强大的预训练XLM模型的收益，该模型是在100种语言和TB级文本上训练的。广泛的实验进一步证明，在预训练的跨语言语言模型上的无监督特征分解优于在超过1亿句话上训练的特定领域语言模型。</p><h2 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h2><h3 id="Problem-Definition-amp-Model-Overview"><a href="#Problem-Definition-amp-Model-Overview" class="headerlink" title="Problem Definition &amp; Model Overview"></a>Problem Definition &amp; Model Overview</h3><p>在本文中，我们考虑的是这样一种情况：我们只有一个特定语言和特定领域的标记集 $D<em>{s,s}$，我们称之为源语言和源领域，而我们想训练一个分类器，在一个不同语言和不同领域的集合 $D</em>{t,t}$上进行测试，我们称之为目标语言和目标领域。我们还假设在训练阶段可以获得一些未标记的原始数据 $D_{s,u}$，包括源语言的目标域，这在实际应用中通常是可行的。我们称这种设置为无监督的跨语言和跨领域（CLCD）适应。</p><p><img src="https://s2.loli.net/2021/12/27/o3tFG5CdeVp19hS.png" alt=""></p><p>如图1所示，建议的方法由三个部分组成：一个预训练的多语言嵌入模块，将输入文档嵌入到语言不变的表示中；一个无监督特征分解（UFD）模块，<strong>从纠缠的语言不变的表示中提取领域不变的特征和特定领域的特征</strong>；<strong>以及一个根据提取的领域不变的特征和特定领域特征训练的特定任务模块。</strong>我们采用XLM1[Conneau and Lample, 2019]作为我们方法中的多语言嵌入模块，它已经被来自各种语言的大规模平行和单语数据预训练过，是目前最先进的跨语言语言模型。我们在下面的小节中描述其他两个模块和训练过程。</p><p>在我们的方法中，我们采用了最近提出的神经估计方法[Belghazi等人，2018]，该方法通过训练一个网络工作来估计两个连续随机变量 $X$ 和 $Y$ 的MI，以区分来自它们的联合分布 $J$ 的样本和它们的边际分布的乘积 $M$ ，这种估计利用了基于KL-divergence的Donsker-Varadhan表示（DV）[Donsker和Varadhan，1983]的MI下限。</p><script type="math/tex; mode=display">I(X;Y) := D_{KL}(J|M) \ge \hat I^{DV}(X;Y)) := E_J[T_w(x,y)] - logE_M[e^{T_w(x,y)}]</script><p>其中，$T<em>ω$是一个辨别函数，由一个具有可学习参数 $ ω$ 的神经网络作为参数。通过最大化 $\hat I^{DV}$， $T</em>ω$ 被鼓励区分从 $J$ 和 $M$ 中抽取的样本，给前者分配大值，给后者分配小值。</p><h3 id="Proposed-Method"><a href="#Proposed-Method" class="headerlink" title="Proposed Method"></a>Proposed Method</h3><p>让 $X∈R^d$ 表示由预训练的多语言嵌入模块生成的语言不变量表示。然后将其作为输入输入到拟议的 UFD模块。</p><p>如图1所示，我们引入了两个特征提取器：领域不变的提取器 $F_s$（即左边的ReLU激活的两层前馈网络），以及领域特定的提取器 $F_p$（即右边的两层网络）。我们把提取的特征分别表示为 $F_s(X)$ 和 $F_p(X)$。请注意，对于 $F_s$，我们增加了剩余连接，以更好地保持 $X$ 的领域不变属性。</p><p>具体来说，$F_s$ 旨在以无监督的方式从语言不变量的表述中提取领域不变量的特征。<strong>由于多语言嵌入模块是在超过一百种语言的开放领域数据集上进行预训练的，因此可以推测，生成的语言不变量表示应该包含某些可以跨领域泛化的属性。</strong></p><p>当 $F_s$ 在多个领域接受训练，每个领域的输入和输出之间的 $MI$ 共同最大化时，鼓励它从语言不变的表征中保留这些领域之间的共享特征。通过这种方式，$F_s$ 被迫将领域不变的信息从 $X$ 传递给 $F_s(X)$。</p><p>我们利用方程（1）中提出的基于神经网络的估计器来计算MI。在我们的案例中，由于 $F_s(X)$依赖于 $X$ ，我们可以将基于DV-based 的MI估计器简化为Jensen-Shannon MI估计器，正如[Hjelm等人，2019]中建议的那样:</p><script type="math/tex; mode=display">\hat I^{JSD} (X; F_s(X)) := E_p[-sp(-T_w(x, F_s(x)))] - E_{p\times p}[sp(T_w(x',F_s(x)))]</script><p>其中 x 是一个具有经验概率分布 P 的输入嵌入。由于 $F_s(x)$ 是直接从 $x$ 计算出来的，$(x, F_s(x))$ 可以被视为从 $x$ 和 $F_s(x)$ 的联合分布中抽取的样本。$x’$ 对应于来自 $\hat P=P$的输入嵌入，即 $x$ 是从同一输入分布中抽取的随机样本计算出来的，这样 $(x’,F_s(x))$ 就是从边际分布的乘积中抽取的。$sp(z) = log(1+e^z)$ 是 softplus 激活函数。$F_s$ 的训练目标是使 $X$ 和 $F_s (X )$上的MI最大化，损失表述如下:</p><script type="math/tex; mode=display">L_s(w_s,\phi_s) = -\hat I^{JSD}(X,F_s(X))</script><p>其中 $ω_s$ 表示估计器中的辨别网络工作的参数，$ψ_s$表示 $F_s$ 的参数。为了便于学习领域不变的特征，我们还提出对 $F_s(X)$和相应的中间表示(第一层输出) $F’_s(X )$ 的MI最大化，训练损失如下:</p><script type="math/tex; mode=display">L_r(w_r, \phi_s) = -\hat I^{JSD}(F'_s(X), F_s(X))</script><p>其中 $ω_r$ 表示估计器中判别器网络的参数。回顾一下，$F_p$ 的目标是提取特定领域的特征，这应该是排他性的，并且独立于领域的不变量特征。我们建议最小化由 $F_s$ 和 $F_p$ 提取的特征之间的 $MI$，训练损失表述如下:</p><script type="math/tex; mode=display">L_p (w_p, \phi_s, \phi_p) = \hat I^{JSD} (F_s(X), F_p(X))</script><p>其中 $ψ_p$ 表示 $F_p$ 的参数。 $ω_p$ 表示MI估计器中歧视网络的参数。</p><p>因此，拟议的UFD组件的训练目标是使整体损失最小化，具体如下:</p><script type="math/tex; mode=display">L_{UFD} = \alpha L_s +\beta L_r + \gamma L_p</script><p>其中，α、β和γ是用于平衡次损失影响的超参数。</p><h3 id="Task-Specific-Module"><a href="#Task-Specific-Module" class="headerlink" title="Task-Specific Module"></a>Task-Specific Module</h3><p>在特定任务模块中，我们首先采用一个线性层，将 $R^{2d}$ 中的领域不变特征和领域特定特征的串联映射为 $R^d$中的矢量表示。然后，在这个映射的向量表示上采用一个简单的前馈层，用softmax激活来输出任务标签。我们在 $D_{s,s}$上训练这个模块，交叉熵损失表示为 $L_t$，作为训练目标。</p><h3 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h3><p>请注意，多语言嵌入模块的参数是经过预训练的，并且在整个训练过程中被设定为冻结。我们首先优化UFD的参数，即{ωs,ωr,ωp,ψs,ψp}，通过最小化无标签集Ds,u上的LUFD。一旦UFD模块训练完成，我们就固定其参数，并通过在有标签的集合Ds,s上最小化Lt来训练特定任务的模块。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Unsupervised-Domain-Adaptation-of-a-Pretrained-Cross-Lingual-Language-Model&quot;&gt;&lt;a href=&quot;#Unsupervised-Domain-Adaptation-of-a-Pretraine</summary>
      
    
    
    
    
    <category term="context detection" scheme="http://example.com/tags/context-detection/"/>
    
  </entry>
  
  <entry>
    <title>Contrastive Representation Distillation</title>
    <link href="http://example.com/2021/12/22/Contrastive-Representation-Distillation/"/>
    <id>http://example.com/2021/12/22/Contrastive-Representation-Distillation/</id>
    <published>2021-12-22T15:50:39.000Z</published>
    <updated>2021-12-22T15:59:23.978Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Contrastive-Representation-Distillation"><a href="#Contrastive-Representation-Distillation" class="headerlink" title="Contrastive Representation Distillation"></a>Contrastive Representation Distillation</h1><p>我们经常希望将表征性知识从一个神经网络转移到另一个神经网络。这方面的例子包括将一个大型网络提炼成一个较小的网络，将知识从一种感觉模式转移到另一种感觉模式，或者将一系列模型集合成一个单一的估计器。知识提炼是解决这些问题的标准方法，它使教师和学生网络的概率输出之间的KL散度最小。我们证明这个目标忽略了教师网络的重要结构知识。</p><p>这促使我们提出了另一个目标，即训练学生在教师的数据表述中捕捉到更多的信息。我们把这个目标表述为对比学习。</p><p>实验证明，我们所产生的新目标在各种知识迁移任务上优于知识蒸馏和其他尖端的蒸馏器，包括单一模型压缩、集合蒸馏和跨modal转移。我们的方法在许多迁移任务中创造了新的最先进的技术，当与知识蒸馏相结合时，有时甚至超过了教师网络。</p><h2 id="INTRODUCTION"><a href="#INTRODUCTION" class="headerlink" title="INTRODUCTION"></a>INTRODUCTION</h2><p>知识蒸馏（KD）将知识从一个深度学习模型（教师）转移到另一个（学生）。最初由Hinton等人（2015）提出的目标是最小化教师和学生输出之间的KL散度。当输出是一个分布时，这种表述具有直观的意义，例如，在类上的概率质量函数。然而，我们经常希望迁移关于一个表示的知识。例如，在 “跨模型蒸馏 “的问题中，我们可能希望将图像处理网络的表示迁移到声音（Aytar等人，2016）或深度（Gupta等人，2016）处理网络，这样，图像的深度特征和相关的声音或深度特征是高度相关的。在这种情况下，KL散度是不确定的。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Contrastive-Representation-Distillation&quot;&gt;&lt;a href=&quot;#Contrastive-Representation-Distillation&quot; class=&quot;headerlink&quot; title=&quot;Contrastive Re</summary>
      
    
    
    
    
    <category term="context detection" scheme="http://example.com/tags/context-detection/"/>
    
  </entry>
  
  <entry>
    <title>Achieving Forgetting Prevention and Knowledge Transfer in Continual Learning</title>
    <link href="http://example.com/2021/12/22/Achieving-Forgetting-Prevention-and-Knowledge-Transfer-in-Continual-Learning/"/>
    <id>http://example.com/2021/12/22/Achieving-Forgetting-Prevention-and-Knowledge-Transfer-in-Continual-Learning/</id>
    <published>2021-12-22T06:09:05.000Z</published>
    <updated>2021-12-27T09:06:46.628Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Achieving-Forgetting-Prevention-and-Knowledge-Transfer-in-Continual-Learning"><a href="#Achieving-Forgetting-Prevention-and-Knowledge-Transfer-in-Continual-Learning" class="headerlink" title="Achieving Forgetting Prevention and Knowledge Transfer in Continual Learning"></a>Achieving Forgetting Prevention and Knowledge Transfer in Continual Learning</h1><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>持续学习（CL）是指逐步学习一连串的任务，目的是实现两个主要目标：克服灾难性遗忘（CF）和鼓励跨任务的知识转移（KT）。然而，大多数现有的技术只注重克服CF，没有鼓励KT的机制，因此在KT中表现不佳。尽管有几篇论文试图同时处理CF和KT，但我们的实验表明，当任务没有太多的共享知识时，它们受到严重的CF影响。</p><p>另一个观察结果是，目前大多数CL方法没有使用预训练的模型，但事实证明，这种模型可以大大改善最终的任务表现。例如，在自然语言处理中，对类似BERT的预训练语言模型进行微调是最有效的方法之一。</p><p> 然而，对于CL来说，这种方法受到了严重的CF的影响。一个有趣的问题是如何将预训练的模型最好地用于CL。本文提出了一个名为CTR的新模型来解决这些问题。我们的实验结果证明了CTR的有效性。</p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>本文研究了在任务持续学习（Task-CL）环境下的自然语言处理（NLP）任务序列的持续学习（CL）。它的目的是 </p><ul><li>(i) 防止灾难性遗忘(CF)</li><li>(ii)跨任务的知识转移</li></ul><p>(ii)特别重要，因为NLP中的许多任务共享类似的知识，可以利用这些知识来实现更好的准确性。CF意味着在学习一个新的任务时，为以前的任务所学的现有网络参数可能会被修改，从而降低以前任务的性能[40]。</p><p> 在任务-持续学习设置中，在测试中为每个测试案例提供任务ID，这样就可以应用网络中任务的特定模型来对测试案例进行分类。另一个流行的CL设置是类持续学习，它在测试中不提供任务ID，但它是为了解决不同类型的问题。</p><p>现有的CL论文大多集中在处理CF[21, 5]。也有一些论文是进行知识转移的。要实现这两个目标是非常具有挑战性的。为了克服任务-CL设置中的CF，我们不希望新任务的训练更新为以前的任务学习的模型参数，以实现模型分离。</p><p> 但是，为了实现跨任务的知识转移，我们希望新任务能够利用从以前的任务中学到的知识来学习更好的模型（前向转移），也希望新任务能够提高以前类似任务的性能（后向转移）。</p><p>这意味着有必要更新以前的模型参数。这是个两难的问题。虽然有几篇论文试图处理这两方面的问题[22, 37]，但它们只使用具有强大共享知识的情感分析任务进行测试。当用没有太多共享知识的任务进行测试时，它们会受到严重的CF影响（见5.4节）。那些专注于处理CF的现有论文在知识转移方面做得不好，因为它们没有明确的机制来促进转移。</p><p>关于目前CL研究的另一个观察结果是，大多数技术没有使用预训练的模型。但这种预训练的模型或特征提取器可以显著提高CL的性能[18, 24]。一个重要的问题是如何在CL中最好地利用预训练的模型。本文也使用NLP任务来研究这个问题，但我们相信所开发的思想也适用于计算机视觉任务，因为大多数预训练的模型都是基于变换器架构的[60]。我们将看到，在预训练模型上直接添加CL模块的天真或传统方式并不是最佳选择（见第5.4节）。</p><p>在NLP中，微调一个类似于BERT[8]的预训练语言模型已被视为应用中最有效的技术之一[65, 57]。然而，微调对持续学习的效果很差。这是因为一个任务的微调BERT捕获了高度特定的任务信息[41]，这很难被其他任务所使用。当为一个新的任务进行微调时，它必须更新以前的任务已经微调的参数，这将导致严重的CF（见第5.4节）。</p><p>本文提出了一种新型的神经结构，以实现CF的预防和知识转移，同时也处理了具有BERT微调的CF问题。提出的系统被称为CTR（持续学习的胶囊和转移路由）。CTR在BERT的两个位置插入了一个持续学习插件（CL-plugin）模块。在BERT中加入这对CL-插件模块后，我们不再需要为每个任务对BERT进行微调，因为这将导致BERT中的CF，但我们却可以实现BERT微调的功能。CTR与Adapter-BERT[16]有一些相似之处，后者在BERT中增加了适配器，用于参数的有效转移学习，这样，不同的终端任务可以有其独立的适配器（其尺寸非常小）来为各个终端任务调整BERT，并将BERT的知识转移到终端任务中。那么，就不需要为每个任务采用单独的BERT并对其进行微调，如果需要学习许多任务，那么参数效率是非常低的。适配器是一个简单的2层全连接网络，用于将BERT适应于特定的终端任务</p><p>CL-插件与适配器有很大不同。我们不使用一对CL-插件模块来为每个任务调整BERT。相反，CTR只使用插入到BERT中的一对CL-插件模块来学习所有的任务。CL-插件是一个完整的CL网络，可以利用预训练的模型，处理CF和知识转移。具体来说，它使用一个胶囊[15]来代表每个任务，并使用一个拟议的转移路由算法来识别和转移跨任务的知识，以达到提高准确性的目的。它进一步学习和使用任务掩码来保护特定任务的知识，以避免遗忘。经验评估表明，CTR的性能优于强大的基线。还进行了消融实验，以研究在何处插入BERT中的CL-插件模块，以实现最佳性能（见第5.4节）。</p><h2 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h2><h3 id="Catastrophic-Forgetting"><a href="#Catastrophic-Forgetting" class="headerlink" title="Catastrophic Forgetting"></a>Catastrophic Forgetting</h3><p>CL的现有工作主要集中在使用以下方法来克服CF。(1) 基于正则化的方法，如[27, 30, 51, 69]，在损失中加入正则化，以便在学习新任务时巩固以前任务的权重。(2）基于重放的方法，如[45, 36, 4, 63]中的方法，保留一些旧任务的训练数据，并在学习新任务时使用它们。54, 20, 47, 14]中的方法学习数据生成器并生成旧任务数据用于学习新任务。(3) 基于参数隔离的方法，如[52, 21, 39, 10]中的方法，分配专用于不同任务的模型参数，并在学习新任务时将其屏蔽。(4) 基于梯度投影的方法[68]确保梯度更新只发生在旧任务输入的正交方向上，因此不会影响旧任务。最近的一些论文使用了预训练的模型[18, 23, 24]和每个任务学习一个类[18]。应对CF只处理模型恶化的问题。这些方法的表现比单独学习每个任务要差。在[44]中对CF的原因和任务相似性对CF的影响进行了实证研究。</p><p>一些NLP的应用也涉及到CF。例如，CL模型已被提出用于情感分析[23, 24, 37, 43]、对话槽填充[53]、语言建模[58, 7]、语言学习[31]、句子嵌入[33]、机器翻译[25]、跨语言建模[35]，以及问题回答[12]。在[38]中也报告了一个对话CL数据集。</p><h3 id="Knowledge-Transfer"><a href="#Knowledge-Transfer" class="headerlink" title="Knowledge Transfer"></a>Knowledge Transfer</h3><p>理想情况下，从任务序列中学习也应该允许多个任务通过知识转移相互支持。CAT[21]（一个任务-CL系统）在相似和不相似的任务的混合序列上工作，可以在自动检测到的相似任务之间转移知识。渐进式网络[48]做了前向转移，但它是针对类持续学习（Class-CL）。</p><p>本文中的知识转移与终身学习（LL）密切相关，其目的是在不处理CF的情况下提高新的/最后的任务学习[56, 49, 5]。在NLP领域，NELL[3]进行了LL信息提取，还有几篇论文致力于终身的文档情感分类（DSC）和方面情感分类（ASC）。[6]和[61]提出了两种Naive Bayesian方法来帮助提高新任务的学习。[64]提出了一种基于投票的LL方法。[55]将LL用于方面提取。[43]和[62]分别将神经网络用于DSC和ASC。有几篇论文也研究了终身主题建模[5, 13]。然而，所有这些工作都没有涉及到CF。</p><p>SRK[37]和KAN[22]试图在持续情感分类中同时处理CF和知识转移问题。然而，它们有两个关键的弱点。(i) 它们的RNN架构不能使用插件或适配器模块来调整BERT，这大大限制了它们的能力。(ii) 由于它们主要是为知识转移而设计的，因此它们受到了严重的CF（见第5.4节）。B-CL[24]使用适配器的想法[16]来调整BERT的情感分析任务，这两者之间是相似的。然而，由于其知识转移的动态路由机制非常弱，其知识转移能力明显比CTR差（见第5.4节）。CLASSIC[23]是另一个关于知识转移的持续学习的最新工作，但其CL设置是领域持续学习。它的知识转移方法是基于对比学习。</p><p>AdapterFusion[42]使用了[16]中提出的适配器。它提出了一个两阶段的方法来学习一组任务。在第一阶段，它使用任务的训练数据为每个任务独立学习一个适配器。在第二阶段，它再次使用训练数据来学习第一阶段学到的适配器的良好组合，以产生所有任务的最终模型。AdapterFusion基本上试图改善多任务学习。它不是为了持续学习，因此没有CF。正如第1节所解释的，CTR中的CL-插件概念与为每个任务适应BERT的适配器不同。CL-插件是利用预先训练的模型的持续学习系统。</p><h2 id="CTR-Architecture"><a href="#CTR-Architecture" class="headerlink" title="CTR Architecture"></a>CTR Architecture</h2><p><img src="https://s2.loli.net/2021/12/22/5RCDskL4aQvEJeN.png" alt=""></p><p>本节介绍了 CTR 的总体架构。关于其关键组件 CL-plugin 的细节将在下一节介绍。由于其良好的性能，BERT[8]及其变压器[60]结构在我们的模型CTR中被用作基础。由于BERT微调容易出现CF（第1节），我们提出了CL-plugin的想法，其灵感来自Adapter-BERT[16]。CL-插件是一个完整的持续学习模块，旨在与预先训练的模型（在我们的例子中是BERT）进行交互。</p><h3 id="Inserting-CL-plugins-in-BERT"><a href="#Inserting-CL-plugins-in-BERT" class="headerlink" title="Inserting CL-plugins in BERT"></a>Inserting CL-plugins in BERT</h3><p>一个常用的利用预训练模型的方法是在预训练模型的基础上增加终端任务模块。然而，正如第1节所解释的，对预训练模型进行微调会给CL带来严重的CF。使用这种方法的CL系统PCL[18]，将预训练的模型冻结起来，以避免遗忘。但正如我们将在第5.4节中看到的，这不是最好的选择。CTR在BERT的两个位置插入了提议的CL插件，即在BERT的每个变压器层中。我们还将在第5.4节中看到，在一个位置只插入一个CL插件是次优的。图1给出了CTR架构，我们可以看到两个CL-插件被添加到BERT中。在学习中，只有这两个CL插件和分类头被训练。原始预训练的BERT的组件是固定的。</p><h3 id="Continual-learning-plug-in-CL-plugin"><a href="#Continual-learning-plug-in-CL-plugin" class="headerlink" title="Continual learning plug-in (CL-plugin)"></a>Continual learning plug-in (CL-plugin)</h3><p>CL-plugin采用了类似胶囊网络（CapsNet）[15, 50]的架构。在经典的神经网络中，一个神经元输出一个标量、实值的激活作为特征检测器。CapsNets用一个矢量输出的胶囊代替，以保留额外的信息。一个简单的CapsNet由两个胶囊层组成。第一层存储低级别的特征图，第二层生成分类概率，每个胶囊对应一个类别。CapsNet使用动态路由算法，使每个低层的胶囊将其输出发送到类似的（或 “同意的”，由点积计算的）高层胶囊。这一特性已经可以用来对类似的任务及其可共享的特征进行分组，以产生一个CL系统（见5.4节中的消融研究）。CL-插件的关键思想之一（见图2(A)）是一个转移胶囊层，它有一个新的转移路由算法，可以明确地识别从以前的任务转移到新任务的可转移特征/知识。</p><h2 id="Continual-Learning-Plug-in-CL-plugin"><a href="#Continual-Learning-Plug-in-CL-plugin" class="headerlink" title="Continual Learning Plug-in (CL-plugin)"></a>Continual Learning Plug-in (CL-plugin)</h2><p>我们的持续学习插件（CL-plugin）的结构如图2（A）所示。CL-plugin需要两个输入。(1) 来自变压器层内前馈层的隐藏状态h(t)和 (2) 任务ID t，这是任务持续学习（Task-CL）的要求。输出是具有适合第t个任务分类的特征的隐藏状态。在CL-plugin内部，有两个模块。(1）知识共享模块（KSM），用于识别和转移以前类似任务的可共享知识到新任务t，以及（2）任务特定模块（TSM），用于学习任务特定的神经元及其掩码（可以保护神经元不被未来任务更新，以处理CF）。由于TSM是可分的，整个系统CTR可以进行端到端的训练。</p><h3 id="Knowledge-Sharing-Module-KSM"><a href="#Knowledge-Sharing-Module-KSM" class="headerlink" title="Knowledge Sharing Module (KSM)"></a>Knowledge Sharing Module (KSM)</h3><p>KSM通过任务封装层(TK-Layer)、传输胶囊层(TR-Layer)和传输路由机制实现相似任务之间的知识传输。</p><h4 id="Task-Capsule-Layer-TK-Layer"><a href="#Task-Capsule-Layer-TK-Layer" class="headerlink" title="Task Capsule Layer (TK-Layer)"></a>Task Capsule Layer (TK-Layer)</h4><p>TK层中的每个胶囊代表一个任务，它准备了从每个任务中得到的低层次特征（图2（A））。因此，每个新任务都有一个胶囊被添加到TK层中。这种递增式的增长是有效和容易的，因为这些胶囊是离散的，不共享参数。另外，每个胶囊只是一个具有少量参数的2层全连接网络。让 $h(t)∈R^{d_t×d_e}$ 是CL-plugin的输入，其中dt是tokens的数量，de是维数，t是当前任务。在TK层中，我们为每个任务准备了一个胶囊。假设到目前为止我们已经学会了t个任务。第i个（i≤t）任务的胶囊是:</p><script type="math/tex; mode=display">p_i^{(t)} = f_i(h^{(t)})</script><p>其中$f_i(·)=MLP_i(·)$表示2层全连通网络。</p><h4 id="Transfer-Routing-and-Transfer-Capsule-Layer"><a href="#Transfer-Routing-and-Transfer-Capsule-Layer" class="headerlink" title="Transfer Routing and Transfer Capsule Layer"></a>Transfer Routing and Transfer Capsule Layer</h4><p>转移胶囊层（TR层）中的每个胶囊代表从TK层中提取的可转移表示。如图2（A）所示，TK层的低级胶囊和TR层的高级胶囊之间的转移路由有三个组成部分：预路由向量发生器（PVG）、相似性估计器（SE）和任务路由器（TR）。鉴于TK层中的任务胶囊，我们首先通过一个可训练的权重矩阵来转换特征。我们把这种转换的输出称为预路由向量。每个SE使用预路由向量估计以前的任务和当前的任务之间的相似性，从而为每个高层的胶囊得出相似性分数。此外，每个SE都有一个TR模块，一个作为门的可区分的任务路由器。这个路由器估计一个二进制信号，决定是否连接或断开两个连续的胶囊层（即CL-插件中的TK层和TR层）之间的当前路线。由TR估计的二进制信号可以被看作是一个可区分的二进制注意。从概念上讲，每个SE和TR对一起以随机和可区分的方式学习胶囊之间的连接性，这可以被看作是一个基于任务相似性的连接性搜索机制。这种转移路由确定了来自多个任务胶囊的共享特征/知识，并帮助知识在类似任务之间转移。接下来，我们讨论预路由向量发生器、相似性估计器和任务路由器。</p><h1 id="CLASSIC-Continual-and-Contrastive-Learning-of-Aspect-Sentiment-Classification-Tasks"><a href="#CLASSIC-Continual-and-Contrastive-Learning-of-Aspect-Sentiment-Classification-Tasks" class="headerlink" title="CLASSIC: Continual and Contrastive Learning of Aspect Sentiment Classification Tasks"></a>CLASSIC: Continual and Contrastive Learning of Aspect Sentiment Classification Tasks</h1><p>本文研究了在一个特殊的持续学习（CL）环境下的一系列方面情感分类（ASC）任务，称为领域递增学习（DIL）。每个任务都来自不同的领域或产品。DIL设置特别适用于ASC，因为在测试中，系统不需要知道测试数据所属的任务/领域。据我们所知，这种设置以前还没有为ASC研究过。本文提出了一个叫做CLASSIC的新模型。关键的创新点是一种对比性的持续学习方法，它既能实现跨任务的知识转移，又能将知识从旧任务提炼到新任务，这就消除了测试中对任务ID的需求。实验结果表明，CLASSIC的有效性很高。</p><h2 id="Introduction-1"><a href="#Introduction-1" class="headerlink" title="Introduction"></a>Introduction</h2><p>持续学习（CL）以递增的方式学习一连串的任务。在学习完一个任务后，其训练数据通常被丢弃（Chen和Liu，2018）。当数据隐私是一个问题时，CL设置是有用的，即数据所有者不希望他们的数据被其他人使用（Ke等人，2020b；秦等人，2020；Ke等人，2021）。在这种情况下，如果我们想利用过去学到的知识来改善新的任务学习，CL是合适的，因为它只分享学到的模型，而不是数据。在我们的案例中，一个任务是一个产品或领域（例如，相机或手机）的一个单独的方面情感分类（ASC）问题（刘，2012）。ASC表述如下。给出一个方面的术语（例如，手机评论中的声音质量）和一个包含该方面的句子（例如，”声音质量很差”），ASC对该句子是否表达了对该方面的积极、消极或中立的意见进行分类。</p><p>有三种CL设置（van de Ven and Tolias, 2019）。类增量学习（CIL），任务增量学习（TIL），和域增量学习（DIL）。在CIL中，任务包含不重叠的类。对于目前看到的所有类别，只建立一个模型。在测试中，不提供任务信息。这种设置不适合ASC，因为ASC任务有相同的三个类。TIL为共享网络中的每个任务建立一个模型。在测试中，系统需要每个测试实例（例如，”音质很好”）所属的任务（例如，电话领域），并且只使用任务的模型来对实例进行分类。重新要求任务信息（如电话领域）是一个限制。理想情况下，用户不应该为一个测试句子提供这些信息。这就是DIL设置，即所有任务共享相同的固定类别（例如，积极、消极和中立）。在测试中，不需要任何任务信息。</p><p>这项工作使用DIL设置来学习神经网络中的一系列ASC任务。关键的目标是在不同的任务之间转移知识，以改善分类，而不是单独学习每个任务。任何CL的一个重要目标是克服灾难性遗忘（CF）（McCloskey和Cohen，1989），这意味着在学习一个新的任务时，系统可能会改变为以前的任务学习的参数，导致其性能下降。我们也要解决CF的问题，否则我们就不能达到提高准确性的目的。然而，DIL中的所有任务共享分类头，使得跨任务干扰/更新不可避免。没有测试中提供的任务信息，使DIL更具挑战性。</p><p>以前的研究表明，ASC最有效的方法之一（Xu等人，2019；Sun等人，2019）是使用训练数据对BERT进行微调（Devlin等人，2019）。然而，我们的实验表明，这对DIL来说效果很差，因为一个任务上的微调BERT捕获了高度的任务特定特征，而这些特征很难被其他任务使用。</p><p>在本文中，我们在DIL设置中提出了一个名为CLASSIC（Continual and contrastive Learning for ASpect SentIment Classification）的新型模型。CLASSIC没有为每个任务微调BERT，这将导致严重的CF，而是使用（Houlsby等人，2019）中的Adapter-BERT的想法来避免改变BERT参数，但却能获得与BERT微调同样好的结果。提出了一种新颖的对比性持续学习方法（1）将可共享的知识转移到不同的任务中，以提高所有任务的准确性；（2）将以前的任务中的知识（包括可共享的和不可共享的）提炼到新任务的模型中，使新的/最后一个任务模型能够执行所有的任务，这样就不需要在测试中提供任务信息（如任务ID）。现有的对比学习（Chen等人，2020）无法做到这些。</p><p>任务 mask 也被学习并用于保护特定任务的知识以避免遗忘（CF）。已经进行了大量的实验来证明CLASSIC的有效性。<br>综上所述，本文有以下贡献。(1) 它提出了ASC的领域持续学习问题，这在以前是不可能的。(2) 它提出了一个名为CLASSIC的新模型，该模型使用适配器将预先训练好的BERT纳入ASC的持续学习中，使用一种新颖的对比性持续学习方法进行知识转移和提炼，并使用任务掩码隔离特定任务的知识以避免CF。</p><h2 id="Proposed-CLASSIC-Method"><a href="#Proposed-CLASSIC-Method" class="headerlink" title="Proposed CLASSIC Method"></a>Proposed CLASSIC Method</h2><p><img src="https://s2.loli.net/2021/12/22/Gpm9vTXgPAfsqyt.png" alt=""></p><h3 id="3-1-Overview-of-CLASSIC"><a href="#3-1-Overview-of-CLASSIC" class="headerlink" title="3.1 Overview of CLASSIC"></a>3.1 Overview of CLASSIC</h3><p>图1中给出了CLASSIC的结构，它在ASC的DIL设置中工作。它使用Adapter-BERT来避免对BERT进行微调。CLASSIC在训练中需要两个输入。(1) 来自BERT变压器层的前馈层的隐藏状态 $h(t)$ 和  (2) 任务 id $t$（测试时不需要任务 id，见第3.2.3节）。输出是带有任务 $t$ 特征的隐藏状态，以建立一个分类器。</p><p>CLASSIC使用三个子系统来实现其目标（见第1节）。</p><ul><li>(1) 对比性集合提炼(CED)，通过将以前的任务知识提炼到当前的任务模型中来减轻CF；</li><li>(2) 对比性知识共享(CKS)，鼓励知识转移；</li><li>(3) 当前任务模型的对比性监督学习(CSC)，提高当前任务模型的准确性。我们把这个框架称为对比性持续学习，其灵感来自于对比性学习。</li></ul><p>对比学习使用现有数据的多个视图进行表征学习，将相似的数据组合在一起，并将不相似的数据推得很远，这使得学习更准确的分类器更加容易。它使用现有数据的各种转换来创建有用的视图。给定一个由 $N$ 个训练实例组成的小型批次，如果我们为每个实例创建另一个视图，该批次将有 $2N$ 个样本。</p><p>我们假设 $i$ 和 $j$ 是训练实例的两个视图。如果我们用 $i$ 作为锚点。$(i, j)$ 被称为正对。所有其他 $k\ne i$ 的对$(i,k)$都是负对。这个正数对的对比损失是（Chen等人，2020）,</p><script type="math/tex; mode=display">L_{i,j} = - log\frac{exp((h_i\cdot h_j)/ \tau)}{\sum_{k=1}^{2N} 1_{k\ne j} exp((h_i\cdot h_k)/ \tau)}</script><p>其中点积 $h_i \cdot h_j$ 被视为隐藏空间中的相似性函数，$τ$ 是温度。该批次的最终损失是在所有的正数对中计算的。上式是用于无监督的对比学习。它也可以用于监督对比学习，来自同一类别的任何两个实例/视图形成一个正例对，而一个类别的任何实例和其他类别的任何实例形成一个负例对。</p><h3 id="3-2-Overcoming-Forgetting-via-Contrastive-Ensemable-Distillation-CED"><a href="#3-2-Overcoming-Forgetting-via-Contrastive-Ensemable-Distillation-CED" class="headerlink" title="3.2 Overcoming Forgetting via Contrastive Ensemable Distillation (CED)"></a>3.2 Overcoming Forgetting via Contrastive Ensemable Distillation (CED)</h3><p>CED的目标是处理CF。我们首先介绍了CED所依赖的任务掩码，以保留以前的任务知识/模型，将其提炼到新的任务模型中，以避免CF。</p><h4 id="3-2-1-Task-Masks-TMs"><a href="#3-2-1-Task-Masks-TMs" class="headerlink" title="3.2.1 Task Masks (TMs)"></a>3.2.1 Task Masks (TMs)</h4><p>给定来自转换层前馈层的输入隐藏状态 $h^{(t)} $，adapter 通过全连接网络将其映射为输入$k^{(t)}_l$，其中 $l$ 是适配器的第 $l$ 层。</p><p>在训练任务 $t$ 的分类器时，在 adapter 的每一层 $l$ 为每个任务 $t$ 训练一个 TM（一个 “软 “二进制掩码）$m^{(t)}_l$，表明该层中对任务重要的神经元。在这里，我们借鉴了（Serrà等人，2018）中的 hard attention 思想，并利用任务 id 嵌入来训练TM。</p><p>对于一个任务id t，它的嵌入$e^{(t)}_l$ 由可微调的参数组成，可以和网络的其他部分一起学习，它是为 adapter 中的每一层训练的。为了从 $e^{(t)}_l $ 中生成TM $m^{(t)}_l$，Sigmoid被用作伪门，并应用一个正的缩放超参数 $s$ 来帮助训练。$m^{(t)}_l $的计算方法如下:</p><script type="math/tex; mode=display">m_l^{(t)} = \sigma (se_l^{(t)})</script><p>请注意，$ m^{(t)}_l $ 中的神经元可能与以前任务中的其他 $m^{(iprev)}_l$ 的神经元重叠，显示出一些共享的知识。给出适配器中每一层的输出，$k^{(t)}_l $，我们将其进行元素乘法计算 $k^{(t)}_l ⊗ m^{(t)}_l$。</p><p>最后一层的屏蔽输出 $k^{(t)}_l \otimes m_l^{(t)} $ 被送入BERT的下一层，有一个跳过的连接（见图2）在学习任务 $t$ 之后，最终的 $m^{(t)}_l $ 被保存并添加到集合 ${m^{(t)}_l}$中。</p><p><img src="https://s2.loli.net/2021/12/22/UNWkgiRwKYlq4en.png" alt=""></p><h4 id="3-2-2-Training-Task-Masks-TMs"><a href="#3-2-2-Training-Task-Masks-TMs" class="headerlink" title="3.2.2 Training Task Masks (TMs)"></a>3.2.2 Training Task Masks (TMs)</h4><p>对于每个先前的任务 $i<em>{prev} \in T</em>{prev}$，其TM $m^{(iprev)}_l$表明哪些神经元被该任务使用并需要保护。在学习任务 $t$ 中，$m^{(iprev)}_l $ 用来设置 $l$ 层所有使用的神经元上的梯度 $g(t)$ 层的所有神经元的梯度为 0。在修改梯度之前，我们首先积累所有以前的任务TMs 所使用的神经元。由于 $m^{(iprev)}_l$ 是二进制的，我们用最大池化来实现累积：</p><script type="math/tex; mode=display">m_l^{(t_{ac})} = MaxPool(\{m_l^{(i_{prev})}\})</script><p>term $m^{(T_{ac})}_l$用于梯度：</p><script type="math/tex; mode=display">g_l^{'(t)} = g^{(t)}_l \otimes (1-m_l^{(t_{ac})})</script><p>那些对应于 $m^{(t<em>{ac})}_l$ 中1项的梯度被设置为0，而其他梯度则保持不变。通过这种方式，旧任务中的神经元被保护起来。请注意，我们扩展（复制）矢量 $m^{(t</em>{ac})}_l $ 以匹配 $g^{(t)}_l$ 的尺寸。</p><p>虽然这个想法很直观，但 $e^{(t)}<em>l $ 并不容易训练。为了使 $e^{(t)}_l $ 的学习更容易、更稳定，采用了退火策略。也就是说，s在训练期间被退火，诱发梯度 flow，在测试期间设置 $s=s</em>{max}$。公式2将一个单位 step 函数近似为mask，当 $s→∞$ 时，$m^{(t)}_l→{0,1}$。一个训练周期开始时，所有的神经元都是同样活跃的，在周期内逐渐极化。具体来说，$s$ 的退火情况如下:</p><script type="math/tex; mode=display">s = \frac{1}{s_{max}} + (s_{max} - \frac{1}{s_{max}}) \frac{b-1}{B-1}</script><p>其中 $b$ 是批次索引，$B$ 是一个 epoch中的总批次数。</p><p><strong>Illustration</strong> :在图2中，在学习了任务1之后，我们得到了其有用的神经元，用橙色标记，每个神经元中都有一个 “1”，在学习未来的任务时，它可以作为一个屏蔽。在学习任务2时，那些对任务1有用的神经元被掩盖了（左边那些橙色的神经元上有 “0”）。这个过程还学习了任务2的有用神经元，用绿色的 “1 “标记。当任务3到来时，任务1和任务2的所有神经元都被屏蔽了，也就是说，它的TM条目被设置为0（训练前为橙色和绿色）。训练完任务3后，我们看到任务3和任务2有一个共享神经元，对两者都很重要。该共享神经元被标记为红色和绿色。</p><h4 id="3-2-3-Contrastive-Ensemble-Distillation-CED"><a href="#3-2-3-Contrastive-Ensemble-Distillation-CED" class="headerlink" title="3.2.3 Contrastive Ensemble Distillation (CED)"></a>3.2.3 Contrastive Ensemble Distillation (CED)</h4><p>TMs机制为不同的任务隔离了不同的参数。这对于克服遗忘似乎是完美的，因为以前的任务参数是固定的，不能被未来的任务所更新。</p><p>然而，由于DIL设置在测试中没有任务 id，我们不能直接利用TM的优势。为了解决这个问题，我们提出了CED目标，以帮助提炼所有先前的知识到当前的任务模型，这样我们就可以简单地使用最后的模型作为最终模型，而不需要在测试中使用任务 id。</p><p><strong>Representation of Previous Tasks</strong>。回顾一下，我们通过阅读 ${m^{(i)}_l}$ 知道哪些神经元/单元是用于哪个任务的。对于当前任务 $t$ 的每个以前的任务 $i$ 我们可以通过将 $m^{(i)}_l $ 应用于Adapter-BERT(分类头之前的那一层)来计算它的 mask 输出。</p><p><strong>Ensemble Distillation Loss</strong> 我们将以前的任务集合的知识提炼成 单一的当前任务模型。由于我们在DIL中的所有任务都有一个共享的分类头，它被暴露在遗忘中，所以提炼应该基于分类头的输出。具体来说，给定前一个任务的Adapter-BERT输出 $h^{(i)}_m $，我们用 $h^{(i)}_m$ 计算分类头的输出，这就得到了logit（未归一化的预测）值 $z^{(i)}_m$。然后，我们利用 $z^{(i)}_m $和当前任务分类头的输出 $z^{(t)}$ 来提炼知识，其灵感来自于（Tian等人，2020a）的对比损失</p><script type="math/tex; mode=display">L_{CED}^{(i)} = \sum_{n=1}^{2N} - log \frac{exp((z_{m:2n-1}^{(i)} \cdot z^{(t)}_{m:2n}) /\tau)}{ \sum_{j=1}^{2N} 1_{n\neq j} exp((z_{m:n}^{(i)} \cdot z_{m:j}^{(t)})/ \tau)}</script><p>其中，$N$ 是批次大小，$τ&gt;0$ 是一个可调节的温度参数，控制类的分离。索引 $n$ 是锚点，符号 $z^{(i)}_{m:n} $ 指的是 $z^{(i)}_m $ 中的第 $n$ 个样本。</p><p>$z^{(i)}<em>{m:2n-1}$ 和 $z</em>{m:2n}^{(t)}$  是先前和当前任务模型对同一输入样本的对数，是对比学习中的一对正例。所有其他可能的配对都是负例的配对。请注意，对于每个锚点 $i$ ，都有1对正数和 $2N-2$ 对负数。</p><p>分母总共有 $2N - 1$个项（包括正项和负项）。请注意，以前的任务模型是固定的，因此可以作为教师网络。由于我们有$i≥1$ 个以前的任务，因此 $i≥1$个教师网络，但只有一个当前任务的学生网络。我们采用对比性框架，在 $z^{(i)}_m $ 和  $z^{(t)}_m $ 之间定义多个配对的损失。这些损失相加，得出最终的CED损失,</p><script type="math/tex; mode=display">L_{CED} = \sum_{i=1}^{t-1} L_{CED}^{(i)}</script><h3 id="3-3-Transferring-Knowledge-via-Contrastive-Knowledge-Sharing-CKS"><a href="#3-3-Transferring-Knowledge-via-Contrastive-Knowledge-Sharing-CKS" class="headerlink" title="3.3 Transferring Knowledge via Contrastive Knowledge Sharing (CKS)"></a>3.3 Transferring Knowledge via Contrastive Knowledge Sharing (CKS)</h3><p>CKS旨在捕捉任务间的共享知识，帮助新任务学习更好的表示和更好的分类器。CKS的直觉是这样的。对比学习有能力捕捉不同观点之间的共享知识（Tian等人，2020b；van den Oord等人，2018）。这是通过寻求不变的跨类似观点的表示来实现的。</p><p><strong>如果我们能从以前的任务中产生一个与当前任务相似的视图，那么对比性损失就能捕捉到共享的知识</strong>，<strong>并为知识转移到新的任务学习中学习一个表示</strong>。下面，我们首先介绍如何构建这样的视图并在CKS目标中使用它。</p><h4 id="3-3-1-Task-based-Self-Attention"><a href="#3-3-1-Task-based-Self-Attention" class="headerlink" title="3.3.1 Task-based Self-Attention"></a>3.3.1 Task-based Self-Attention</h4><p>直观地说，这两项任务越是相似，它们的共享知识就越多。它们拥有的共享知识就越多。为了实现我们的目标，我们应该将所有类似的任务合并为 共享知识视图。为了专注于 类似的任务，我们建议使用Task-based Self-Attention来关注它们。</p><p>在(Zhang等人，2018年)的启发下，给定Adapter-Bert针对所有先前和当前任务的输出的级联，$h<em>{m}^{(\le t)} = cat({h_m^{(i)}}</em>{i=1}^t)$, 并且 task $i\le t$， 我们首先转换它到两个特征空间，通过 $f(h_m^{(i)}) = W_fh_m^{(i)},  g(h_m^{(i)})=W_gh_m^{(i)}$  （见图1 CKS）</p><p>为了比较任务 $i≤t$ 和 $j≤t$ 之间的相似度，我们通过以下方式计算相似度 $s_{ij}$ :</p><script type="math/tex; mode=display">s_{ij} = f(h_m^{(i)})^T g(h_m^{(j)})</script><p>然后，我们计算注意力分数 $α_{j,i} $，以表明根据当前任务数据，哪些类似的任务（与当前任务 $t$ 类似）应该被关注:</p><script type="math/tex; mode=display">\alpha_{i,j} = \frac{exp(s_{ij})}{\sum_{i=1}^t exp(s_{ij})}</script><p>注意力得分被应用于 $h_m^{(\le t)}$ 中的每个任务，以获得加权和的注意力输出 $o_j$ :</p><script type="math/tex; mode=display">o_j = v(\sum_{i=1}^t \alpha_{j,i} q(h_m^{(i)}))</script><p>其中 $v(-)$ 和 $q(-)$ 是两个用于转换特征空间的函数：$v(h^{(i)}_m) = W_vh^{(i)}_m $和  $q(h^{(i)}_m) = W_vh^{(i)}_m$。</p><p>最后，我们将注意力层的输出乘以一个比例参数，再加回输入特征 $h^{(≤t)}<em>{cks}$。$h^{(≤t)}</em>{CKS}$的最终输出是所有考虑的任务之和,</p><script type="math/tex; mode=display">h_{CKS}^{(\le t)} = \sum_{i=1}^t (\gamma o_i+h_m^{(i)})</script><p>其中 $\gamma$ 是可学习的标量，并且被初始化为0，这允许模型首先在当前任务上进行学习，然后逐渐学习为其他任务分配更多的权重。</p><h4 id="3-3-2-Knowledge-Sharing-Loss"><a href="#3-3-2-Knowledge-Sharing-Loss" class="headerlink" title="3.3.2 Knowledge Sharing Loss"></a>3.3.2 Knowledge Sharing Loss</h4><p>基于任务的自我关注的输出为我们提供了 知识共享视图 $h^{(≤t)}<em>{CKS}$。 伴随着Adapter-BERT对当前任务 $h^{(t)}</em>{m}$ 的输出，我们可以很容易地在这两种观点之间进行对比性学习。</p><p>请注意，$h^{(≤t)}_{CKS} $ 是计算出来的基于当前的任务数据和它们相应的类标签，所以我们给两个视图有相同的标签，因此我们可以在我们的CKS损失中整合标签信息 :</p><script type="math/tex; mode=display">L_{CKS} = \sum_{n=1}^N - \frac{1}{N_{y_n} -  1} \sum_{j=1}^N 1_{n\le j}\  1_{y_n=y_j} log\frac{exp((h^{(\le t)}_{CKS:n} \cdot h_{m:j}^{(t)}) / \gamma)}{ \sum_{k=1}^N 1_{n\ne k} exp((h^{(\le t)}_{CKS:n}) \cdot  h_{m:k}^{(t)})/ \gamma}</script><p>其中，$N$ 是批次大小，$N<em>{yn} $是批次中具有标签 $y_n$的例子的数量。 $h</em>{CKS}^{(\le t)}$ 是第一个视图， 同时 $h_m^{(t)}$ 是第二个视图。</p><p>他们之间的共享知识代表了以前和当前任务之间的共享知识。 与CED损失不同，CKS损失利用了类别信息，因此可以通过两个样本是否共享相同的类别标签来决定多个正例对。</p><h3 id="3-4-Contrastive-Supervised-Learning-of-the-Current-Task-CSC"><a href="#3-4-Contrastive-Supervised-Learning-of-the-Current-Task-CSC" class="headerlink" title="3.4 Contrastive Supervised Learning of the Current Task (CSC)"></a>3.4 Contrastive Supervised Learning of the Current Task (CSC)</h3><p>我们通过采用监督对比损失法进一步提高了当前任务的性能。通过在当前任务 $h(t)$ 上采用有监督的对比性损失 (Khosla et al., 2020)对当前任务 $h^{(t)}_m$：</p><script type="math/tex; mode=display">L_{CSC} = \sum_{n=1}^{N} - \frac{1}{N_{y_n} -1} \sum_{j=1}^N 1_{n\le j} 1_{y_n = y_j} log \frac{exp((h_{m:n}^{(t)}\cdot h_{m:j}^{(t)})/ \tau)}{ \sum_{k=1}^N 1_{n\ne k} exp((h_{m:n}^{(t)} \cdot h_{m:k}^{(t)})/ \tau)}</script><h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><h3 id="Compared-Baselines"><a href="#Compared-Baselines" class="headerlink" title="Compared Baselines"></a>Compared Baselines</h3><p>我们采用了46个基线，其中包括非持续学习和持续学习方法。由于在DIL方面所做的工作很少，我们通过合并分类头来使最近的TIL系统适应DIL，形成DIL系统。</p><p><strong>Non-Continual Learning Baselines</strong> 这些基线中的每一个都为每个任务独立建立一个单独的模型，我们称之为一个变体。因此，它没有知识转移或CF。有8个ONE变体。四个是使用（1）带有微调的BERT，（2）没有微调的BERT（冷冻）（3）Adapter-BERT（Houlsby等人，2019）和（4）W2V（使用FastText（Grave等人，2018）中的亚马逊评论数据训练的word2vec嵌入）。添加CSC（Contrastive Supervised learning of the Current task）会产生另外4种变体。 我们采用（Xue和Li，2018）中的ASC网络工作，将方面术语和评论句子作为BERT变体的输入。对于W2V变体，我们使用它们的连接。</p><p><strong>Continual Learning (CL) Baselines.</strong>CL设置有5个类别的38个基线。</p><ul><li>第一类是使用 自然的CL（NCL）方法。它只是用一个网络来学习所有的任务，没有处理CF或知识迁移的机制。像ONE一样，我们有8个NCL的变体。</li><li>第二类有11条使用最近的CL方法KAN（Ke等人，2020b）、SRK（Lv等人，2019）、HAT（Serrà等人，2018）、UCL（Ahn等人，2019）、EWC（Kirkpatrick等人，2016）、OWM（Zeng等人，2019）和DER++（Buzzega等人，2020）创建的基线。</li></ul><p>KAN 和 SRK是用于文档情感分类。我们使用方面和句子的串联作为输入。HAT、UCL、EWC、OWM和DER++最初是为图像分类设计的。我们用CNN取代它们原来的图像分类网络，用于文本分类（Kim，2014）。HAT是最好的TIL方法之一，几乎没有遗忘。UCL是一种最新的TIL方法。EWC是一种流行的CIL方法，在（Serrà等人，2018）中被调整为TIL。它们通过合并分类头被转换为DIL版本。</p><p>OWM（Zeng等人，2019）是一种CIL方法，我们也将其改编为EWC这样的DIL方法。DER++和SRK可以在DIL环境下工作。HAT和KAN在测试中需要任务ID作为输入，不能在DIL设置中发挥作用。我们创建了HAT（和KAN）的两个变体：在测试中使用最后一个模型，就像CLASSIC所做的那样，或者使用熵法检测任务ID，在这个类别中使用BERT（冻结）作为基础。第三类有7个基线使用Adapter-BERT。KAN和SRK不能被调整为使用适配器。第四类使用W2V，这又有11条基线。最后一类有一个基线LAMOL（Sun等人，2020），它使用GPT-2模型。</p><p>Evaluation Protocol: 我们遵循（Lange等人，2019）中的标准CL评估方法。我们首先向CLASSIC提出一连串的ASC任务供其学习。一旦一个任务被学会，它的训练数据就被丢弃。在所有任务都学会后，我们使用所有任务的测试数据进行测试，而不给任务的ID。</p><h1 id="Continual-Learning-of-a-Mixed-Sequence-of-Similar-and-Dissimilar-Tasks"><a href="#Continual-Learning-of-a-Mixed-Sequence-of-Similar-and-Dissimilar-Tasks" class="headerlink" title="Continual Learning of a Mixed Sequence of Similar and Dissimilar Tasks"></a>Continual Learning of a Mixed Sequence of Similar and Dissimilar Tasks</h1><p>现有的关于一连串任务的持续学习的研究集中在处理灾难性的遗忘上，在这种情况下，任务被认为是不相似的，并且几乎没有共享的知识。也有一些工作是在任务相似且有共享知识的情况下，将以前学到的知识转移到新的任务中。据我们所知，还没有人提出学习混合的相似和不相似的任务序列的技术，该技术可以处理遗忘问题，也可以向前和向后转移知识。本文提出了这样一种技术来学习同一网络中的两种类型的任务。对于不相似的任务，该算法侧重于处理遗忘问题，而对于相似的任务，该算法侧重于有选择地转移从以前一些相似的任务中学到的知识，以提高新任务的学习。此外，该算法还自动检测一个新任务是否与以前的任何任务相似。使用混合任务序列的实证评估表明了所提出的模型的有效性。</p><h1 id="Continual-Learning-with-Knowledge-Transfer-for-Sentiment-Classification"><a href="#Continual-Learning-with-Knowledge-Transfer-for-Sentiment-Classification" class="headerlink" title="Continual Learning with Knowledge Transfer for Sentiment Classification"></a>Continual Learning with Knowledge Transfer for Sentiment Classification</h1><p>本文研究了情感分类（SC）的持续学习（CL）。在这种情况下，持续学习系统在一个神经网络中逐步学习一连串的情感分类任务，每个任务建立一个分类器，对特定产品类别或领域的评论进行分类。两个自然的问题是。系统能否将过去从以前的任务中学到的知识转移到新的任务中，以帮助它为新的任务学习一个更好的模型？而且，在这个过程中，以前的任务的旧模型是否也能得到改善？本文提出了一种叫做KAN的新技术来实现这些目标。KAN可以通过前向和后向的知识转移，明显地提高新任务和旧任务的SC准确性。通过大量的实验证明了KAN的有效性。</p><p>类持续学习（CCL）。在CCL中，每个任务包括一个或多个要学习的类。到目前为止，只为所有的类建立一个模型。在测试中，一个来自任何类别的测试实例可能会被提交给模型，让它进行分类，而不给它任何训练中使用的任务信息。</p><p>任务持续学习（TCL）。在TCL中，每个任务都是一个单独的分类问题（例如，一个是对不同品种的狗进行分类，另一个是对不同类型的鸟进行分类）。TCL在一个神经网络中建立了一组分类模型（每个任务一个）。在测试中，系统知道每个测试实例属于哪个任务，只使用该任务的模型对测试实例进行分类。</p><p>在本文中，我们在TCL环境中工作，不断地学习一连串的情感分析（SA）任务。通常情况下，一个情感分析公司必须为许多客户工作，每个客户都想研究公众对其产品/服务的一个或多个类别以及其竞争对手的意见。对每一类产品/服务进行情感分析是一项任务。为了保密，客户往往不允许SA公司与其他客户分享数据或将其数据用于其他客户。持续的学习是一个自然的过程。在这种情况下，我们也希望在不违反保密性的情况下，随着时间的推移提高SA的准确性。这就提出了两个关键的挑战。(1)如何将从以前的任务中学到的知识转移到新的任务中，以帮助它在不使用以前任务的数据的情况下更好地学习，(2)如何在没有CF的情况下在这个过程中改进以前任务的旧模型？在[15]中，作者表明CL可以帮助提高文档级情感分类（SC）的准确性，这是SA[13]的一个子问题。在本文中，我们提出了一个明显更好的模型，称为KAN（知识可及性网络）。请注意，这里的每个任务都是一个两类SC问题，即对一个产品的评论是正面还是负面进行分类。</p><p>在遗忘方面已经做了相当多的工作。然而，现有的技术主要集中在处理灾难性遗忘（CF）方面[4,18]。在学习一个新的任务时，他们通常试图使权重朝着对以前的任务伤害较小的方向更新，或者防止以前的任务的重要权重被显著改变。我们将在下一节详细介绍这些和其他相关的工作。只处理CF对SC来说是远远不够的。在大多数现有的关于CL的研究中，任务是相当不同的，而且几乎没有共享的知识。因此，专注于处理CF是有意义的。然而，对于SC来说，任务是相似的，因为用于表达不同产品/任务的情感的词和短语是相似的。正如我们在第4.4节中所看到的，由于任务间的共享知识，CF在SC的CL中不是一个主要问题。因此，我们的主要目标是利用任务间的共享知识，使其表现明显优于单独学习单个任务。</p><p>为了实现利用任务间的共享知识来提高SC的准确性的目标，KAN使用了两个子网络，主要的持续学习（MCL）网络和可及性（AC）网络。MCL的核心是一个知识库（KB），它存储了从所有训练过的任务中学到的知识。在学习每个新任务时，AC网络决定过去的知识中哪一部分对新任务有用，并可以共享。这就实现了向前的知识转移。同样重要的是，在新任务训练期间，共享的知识利用其数据得到加强，这导致了后向知识转移。因此，KAN不仅提高了新任务的模型精度，而且还提高了以前任务的精度，而无需任何额外的操作。大量的实验表明，KAN明显优于最先进的基线。</p><h2 id="Proposed-Model-KAN"><a href="#Proposed-Model-KAN" class="headerlink" title="Proposed Model KAN"></a>Proposed Model KAN</h2><p><img src="https://s2.loli.net/2021/12/23/uVSoghHPCYUfrqa.png" alt=""></p><p>为了提高分类的准确性，同时也为了避免遗忘，我们需要确定一些过去的知识，这些知识在学习新的任务时是可以共享和更新的，这样就不会发生遗忘过去知识的情况，新的任务和过去的任务都可以得到改善。<br>我们通过从我们人类似乎做的事情中获取灵感来解决这个问题。例如，我们可能会 “忘记 “10年前的电话号码，但如果同样的号码或类似的号码再次出现，我们的大脑可能会迅速检索出旧的电话号码，并使新旧号码都得到更牢固的记忆。生物学研究[10]表明，我们的大脑会对知识的可及性进行追踪。如果我们以前知识的某些部分对新任务有用（即新任务和以前一些任务之间的共享知识），我们的大脑就会将这些部分设置为可访问，以实现知识的前向转移。这也使后向知识转移成为可能，因为它们现在可以被访问，我们有机会根据新的任务数据来加强它们。对于那些以前的知识中没有用的部分，它们被设置为不可访问，这样可以保护它们不被改变。受到这个想法的启发，我们设计了一个记忆和可访问性机制。<br>我们需要解决两个关键问题。(1）如何检测内存（我们称之为知识库（KB））中的知识的可访问性，即识别以前的知识中对新任务有用的部分；（2）如何利用识别的有用/共享的知识来帮助新任务的学习，同时也保护其他部分。为了应对这些挑战，我们提出了图1所示的知识和可及性网络（KAN）。</p><p>KAN有两个组件（见图1），紫色框中的主要持续学习（MCL）组件和黄色框中的可及性（AC）组件。MCL执行主要的持续学习和测试（AC在测试中不使用，除了从任务id t生成的掩码）。我们看到每个任务的情感分类头（正/负）在顶部。下面是密集层，再往下是绿色虚线框内的知识库（KB）（记忆）。知识库使用RNN（我们在系统中使用GRU）建模，被称为KB-RNN，包含特定任务和跨任务的共享知识。AC通过设置一个基于任务的二进制掩码来决定KB中的哪部分知识（或单元）可以被当前任务t访问。每个任务由AC-EMB从任务ID（t）中产生的任务嵌入来表示。AC-EMB是一个随机初始化的嵌入层。KAN的输入是任务id t和文档d。它们通过掩码a和{hKB}用于训练两个组件。(KB-RNN中的隐藏状态)链接来训练两个组件。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Achieving-Forgetting-Prevention-and-Knowledge-Transfer-in-Continual-Learning&quot;&gt;&lt;a href=&quot;#Achieving-Forgetting-Prevention-and-Knowledg</summary>
      
    
    
    
    
    <category term="context detection" scheme="http://example.com/tags/context-detection/"/>
    
  </entry>
  
  <entry>
    <title>On Transferability of Prompt Tuning for Natural Language Understanding</title>
    <link href="http://example.com/2021/12/21/On-Transferability-of-Prompt-Tuning-for-Natural-Language-Understanding/"/>
    <id>http://example.com/2021/12/21/On-Transferability-of-Prompt-Tuning-for-Natural-Language-Understanding/</id>
    <published>2021-12-21T07:44:25.000Z</published>
    <updated>2021-12-30T15:17:52.830Z</updated>
    
    <content type="html"><![CDATA[<h1 id="On-Transferability-of-Prompt-Tuning-for-Natural-Language-Understanding"><a href="#On-Transferability-of-Prompt-Tuning-for-Natural-Language-Understanding" class="headerlink" title="On Transferability of Prompt Tuning for Natural Language Understanding"></a>On Transferability of Prompt Tuning for Natural Language Understanding</h1><p>Prompt tuning（PT）是一种很有前途的参数高效方法，可以利用极其庞大的预训练语言模型（PLM），只需 tuning 几个软提示，就可以达到与全参数微调相当的性能。</p><p>然而，与微调相比，经验上PT需要更多的训练步骤。为了探索是否可以通过重复使用训练好的 soft prompts 和分享学到的知识来提高 PT 的效率，我们从经验上研究了 soft prompts 在不同任务和模型中的可迁移性。</p><ul><li>在跨任务迁移中，发现经过训练的  soft prompts  可以很好地迁移到类似的任务中，并为它们初始化PT，以加速训练和提高性能。此外，为了探索哪些因素会影响 prompts 的跨任务转移性，我们研究了如何测量 prompt 的相似性，发现<strong>激活的神经元的重叠率与迁移性高度</strong>相关。</li><li>在跨模型迁移中，我们探索了如何将一个PLM的 prompt 投射到另一个PLM上，并成功地训练了一种 projector，该projector 可以在类似的任务上实现非微不足道的迁移性能。然而，用投影的 prompt 初始化PT的效果并不好，这可能是由<strong>优化偏好</strong>和<strong>PLM的高冗余</strong>度造成的。</li></ul><p>我们的研究结果表明，用知识转移来改善PT是可能的，也是有希望的，而提示的跨任务迁移性一般比跨模型转移性好。</p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>预训练的语言模型（PLM），如BERT（Devlin等人，2019）和GPT（Radford等人，2018）在各种自然语言处理任务上取得了很好的性能（Han等人，2021）。最近，在GPT-3（Brown等人，2020）取得成功后，人们发现极大型的PLM可以取得显著的自然语言理解（NLU）性能，各种大型PLM不断被开发出来（Raffel等人，2020；Zhang等人，2021；Zeng等人，2021；Wei等人，2021；Sun等人，2021），它们包含的参数多达数千亿。</p><p>考虑到这些最先进的PLMs的极大规模，传统的全参数微调方法使PLMs适应下游任务，在计算上变得难以承受。因此，各种参数高效的调谐方法（Houlsby等人，2019；Ben Zaken等人，2021；Lester等人，2021；Li和Liang，2021；Liu等人，2021）得到了探索，其中prompt-tuning（PT）引起了广泛的研究关注。</p><p>PT将一些 soft-prompt（本质上是可学习的虚拟 token）预置到输入序列中，并通过反向传播训练它们，同时保持所有PLM参数的固定。训练的目的是输出表示相应标签的 token，即标签 token。PT仅用数千个可调整的参数就可以实现卓越的NLU性能。</p><p>此外，Lester等人（2021）表明，当PLM的规模增长时，PT变得更加有效，当PLM有数十亿个参数时，最终可以达到与全参数微调相当的性能。</p><p>尽管PT是利用极其庞大的PLM的有效方法，但它需要比微调多得多的训练步骤来达到收敛（参考3.1节），<strong>因此值得探讨如何提高PT的效率。直观地说，由于 soft prompt 是PT中唯一可学习的参数，代表了以PLM为条件解决任务的特定知识</strong>，一个任务的训练提示可能对其他需要类似知识的任务有帮助。此外，由于不同的PLM都从预训练中学习了一般的语言理解能力，以不同的PLM为条件的训练过的 prompts 可能在PLM之间迁移。</p><p><img src="https://s2.loli.net/2021/12/21/QYkwWa7o4FR1CI3.png" alt=""></p><p>因此，通过训练有素的 soft prompts 将学到的知识迁移到其他任务和PLM上可能是一种有希望的方式，以加速新任务和PLM的PT。为了了解基本特征并帮助开发PT的迁移学习方法，我们在本文中实证分析了PT在不同任务和模型中的可迁移性，如图1所示。</p><p>在跨任务迁移中，我们研究在同一PLM上训练的 soft-prompt 是否能在不同的NLU任务中转移。</p><ul><li>(1) 我们研究了 soft prompt 在13个NLU任务上的 zero-shot 迁移性能，这些任务根据所需的语言理解能力被分为四种类型。我们发现，经过训练的 soft prompt 可以直接迁移到同一类型的类似任务中，并取得非同寻常的表现，但迁移到需要不同的NLU能力的不同类型的任务中却很差。</li><li>(2) 基于这些结果，我们提出了跨任务的可转移prompt tuning（$TPT<em>{TASK}$），即用类似任务的训练好的 soft prompt作为初始化来启动PT。实验表明，与普通的PT相比，$TPT</em>{TASK}$可以大大加快训练速度，而且还能实现一定的性能提升。</li><li>(3) 我们进一步探讨为什么 prompts 可以跨任务转移，是什么控制了它们的迁移性。为此，我们研究了各种 prompt 相似性指标与prompt 可迁移性的相关性，发现其在PLM前馈层中激活的神经元的重叠率可以更好地反映 prompts 可转移性。</li></ul><p>这表明提示<strong>实质上是在刺激PLM的内在能力在参数（神经元）之间分配，以完成特定的NLU任务，prompts 之间的可迁移性取决于它们在模型刺激方面的相似性，而不是嵌入的相似性</strong>，这可能启发未来PT转移方法的设计。</p><p>在跨模型转移中，我们在两种情况下研究软提示在不同PLM中的可转移性。</p><ul><li>(1) 在相同规模的异质PLM之间转移（例如BERTBASE到RoBERTaBASE）</li><li>(2) 从较小的PLM迁移到较大的同质模型（例如RoBERTaBASE到RoBERTaLARGE）。</li></ul><p>我们发现，直接在目标PLM上重复使用 prompts 是无益的，这一点在实验中得到了证明，或者是不可行的，这是因为不同尺寸的PLM的嵌入尺寸不一致。</p><ul><li>(1）因此，我们开发了各种 prompt projectors，将在一个PLM上训练的 soft prompt 投射到其他PLM的语义空间中，并发现通过在一些任务上用PT训练 projectors，训练后的 projectors 可以成功地投射出类似任务的软提示，并取得非同寻常的性能。</li><li>(2) 与 $TPT<em>{TASK}$ 类似，我们提出了跨模型的可迁移 prompt tuning（$TPT</em>{MODEL}$），即用目标PLM上同一任务的预测 prompt 开始PT。然而，实验表明，$TPT<em>{MODEL}$的效果并不如 $TPT</em>{TASK}$那么好。</li><li>(3) 我们观察到，投射过的 prompts 的激活神经元与最初在目标PLM上训练的 prompt 不相似。考虑到PLM的高冗余度（Aghajanyan等人，2021），这可能表明预测的 prompt 是在目标PLM上完成任务调节的不同解决方案，而PT并不喜欢这些解决方案，并且很难用它们来持续优化。</li></ul><p>总的来说，我们的发现和分析表明，通过知识迁移提高PT的效率是可能的，也是有希望的，在不同的PLM之间迁移提示比在同一PLM的不同任务之间转移更具挑战性。我们希望这些发现能够促进对可迁移和高效的PT的进一步研究。</p><h2 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h2><h3 id="Prompt-Tuning"><a href="#Prompt-Tuning" class="headerlink" title="Prompt Tuning"></a>Prompt Tuning</h3><p>在海量数据上预训练PLM（Radford等人，2018；Devlin等人，2018；Yang等人，2019；Liu等人，2019b；Raffel等人，2020），然后将其调整为下游任务，这已经成为NLP的典型范式。传统上，适应是通过面向任务的微调完成的，它通过特定任务的监督优化PLM的所有参数。</p><p>然而，随着PLM参数的持续增长，全参数微调对于典型的范式和模型存储都变得难以承受。为了弥补这一缺陷，人们提出了许多参数高效的调谐方法（Ben Zaken等人，2021；Houlsby等人，2019；Li和Liang，2021；Qin和Eisner，2021；Lester等人，2021），这些方法只调整几个参数，而保持大部分PLM参数的冻结。</p><p>在这些具有参数效率的微调变体中，prompt tuning 得到了广泛的关注，这是由GPT-3激发的。 它通过在输入文本之前给每个任务预留一个文本提示，并让PLM直接生成答案，从而展示了显著的 few-shot 性能。</p><p>最近，出现了许多基于 prompt 的工作，即人工设计的（Schick和Schütze，2021a，b；Mishra等人，2021）或自动搜索的（Jiang等人，2020；Shin等人，2020；Gao等人，2021）硬提示，它们是离散的 token，但不一定是人类可读的。此外，软提示（Li and Liang, 2021; Hambardzumyan et al., 2021; Zhong et al., 2021; Liu et al., 2021）出现了，它们是可调整的嵌入而不是词汇表中的 token，可以直接用特定任务的监督来训练。</p><p>而Lester等人（2021）证明，当PLM尺寸极大时，这种 PT 方法可以与全参数微调的性能相匹配。这表明 PT 在利用极大的PLM方面很有前景。然而，达到收敛所需的更多训练步骤（第3.1节）使PT效率低下。在这项工作中，我们表明 prompt迁移可以弥补这一点，也在一定程度上提高了知识转移的有效性，并实证分析了PT在不同任务和模型中的转移性。</p><h3 id="Transferring-for-PLM"><a href="#Transferring-for-PLM" class="headerlink" title="Transferring for PLM"></a>Transferring for PLM</h3><p>跨任务转移，或一般的多任务学习（Ruder，2017）一直是提高NLP系统的有效性和效率的一种长期方式。在PLM时代，一些作品提出在中间任务上调整PLM（Phang等人，2019；Pruksachatkun等人，2020；Gururangan等人，2020；Wang等人，2019a；Vu等人，2020；Poth等人，2021），然后再对具体的目标任务进行微调，并取得一定成效。特别是，Vu等人（2020）在这种情况下实证分析了跨任务的可迁移性。然而，这些探索都是针对微调的。Prompt Tuning（PT）是利用大型PLM的一种有前途的方式，我们认为PT的可转移性和转移方法值得探索。</p><p>作为先前的尝试，Lester等人（2021）证明了PT对同一任务的跨域迁移能力强于微调。与我们的工作类似，同时进行的工作（Vu等人，2021）证明了PT的跨任务转移能力，也提出了用提示初始化来进行跨任务迁移。不同的是，我们通过模型刺激的视角进一步分析了 prompt，并通过跨任务迁移提高了PT的效率。此外，我们还尝试了 prompt 的跨模型迁移，这受到了以往跨模型知识迁移工作的启发，如Net2Net（Chen等人，2016）、知识蒸馏（Hinton等人，2015）和知识继承（Qin等人，2021a）。</p><h2 id="Preliminary"><a href="#Preliminary" class="headerlink" title="Preliminary"></a>Preliminary</h2><p>在这一节中，我们介绍了关于 prompt tuning（PT）的基本知识（§3.1）以及实验中调查的下游任务（§3.2）和模型（§3.3）。</p><h3 id="Prompt-Tuning-1"><a href="#Prompt-Tuning-1" class="headerlink" title="Prompt Tuning"></a>Prompt Tuning</h3><p>在这项工作中，我们研究了能够调整大型PLM的PT方法（Li and Liang, 2021; Lester et al, 2021; Liu et al, 2021），同时冻结PLM参数。考虑到我们专注于NLU的能力，我们没有探索在生成任务上工作的前缀调谐（Li and Liang, 2021）。</p><p>PT直接在PLM的输入中预置一些虚拟 token，即 soft prompt，以提供关于下游任务的知识。soft prompt本质上是可调整的嵌入向量，其训练的目的是强制 PLM 解码表示输入的相应标签的 token，而PLM的模型参数则保持冻结。对应于标签的 token  被称为标签 token。</p><p>从形式上讲，给定一个输入序列 $X={x_1,x_2,…,x_n}$，其中 $x_i$ 是 token，我们首先在它们前面预置 $l$ 个随机初始化的软提示 $P={P_1,P_2,…,P_l}$，其中 $P_i\in R_d$是一个嵌入向量，$d$ 是PLM的输入维度。在它们之前，我们先加一个[MASK] token，用来预测标签token $y$。训练目标是使解码 $y$ 的可能性最大化。</p><script type="math/tex; mode=display">L = p(y|[MASK], P, x_1,...,x_n)</script><p>而只有P是可学习的。因此，PT中的调整参数比全参数微调要少得多，这对调谐大型PLM很友好。</p><p>当使用的PLM非常大时，PT可以达到与微调相当的性能，但当PLM不那么大时，明显的性能差距仍然存在，而且PT也比微调需要更多的内存。</p><p>此外，我们根据经验发现，PT的收敛速度明显慢于微调，如图2所示。因此，我们认为PT的效率需要进一步提高，而知识迁移的直观性可能有所帮助。</p><h3 id="Investigated-NLU-Tasks"><a href="#Investigated-NLU-Tasks" class="headerlink" title="Investigated NLU Tasks"></a>Investigated NLU Tasks</h3><p>为了全面研究 soft-prompt 在各种NLU任务中的可迁移性，我们涉及了13个不同的任务，这些任务可以分为4种类型。</p><p>(1）情绪分析（SA），包括IMDB（Maas等人，2011）、SST-2（Socher等人，2013）、笔记本电脑（Pontiki等人，2014）、餐厅（Pontiki等人，2014）、电影理由（Movie）（Zaidan等人，2008）和TweetEval（Tweet）（Bar- bieri等人，2020）；（2）自然语言推理（NLI），包括MNLI（Williams等人，2018 )、QNLI（Wang等人，2019b）和SNLI（Bow- man等人，2015）；（3）伦理判断（EJ），包括deontology（Hendrycks等人，2021）和justice（Hendrycks等人，2021）；（4）转述识别（PI），包括QQP（Sharma等人，2019）和MRPC（Dolan and Brockett，2005）。任务的细节、使用的标签令牌和实施方法分别留在附录A.1、附录A.3和附录A.2中。</p><h3 id="Investigated-Models"><a href="#Investigated-Models" class="headerlink" title="Investigated Models"></a>Investigated Models</h3><p>为了研究跨模型的可转移性，我们调查了两种PLM。BERT（Devlin等人，2019）和RoBERTa（Liu等人，2019b），它们被广泛用于NLU任务。具体来说，我们在实验中使用RoBERTaBASE、RoBERTaLARGE和BERTBASE检查点。RoBERTaBASE和BERTBASE模型由12个Transformer（Vaswani等人，2017）编码器层组成，它们的嵌入尺寸都是768，而RoBERTaLARGE是24个Transformer层和1024个嵌入尺寸。</p><h2 id="Cross-Task-Transfer"><a href="#Cross-Task-Transfer" class="headerlink" title="Cross-Task Transfer"></a>Cross-Task Transfer</h2><p>在这一节中，我们实证研究了 soft-prompt 的跨任务迁移性（第4.1节），并试图通过利用迁移性来提高 prompt tuning的有效性和效率（第4.2节），然后我们通过分析各种 prompts 的相似性指标来探索为什么 prompts可以迁移，是什么控制了prompts之间的转移性（第4.3节）。本节的所有实验都是在RoBERTaBASE上进行的。</p><p><img src="https://s2.loli.net/2021/12/21/UoFWAp8aQ9bnKPd.png" alt=""></p><h3 id="Zero-shot-Transferability"><a href="#Zero-shot-Transferability" class="headerlink" title="Zero-shot Transferability"></a>Zero-shot Transferability</h3><p> 结果如图3所示，从图中我们可以看出。</p><ul><li>(1) 对于同一类型的任务，在它们之间迁移soft prompt一般可以表现良好，甚至可能在target数据集上超过vanilla PT，特别是当源任务的数据集比目标任务大的时候（从IMDB转到Movie的例子），这表明用类似任务的知识转移来提高PT的效果和效率是有希望的。</li><li>(2）对于不同类型的任务，soft prompt 在它们之间的可迁移性普遍较差，迁移的 soft prompt 在很多情况下只能达到与给定的随机初始化 prompt 相似的性能。可转移性差的原因可能是不同类型的任务通常使用不同的标签，例如，entailment和convadict是用于NLI任务，而positive和negative是用于SA任务。为了排除这个因素，我们将不同任务的标签标记统一为同一组数字$(1，2，…)$，结果如图3（b）所示，从中我们可以看出，不同类型任务之间的可转移性一般不会通过这种方式得到改善。这表明，不同类型的任务肯定需要不同的能力，这就禁止在它们之间重复使用prompts。</li><li>(3) 一些任务之间的可迁移性是直观的，例如IMDB表现最好的源任务是Movie。然而，有些则是反直觉的，比如laptop的最佳来源任务是Tweet。为了理解这一点，值得探讨是什么控制了prompts之间的迁移性，我们将在第4.3节做一些初步研究。</li></ul><h3 id="Transfer-with-Initialization"><a href="#Transfer-with-Initialization" class="headerlink" title="Transfer with Initialization"></a>Transfer with Initialization</h3><p>为了研究如何通过跨任务迁移来提高PT的有效性和效率，我们在本节中探讨了跨任务迁移的 prompt tuning（$TPT<em>{TASK}$）。$TPT</em>{TASK}$在开始 prompt tuning 之前，用训练有素的类似任务的 soft prompt 来初始化 soft prompt，并观察它是否能加速训练和提高最终的表现。</p><p>对于13个被调查的任务，我们用训练好的其他任务的 soft prompt 来启动 $TPT<em>{TASK}$，可以达到图3（a）中的最佳性能。性能和训练时间的比较见表1。从结果中，我们可以看到 $TPT</em>{TASK}$在大多数情况下可以达到比 vanilla PT更好或相当的性能，从随机初始化开始，它需要较少的训练步骤来达到相当的性能和收敛性。关于训练曲线的详细比较，请参考附录B。</p><p><img src="https://s2.loli.net/2021/12/21/k29VadtAsJclmvN.png" alt=""></p><h3 id="Exploring-Transferability-Indicator"><a href="#Exploring-Transferability-Indicator" class="headerlink" title="Exploring Transferability Indicator"></a>Exploring Transferability Indicator</h3><p>此外，我们还探讨了为什么 soft prompt 可以跨任务迁移，是什么控制了它们之间的可迁移性，这可能有助于揭示PT成功背后的机制，有助于设计可迁移的PT方法。为此，我们探索了各种 prompts 的相似性指标，并考察了它们与 zero-shot 迁移性能的吻合程度。</p><p>如果所设计的相似性度量标准能够很好地表明可迁移性，我们可以说在设计这个度量标准时考虑的因素大多控制了 prompts 之间的可迁移性。此外，提示的相似性指标可以用训练好的 soft prompt 作为任务嵌入来限定任务的相似性，并可能有助于设计跨任务的迁移方法。作为一个直接的例子，如果我们建立了一个包含不同任务的训练 prompt 的 prompt仓库，我们可以为一个新的任务检索具有一定相似性度量的相似任务的 prompt，并通过 $TPT_{TASK}$在新任务上更好地改进PT。在这项工作中，我们探讨了以下两种度量。</p><h4 id="Embedding-Similarity"><a href="#Embedding-Similarity" class="headerlink" title="Embedding Similarity"></a>Embedding Similarity</h4><p>在第一类被调查的相似性度量中，我们把训练好的 soft prompt 看作是向量空间中的嵌入，用两个常规度量来计算它们的相似性。欧氏相似度和余弦相似度。</p><p>给出两组包含 $l$ 个虚拟 token 的训练有素的 prompts: $P^{t_1} = {P_1^{t_1},…, P_l^{t_1}}$ 和 $P^{t_2} = {P_1^{t_2},.., P_l^{t_2}}$ 对应的任务为 $t_1,t_2$。 首先，我们串联 $l$ prompt token嵌入并得到 $l×d$ 维嵌入 $\hat P^{t_1}$， $ \hat P^{t_2}$，然后我们为它们计算欧氏相似度和余弦相似度:</p><script type="math/tex; mode=display">E_{concat} (P^{t_1}, P^{t_2}) = \frac{1}{ 1+ ||\hat P^{t_1} - \hat P^{t_2}||}</script><script type="math/tex; mode=display">C_{concat} (P^{t_1}, P^{t_2}) = \frac{\hat P^{t_1}\cdot \hat P^{t_2}}{||\hat P^{t_1}||||\hat P^{t_2}||}</script><p>考虑到由于我们在 PT 期间没有将Transformer（Vaswani等人，2017）中的位置嵌入添加到 prompt 中，所以提示是位置不变的，我们进一步介绍了一种简单的方法，使度量标准对 token 位置不变。</p><p>直截了当地，我们为两组中的每个 prompt 对计算欧氏距离和余弦相似度，并使用平均结果作为两个 soft prompt 的最终相似度指标。</p><script type="math/tex; mode=display">E_{average}(P^{t_1}, P^{t_2}) = \frac{1}{ 1+ \frac{1}{l^2}\sum_{i=1}^l \sum_{j=1}^l ||P^{t_1}_i - P^{t_2}_j||}</script><script type="math/tex; mode=display">C_{average} (P^{t_1},P^{t_2}) = \sum_{i=1}^l\sum_{j=1}^l \frac{P^{t_1}_i \cdot P^{t_2}_j}{||P_i^{t_1}||||P_j^{t_2}||}</script><h4 id="Model-Stimulation-Similarity"><a href="#Model-Stimulation-Similarity" class="headerlink" title="Model Stimulation Similarity"></a>Model Stimulation Similarity</h4><p>在第二种方式中，我们不只将 soft prompt 视为嵌入向量，而是根据它们如何刺激 PLM 来描述它们的相似性，也就是说，我们研究PLM对两个训练过的 soft prompt 的反应的相似性。受Mor等人（2021）和Dai等人（2021）的启发，他们都发现Transformer模型的前馈层中间的神经元的激活与特定的模型行为相对应，我们建议使用激活的神经元的重叠率作为软提示的相似性指标。</p><p>具体来说，Transformer（Vaswani等人，2017）层中的前馈网络FFN（-）如下：</p><script type="math/tex; mode=display">FFN(x) = max(0, xW_1^T + b_1) W_2 + b_2</script><p>其中 $x \in R^d$ 是输入embedding， $W_1,W_2\in R^{d_m\times d }$是可训练的矩阵，并且 $b_1,b_2$ 是bias 向量。 $max(xW_1^T +b_1,0)$ 可以被视为 $d_m$ 隐含神经元的非负激活值。然后我们把 $max(xW_1^T + b_1, 0)$的所有正元素改为1，得到 one-hot 激活状态向量$s$ 。</p><p>我们输入一个输入序列 ${[MASK], p_1,…,P_l, <s>}$ 到PLM，其中$<s>$ 是特殊token表示句子的开头。这种格式本质上是PT输入的格式，但没有具体的输入语句。对于PLM的每个Transformer层，我们使用[MASK]位置的激活状态 $s$，因为 $[MASK]$ 是用来预测标签 token 的，因此更具有任务针对性。然后，我们将PLM中所有层的激活状态连接起来，得到整个PLM激活状态：</p><script type="math/tex; mode=display">AS(P) = [s_1;s_2;...,;s_L]</script><p>在相似性计算中，我们也只能检索到一部分层的激活状态。我们用余弦相似度来计算任务 $t_1$ 和 $t_2$ 的训练软提示之间的激活神经元 $ON(P^{t_1} , P^{t_2})$的重叠率：</p><script type="math/tex; mode=display">ON(P^{t_1},P^{t_2}) = \frac{AS(P^{t_1}) \cdot AS(P^{t_2})}{||AS(P^{t_1})|| ||AS(P^{t_2})||}</script><h3 id="Experimental-Results"><a href="#Experimental-Results" class="headerlink" title="Experimental Results"></a>Experimental Results</h3><p>为了评估上述 soft prompt 的相似性指标的有效性，</p><ul><li><p>（1）测试相似性指标是否能区分相同任务和不同任务的训练prompt </p></li><li><p>（2）检查这些指标是否与 soft prompt 的 zero-shot 迁移性能一致。</p></li></ul><p>我们在表2中比较了同一任务内（用不同的随机种子训练的）和不同任务之间两个训练好的 prompt 的相似度值。从结果中，我们可以观察到。</p><p><img src="https://s2.loli.net/2021/12/21/TBX3ghk7ExawsYK.png" alt=""></p><ul><li>(1) 所有的指标都能很好地区分同一任务和不同任务的 prompt 。从嵌入相似性的角度来看，这表明不同任务的训练有素的 soft prompt 形成了可以区分的集群。从模型刺激相似性的角度来看，这表明不同的任务确实需要 soft prompt 来刺激PLM中的不同能力。</li><li>(2)对于激活的神经元的过度覆盖率，任务的差异往往在顶层更大。这与探测结果（Liu et al., 2019a）一致，显示顶层往往更具有任务特异性。激活神经元的重叠率的细节留在附录C中。</li></ul><p>此外，我们还评估了 prompt 的相似性指标是否与图3中的 zero-shot 转移性能一致。具体来说，(a)，我们计算每个目标任务的各种源任务 prompt 的相似性和 zero-shot 迁移性能之间的Spearman’s rank correlation（Spearman, 1987）。结果见表3，从中我们观察到</p><p><img src="https://s2.loli.net/2021/12/21/V6pNjQorDw9LKCe.png" alt=""></p><p> (1) 激活神经元的重叠率(ON)指标一般比所有的嵌入相似性效果好，这表明模型刺激在 prompt 迁移性方面比嵌入距离占据了更重要的位置。我们鼓励未来的工作探索如何更好地模拟提示的刺激。</p><p>(2) 在所有的嵌入相似性度量中，基于欧氏距离的两个度量效果不佳，甚至在某些任务上有负相关。基于余弦相似度的度量工作得更好，$C<em>{average}$度量可以达到与使用底层的ON度量相当的性能。然而，$C</em>{average}$区分不同任务的能力（表2）显然更差。这些结果表明，提示嵌入空间的属性是很棘手的，很难在此基础上设计可迁移的PT方法。</p><p> (3)使用较高模型层的ON的结果一般比使用较低层的好，这再次证实了最高层的模型更具有任务针对性。然而，也有一些反例，如 justice 和QQP，这可能来自于这些任务中需要一些特定的语言能力，需要仔细研究。</p><h2 id="Cross-Model-Transfer"><a href="#Cross-Model-Transfer" class="headerlink" title="Cross-Model Transfer"></a>Cross-Model Transfer</h2><p>在本节中，我们研究了软提示的跨模型转移能力。在实验中，我们研究了两种实际情况：从一个PLM转移到一个异质的同尺寸PLM（BERTBASE到RoBERTaBASE）和从一个较小的PLM转移到一个同质的较大的PLM（RoBERTaBASE到RoBERTaLARGE）。在不同大小的模型之间直接重用训练好的软提示是不可行的，因为嵌入维度不一致，在异质同大小的PLM之间重用的性能很差（见表4的直接重用行），这很直观，因为嵌入空间是不同的。因此，我们研究如何将在一个模型上训练的软提示投射到其他模型的空间（§5.1），并看到转移的性能（§5.2）。此外，与第4.2节类似，我们研究是否可以通过跨模型转移初始化来进一步提高效果和效率（第5.3节）。</p><h3 id="Projecting-Prompts-to-Different-Models"><a href="#Projecting-Prompts-to-Different-Models" class="headerlink" title="Projecting Prompts to Different Models"></a>Projecting Prompts to Different Models</h3><p>在本节中，我们探讨了如何将一个模型的训练好的 soft prompt 投射到另一个模型的语义空间。为此，我们用各种监督方式训练 projectpr，并检验不同 projector 训练方法的有效性。</p><p>训练跨模型 projector 的好方法可能需要一些特定的任务监督，例如两个模型的平行 soft prompt 或某些任务的监督数据，但训练后的 projector 应能泛化到不同的任务，从而提高目标模型上PT新任务的学习效率。</p><p>从形式上讲，projector $Proj(-)$ 是将源模型中训练好的 soft prompt $P^s \in R^{l×d_s} $ 投影到目标模型语义空间中的相应 prompts $\hat P^s \in R^{l×d_t}$，其中 $d_s$ 和 $d_t$ 分别是源模型和目标模型的输入嵌入维度。在这项工作中，projector 的参数化是用两层感知器，具体如下:</p><script type="math/tex; mode=display">\hat P^s = Proj(P^s) = LayerNorm(W_2(tanh(W_1P^s + b_1)) + b_2)</script><p>其中W1、W2是可训练的矩阵，b1、b2是可训练的偏置项，tanh是非线性激活函数，LayerNorm是层归一化。</p><p>我们研究了三种类型的学习目标来训练交叉模型投影仪:</p><ul><li><p>Prompt Mapping : 我们首先尝试通过学习在不同PLM上训练的同一任务的平行 soft prompt 之间的映射来学习跨模型预测。给出同一任务的两组提示 $P^s、P^t$，它们分别在源模型和目标模型上训练。投影仪将投影 $P^s$，训练目标是最小化L2准则:</p><script type="math/tex; mode=display">L_p = ||Proj(P^s) - P^t||_2</script></li><li><p>Token Mapping : 由于提示是预置在输入 token 上的虚拟 token，我们探讨两个不同PLM的输入 token 嵌入之间的映射是否也能适用于提示嵌入。给定一个 token x和它相应的token 嵌入 $x^s$ , $x^t$，它们分别属于源PLM和目标PLM。我们训练投影仪以最小化L2准则:</p><script type="math/tex; mode=display">L_t = ||Proj(x^s) - x^t||_2</script><p>并将词汇表中的所有输入 token 作为训练样本。</p></li><li><p>Task Tuning : 考虑到第4.3节中的发现，即 soft prompt 的可迁移性更多地与它们如何刺激PLM有关，而不是它们的嵌入距离，我们尝试用相应的任务直接调整目标PLM上的投影 prompt，并以这种方式训练投影仪，它应从任务调整中学习如何刺激目标PLM。然后，我们看看经过训练的投影仪是否可以推广到其他未见过的任务。</p></li></ul><p>Prompt Mapping 和 Task Tuning  方法依靠一些任务（平行训练的 soft prompts  或训练数据）来训练投影仪。在实验中，我们分别选择了两个有代表性的SA任务（IMDB和笔记本电脑）和一个NLI任务（MNLI），供投影仪学习。Token Mapping需要源PLM和目标PLM的词汇表是一致的，因此我们只在RoBERTaBASE到RoBERTaLARGE的设置中尝试。</p><h3 id="Transfer-Performance"><a href="#Transfer-Performance" class="headerlink" title="Transfer Performance"></a>Transfer Performance</h3><p><img src="https://s2.loli.net/2021/12/21/khYgN9EDZpWB2lF.png" alt=""></p><p>在从BERTBASE到RoBERTaBASE和从RoBERTaBASE到RoBERTaLARGE的设置上，各种投影仪-学习方法的转移性能分别见表4和表5。我们可以观察到。</p><ul><li>(1）虽然BERTBASE和RoBERTaBASE的输入嵌入维度一致，但它们之间直接重用训练好的 soft prompt 的性能与使用随机生成的 prompt 相似，这证实了不同模型的 prompt 语义空间差距巨大。</li><li>(2) Token Mapping方法的性能也接近于随机基线，这表明虽然 soft prompt 与输入的 token 一起被送入PLM，但它们并不在同一个embedding空间。</li><li>(3) Prompt Mapping在 迁移 投影仪训练中涉及的提示时效果很好，但在未见过的任务上又回到了随机性能，这是不现实的。这与我们在第4.3节中的发现一致，即嵌入的相似性/差异不能很好地反映任务之间的可迁移性。</li><li>(4) Task Tuning 的效果最好，并且成功地将训练任务推广到同类型的未见过的任务中（例如，用MNLI训练的投影仪的NLI任务），这表明为PT设计实用的跨模型迁移方法的可行性。与Prompt Mapping的失败相比，这证实了从模型刺激的角度来分析和操作提示语是更有效的。然而，用任务调谐法训练的投影仪仍然不能用于不同类型的任务，这就要求采用更先进的转移方法。</li></ul><h3 id="Transfer-with-Initialization-1"><a href="#Transfer-with-Initialization-1" class="headerlink" title="Transfer with Initialization"></a>Transfer with Initialization</h3><p>与第4.2节类似，我们进一步研究投射的 soft-prompt 是否能在目标模型上初始化PT，并加速训练以及提高性能。基于第5.2节的结果，我们提出了跨模型迁移 prompt tuning，即 $TPT_{MODEL}$，它采用 Task tuning投射器，将在源PLM上训练的soft prompt 投射到目标PLM上，并用投射的 prompt 初始化PT。</p><p>在从BERTBASE转移到RoBERTaBASE的设置中，性能和训练时间的比较见表6</p><p><img src="https://s2.loli.net/2021/12/21/bJfqPcs5GiVjh8g.png" alt=""></p><p>我们可以注意到。(1)对于同一类型的投影仪训练任务，TPTMODEL大多能以较少的训练步骤获得相当或稍好的性能，这表明实用的跨模型提示转移环是可能的，尽管先前的方法在这里不能取得明显的优势。(2）对于不同类型的投影仪训练任务，$TPT<em>{MODEL}$通常不能在性能和训练时间上带来优势，这表明 $TPT</em>{MODEL}$ 仍然严重受限于提示投影仪的质量。</p><p>一般来说，$TPT<em>{MODEL}$带来的优势是中等的，明显低于 $TPT</em>{TASK}$。为了分析是什么影响了跨模型的可转移性，我们观察了在目标PLM上训练的原始提示和用4.3节中的提示相似度指标预测的提示之间的相似性。结果显示在表7中。我们可以看到，对于用所有指标衡量的所有任务，预测的提示语与最初在目标PLM上训练的提示语高度不相似，而投影仪训练任务的预测提示语可以达到与最初训练的提示语相当的性能。我们猜测这表明由于PLM的高冗余度（Aghajanyan等人，2021），不同的提示激活不同的神经元也能刺激PLM做类似的工作，但由优化器和超参数决定的优化动态更倾向于找到类似的解决方案（表2）。</p><p><img src="https://s2.loli.net/2021/12/21/5hMpG8EmgjD1XK6.png" alt=""></p><h2 id="Discussion"><a href="#Discussion" class="headerlink" title="Discussion"></a>Discussion</h2><h3 id="Using-multiple-source-prompts"><a href="#Using-multiple-source-prompts" class="headerlink" title="Using multiple source prompts."></a>Using multiple source prompts.</h3><p>在 $TPT<em>{TASK}$  和 $TPT</em>{MODEL} $中，我们只使用一个源提示进行初始化，也就是事先尝试。直观地说，将多个源提示混合起来可能会实现进一步的性能和效率提升。实际上，同时进行的工作（Vu等人，2021）在跨任务转移中已经证实了这一点。<strong>未来的工作可以探索先进的混合/组合方法</strong>，以实现更好的初始化，本文探索的提示相似度指标可能有助于实现这一目的。</p><h3 id="Finding-better-prompt-similarity-metric"><a href="#Finding-better-prompt-similarity-metric" class="headerlink" title="Finding better prompt similarity metric"></a>Finding better prompt similarity metric</h3><p>在第5.3节中，我们发现，尽管从另一个PLM投射的提示可以达到与最初在目标PLM上训练的提示相当的性能，但用本文所有的提示相似度指标（包括激活神经元的重叠率）来衡量，这两种提示是高度不相似的。这表明，考虑到PLMs的高度冗余，我们仍然需要一个更好的提示相似性指标，并测量提示的基本因素，这需要对PLMs的机制有更深入的了解。以前的工作（Aghajanyan等人，2021；Qin等人，2021b）表明，各种NLP任务可以被重新参数化为类似的低维子空间，以PLMs为条件，这可能有助于实现这一目的。</p><h3 id="Designing-better-cross-model-prompt-projection"><a href="#Designing-better-cross-model-prompt-projection" class="headerlink" title="Designing better cross-model prompt projection."></a>Designing better cross-model prompt projection.</h3><p>与 $TPT<em>{TASK}$相比，本文中 $TPT</em>{MODEL} $ 的结果要弱得多，这是因为源PLM和目标PLM之间的特征不同，而且投影方法有限。在第5.3节中，我们发现我们的跨模型投影倾向于投影到性能相当的解决方案，但不是那些优化过程中的首选方案；因此 $TPT<em>{MODEL}$ 的效果不如 $TPT</em>{TASK}$好。而且我们发现，当我们去掉任务调优中公式7的LayerNorm(-)后，这种现象更加明显，即使用 $TPT_{MODEL}$时，学习损失并没有减少。详细情况请参考附录D。这表明我们应该设计更好的跨模型投影方法来克服不同PLM的异质性和不同的优化偏好。</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>在本文中，我们实证研究了提示调谐在不同任务和模型中的可转移性。在跨任务的设置中，我们发现软提示可以在不训练的情况下转移到类似的任务中，并且使用训练过的软提示作为初始化可以加速训练并提高效果。我们还探索了各种提示的相似性指标，并表明提示如何刺激PLM比它们的嵌入距离在转移性方面更重要。在跨模型的设置中，我们探索了各种将软提示投射到其他模型空间的方法，发现使用投射提示的转移初始化只能取得适度的改善，这可能是由于PLM的冗余性。我们希望这项工作中的实证分析和尝试的转移方法能够促进PT转移的进一步研究。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;On-Transferability-of-Prompt-Tuning-for-Natural-Language-Understanding&quot;&gt;&lt;a href=&quot;#On-Transferability-of-Prompt-Tuning-for-Natural-La</summary>
      
    
    
    
    
    <category term="context detection" scheme="http://example.com/tags/context-detection/"/>
    
  </entry>
  
  <entry>
    <title>TransPrompt Towards an Automatic Transferable Prompting Framework for Few-shot Text Classification</title>
    <link href="http://example.com/2021/12/19/TransPrompt-Towards-an-Automatic-Transferable-Prompting-Framework-for-Few-shot-Text-Classification/"/>
    <id>http://example.com/2021/12/19/TransPrompt-Towards-an-Automatic-Transferable-Prompting-Framework-for-Few-shot-Text-Classification/</id>
    <published>2021-12-19T13:59:11.000Z</published>
    <updated>2022-01-22T06:30:18.654Z</updated>
    
    <content type="html"><![CDATA[<h1 id="TransPrompt-Towards-an-Automatic-Transferable-Prompting-Framework-for-Few-shot-Text-Classification"><a href="#TransPrompt-Towards-an-Automatic-Transferable-Prompting-Framework-for-Few-shot-Text-Classification" class="headerlink" title="TransPrompt: Towards an Automatic Transferable Prompting Framework for Few-shot Text Classification"></a>TransPrompt: Towards an Automatic Transferable Prompting Framework for Few-shot Text Classification</h1><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>最近的研究表明，prompts 可以提高大型预训练语言模型在 few-shot 文本分类中的表现。然而，目前还不清楚如何在类似的NLP任务中迁移 prompts 知识以达到相互强化的目的。基于连续的 prompts 嵌入，我们提出了TransPrompt，一个可迁移的 prompt 框架，用于在类似的任务中进行 few-shot 的学习。</p><p> 在TransPrompt中，我们采用了一个多任务元知识获取程序来训练一个元学习者，以捕获跨任务的可迁移知识。我们进一步设计了两种去偏技术，使其对任何任务都更具有任务无关性和无偏性。</p><p>之后，元学习器可以以高精确度适应目标任务。大量的实验表明，TransPrompt在多个NLP任务和数据集上的表现优于单任务和跨任务的强基线。我们进一步表明，元学习器可以有效地提高以前未见过的任务的性能。当用完整的训练集学习时，TransPrompt也优于强大的微调基线。</p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>微调预训练语言模型（PLM）已经成为大多数NLP任务训练模型的标准做法（Devlin等人，2019；Liu等人，2019b；Qiu等人，2020）。为了确保高精确度，有必要为下游任务获得足够数量的训练数据，这往往是低资源场景下的瓶颈。</p><p>超大型PLM的应用，如GPT-3（Brown等人，2020），证明了这种PLM可以通过很少的训练样本来学习解决一个任务。受这些工作的启发，Gao等人（2020）提出了一种基于 prompt 的方法，以在少量的学习环境中对BERT-风格的PLM进行微调，它使PLM适应于产生对应于每个类别的特定标记，而不是学习预测头。Schick和Schütze（2020）；Scao和Rush（2021）；Schick和Schütze（2021）等人也表明了 prompt 的有效性。然而，设计高绩效的提示语是具有挑战性的，需要非常大的验证集。为了缓解这个问题，Liu等人（2021）提出了具有完全可分参数的连续 prompt 嵌入，避免了繁琐的手工提示工程过程。</p><p>尽管取得了显著的成功，我们注意到目前基于提示的方法可能有一些限制。对于 few-shot 的学习，下游任务的性能仍然受到训练实例数量的限制。如果模型能够在适应 few-shot 样本的特定任务之前，从类似的NLP任务中获得可迁移的知识，那将是非常理想的。然而，目前还不清楚提示编码器和具有提示技术的PLM中的知识是如何跨任务转移的。一个自然的问题出现了：我们如何为BERT风格的模型设计一个提示框架，以捕捉类似NLP任务中的可转移知识，从而提高少数样本学习的性能？</p><p>上述问题的一个直接解决方案是在这些类似的NLP任务中采用多任务微调。当训练数据稀缺时，微调后的PLM很容易对特定实例过度拟合（Nakamura and Harada, 2019）。在机器学习中，元学习范式被广泛研究，它产生的模型能够以很少的学习步骤迅速适应一组类似的任务（Wang等人，2020c；Huisman等人，2020）。对于PLM，Wang等人（2020a）发现，训练PLM的元学习者能够有效地捕捉不同领域的可转移知识。然而，这种方法并不是为提示性的少量学习而设计的，而且缺乏为所有任务学习无偏见的表征的机制。</p><p>在本文中，我们提出了TransPrompt这个提示框架，它允许PLMs为少量文本分类捕获跨任务的可转移知识，其高级架构如图1所示。TransPrompt首先采用多任务元知识获取（MMA）程序，在类似的NLP任务中共同学习提示编码器和PLM的可转移表示。为了减少过度拟合，使底层PLM更具有任务无关性，并减少对任何特定任务的偏倚，我们提出了两种去偏倚技术，即基于原型的去偏倚和基于熵的去偏倚。学习到的模型可以被看作是一组类似NLP任务的元学习器。</p><p><img src="https://s2.loli.net/2021/12/22/qsxCBdtK18mHhgM.png" alt=""></p><p>在MMA之后，TransPrompt采取了任务意识模型规范（TMS）的步骤，这可以进一步分为两种情况。 i）当模型在MMA期间适应现有任务时，可以应用P-tuning（Liu等人，2021）的变体来进行有效适应。 ii）当需要适应以前未见过的任务时，采用模型泛化策略，具体考虑模型中的通用提示知识。这通常是指由于数据隐私或计算效率问题，对所有任务的元精简器进行重新训练是不可行的情况。</p><p>为了进行评估，我们在三组少有的NLP任务（共包括七个公共数据集）上测试了TransPrompt框架：i）情感分析；ii）自然语言推理（NLI）；以及iii）转述。实验结果表明，TransPrompt在单任务和跨任务的强大基线上都有稳定的表现。我们进一步证明：i）由TransPrompt训练的元学习器可以有效地推广到未见过的任务；ii）在用完整的训练集学习时，TransPrompt也优于流行的微调算法。综上所述，我们在这项工作中做出了以下主要贡献。</p><ul><li>我们介绍了新的TransPrompt框架，以学习跨任务的可转移知识，用于少数文本分类。</li><li>我们提出了一个基于提示的元学习者训练算法和两种去偏技术，以获取可转移的知识。</li><li>在多种类型的NLP任务上的实验表明，TransPrompt在少量学习和标准微调方面的表现一直优于强大的基线。</li></ul><h2 id="The-TransPrompt-Framework"><a href="#The-TransPrompt-Framework" class="headerlink" title="The TransPrompt Framework"></a>The <em>TransPrompt</em> Framework</h2><h3 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h3><p>$T_1, …, T_M$ 是 $M$ 个类似的 few-shot 的文本分类任务。第 $m$ 项任务可以表示为：$T_m:x \to y$， 其中 $x$ 和$y\in Y$ 表示输入文本和分类标签。</p><p>$Y$ 是预先定义的标签集，$|Y| = N$, 其中 $N$ 是预定义的常数。假设在每个任务 $T_m$ 中，有 $K$ 个训练样本与每个类 $y\in Y$相关。因此，我们对每个任务 $T_m$ 有一个训练集 $D_m$，每个训练集包含 $N×K$ 个样本。$M$ 个任务的训练实例的总数是$ N×K×M$ 。</p><p>在 TransPrompt 中，根据 $M$ 个few-shot的训练集 $D<em>1,…,D_M$ 来训练一个元学习器 $F</em>{meta}$，其参数从任何PLM中初始化。之后，$F_{meta}$ 根据每个任务的训练集 $D_m$ 来适应每个任务 $T_m$。特定任务的模型被表示为 $F_m$。</p><p>由于 $F<em>{meta}$ 的设计是为了消化跨任务的可转移知识，而不是简单的多任务学习，$F</em>{meta}$ 也可以适应以前没有见过的任务。</p><p>由于数据隐私或计算效率问题，当在 $F<em>{meta}$ 的训练过程中无法获得相似任务 $\hat T$ 的少量训练集 $\hat D$ 时，我们探索如何利用TransPrompt 来生成基于 $F</em>{meta}$ 和 $\hat D$ 的精确模型 $\hat F$。在这种情况下，$F_{meta}$ 在MMA期间接受训练时，对新任务 $\hat T$ 没有任何了解。</p><p>在下文中，将介绍TransPrompt框架的详细技术，它由两个主要阶段组成，即多任务元知识获取（MMA）和任务意识模型规范（TMS）。最后，我们讨论了如何将 TransPrompt 应用于标准的微调场景，其中我们有相对较大的训练集，而不是解决 $N$ 路 K-shot 问题。</p><h3 id="Multi-task-Meta-knowledge-Acquisition"><a href="#Multi-task-Meta-knowledge-Acquisition" class="headerlink" title="Multi-task Meta-knowledge Acquisition"></a>Multi-task Meta-knowledge Acquisition</h3><p><img src="https://s2.loli.net/2021/12/19/B5Zh3pWesnRJGai.png" alt=""></p><h4 id="Prompt-Encoding"><a href="#Prompt-Encoding" class="headerlink" title="Prompt Encoding"></a>Prompt Encoding</h4><p>由于 TransPrompt 框架被置于多任务设置中，对于每个任务 $T_m$，我们有一个特定任务的提示模板 $t^{(m)} (x)$，如下所示:</p><script type="math/tex; mode=display">P_1^{(m)},...,P_i^{(m)}, x, P_{i+1}^{(m)} ,..., P_I^{(m)} , MASK</script><p>其中 $P_i^{(m)}$ 是 prompt 伪 token，$I$ 是伪token的总数，MASK是特殊 token 是一个特殊标记，用作模型输出的占位符。 我们还为所有任务定义了一个通用提示模板 $t^{(∗)}(x)$ :</p><script type="math/tex; mode=display">P_1^{(*)},...,P_i^{(*)}, x, P_{i+1}^{(*)} ,..., P_I^{(*)} , MASK</script><p>对于一个实例$(x,y)\in D_m$，提示嵌入 $PE^{(m)}(x)$可以计算如下:</p><script type="math/tex; mode=display">PE^{(m)}(x) = AvgPool(MLP(BiLSTM(t^{(m)}(x))) , MLP(BiLSTM(t^{(*)}(x))))</script><p>其中我们使用双向LSTM网络与多层感知器作为提示编码器（Liu等人，2021）。特定任务和通用提示编码器的平均集合结果被视为提示嵌入。提示嵌入 $PE^{(m)}(x)$ 是一个序列，作为PLM的输入:</p><script type="math/tex; mode=display">h_1,...,h_i, h_{[x]}, h_{i+1} ,..., h_I, h_{[MASK]}</script><p>其中 $h<em>{[x]}$ 是输入 $x$ 的序列嵌入，$h</em>{[MASK]}$ 是被MASK的输出 token 嵌入。由于提示参数是完全可微的，在反向传播过程中，它们有效地捕捉了特定任务和一般知识。</p><h4 id="Training-the-Meta-learner"><a href="#Training-the-Meta-learner" class="headerlink" title="Training the Meta-learner"></a>Training the Meta-learner</h4><p>获得元学习者的一个天真的方法是在 $M+1$ 个 prompt 编码器的 $M$ 个任务中应用P-tuning过程（Staudemeyer和Morris，2019）。然而，在实践中，它不能保证满意的结果。由于大型PLMs在 few-shot 学习过程中很容易出现过度拟合（Gao等人，2020），在跨任务的情况下，元学习者会不幸地记住非目标任务中的不可转移的知识。为了缓解这个问题，我们提出了两种去偏技术，以获得一个用可转移知识编码的更无偏见的元学习者，</p><p>即i）基于原型的去偏 和 ii）基于熵的去偏。</p><ul><li><p>Prototype-based De-biasing：这种技术旨在在元学习者的训练过程中对跨任务的原型实例给予更多的重视。在这里，我们扩展了Snell等人（2017）构建的轻量级多任务原型网络G。在网络G中，每个任务 $T_m$ 的类中心点嵌入$c_m(y)(y∈Y)$被计算并存储为:</p><script type="math/tex; mode=display">c_m(y) = \frac{1}{|D_{m,y}|}\sum_{(x,y)\in D_{m,y}} \Epsilon(x)</script><p>其中 $D<em>{m,y}$ 是 $D_m$ 的子集，使得 $D</em>{m,y}$中的每个实例都有标签 $y$ ，而 $E(x)$ 是由前面描述的元学习器生成的 $x$ 的表示。对于每个实例 $(x,y)\in D_m$，我们将文本 $x$ 通过网络来生成跨任务原型得分，表示为 $s(x)$:</p><script type="math/tex; mode=display">s(x) = \tau \cdot \frac{sim(E(x), c_m(y))}{\sum_{\hat y\in Y} sim(E(x), c_m(\hat y))}+ \frac{1-\tau} {M-1} \sum_{\hat m=1 (m\neq\hat m)} \frac{sim(E(x), c_m(y))}{\sum_{\hat y\in Y} sim(E(x), c_m(\hat y))}</script><p>其中 $0&lt;\tau &lt;1$ 是预定义的平衡因素，$sim(\cdot, of K nowcdot)$ 是两个嵌入的相似函数，我们可以看到，如果一个实例与任务 $T<em>m$ 本身和其他任务的中心点都有语义上的联系，那么它就会得到更高的分数，因此更容易跨任务迁移。通过将 $s(x)$ 视为优化权重，$F</em>{meta}$ 的整体损失函数 $L(Θ)$可以通过以下方式给出:</p><script type="math/tex; mode=display">L(\theta) = \sum_{m=1}^M \sum_{(x,y)\in D_m} s(x) l(x,y;\theta) + \lambda_1||\theta||</script><p>其中Θ是所有模型参数的集合，$l(x, y; Θ)$是样本间交叉熵损失，$λ_1$是正则化超参数。</p></li><li><p>Entropy-based De-biasing：仅仅应用基于原型的去偏移技术的一个潜在风险是获得一个非任务无关性的元学习者。考虑三个任务T1、T2和T3。如果T1和T2高度相似，而T3则更不相似。在D1和D2中，自然会得到较高的原型分数，使得元学习者偏向于T1和T2，而对T3很少关注。因此，当元学习者需要拟合T3时，它的参数初始化设置可能很差。为了使其更具任务无关性，受Jamal和Qi（2019）的启发，我们考虑了 $D_m$ 上的模型预测熵 $H(D_m)$：</p><script type="math/tex; mode=display">H(D_m) = -\frac{1}{|D_m|} \sum_{(x,y)\in D_m} \sum_{\hat y \in Y} \hat y(x) \log \hat y(x)</script><p>其中 $\hat y(x)$是 $x$ 被分配到 $\hat y∈Y$类的预测概率。当 $H(D_m)$ 被用作模型正则器的一部分时，元学习器在任何特定任务上的过度训练将减少。</p><p>将 $H(D_m)$ 项插入损失函数 $L(Θ)$，我们就有了新的损失函数 $L’(Θ)$:</p><script type="math/tex; mode=display">L'(\theta) = \sum_{m=1}^M\sum_{(x,y)\in D_m} (s(x) l(x,y;\theta) - \frac{\lambda_2}{|D_m|}\sum_{\hat y \in Y} \hat y(x)\log\hat y(x)) + \lambda_1||\theta||</script><p>其中 $\lambda_2$ 是正则化超参数</p></li><li><p>Optimization Procedure：尽管它的公式很简单，但最小化 $L’(Θ)$是一个非简单的问题。 这是因为当我们计算 $s(x)$时，我们必须事先获得PLM的模型参数，而这在训练过程之前是无法获得的。另一方面，$L (Θ)$的优化重新要求所有训练样本的 $s(x)$ 值，这就造成了 “鸡生蛋，蛋生鸡 “问题。</p><p>我们采用双重优化过程来解决 $L’(Θ)$的问题。在初始阶段，所有的 $s(x)$s都被均匀地初始化。接下来，我们将 $s(x)$s固定为常数，使 $L′(Θ)$ 中的 $l(x, y; Θ)$ 最小化。一个关于PLM的推理过程可以被应用来获得所有的 $s(x)$s。这个过程迭代了一定数量的epoch。读者也可以参考算法1来了解算法的概况。</p><p><img src="https://s2.loli.net/2021/12/22/LdFBUD4zs3OrJcq.png" alt=""></p></li></ul><h3 id="Task-aware-Model-Specification"><a href="#Task-aware-Model-Specification" class="headerlink" title="Task-aware Model Specification"></a>Task-aware Model Specification</h3><p>在MMA之后，元学习者可以很容易地适应特定的任务。对于一个已经被元学习器 “看到 “的任务 $T_m$，我们通过最小化损失函数 $L^{(m)}(Θ)$来微调相应的 prompt 编码器和PLM:</p><script type="math/tex; mode=display">L^{(m)}(\theta) = \sum_{(x,y)\in D_m} l(x,y;\theta) + \lambda_1||\theta||</script><p>这是P-tuning的一个变种（Liu等人，2021），具有更好的参数初始化。</p><p>对于一个先前未见过的任务 $\hat  T$，采用模型泛化策略。这里，我们使用通用 prompt 编码器来初始化其 prompt编码器。整个模型在数据集 $\hat D $上进行训练，损失函数 $\hat L(\theta)$如下:</p><script type="math/tex; mode=display">\hat L(\theta) = \sum_{(x,y)\in \hat D} l(x,y;\theta) + \lambda_1||\theta||</script><p>由于元学习器是高度泛化的，它可以为少数几次的学习任务 $\hat T$提供良好的初始化。</p><h3 id="Learning-with-Full-Training-Sets"><a href="#Learning-with-Full-Training-Sets" class="headerlink" title="Learning with Full Training Sets"></a>Learning with Full Training Sets</h3><p>当我们有相对较大的训练集时，TransPrompt也可以应用于标准的微调，并进行少量修改。在MMA过程中，我们注意到，当它不是一个N-way K-shot问题时，$D_1,…,D_M$ 的大小会有很大的不同。直接在这些数据集上优化 $L’(Θ)$ 会使元学习者偏向于大数据集。为了解决这个问题，当我们从 $D_1, …, D_M$ 中抽出一批样本时，我们采用分层抽样的方式，以与数据集分布 $Pr(D_m)$ 成比例的概率选择训练实例:</p><script type="math/tex; mode=display">Pr(D_m) = \frac{log|D_m| +\gamma}{ \sum_{\hat m=1}^M log|D_{\hat m}| + \gamma}</script><p>其中 $γ&gt;0$ 是一个平滑系数。这导致了对小数据集的过度采样和对大数据集的不足采样。</p><h2 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h2><p>本文旨在解决few-shot的分类问题。这个问题的定义从根本上不同于 与传统的分类法根本不同，传统的分类法的目标不是对其目的不是对未见过的样本进行分类，而是要快速地将元知识适应于新的任务。具体来说，提供一个有足够训练样本的标记数据集。提供了一个有足够训练样本的基础类 $C^{base}$，其目标是用非常有限的数据来学习概念。一组新类 $C^{novel}$，其中 $C^{base} ∩C^{novel} = ∅$。解决 few-shot 问题的一个有效方法是使用情节采样策略episodic sampling strategy.。</p><p>在这个框架中，元训练和元测试中的样本不是样本，而是情节 ${T}$，每个情节包含 $N$ 个类别（方式）和每个类别的 $K$ 个镜头。</p><p>特别地，对于N-way K-shot 任务，采样支持集 $S = {(x<em>i, y_i)}</em>{i=1}^{N\times K}$ 和查询集 $Q = {(x<em>i,y_i)}</em>{i=N\times K +1}^{N\times K +T}$ </p><p>这里，$x_i$ 和 $y_i \in {C_1,…,C_N}$是第 $i$ 个输入数据，并且是来自 $C^{base}$。在元测试中，测试任务也是从未见过的类别$C^{novel}$ 中抽出同样大小的情节。其目的是将查询集中的 $T$ 个未标记的样本正确地分类到 $N$ 个类别中。</p><h3 id="Overview-of-Framework"><a href="#Overview-of-Framework" class="headerlink" title="Overview of Framework"></a>Overview of Framework</h3><p><img src="https://s2.loli.net/2021/12/20/O1FaqzQe4CcDdfl.png" alt=""></p><p>图1说明了所提方法的框架。它主要由三个部分组成，即用于鉴别性特征提取的编码器，用于表达性元知识存储的记忆模块，用于综合推理的图增强模块。一般来说，我们的方法可以概括为三个阶段（即预训练、元训练、元测试）。</p><ul><li>Phase-I Pre-Train. 我们遵循一个简单的基线[Chen <em>et al.</em>, 2020]：在元训练集C的基础上学习一个有监督的表示，然后在这个表示之上学习一个线性分类器。事实证明，这个预训练阶段对下游的 few-shot 任务是有益的[Tian <em>et al.</em>, 2020]，然后将训练好的特征提取器（<em>如ResNet-12[He </em>et al.*, 2016]）和分类器分别作为我们编码器和记忆库的初始化。</li><li>Phase-II Meta-Train. 我们首先提取支持和查询样本的特征作为任务相关的嵌入$V^t$。然后为了促进快速适应，我们的方法拥有一个记忆库来存储支持集的表达式。这个记忆库通过一个新的更新方案进行优化，以逐步净化鉴别性信息（在第2.2节中介绍）。此外，净化后的内存与图的增强模块相结合，用于稳健预测（在第2.3节中介绍）。在这个模块中，我们挖掘相关的原型 $V^m$ ，在本文中被称为元知识，通过图神经网络传播 $V^t$ 和 $V^m$ 之间的相似性。因此，我们的模型能够以可忽略不计的内存成本方便地泛化到新的任务。</li><li>Phase-III Meta-Test. Meta-Test的程序与Meta-Train相似，也是采用情节性抽样策略。但与第二阶段不同的是，记忆库和其他模块在整个过程中不会被更新。换句话说，开关将被关闭，如图1所示。</li></ul><h3 id="Refined-Memory-Updating"><a href="#Refined-Memory-Updating" class="headerlink" title="Refined Memory Updating"></a>Refined Memory Updating</h3><p>元知识在从未见过的样本中学习新概念方面起着重要作用，最近 FSL 的进展[Ramalho和Garnelo, 2019]经常利用内存机制来存储这种元知识。在其典型的设置中，存储器试图保留尽可能多的信息（例如，存储整个特征）。然而，我们认为这种策略是无效的和低效的。在FSL的背景下，偶发抽样使得特征提取器以很少的样本迅速学习新的概念，这就造成了一个问题：当特征提取器处于一个非常不同的任务背景下时，记忆中的特征会被更新。从这个角度来看，从不同的任务中学习到的表征需要一个净化的过程才能成为一个稳定的概念。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;TransPrompt-Towards-an-Automatic-Transferable-Prompting-Framework-for-Few-shot-Text-Classification&quot;&gt;&lt;a href=&quot;#TransPrompt-Towards-an</summary>
      
    
    
    
    
    <category term="GNN" scheme="http://example.com/tags/GNN/"/>
    
  </entry>
  
  <entry>
    <title>Iterative Network Pruning with Uncertainty Regularization for Lifelong Sentiment Classification</title>
    <link href="http://example.com/2021/12/07/Iterative-Network-Pruning-with-Uncertainty-Regularization-for-Lifelong-Sentiment-Classification/"/>
    <id>http://example.com/2021/12/07/Iterative-Network-Pruning-with-Uncertainty-Regularization-for-Lifelong-Sentiment-Classification/</id>
    <published>2021-12-07T13:20:14.000Z</published>
    <updated>2022-01-19T10:41:14.240Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Iterative-Network-Pruning-with-Uncertainty-Regularization-for-Lifelong-Sentiment-Classification"><a href="#Iterative-Network-Pruning-with-Uncertainty-Regularization-for-Lifelong-Sentiment-Classification" class="headerlink" title="Iterative Network Pruning with Uncertainty Regularization for Lifelong Sentiment Classification"></a>Iterative Network Pruning with Uncertainty Regularization for Lifelong Sentiment Classification</h1><p>提出了一种新的具有不确定性正则化的迭代网络修剪方法，用于终身情感分类（IPRLS），它利用了网络修剪和权重正则化的原则。通过以迭代的方式进行网络修剪和不确定性正则化，IPRLS可以使一个单一的BERT模型适应来自多个领域的连续到达的数据，同时避免灾难性的遗忘和相互影响。</p><p>具体来说，利用迭代修剪方法来去除大型深度网络中的冗余参数，这样释放出来的空间就可以用来学习新的任务，解决灾难性遗忘的问题。</p><p>在学习新任务时，我们也使用基于贝叶斯在线学习框架的不确定性正则化来约束BERT中旧任务权重的更新，这使得正向转移成为可能，即学习新任务可以提高过去任务的表现，同时保护旧知识不被丢失。</p><p>此外，我们提出了一个与BERT各层并行的特定任务的低维残差函数，这使得IPRLS在学习新任务时不容易丢失保存在基础BERT网络中的知识。</p><h2 id="INTRODUCTION"><a href="#INTRODUCTION" class="headerlink" title="INTRODUCTION"></a>INTRODUCTION</h2><p>随着网络上大量富含观点的文档的增加，人们对情感分类给予了极大的关注，其目的是自动预测给定文本的情感极性。近年来，深度学习取得了巨大的成功，在情感分类领域几乎占主导地位[35, 36, 38]。强大的深度神经网络必须依赖于大量的注释训练资源。然而，标注大型数据集通常是费时费力的，在将训练好的情感分类器应用于新领域时，会产生很大的障碍。此外，无论收集多少数据并用于训练情感分类器，都很难覆盖网络上所有可能的意见数据领域。因此，当在实践中部署时，训练有素的情感分类器的表现往往不尽如人意。</p><h2 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h2><h3 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h3><p>在本文中，我们使用BERT作为基础模型来构建情感分类器。BERT是快速发展的预训练模型的一个重要代表，它在各种NLP任务中显示出卓越的性能。一般来说，当任务依次到达时，BERT在学习新任务时，会对旧任务产生 “灾难性的遗忘”。为了缓解 “灾难性遗忘 “的问题，我们利用基于架构和基于正则化的持续学习方法来提高BERT在终身情感分类中的性能。具体来说，我们探索了两种机制，以促进BERT模型在学习新任务时保留对先前任务重要的知识。首先，我们探索了一种具有不确定性正则化的迭代修剪，以将来自多个任务的重要知识整合到一个单一的BERT模型中，同时确保准确性的最小下降。其次，我们在每个BERT层中 “并行 “添加一个特定任务的并行残差函数，以进一步保留最重要的新知识，同时适应新任务。接下来，我们将详细说明BERT、具有不确定性正则化的迭代修剪和特定任务的平行残差函数。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Iterative-Network-Pruning-with-Uncertainty-Regularization-for-Lifelong-Sentiment-Classification&quot;&gt;&lt;a href=&quot;#Iterative-Network-Pruning</summary>
      
    
    
    
    
    <category term="context detection" scheme="http://example.com/tags/context-detection/"/>
    
  </entry>
  
  <entry>
    <title>Continual Learning with Hypernetworks</title>
    <link href="http://example.com/2021/12/03/Continual-Learning-with-Hypernetworks/"/>
    <id>http://example.com/2021/12/03/Continual-Learning-with-Hypernetworks/</id>
    <published>2021-12-03T12:18:00.000Z</published>
    <updated>2022-02-14T12:12:29.776Z</updated>
    
    <content type="html"><![CDATA[<p>[TOC]</p><h1 id="Continual-Learning-with-Hypernetworks"><a href="#Continual-Learning-with-Hypernetworks" class="headerlink" title="Continual Learning with Hypernetworks"></a>Continual Learning with Hypernetworks</h1><p>当人工神经网络在多个任务上进行顺序训练时，它们会遭受灾难性的遗忘。 为了克服这个问题，我们提出了一种基于任务条件超网络的新方法，即基于任务身份生成目标模型权重的网络。</p><p>由于一个简单的关键特征，此类模型的持续学习 (CL) 难度较小：任务条件超网络不需要回忆所有先前看到的数据的输入-输出关系，只需要排练特定于任务的权重实现，这可以 使用简单的正则化器在内存中维护。</p><p>除了在标准的CL基准上取得最先进的性能外，对长任务序列的额外实验显示，任务条件下的超网络显示出非常大的能力来保留以前的记忆。</p><p>值得注意的是，当可训练的超网络权重数量与目标网络大小相当或小于目标网络大小时，如此长的记忆寿命是在一个压缩制度下实现的。我们对低维任务嵌入空间（超网络的输入空间）的结构进行了深入研究，并表明任务条件下的超网络展示了迁移学习。最后，基于CIFAR-10/100图像数据集的挑战性CL基准的经验结果<strong>进一步支持了前向信息迁移。</strong></p><h2 id="INTRODUCTION"><a href="#INTRODUCTION" class="headerlink" title="INTRODUCTION"></a>INTRODUCTION</h2><p>我们假设一个具有可训练权重 $Θ$ 的神经网络 $f(x,Θ)$ 被赋予来自一组任务的数据 ${(X^{(1)}Y^{(1)})}$， 输入样本 $X^{(t)} = {x^{(t,i)}}<em>{i=1}^{n_i}$，输出样本 $Y^{(t)} = {y^{(t,i)}}</em>{i=1}^{n_t}$ , 其中 $n_t = |X^{(t)}|$ 。</p><p>一个标准的训练方法是使用所有任务的数据来学习模型 一次性从所有任务中学习模型。然而，这在现实世界的问题中并不总是可能的，在在线学习环境中也不可取。持续学习（CL）指的是一种在线学习设置，其中任务是按顺序呈现的（关于持续学习的最新评论，见van de Ven &amp; Tolias, 2019）。</p><p> 在CL中，当学习一个新的任务 $t$ 时，从权重 $Θ^{(t-1)}$ 开始，只观察$(X^{(t)},Y^{(t)})$ ，目标是找到一组新的参数 $Θ^{(t)}$，与 $Θ^{( t-1)}$相比，（1）保留（无灾难性遗忘）或（2）提高（正向转移）以前任务的性能，（3）解决新任务 $t$ 可能利用以前获得的知识（正向转移）。实现这些目标是不容易的，也是神经网络研究中的一个长期问题。</p><p>在这里，我们提议在 meta level 上解决灾难性遗忘问题：我们不直接尝试为以前的任务保留 $f( x,Θ)$，而是固定一个元模型 $f_h(e,Θ_h)$ 的输出，该模型被称为任务条件超网络，将任务嵌入 $e$ 映射到权重 $Θ$ 。现在，每个任务必须记住single point。</p><p>为了激励这种方法，我们做了一个思想实验：我们假设允许我们存储所有的输入 ${X^{(1)},…, X^{(T)} }$，并使用这些数据来计算对应于 $Θ^{(T-1)}$的模型输出。</p><p>在这个理想化的设置中，我们可以通过简单地将当前任务的数据与过去的数据混合来避免遗忘，${(X^{(1)}, Y^{(1)}), . . . , (X^{(T -1)}, Y^{(T -1)}), (X^{(T )}, Y^{(T )})}$，其中 $Y^{(t)}$ 是指使用模型本身 $f(-,Θ^{(t-1)})$ 生成的一组合成目标。因此，通过训练保留以前获得的输入-输出映射，我们可以得到一个原则上与多任务学习一样强大的顺序算法。多任务学习，即所有的任务都是同时学习的，可以被看作是CL的上限。上面描述的策略被称为排练（Robins, 1995）。然而，存储以前的任务数据违反了我们的CL要求。</p><p>因此，我们引入了一个视角的变化，<strong>从维护单个输入输出数据点的挑战转向维护参数集 ${Θ^{(t)}} $ 的问题</strong>，而不明确存储它们。<br>为了实现这一点，我们<strong>训练元模型参数 $Θ_h$，类似于上面概述的学习方案，现在的合成目标对应于适合以前任务的权重配置。</strong>这样就可以用一个低维任务描述符来交换整个数据集的存储，除了最简单的任务外，还能节省大量内存。尽管依赖于正则化，但我们的方法在概念上与之前基于权重正则化的算法（如Kirkpatrick等人，2017；Zenke等人，2017）或激活空间（如He &amp; Jaeger，2018）有所不同。</p><p>我们的实验结果表明，在一组标准的CL基准上，任务条件的超网络并没有遭受灾难性的遗忘。值得注意的是，在面对非常长的任务序列时，它们能够保留记忆，而且性能几乎没有下降。由于神经网络的表达能力，任务条件超网络<strong>利用了任务与任务之间的相似性，并将信息及时迁移到未来的任务中</strong>。最后，我们提出的任务条件元模型观点是通用的，因为它不依赖于目标网络架构的具体细节。我们利用这一关键原则，并表明同样的元模型框架延伸到并可以改善一类重要的CL方法，即生成性重放方法，这些方法在许多实际问题中是目前最先进的表现（Shin等人，2017；Wu等人，2018；van de Ven &amp; Tolias，2018）。</p><h2 id="MODEL"><a href="#MODEL" class="headerlink" title="MODEL"></a>MODEL</h2><h3 id="TASK-CONDITIONED-HYPERNETWORKS"><a href="#TASK-CONDITIONED-HYPERNETWORKS" class="headerlink" title="TASK-CONDITIONED HYPERNETWORKS"></a>TASK-CONDITIONED HYPERNETWORKS</h3><p><strong>Hypernetworks parameterize target models. </strong> 我们持续学习方法的核心是超网络，图1a。<strong>我们不是直接学习一个特定函数 $f<em>{trgt} $ 的参数 $Θ</em>{trgt}$（目标模型），而是学习一个元模型的参数 $Θ<em>h$。这种元模型的输出，即超网络，是 $Θ</em>{trgt}$。因此，超网络可以被认为是权重生成器，它最初是为了以压缩的形式动态地对模型进行参数化</strong>（Ha等人，2017；Schmidhuber，1992；Bertinetto等人，2016；Jia等人，2016）。</p><p><img src="https://i.loli.net/2021/12/03/8AEnX2IeSbGjmhT.png" alt=""></p><p>(a) <strong>通常，神经网络的参数是根据数据直接调整的，以解决一个任务。在这里，一个被称为超网络的权重生成器被学习</strong>。<strong>超网络将嵌入向量映射为权重，从而为目标神经网络提供参数。</strong>在持续学习的情况下，<strong>一组特定任务的嵌入是通过反向传播学习的。嵌入向量提供与任务相关的背景，并使超网络偏向于特定的解决方案。</strong></p><p>(b) 一个较小的、分块的超网络可以被反复使用，一次产生一大块目标网络权重（例如，一次一个层）。分块超网络可以实现模型压缩：可训练参数的有效数量可以小于目标网络权重的数量。</p><p><strong>Continual learning with hypernetwork output regularization.</strong> <strong>避免灾难性遗忘的一种方法是存储以前任务的数据和相应的模型输出，然后固定这种输出。这可以通过以下形式的输出正则器来实现，其中过去的输出起到了伪目标的作</strong>用（Robins, 1995; Li &amp; Hoiem, 2018; Benjamin等人, 2018）</p><script type="math/tex; mode=display">L_{output} = \sum_{t=1}^{T-1} \sum_{i=1}^{|X^{(t)}|} ||f(x^{(t,i)}, \theta^*) - f(x^{(t,i)}, \theta)||^2</script><p>在上面的方程式中，$Θ^∗$是尝试学习任务 $T$ 之前的参数集，$f$ 是学习者。<strong>然而，这种方法需要存储和迭代以前的数据，这个过程被称为排练。这在内存方面可能很昂贵，而且不是严格意义上的在线学习。一个可能的变通方法是通过对随机模式（Robins, 1995）或当前任务数据集（Li &amp; Hoiem, 2018）评估 $f$ 来生成伪目标。</strong>然而，这不一定能固定函数 $f$ 在感兴趣区域的行为。</p><p><strong>超网络自然避开了这个问题。在目标网络权重空间中，每个任务必须固定一个点（即一组权重）。</strong>这可以通过任务条件超网络有效地实现，即把超网络的输出固定在适当的任务嵌入上。</p><p>与Benjamin等人（2018）类似，我们使用两步优化程序来引入内存保护的超网络输出约束。首先，我们计算出一个候选变化 $ΔΘ<em>h$，该变化使当前任务损失 $L(T)=L</em>{task}(Θ_h,e^{(T)},X^{(T)},Y^{(T)})$ 相对于 $Θ$ 最小。候选任务 $∆Θ_h$ 是通过选择的优化器得到的（我们自始至终使用Adam；Kingma &amp; Ba, 2015）。然后通过最小化以下总损失来计算实际的参数变化: </p><script type="math/tex; mode=display">\begin{equation}\begin{split} L_{total} &= L_{task}(\theta_h, e^{(T)}, X^{(T)}, Y^{(T)}) + L_{output} (\theta_{h}^*, \theta_h, \Delta \theta_{h}, \{e^{t}\})\\&=  L_{task}(\theta_h, e^{(T)}, X^{(T)}, Y^{(T)}) + \frac{\beta_{output}}{T-1} \sum_{t=1}^{T-1}||f_h(e^{(t)}, \theta^*_h) - f_h(e^{(t)}, \theta_h + \Delta\theta_h)||^2\end{split}\end{equation}</script><p>其中 $Θ^∗<em>h$ 是尝试学习任务 $T$ 之前的超网络参数集，$ΔΘ_h$ 被认为是固定的，$β</em>{output}$是一个控制正则器强度的超参数。在附录D中，我们对 $β_{output}$进行了敏感性分析，并实验了一个更有效的随机正则器，其中平均化是在过去任务的一个随机子集上进行的。</p><p>可以采用更多的计算密集型算法，包括完整的内环细化，或者通过 $∆Θ<em>h$的反向传播使用二阶梯度信息。然而，我们根据经验发现，我们的单步校正效果很好。探索性的超参数扫描显示，在加入前瞻 $∆Θ_h$带来了性能上的小幅提升，即使是用廉价的一步程序计算时。请注意，与公式1不同的是，保存记忆的项 $L</em>{output}$并不依赖于过去的数据。以前任务的记忆只通过以下集合进入任务嵌入 ${e^{(t)}}^{T-1}_{t-1}$。</p><p><strong>Learned task embeddings.</strong> <strong>任务嵌入是可以学习的可区分的确定性参数</strong>，就像 $Θ<em>h$ 一样。**在我们算法的每个学习步骤中，我们也会更新当前的任务嵌入 $e^{(T )}$，以最小化任务损失 $L^{(T)}</em>{task}$。<strong>学</strong>习任务后，最终的嵌入被保存下来 并添加到集合${e^{(t)}}$中。**</p><h3 id="MODEL-COMPRESSION-WITH-CHUNKED-HYPERNETWORKS"><a href="#MODEL-COMPRESSION-WITH-CHUNKED-HYPERNETWORKS" class="headerlink" title="MODEL COMPRESSION WITH CHUNKED HYPERNETWORKS"></a>MODEL COMPRESSION WITH CHUNKED HYPERNETWORKS</h3><p><strong>Chunking.</strong> 在一个直接的实现中，超网络产生目标神经网络的整个权重集。对于现代深度神经网络，这是一个非常高维的输出。然而，超网络可以被迭代调用，在每一步只填入目标模型的一部分，分块进行（Ha等人，2017；Pawlowski等人，2017）。这种策略允许应用可重复使用的较小的超网络。有趣的是，通过分块超网络，有可能在压缩制度下解决任务，其中学习的参数（超网络的参数）的数量实际上小于目标网络参数的数量。</p><p><strong>Chunk embeddings and network partitioning.</strong> 多次重新应用相同的超网络会在目标网络的各个分区中引入权重共享，这通常是不可取的。为了允许目标网络的灵活参数化，我们引入了一组 $C={c<em>i}^{N_c}</em>{i=1}$ 的块嵌入，它们被用作超网络的额外输入，图1b。因此，整套目标网络参数 $Θ<em>{trgt}=[f_h(e,c_1),…,f_h(e,c</em>{N_C})]$ 是通过对 C 的迭代产生的，保持任务嵌入e不变。这样，超网络可以为每个块产生不同的权重。此外，块嵌入，就像任务嵌入一样，是普通的确定性参数，我们通过反向传播学习。为了简单起见，我们对所有任务使用一组共享的块嵌入，我们不探索特殊的目标网络分区策略。</p><p>我们的方法有多灵活？分块神经网络原则上可以任意地接近任何目标权重配置。为了完整起见，我们在附录E中正式说明这一点。</p><h3 id="CONTEXT-FREE-INFERENCE-UNKNOWN-TASK-IDENTITY"><a href="#CONTEXT-FREE-INFERENCE-UNKNOWN-TASK-IDENTITY" class="headerlink" title="CONTEXT-FREE INFERENCE: UNKNOWN TASK IDENTITY"></a>CONTEXT-FREE INFERENCE: UNKNOWN TASK IDENTITY</h3><p><strong>Determining which task to solve from input data. </strong> 我们的<strong>超网络需要一个任务嵌入输入来生成目标模型权重</strong>。在<strong>某些CL应用中，可以立即选择一个合适的嵌入，因为任务身份是明确的，或者可以很容易地从上下文线索中推断出来。</strong>在其他情况下，手头的任务知识在推理过程中并不明确可用。在下文中，我们展示了我们的元模型框架对这种情况的概括。特别是，我们考虑从一个给定的输入模式中推断出要解决的任务的问题，这是一个著名的基准挑战（Farquhar &amp; Gal, 2018; van de Ven &amp; Tolias, 2019）。下面，我们探讨了在这种CL设置中利用任务条件超网络的两种不同策略。</p><p><strong>Task-dependent predictive uncertainty.</strong> 神经网络模型在指示新奇性和适当处理分布外数据方面越来越可靠。对于分类目标分布，网络最好对未见过的数据产生平坦的、高熵的输出，反之，对分布中的数据产生峰值、低熵的响应（Hendrycks &amp; Gimpel, 2016; Liang et al., 2017）。这表明了第一种简单的任务推理方法（HNET+ENT）。给定一个任务身份未知的输入模式，我们选择产生最低预测不确定性的任务嵌入，这是由输出分布熵量化的。虽然这种方法依赖于精确的新奇性检测，而这本身就是一个远未解决的研究问题，但它在其他方面的实现是很简单的，不需要额外的学习或模型来推断任务身份。</p><p><strong>Hypernetwork-protected synthetic replay.</strong> 当生成模型可用时，灾难性遗忘可以通过将当前任务数据与重放的过去合成数据混合来规避（最近的工作见Shin等人，2017；Wu等人，2018）。除了保护生成模型本身，合成数据还可以保护另一个感兴趣的模型，例如另一个区分性模型。这种概念上简单的策略在实践中往往是最先进的CL解决方案（van de Ven &amp; Tolias, 2019）。受这些成功的启发，我们探索用重放网络来增强我们的系统，这里是一个标准的变异自动编码器（VAE；Kingma &amp; Welling，2014）（但见附录F中的生成对抗网络实验，Goodfellow等人，2014）。</p><p>合成重放是一个强大的，但并不完美的CL机制，因为生成模型会出现漂移，而错误往往会随着时间的推移而积累和放大。在此，我们基于以下关键观察：就像目标网络一样，重放模型的生成器可以由超网络指定。这允许用输出正则器（公式2）来保护它，而不是像相关工作中那样，用模型自身的重放数据来保护它。因此，在这个组合方法中，合成重放和任务条件元模型都是串联起来的，以减少遗忘。</p><p>我们在两个不同的设置中探索超网络保护的重放。首先，我们考虑一个最小的架构（HNET+R），其中只有重放模型，而不是目标分类器，是由超网络提供参数。在这里，目标网络中的遗忘是通过混合当前数据和合成数据来避免的。以前任务的合成目标输出值是用软目标方法产生的，即在合成输入数据上学习新任务之前简单地评估目标函数。其次（HNET+TIR），我们引入了一个辅助的任务推理分类器，使用合成重放数据进行保护，并训练它从输入模式预测任务身份。这种结构需要额外的建模，但当任务有强烈的不相似性时，它可能会很好地工作。此外，任务推理子系统可以很容易地应用于处理更普遍形式的上下文信息，超越了当前的输入模式。我们在附录B和附录C中提供了更多的细节，包括网络结构和被优化的损失函数。</p><h2 id="RESULTS"><a href="#RESULTS" class="headerlink" title="RESULTS"></a>RESULTS</h2><p>我们在MNIST、CIFAR-10和CIFAR-100公共数据集的一组标准图像分类基准上评估我们的方法1。我们的主要目的是：（1）研究任务条件超网络在三种持续学习环境中的记忆保持能力，以及（2）研究在连续学习的任务中的信息转移。</p><h3 id="Continual-learning-scenarios"><a href="#Continual-learning-scenarios" class="headerlink" title="Continual learning scenarios."></a>Continual learning scenarios.</h3><p>在我们的实验中，我们考虑了三种不同的CL场景。在CL1中，任务身份被赋予了系统。这可以说是标准的顺序学习情景，除非另有说明，否则我们考虑的就是这种情景。在CL2中，任务身份对系统来说是未知的，但它不需要明确地确定。需要一个有固定头部的目标网络来解决多个任务。在CL3中，任务身份必须被明确推断出来。有人认为，这种情况是最自然的，也是对神经网络来说比较困难的。</p><h3 id="Experimental-details"><a href="#Experimental-details" class="headerlink" title="Experimental details"></a>Experimental details</h3><p>为了实现可比性，在MNIST数据集的实验中，我们将目标网络建模为全连接网络，并按照van de Ven &amp; Tolias（2019）的方法设置所有超参数，他们最近审查并比较了一大批CL算法。对于我们的CIFAR实验，我们选择了ResNet-32目标神经网络（He等人，2016）来评估我们方法的可扩展性。附录C提供了对架构和特定超参数选择的简要描述，以及其他实验细节。我们强调，在我们所有的实验中，<strong>超网络参数的数量总是小于或等于我们与之比较的模型的参数数量。</strong></p><p><img src="https://s2.loli.net/2022/01/03/u6adf9U41GR5IZL.png" alt=""></p><p>图2：一维非线性回归。(a) 具有输出正则化的任务条件超网络可以很容易地对一连串度数增加的多项式建模，同时以持续的方式学习。(b) 直接对所有任务同时进行训练的目标网络找到的解决方案是相似的。(c) 微调，即按顺序学习，导致对过去任务的遗忘。虚线描述的是基础事实，标记显示的是模型预测。</p><h3 id="Nonlinear-regression-toy-problem"><a href="#Nonlinear-regression-toy-problem" class="headerlink" title="Nonlinear regression toy problem."></a>Nonlinear regression toy problem.</h3><p>为了说明我们的方法，我们首先考虑一个简单的非线性回归问题，其中要近似的函数是标量值的，图2。在这里，必须从嘈杂的数据中推断出一串度数增加的多项式函数。这激发了持续学习的问题：当通过修改 $Θ_h$并关闭保存记忆的正则器（βoutput = 0，见公式2）来连续学习每个任务时，网络学习了最后的任务，但忘记了以前的任务，图2c。正则器保护了旧的解决方案，图2a，并且性能与离线非连续学习器相当，图2b。</p><h3 id="Permuted-MNIST-benchmark"><a href="#Permuted-MNIST-benchmark" class="headerlink" title="Permuted MNIST benchmark."></a>Permuted MNIST benchmark.</h3><p>接下来，我们研究了permuted MNIST基准。这个问题的设置如下。首先，向学习者提供完整的MNIST数据集。随后，通过对输入的图像像素进行随机置换，获得新的任务。这个过程可以重复进行，以产生一个长的任务序列，其典型长度为T=10个任务。考虑到生成的任务的低相似性，混杂的MNIST很适合研究持续学习者的记忆能力。对于T=10，我们发现，任务条件超网络在CL1上是最先进的，表1。有趣的是，通过预测分布熵（HNET+ENT）推断出的任务在permuted MNIST基准上效果很好。尽管方法简单，但突触智能（SI；Zenke等人，2017）和在线弹性重量巩固（EWC；Schwarz等人，2018）在CL3上的表现都要高出很多。当辅以生成性重放 方法时，任务条件超网络（HNET+TIR和HNET+R）在所有三种CL场景中表现最好。</p><p><img src="https://s2.loli.net/2022/01/03/ApV5gDtvwZ3YM2i.png" alt=""></p><p>图3：在置换的MNIST基准上进行的实验。(a) 在学习了一百个排列组合（PermutedMNIST-100）之后，第 $t$ 个任务的最终测试集分类准确率。任务条件下的超网络（hnet，红色）在permuted MNIST基准上实现了非常大的记忆寿命。突触智能（SI，蓝色；Zenke等人，2017）、在线EWC（橙色；Schwarz等人，2018）和深度生成重放（DGR+distill，绿色；Shin等人，2017）方法被显示出来进行比较。SI和DGR+distill的记忆保持率优雅地下降，而EWC则受到僵化的影响，永远无法达到非常高的准确性，即使记忆持续了整个实验时间。(B)压缩比 $\frac{|\theta<em>h \cup {e^{(t)}}|}{\theta</em>{trgt}}$对于PermutedMNIST-10基准，在学习所有任务(标记为“最终”，红色)之后和紧接着学习任务(标记为“期间”，紫色)之后的任务平均测试集准确性。超网络允许模型压缩，即使目标模型参数的数量超过其自身，也有良好的表现。性能的衰减是非线性的：在压缩比低于1的大范围内，精度保持大致不变。对压缩比≈1的超参数进行一次调整，然后用于所有压缩比。阴影部分表示5个随机种子的STD（a）和SEM（b）。</p><p>在长序列的限制下，性能差异变得更大，图3a。对于较长的任务序列（T=100），SI和DGR+distill（Shin等人，2017；van de Ven &amp; Tolias，2018）优雅地退化，而在线EWC的正则化强度使该方法无法实现高精确度（见图A6，关于相关工作的超参数搜索）。值得注意的是，任务条件的超网络显示出最小的内存衰减，并找到高性能的解决方案。由于超网络在压缩制度下运行（见图3b和图A7对压缩率的探索），我们的结果并不天真地依赖于参数数量的增加。相反，它们表明以前的方法还没有能力在CL环境下充分利用目标模型的能力。我们在附录D中报告了一组关于该基准的扩展结果，包括对CL2/3（T=100）的研究，其中HNET+TIR强烈地超过了相关工作。</p><h3 id="Split-MNIST-benchmark"><a href="#Split-MNIST-benchmark" class="headerlink" title="Split MNIST benchmark."></a>Split MNIST benchmark.</h3><p>拆分MNIST是另一个流行的CL基准，旨在引入任务重叠。在这个问题中，各种数字被依次配对，并用于形成五个二进制分类任务。在这里，我们发现任务条件下的超网络是整体表现最好的。特别是，HNET+R在CL2和CL3上都改进了以前最先进的方法DGR+distill，几乎饱和了重放模型的CL2上限（附录D）。由于HNET+R本质上是超网络保护的DGR，这些结果证明了任务条件超网络作为有效内存保护器的普遍性。为了进一步支持这一点，我们在附录F中表明，我们的重放模型（我们用VAE和GAN做实验）可以以类增量的方式学习完整的MNIST数据集。最后，HNET+ENT再次胜过EWC和SI，没有任何生成模型。</p><p>在分裂的MNIST问题上，任务是重叠的，因此持续学习者可以跨任务转移信息。为了分析这种影响，我们研究了具有二维任务嵌入空间的任务条件超网络，它可以很容易地被可视化。尽管学习是持续进行的，但我们 我们发现，在适当的任务嵌入下，算法会收敛到一个超网络配置，该配置可以产生同时解决新旧任务的目标模型参数，图4。</p><p><img src="https://s2.loli.net/2022/01/03/1yGoNSQ2X7KdfAW.png" alt=""></p><p>图4：分裂的MNIST基准的二维任务嵌入空间。在学习了五种拆分后的彩色编码的测试集分类准确率，随着嵌入向量成分的变化而显示。标记表示最终任务嵌入的位置。(a) 即使e-空间是低维的，也能实现高分类性能，几乎没有遗忘。该模型显示了嵌入空间中的信息转移：第一个任务在一个包括后续学习任务的嵌入的大体积中得到解决。(b) 嵌入空间的竞争：最后一个任务占据了一个有限的高性能区域，在远离嵌入矢量的地方出现了优雅的退化。以前学到的任务嵌入仍然导致适度的、高于机会的性能。</p><h3 id="Split-CIFAR-10-100-benchmark"><a href="#Split-CIFAR-10-100-benchmark" class="headerlink" title="Split CIFAR-10/100 benchmark"></a>Split CIFAR-10/100 benchmark</h3><p>最后，我们研究了一个更具挑战性的基准，学习者首先被要求解决完整的CIFAR-10分类任务，然后从CIFAR-100数据集中拿出10个类别的集合。我们用一个高性能的ResNet-32目标网络结构（图5）和一个较浅的模型（图A3）进行了实验，我们完全复制了以前的工作。值得注意的是，在ResNet-32模型上，我们发现有任务条件的超网络基本上可以完全消除遗忘。此外，还发生了前向信息转移；与从初始条件单独学习每个任务时相比，来自先前任务的知识使网络能够找到更好的解决方案。有趣的是，在浅层模型实验中，前向转移更强（图A3），否则我们发现我们的方法与SI的表现相当。</p><h2 id="DISCUSSION"><a href="#DISCUSSION" class="headerlink" title="DISCUSSION"></a>DISCUSSION</h2><h3 id="Bayesian-accounts-of-continual-learning"><a href="#Bayesian-accounts-of-continual-learning" class="headerlink" title="Bayesian accounts of continual learning."></a>Bayesian accounts of continual learning.</h3><p>根据标准的贝叶斯CL观点，后验参数分布是使用贝叶斯规则递归更新的，因为任务到达了. 虽然这种方法在理论上是合理的<strong>，但在实践中，通常首选的近似推理方法会导致僵硬的模型，因为必须在第一个任务确定的模式内找到适合所有任务的折中方案。</strong> 这种限制并不适用于超网络，它原则上可以为复杂的多模态分布建模。因此，丰富的、超网络建模的先验是贝叶斯CL方法的一个改进途径。有趣的是，任务条件提供了另一种可能性：<strong>与其把每个任务合并到一个单一的分布上，不如利用一个共享的任务条件超网络来模拟一组参数后验分布。这种条件元模型自然地将我们的框架扩展到贝叶斯学习环境中。与传统的递归贝叶斯更新相比，这种方法可能会受益于额外的灵活性。</strong></p><h3 id="Related-approaches-that-rely-on-task-conditioning"><a href="#Related-approaches-that-rely-on-task-conditioning" class="headerlink" title="Related approaches that rely on task-conditioning."></a>Related approaches that rely on task-conditioning.</h3><p>我们的模型符合，并在某些方面概括了以前的CL方法，该方法将网络计算置于任务描述符上。任务条件通常在模块（Rusu等人，2016；Fernando等人，2017）、神经元（Serra等人，2018；Masse等人，2018）或权重（Mallya和Lazebnik，2018）层面上使用乘法掩码来实现。这类方法在大型网络中效果最好，而且有很大的存储开销，通常随着任务数量的增加而增加。我们的方法与之不同，它使用元模型，即超网络，明确地对全部参数空间进行建模。由于这个元模型，参数和任务空间的泛化是可能的，任务与任务之间的依赖关系可以被利用来有效地表示解决方案，并将目前的知识转移到未来的问题中。有趣的是，与我们同时进行的工作中也得出了类似的论点（Lampinen &amp; McClelland, 2019），在那里，任务嵌入空间在几率学习的背景下被进一步探索。同样，和这里开发的方法一样，最近在CL中的工作将最后一层网络参数作为管道的一部分来生成，以避免灾难性遗忘（Hu等人，2019），或者将参数提炼到一个收缩的自动编码模型上（Camp等人，2018）。</p><h3 id="Positive-backwards-transfer"><a href="#Positive-backwards-transfer" class="headerlink" title="Positive backwards transfer."></a>Positive backwards transfer.</h3><p>在其目前的形式下，<strong>超网络输出正则器保护以前学到的解决方案不发生变化，这样就只能发生弱的信息反向转移</strong>。鉴于选择性遗忘和完善过去的记忆在实现智能行为方面的作用（Brea等人，2014年；Richards和Frankland，2017年），调查和改进反向转移是未来研究的一个重要方向。</p><h3 id="Relevance-to-systems-neuroscience"><a href="#Relevance-to-systems-neuroscience" class="headerlink" title="Relevance to systems neuroscience."></a>Relevance to systems neuroscience.</h3><p>揭示支持大脑和人工神经网络持续学习的机制是一个长期存在的问题（McCloskey &amp; Cohen, 1989; French, 1999; Parisi et al., 2019）。最后，我们对我们的工作进行了推测性的系统解释（Kumaran等人，2016；Hassabis等人，2017），作为大脑皮层中自上而下的调制信号的模型。<strong>任务嵌入可以被看作是低维语境开关，它决定了一个调节系统的行为，在我们的案例中是超网络。</strong>根据我们的模型，超网络将反过来调节目标皮质网络的活动。</p><p>就目前而言，实现超网络需要动态地改变目标网络或皮层区域的整个连接。这样的过程在大脑中似乎很难想象。然而，这种严格的字面解释是可以放松的。例如，超网络可以输出低维的调节信号（Marder，2012），而不是一整套的权重。 这种解释与越来越多的工作是一致的，这些工作表明调节性输入参与实施上下文或任务相关的网络模式切换（Mante等人，2013；Jaeger，2014；Stroud等人，2018；Masse等人，2018）。</p><h2 id="CONCLUSION"><a href="#CONCLUSION" class="headerlink" title="CONCLUSION"></a>CONCLUSION</h2><p>我们引入了一种新的神经网络模型—任务条件超网络，它非常适合于CL问题。任务条件超网络是一个元模型，它可以学习目标函数的参数化，这些目标函数是用任务嵌入向量以压缩的形式指定和识别的。过去的任务使用超网络输出正则器保存在内存中，该正则器对以前发现的目标权重配置的变化进行惩罚。这种方法是可扩展的和通用的，可作为独立的CL方法或与生成性重放结合使用。我们的结果在标准基准上是最先进的，并表明任务条件下的超网络可以实现较长的记忆寿命，以及将信息转移到未来的任务中，这是持续学习者的两个基本属性。</p><h2 id="TASK-CONDITIONED-HYPERNETWORKS-MODEL-SUMMARY"><a href="#TASK-CONDITIONED-HYPERNETWORKS-MODEL-SUMMARY" class="headerlink" title="TASK-CONDITIONED HYPERNETWORKS: MODEL SUMMARY"></a>TASK-CONDITIONED HYPERNETWORKS: MODEL SUMMARY</h2><p>在我们的模型中，一个有任务条件的超网络产生一个目标神经网络的参数 $Θ<em>{trgt} = f</em>{trgt} (e, Θ<em>{trgt} )$。给定一个这样的参数化，目标模型然后根据输入数据计算预测值 $\hat y=f</em>{trgt}(x,Θ<em>{trgt})$。学习相当于调整超网络的参数 $Θ_h$。超网络的参数，包括一组任务嵌入 ${e^{(t)}}^T</em>{t=1}$，以及一组分块嵌入 ${c<em>i}^{N_C}</em>{i=1}$，以便在寻求压缩或整个超网络太大而无法直接处理的情况下。<strong>为了避免灾难性的遗忘，我们引入了一个输出正则器，它通过惩罚目标模型参数的变化来固定超网络的行为，这些变化是针对以前学习的任务而产生的。</strong></p><h3 id="Variables-that-need-to-be-stored-while-learning-new-tasks"><a href="#Variables-that-need-to-be-stored-while-learning-new-tasks" class="headerlink" title="Variables that need to be stored while learning new tasks."></a>Variables that need to be stored while learning new tasks.</h3><p>在持续学习时，我们的模型的存储要求是什么？</p><ul><li>内存保留依赖于每个任务保存一个嵌入。因此，这个集合 ${e^{(t)}}^T_{t=1}$随T线性增长。这种线性扩展在渐进上是不可取的，但它在实践中基本上可以忽略不计，因为每个嵌入是一个单一的低维向量（例如，见图4中的2D嵌入运行）。</li><li>在学习一个新任务之前，需要保留超网络参数 $Θ^∗_h$的冻结快照，以评估公式2中的输出正则器。</li></ul><h2 id="ADDITIONAL-DETAILS-ON-HYPERNETWORK-PROTECTED-REPLAY-MODELS"><a href="#ADDITIONAL-DETAILS-ON-HYPERNETWORK-PROTECTED-REPLAY-MODELS" class="headerlink" title="ADDITIONAL DETAILS ON HYPERNETWORK-PROTECTED REPLAY MODELS"></a>ADDITIONAL DETAILS ON HYPERNETWORK-PROTECTED REPLAY MODELS</h2><h3 id="Variational-autoencoders"><a href="#Variational-autoencoders" class="headerlink" title="Variational autoencoders."></a>Variational autoencoders.</h3><p>对于正文中报告的所有HNET+TIR和HNET+R实验，我们使用VAE作为我们的重放模型（图A1a，Kingma &amp; Welling，2014）。简而言之，VAE由一对编码器-解码器网络组成，其中编码器网络处理一些输入模式 $x$，其输出 $f<em>{enc}(x) = (μ, σ^2)$ 包括一个对角多变量高斯 $p_Z (z; μ, σ^2)$的参数 $μ$ 和 $σ^2$（在对数域中编码，以强制执行非负性），它支配着潜在样本 $z$ 的分布。在电路的另一端，解码器网络处理一个潜伏样本 $z$ 和一个one-hot编码的任务身份向量，并返回一个输入模式重建，$f</em>{dec}（z，1_t）=\hat x$。</p><p>VAEs可以使用一种叫做生成性重放的技术来保存记忆：当训练任务$T$时，通过改变 $1_t$ 和抽取潜伏空间样本 $z$，从当前重放网络中生成旧任务 $t&lt;T$ 的输入样本。生成的数据可以与当前数据集混合，产生一个增强的数据集 $\gat X$，用于重新学习模型参数。当保护一个判别性模型时，可以通过在 $\hat X$上评估网络来生成合成的 “软 “目标。我们使用这种策略来保护HNET+TIR中的辅助任务推理分类器，并保护HNET+R中的主要目标模型。</p><h3 id="Hypernetwork-protected-replay"><a href="#Hypernetwork-protected-replay" class="headerlink" title="Hypernetwork-protected replay."></a>Hypernetwork-protected replay.</h3><p>在我们的HNET+TIR和HNET+R实验中，我们通过任务条件超网络 $f<em>{h,dec}(e,Θ</em>{h,dec})$ 对解码器网络进行参数化。与我们的输出正则器相结合，这使我们能够利用超网络的记忆保留能力，现在是在生成模型上。</p><p>重放模型（编码器、解码器和解码器超网络）是一个独立的子系统，独立于目标网络进行优化。它的参数 $Θ<em>{enc}$和$Θ</em>{h,dec}$是通过最小化我们的正则化损失函数（公式2）来学习的，这里的任务特定项被设置为标准的VAE目标函数：</p><script type="math/tex; mode=display">L_{VAE}(X,\theta_{enc},\theta_{h,dec}) = L_{rec}(X,\theta_{enc},\theta_{dec}) + L_{prior}(X,\theta_{enc},\theta_{dec})</script><p>$Θ<em>{dec} = f</em>{h,dec}(e, Θ<em>{h,dec})$引入对 $Θ</em>{h,dec}$的依赖。$L<em>{VAE}$平衡了一个重建 $L</em>{rec}$和一个先验匹配 $L_{prior}$的惩罚。对于我们的MNIST实验，我们选择二进制交叉熵（在像素空间）作为重建损失，我们在下面写出一个单一的例子 x</p><script type="math/tex; mode=display">L_{rec} (x,\theta_{enc},\theta_{dec}) = L_{xent}(x,f_{dec}(z, 1_{t(x)}, \theta_{dec}))</script><p>其中$L<em>{xent}(t,y) = - \sum</em>{k}t_klogy_k$是交叉熵，对于一个对于对角线高斯 $p_Z$，先验匹配项可以用分析法评估:</p><script type="math/tex; mode=display">L_{prior} = -\frac{1}{2}\sum_{i=1}^{|z|}(1+log\sigma^2_i-\sigma_i^2-\mu_i^2)</script><p>以上，$z$ 是通过重新参数化技巧获得的 $p<em>Z（z;μ(\hat x),σ^2(\hat x))$的样本（Kingma &amp; Welling，2014；Rezende等人，2014）。这就引入了 $L</em>{rec}$对 $Θ_{enc}$的依赖性。</p><h3 id="Task-inference-network-HNET-TIR"><a href="#Task-inference-network-HNET-TIR" class="headerlink" title="Task inference network (HNET+TIR)."></a>Task inference network (HNET+TIR).</h3><p>在HNET+TIR设置中，我们将我们的系统扩展到包括一个任务推理神经网络分类器 $α(x)$，参数为 $Θ_{TI}$，其中任务被编码为一个T-维softmax输出层。在CL2和CL3场景中，我们对 $α$ 使用了一个不断增长的单头设置，并随着任务的到来增加softmax层的维度。</p><p>当任务不断被学习时，这个网络很容易出现灾难性的遗忘。为了防止这种情况的发生，我们借助于上述由超网络保护的VAE产生的重放数据。更具体地说，我们引入了一个任务推理损失。</p><script type="math/tex; mode=display">L_{TI} (\hat x,\theta_{TI}) = L_{xent} (1_{t(\hat x)}, \alpha(\hat x,\theta_{enc}))</script><p>其中 $t(\hat x)$表示从增强的数据集 $\hat X= {\hat X^{(1)},…,\hat X^{(T-1)},\hat X^{(t)}}$,  其中 $\hat X^{(t)}$  是 $t=1…T-1$ 的合成数据$f<em>dec(z,1_t,Θ</em>{dec})$，而 $\hat X^{(T)}= X^{(T )}$是当前任务数据。重要的是，合成数据对于获得任务推理的定义明确的目标函数至关重要；交叉熵损失$L_{TI}$至少需要两个groundtruth类来进行优化。请注意，重放的数据可以通过从先验中抽取样本 $z$ 来在线生成。</p><p><img src="https://s2.loli.net/2022/01/04/SqdsY5u42WpNBUr.png" alt=""></p><p>图A1：超网络保护的重放模型设置。(a) 一个超网络保护的VAE，我们用于HNET+R和HNET+TIR正文实验。(b) 一个超网络保护的GAN，我们用于类增量学习附录F的实验。(c) 一个用合成重放数据保护的任务推理分类器，用于HNET+TIR的实验。</p><h3 id="Hypernetwork-protected-GANs"><a href="#Hypernetwork-protected-GANs" class="headerlink" title="Hypernetwork-protected GANs"></a>Hypernetwork-protected GANs</h3><p>生成对抗网络（Goodfellow等人，2014年）已经成为生成建模的既定方法，与VAE相比，往往能产生更高质量的图像，即使是在ImageNet这样复杂的数据集规模下（Brock等人，2019年；Lucˇić等人，2019年；Donahue &amp; Simonyan，2019年）。这使得GAN成为强大重放模型的完美候选者。Wu等人（2018）研究的条件GAN（Mirza &amp; Osindero，2014）是CL的一个合适的GAN实例。GAN文献的最新发展已经暗示了使用类似超网络结构的潜力，例如，在注入潜伏噪声时（Karras等人，2019年）或使用类条件批量规范化时，如（Brock等人，2019年）。我们建议更进一步，使用一个超网络，将条件映射到生成器参数的完整集合 $Θ^∗_{gen}$。我们的框架允许一次训练一个条件性的GAN。这可能具有普遍意义，并超出了重放模型的范围，因为像Brock等人（2019）那样以多任务方式训练的条件GAN需要非常大的计算资源。</p><p>对于我们关于类增量MNIST学习的展示实验，图A8，我们的目的不是与相关工作进行比较，因此没有调整超网络中的权重比目标网络中的权重少（对于VAE实验，我们使用与正文中相同的压缩设置，见附录C）。GAN超网络是一个全连接的分块超网络，有2个大小为25和25的隐藏层，然后是75000的输出大小。我们对鉴别器和生成器超网络的学习率都是0.0001，鉴别器的辍学率也是0.4，系统对每个任务进行了10000次迭代训练。我们在实验中使用Mao等人（2017）的Pearson Chi2 Least-Squares GAN损失。</p><h2 id="ADDITIONAL-EXPERIMENTAL-DETAILS"><a href="#ADDITIONAL-EXPERIMENTAL-DETAILS" class="headerlink" title="ADDITIONAL EXPERIMENTAL DETAILS"></a>ADDITIONAL EXPERIMENTAL DETAILS</h2><p>所有的实验都是使用16个NVIDIA GeForce RTX 2080 TI显卡进行的。</p><p>为了简单起见，我们决定始终保持以前的任务嵌入 $e^{(t)}$ , $t = 1, . . . , T - 1$，固定不变，只学习当前的任务嵌入 $e^{(T)}$。一般来说，如果公式2中的正则器有一份学习当前任务之前的任务嵌入 $e^{(t,∗)}$的单独副本，这样 $e^{(t)}$就可以被适应，性能就应该得到提高。因此，目标成为 $f_h(e^{(t,∗)},Θ^∗_h)$ 并保持不变。同时学习任务T。这将使超网络具有调整嵌入的灵活性，即目标的预像，因此代表了任何包括其图像中所有期望目标的函数。</p><p>HNET+TIR的VAE的细节。对于这个变异自动编码器，我们使用两个全连接的神经网络，编码器的层数为1000，1000，解码器为1000，潜伏空间为100。这个设置也是从我们比较的工作中复制过来的。</p><p>HNET+R的VAE的细节。对于这个变异自动编码器，我们使用两个全连接的神经网络，编码器的层数为400，400，解码器的层数为400，400（在相关工作中都是1000，1000），潜空间的维度为100。这里，我们与相关工作不同，为自动编码器选择了一个较小的架构。请注意，我们仍然使用一个超网络，其可训练的参数比相关工作中使用的目标网络（在这种情况下是解码器）少。</p><p>PermutedMNIST-10中目标分类器的超网络细节（HNET+TIR &amp; HNET+ENT）。我们使用与上述VAE相同的超网络设置，但由于目标网络较小，我们将超网络的输出减少到78,000。我们还将参数βoutput调整为0.01，与我们的PermutedMNIST-100实验一致。因此，这个超网络的权重数量是2,029,931个参数（2,029,691个网络权重+240个任务嵌入权重）。相应的目标网络（来自相关工作）将有2,126,100个权重用于CL1和CL3，2,036,010用于CL2（只有一个输出头）。</p><p>PermutedMNIST-100的目标分类器的超网络细节。在这些实验中，我们选择了一个在PermutedMNIST-10基准上运行良好的架构，没有再进行新架构的搜索。对于PermutedMNIST-100，报告的结果是通过使用一个分块超网络获得的，该网络有3个隐藏层，大小为200、250和350（CL2为300），输出大小为7500（CL2为6000）（这样，我们大约与CL1/CL2/CL3的相应目标网络大小一致）。有趣的是，图A2b显示，即使我们不根据目标网络权重的增加来调整超网络权重的数量，我们方法的优越性也是显而易见的。除此之外，图3中的图是用PermutedMNIST-10 HNET+TIR设置生成的（注意，这包括相关工作为PermutedMNIST-10设定的条件，如目标网络大小、训练迭代次数、学习率等）。</p><p>PermutedMNIST-100中用于CL2/CL3的VAE和超网络的细节。我们对VAE和它在HNET+TIR中用于PermutedMNIST-10的超网络使用了非常类似的设置，如上所述。我们只做了以下改动。全连接超网络有一个大小为100的隐藏层；块嵌入大小被设置为12；任务嵌入大小被设置为两个128，VAE的隐藏层大小为400，600。同时，我们增加了VAE其生成器超网络的正则化强度βoutput=0.1。</p><p>HNET+TIR和HNET+ENT的目标分类器的细节。对于这个分类器，我们使用与我们比较的研究（van de Ven &amp; Tolias, 2019）相同的设置，即一个全连接的网络，层的大小为1000，1000。请注意，如果该分类器被用作任务推理模型，它是在重放数据和相应的硬目标，即软目标的argmax上训练的。</p><h1 id="Continual-Model-Based-Reinforcement-Learning-with-Hypernetworks"><a href="#Continual-Model-Based-Reinforcement-Learning-with-Hypernetworks" class="headerlink" title="Continual Model-Based Reinforcement Learning with Hypernetworks"></a>Continual Model-Based Reinforcement Learning with Hypernetworks</h1><p>使用超网络的任务意识持续学习是一种有效和实用的方法，可以适应新的任务和不断变化的动态，用于基于模型的强化学习，而不需要保留旧任务的状态转换，也不需要向动态模型增加容量。</p><h2 id="Hypernetworks-for-Continual-Learning"><a href="#Hypernetworks-for-Continual-Learning" class="headerlink" title="Hypernetworks for Continual Learning."></a>Hypernetworks for Continual Learning.</h2><p>超网络[35], [36]是一个生成另一个神经网络的权重的网络。具有权重 $Θ$ 的超网络 $H<em>Θ(e)=θ$ 可以以嵌入向量 $e$ 为条件，通过改变嵌入向量 $e$ 来输出主（目标）网络的权重 $θ$ ，$f</em>θ(x) = f(x; θ) = f(x; H_Θ(e))$。</p><p>与主网络相比，超网络的可训练参数数量通常更大，因为超网络中输出层的大小等于目标网络中权重的数量。</p><p>超网络已被证明在持续学习环境下[1]对分类和生成模型很有用。这已被证明可以缓解一些灾难性遗忘的问题。它们也被用来实现基于梯度的超参数优化[37]。</p><p>我们考虑MBRL的求解设置，它有一个学习的动力学模型，<strong>其参数是通过一个任务条件超网络推断出来的</strong>。考虑到学习到的任务嵌入 $e<em>t$ 和超网络 $H(-)$ 的参数 $Θ_t$，我们推断出动态神经网络 $f</em>{θ_t}(-)$的参数 $θ_t$。利用这个动力学模型，我们进行CEM优化，生成动作序列，并在环境中用MPC执行K个时间步长。我们将观察到的过渡存储在重放数据集中，并更新超网络的参数 $Θ_t$ 和任务嵌入等（非政策性优化）。我们对每个任务的 $M$ 个插曲，以及每 $T$ 个任务的顺序重复这一过程。</p><p>动态学习。学习的动力学模型是一个前馈神经网络，其参数在不同的任务中是不同的。在不同的任务中学习动力学网络$f<em>θ(-)$的一种方法是随着训练的进行按顺序更新它。然而，由于我们的问题设置是不允许代理人在重放缓冲器中保留以前任务的状态转换数据，因此在不同任务中按顺序调整单个网络的权重可能会导致灾难性的遗忘[1]。为了减轻灾难性遗忘的问题，**同时试图适应网络的权重，我们学习一个超网络，将任务嵌入作为输入，并输出每个任务对应的动态网络的参数，为每个任务t学习不同的动态网络 $f</em>{θ_t}（-）$。**</p><p>我们假设代理人有有限的内存，并且不能访问跨任务的状态转换数据。因此，在每个任务 $t$ 开始时，特定任务的重放缓冲器 $D<em>t$ 被重置。对于当前的情节，代理人使用 $θ_t=H</em>{Θ<em>t}（e_t）$生成一个动力学网络 $f</em>{θ<em>t}$。然后，对于 $k=1…K$个时间段和规划期限 $h$，代理人使用CEM优化行动序列 $a</em>{k：k+h}$，并执行第一个行动 $a<em>k$（MPC）。$D_t$被一个元组（$s_k$,$a_k$, $s</em>{k+1}$）所增强，其中 $s<em>k$ 是当前状态，$a_k$是已执行的行动，$s</em>{k+1}$是任务t下的下一个观察状态。</p><p>超网络的参数 $Θ<em>t$ 和任务嵌入 $e_t$ 通过反向传播梯度更新，涉及动态损失 $L</em>{dyn}$和正则化项之和。</p><p>我们定义了动态损失 $L<em>{dyn}(\theta_t, e_t) = \sum</em>{D<em>t}||\hat s</em>{k+1} - s<em>{k+1}||_2$ , 预测的下一状态在哪里 $\hat s</em>{k+1} = f<em>{\theta_t}(s_k, a_k)$ 和 $\theta_t = H</em>{\theta_t}(e_t)$</p><p>$\hat s<em>{k+1}=f</em>{\theta<em>t}(s_k,a_k)$ 和 $\theta_t = H</em>{\theta_t}(e_t)$</p><p>超网络的规范化:</p><p>为了减轻灾难性的遗忘，我们对超网络的输出进行正则化，即所有以前的任务嵌入 $e<em>{1:t-1}$。在对任务 $t-1$进行训练后，超网络权重的快照被保存为 $Θ</em>{t-1}$。</p><p>对于每个过去的任务 $i = 1…t - 1$，我们使用正则化损失来保持快照 $H<em>{Θ_t} (e_i)$的输出接近当前输出 $H</em>{Θ<em>t} (e_i)$。这种方法避开了存储所有过去任务数据的需要，保留了动态网络 $f</em>{θ<em>t}$的预测性能，并且只需要存储权重空间中的一个点（超网络的副本）。任务嵌入是与超网络的参数一起学习的可微分向量。更新 $Θ_t$和 $e_t$ 的总体损失函数由动态损失 $L</em>{dyn}(-)$和正则化项$L_{reg}(-)$组成，动态损失是根据任务 $t$ 收集的数据评估的:</p><script type="math/tex; mode=display">L_t(\theta_t, e_t) = L_{dyn}(\theta_t, e_t) + L_{reg}(\theta_{t-1}, \theta_t, e_{1:t-1})</script><script type="math/tex; mode=display">L_{reg}(\cdot) = \frac{\beta_{reg}}{t-1}\sum_{i=1}^{t-1}||H_{\theta_{t-1}}(e_i) - H_{\theta_t}(e_i)||_2^2</script><p>CEM优化行动序列的计划目标是由在学习到的任务动力学模型 $f<em>{θ_t}(-)$下执行行动序列 $a</em>{k:k+h}$得到的奖励之和给出的。奖励函数 $r(s,a)$ 被假定为已知的，但在我们目前的框架下，没有什么可以排除从数据中学习它。</p><h1 id="Hypernetworks-for-Continual-Semi-Supervised-Learning"><a href="#Hypernetworks-for-Continual-Semi-Supervised-Learning" class="headerlink" title="Hypernetworks for Continual Semi-Supervised Learning"></a>Hypernetworks for Continual Semi-Supervised Learning</h1><p>从顺序到达的数据中学习，可能在非 i.i.d. 方式，随着时间的推移不断变化的任务分配被称为持续学习。 迄今为止，持续学习的大部分工作都集中在监督学习上，而最近的一些工作则集中在无监督学习上。</p><p>在许多领域，每个任务都包含标记（通常很少）和未标记（通常很多）的训练示例，这需要半监督学习方法。 为了在持续学习环境中解决这个问题，我们提出了一个半监督持续学习的框架，称为持续半监督学习的元合并 (MCSSL)。</p><p>我们的框架有一个超网络，它学习生成作为基础网络的半监督辅助分类器生成对抗网络（Semi-ACGAN）的权重的元分布。 <strong>我们在超网络中巩固序列任务的知识</strong>，基础网络学习半监督学习任务。 此外，我们提出了 Semi-Split CIFAR-10，这是一个用于持续半监督学习的新基准，通过修改 Split CIFAR-10 数据集获得，其中带有标记和未标记数据的任务按顺序到达。 我们提出的模型在持续的半监督学习环境中产生了显着的改进。 我们比较了几种现有的持续学习方法在 Semi-Split CIFAR-10 数据集提出的持续半监督学习基准上的性能。</p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>人类拥有非凡的持续学习能力，即使在顺序设置中也是如此。 在机器学习中，从可能以非 i.i.d. 连续到达的数据中学习。 使任务随时间变化的方式称为持续学习、终身学习或增量学习。 人类学习的另一个突出方面是人类并不总是需要对对象的概念进行监督，他们可以通过对相似的事物进行分组来学习。 相比之下，神经网络在以顺序方式学习新任务时表现出忘记先前获得的知识的趋势 [Kirkpatrick et al., 2017]，这通常被称为灾难性遗忘。</p><p>随着数据的日益多样化，缺乏标记数据是监督机器学习模型面临的一个普遍问题。 然而，未标记的数据很丰富，并且很容易用于训练机器学习模型。 在标准（非连续）环境中，存在几种无监督学习方法，它们可以在没有监督的情况下基于某种相似性概念进行学习。 然而，半监督学习模型可以利用标记和未标记的数据，从而实现两全其美。</p><p>大多数现有的持续学习方法都集中在监督分类设置上。 最近的一些工作探索了持续的无监督学习设置 [Lee et al., 2019; Rao et al., 2019] 专注于图像生成任务的生成模型。</p><p>然而，这些方法中的大多数都没有研究半监督的持续学习设置。 [Smith et al., 2021] 最近的一项工作探索了连续半监督设置，但他们的设置使用了 CIFAR 数据集的超类结构，因此，顺序到达的任务与我们的设置不同 . 此外，他们的方法使用判别分类器，而我们的方法使用生成模型，因为模型学习输入的分布。</p><p>因此，我们研究了一种用于连续半监督学习的新设置，其中连续学习器遇到带有标记和未标记数据的顺序到达任务。 与标准的半监督学习设置类似，未标记数据和标记数据在每个学习任务中具有内在相关性，使学习者能够利用标记数据和未标记数据。</p><p>大多数持续学习方法通过在权重（或参数）空间或数据空间中巩固知识来对抗灾难性遗忘。 根据对人脑的研究，语义知识或解决任务的能力表示在高级语义概念的元空间中。</p><p>此外，<strong>记忆会定期巩固，帮助人类持续学习 受此启发，[Joseph and Balasubramanian, 2020] 最近的工作提出了一个框架，即持续学习的元巩固 (MERLIN)，它巩固了持续任务的知识 在元空间中，即权重生成网络的参数空间</strong>。 这个权重生成网络称为超网络，它生成基础网络的参数。 这样一个基础网络负责解决特定的不断到达的下游任务。 <strong>我们在 [Joseph and Balasubramanian, 2020] 中使用具有特定任务先验的变分自动编码器 (VAE) 模型对超网络进行建模。</strong> 然而，他们只关注监督学习设置。 因此，基础网络是判别神经网络，例如前馈神经网络或改进的残差网络 (ResNet-18)。</p><p>在本文中，我们提出了 MCSSL: Meta-Consolidation for Continual Semi-Supervised Learning，这是一个源自 MERLIN [Joseph and Balasubramanian, 2020] 的框架，其中持续学习发生在权重生成过程的潜在空间中，即 ，在超网络的参数空间中。 然而，[Joseph and Balasubramanian, 2020] 使用判别分类器 (ResNets) 作为基础网络，因此他们只关注持续监督设置。与 [Joseph and Balasubramanian, 2020] 相比，我们的模型使用改进形式的辅助分类器生成对抗网络 (ACGAN) [Odena et al., 2017] 作为基础网络来执行持续的半监督学习。 GAN 中的辅助分类器提供了使用标记数据学习分类的能力。 受 [Salimans et al., 2016] 的启发，我们修改了 ACGAN 中的判别器来处理未标记的数据，我们称之为 Semi-ACGAN。 这导致在 Semi-ACGAN 训练目标中具有监督和非监督组件。 因此，类 VAE 的超网络学习生成 Semi-ACGAN 基础网络的参数，该基础网络执行半监督分类的下游任务。</p><h2 id="MCSSL-Meta-Consolidation-for-Continual-Semi-Supervised-Learning"><a href="#MCSSL-Meta-Consolidation-for-Continual-Semi-Supervised-Learning" class="headerlink" title="MCSSL: Meta-Consolidation for Continual Semi-Supervised Learning"></a>MCSSL: Meta-Consolidation for Continual Semi-Supervised Learning</h2><p>本节从持续半监督学习的问题设置开始。 在此之后，我们介绍了我们提出的框架的概述。 然后，我们将 Semi-ACGAN 描述为基本模型和 Semi-ACGAN 的训练机制。 此外，我们提供了学习特定任务参数分布的超网络 VAE 的详细信息。 此外，我们描述了超网络元整合的细节，然后是推理机制。</p><h3 id="Problem-Set-up-and-Notation"><a href="#Problem-Set-up-and-Notation" class="headerlink" title="Problem Set-up and Notation"></a>Problem Set-up and Notation</h3><p>持续半监督学习的问题涉及从顺序到达的半监督任务中学习，因为任务的数据仅在前一个任务完成后到达。 令 $T_1、T_2、···、T_K$ 为半监督任务序列，使得 $T_k$ 为时间实例 k 处的任务。</p><p>此外，对于 $j ∈{1,····,K}$，每个任务 $T$ 由 $T^{tr}_j$、$T^{val}_j$ 和 $T^{test}_j$ 组成，分别对应于任务 $j$ 的训练集、验证集和测试集。此外，我们定义</p><script type="math/tex; mode=display">T^{tr} = [\{x_m,y_m\}^{M^j_{tr}}_{m=1}, \{u_n\}^{N_{tr}^j}_{n=1}]</script><h3 id="Model-Overview"><a href="#Model-Overview" class="headerlink" title="Model Overview"></a>Model Overview</h3><p>在我们提出的框架中，<strong>超网络是一个类似于 VAE 的模型，具有特定于任务的条件先验，它对基础网络的参数分布进行建模。</strong> 对于每个任务，基础网络的多个实例使用标记和未标记的训练数据来学习下游半监督任务。 <strong>我们使用这些训练过的基础模型的权重作为训练超网络的输入。</strong> <strong>因此，超网络学习为基础网络生成任务特定的权重，最终执行连续的半监督任务。 此外，元整合使超网络能够整合来自先前任务的知识。</strong> 此外，在训练之后，在预测或推理期间对基础网络的权重进行采样和集成。</p><h3 id="Base-Model-Semi-ACGAN"><a href="#Base-Model-Semi-ACGAN" class="headerlink" title="Base Model: Semi-ACGAN"></a>Base Model: Semi-ACGAN</h3><p><img src="https://s4.ax1x.com/2022/01/21/7RzXy4.png" alt=""></p><p>基础网络是一个改进的辅助分类器 GAN (Semi-ACGAN)，因此由一个生成器 G、一个带有辅助分类器的鉴别器 D 组成。 我们使用 $Θ_k$ 表示任务 k 的基础网络的权重。</p><p>在 Semi-ACGAN 中，G 以类标签 y 和噪声 $z<em>b$ 为条件。 因此，生成的样本 $x</em>{fake} = G(z_b,y)$ 对应于一个类标签。让 s 表示样本 x 的来源是真实的还是虚假的。 对于样本 x，判别器给出源 $p(s|x)$ 上的概率分布以及类 $p(y|x)$ 上的概率分布，即 $[p(s|x), p(y| x)] = D(x)$。</p><p>让我们用 $x_{real}$ 表示真实样本，用 $\hat y$ 表示样本的实际类别。 训练目标包括以下内容：</p><ul><li><p>对于标记数据：</p></li><li><ul><li><p>a.记录正确来源的可能性，</p></li><li><script type="math/tex; mode=display">L_s^{L} = E[\log p(s=real|x_{real})] +E[\log p(s=fake|x_{fake})]</script></li><li><p>b.记录正确类别的可能性，</p></li><li><script type="math/tex; mode=display">L_c^L=E[\log p(y=\hat y|x_{real})] + E[\log p(y=\hat y|x_{fake})]</script></li></ul></li><li><p>对于无标注数据：</p></li><li><ul><li><p>a. 记录真实图像正确来源的可能性，</p></li><li><script type="math/tex; mode=display">L_s^{U} = E[\log p(s=real|x_{real})]</script></li></ul></li></ul><p>鉴别器 D 通过最大化 $L^L_c + L^L_s + L^U_s$ 来学习，而生成器 G 通过最大化 $L^L_c - L^L_s$ 来学习。</p><p>请注意，由于缺少未标记数据的类别信息，因此我们不考虑未标记数据情况下正确类别的对数似然。</p><p>生成器 G 是一个接受类标签和噪声的神经网络。 类标签嵌入是使用可训练的类嵌入层从类 id 获得的。 因此，G 学习生成特定类别的样本。</p><p>D 的共享层可以从标记数据和未标记数据中学习。 随着训练的进行，G 学习生成具有已知类标签的真实样本，使 D 能够进行更好的分类。</p><p>图 1 显示了基础网络 Semi-ACGAN 的模块。 由于真实样本可以由标记数据和未标记数据组成，图中分别使用绿色和蓝色箭头显示。 另一方面，红色箭头描绘了生成的样本。 此外，输出以类似的颜色编码。</p><h3 id="Task-specific-Parameter-Distribution-Hypernetwork"><a href="#Task-specific-Parameter-Distribution-Hypernetwork" class="headerlink" title="Task-specific Parameter Distribution: Hypernetwork"></a>Task-specific Parameter Distribution: Hypernetwork</h3><p>由于训练过的基础网络的 B 个实例被用作训练超网络的输入，我们使用 ${Θ^l<em>k}^B</em>{l=1}$ 来表示任务 k 的这个集合。 由于使用具有特定任务条件先验的 VAE 类模型作为超网络，我们将超网络的参数定义为 $[θ, φ]$，使得 $θ$ 和 $φ$ 分别是超网络的编码器和解码器参数 .</p><p>超网络 VAE 对特定于任务的参数分布 $p(Θ|t)$ 进行建模。 因此，学习超网络可以整合元空间中先前任务的知识。 第 k 个任务的向量表示 $t_j$ 可以是任何固定长度的向量表示，包括 Word2Vec [Mikolov et al., 2013]、GloVe [Pennington et al., 2014] 或只是任务标识的 one-hot 编码。 为简洁起见，我们在本小节中使用 $t$ 来表示 $t_j$。</p><p>受 MERLIN [Joseph and Balasubramanian, 2020] 的启发，超网络通过优化类似 VAE 的目标 [Kingma and Welling, 2013] 进行训练。</p><p>参数分布 $p<em>θ (Θ|t) = \int p</em>θ (Θ|z, t)p<em>θ (z|t)dz$ 的边际似然的计算是难以处理的，因为其真实后验 $p</em>{\theta}(z|Θ,t)=\frac{p<em>{\theta}(Θ|z,t) p</em>{\theta}(z|t)}{p_{\theta}(Θ|t)}$ 的计算难以处理。</p><p>因此，我们引入了一个近似变分后验 $q_\phi(z|Θ,t)$ 来解决难以处理的问题。 对数边际似然可以写成：</p><script type="math/tex; mode=display">p_{\theta}(Θ|t) = KL(q_{\phi}(z|Θ,t) || p_{\theta}(z|Θ,t) + L(\theta,\phi|Θ,t)</script><p>其中 $L(\theta,\phi|\theta,t) = \int<em>z q</em>{\phi}(z|Θ,t)\log \frac{p<em>{\theta(z,Θ|t)}}{q</em>{\phi}(z|Θ,t)}$ 是证据下限 (ELBO)。 为了最大化对数似然，可以最大化这个下限。</p><p>此外，$L(θ, φ|Θ, t)$ 可以表示为（完整推导参见[Joseph and Balasubramanian, 2020]）：</p><script type="math/tex; mode=display">L(θ, φ|Θ, t) = -KL(q_{\phi}(z|Θ,t) || p_{\theta}(z|t) + E_{q_{\phi(z|Θ,t)}}[\log p_{\theta}(Θ|z,t)])</script><p>最大化上面方程，最小化 KL 散度项，导致近似后验权重变得接近于特定任务的先验 $p_θ(z|t)$。 第二项是预期的负重构误差，它需要抽样来估计。</p><p>超网络参数 φ 和 θ，也称为编码器和解码器参数，使用反向传播和随机梯度下降进行训练。 我们假设 $p<em>θ (.)$ 和 $q</em>φ (.)$ 是高斯分布。此外，重新参数化技巧 [Kingma and Welling, 2013] 用于通过随机参数进行反向传播。 以 ${Θ^l<em>k}^B</em>{l=1}$ 作为输入，我们通过最大化 上式 来训练超网络。 </p><p>与标准 VAE 不同，特定于任务的先验不是各向同性的多元高斯。 它由以下给出：</p><script type="math/tex; mode=display">p_{\theta}(z|t) = N(z|\mu_t,\Epsilon_t)</script><p>其中 $\mu<em>t = W^T</em>{\mu} t$ 和 $\Epsilon<em>t = W^T</em>{\Epsilon}t$ 这样 $W<em>μ$ 和 $W</em>Σ$ 是可训练的参数，并与超网络参数一起学习。</p><h3 id="Meta-Consolidation"><a href="#Meta-Consolidation" class="headerlink" title="Meta-Consolidation"></a>Meta-Consolidation</h3><p>直接在 ${Θ^l<em>k}^B</em>{l=1}$ 上训练 VAE 会导致分布偏移，即偏向当前任务 $k$。 因此，超网络 VAE 需要巩固来自先前任务的知识。我们称之为元整合。 我们存储所有学习到的特定于任务的先验的均值和协方差，这增加了可以忽略不计的存储复杂性。 元整合机制描述如下：</p><p>1.对于直到当前任务 $k (j=1,…,k) $的每个任务 $z_{t_j}$，</p><ul><li><p>(a) 来自特定任务的先验样本 $z_{t_j }$：</p><script type="math/tex; mode=display">z_{t_j} \sim N(z|\mu_{t_j}, \Epsilon_{t_j})</script></li><li><p>(b) 从解码器中采样 P 个半监督基础伪模型：</p><script type="math/tex; mode=display">Θ_j^i \sim p_{\theta}(Θ|z_{t_j}, t_j); \ where \ \ i\in\{1,2,...,P\}</script></li><li><p>(c)使用公式5计算损失：</p><script type="math/tex; mode=display">Loss = \sum_{i=1}^P L(Θ,\phi|Θ^i_j,t_j)</script></li><li><p>(d)优化 Loss 以更新参数φ，θ</p></li></ul><h3 id="Inference"><a href="#Inference" class="headerlink" title="Inference"></a>Inference</h3><p>学习特定于任务的参数分布 $p_θ(Θ|z,t)$ 可以在推理过程中对多个 $Θ$ 进行采样。 这种能力提供了多个模型的集成效果，而无需先验地存储模型。 与大多数其他持续学习方法一样，我们在推理过程中使用一个小的示例内存缓冲区 $\epsilon$ 进行微调。</p><p>我们的方法可以在推理过程中使用或不使用特定于任务的信息。 然而，我们专注于与任务无关的设置，因为它更加现实和具有挑战性。 任务无关推理的推理过程如下所述：</p><h1 id="HYPERMODELS-FOR-EXPLORATION"><a href="#HYPERMODELS-FOR-EXPLORATION" class="headerlink" title="HYPERMODELS FOR EXPLORATION"></a>HYPERMODELS FOR EXPLORATION</h1><p>我们考虑由参数空间 $θ$ 的元素 $θ$ 参数化的基本模型。 给定 $θ$ ∈ $Θ$ 和输入 $X<em>t ∈ R^{N_x}$ ，基本模型假设输出 $Y</em>{t+1} ∈ R$ 的条件期望由 $E[Y<em>{t+1}|X_t,θ] = f</em>θ(X_t)$ 给出，对于某些函数 f 由 θ 索引。 图 1a 描述了这类参数化基础模型。</p><p>超模型由参数 ν 参数化，参数 ν 标识函数 $g_ν : Z 􏰝→ Θ$。我们将每个 z ∈ Z 称为索引，因为它标识了基本模型的特定实例。 特别是，给定超模型参数 ν，可以通过选择 z ∈ Z 并设置 θ = gν (z) 来生成基本模型参数 θ。</p><p>这种超模型的概念如图 1b 所示。 与超模型一起，为了表示基础模型上的分布，我们必须指定一个参考分布 $p_z$，它可用于对 Z 的元素进行采样。超模型和参考分布通过提供一种机制共同表示基础模型上的分布 通过对索引进行采样并通过映射对其进行采样。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;[TOC]&lt;/p&gt;
&lt;h1 id=&quot;Continual-Learning-with-Hypernetworks&quot;&gt;&lt;a href=&quot;#Continual-Learning-with-Hypernetworks&quot; class=&quot;headerlink&quot; title=&quot;Conti</summary>
      
    
    
    
    
    <category term="context detection" scheme="http://example.com/tags/context-detection/"/>
    
  </entry>
  
  <entry>
    <title>PromptBERT: Improving BERT Sentence Embeddings with Prompts</title>
    <link href="http://example.com/2021/12/02/PromptBERT-Improving-BERT-Sentence-Embeddings-with-Prompts/"/>
    <id>http://example.com/2021/12/02/PromptBERT-Improving-BERT-Sentence-Embeddings-with-Prompts/</id>
    <published>2021-12-02T12:31:29.000Z</published>
    <updated>2021-12-21T07:07:19.885Z</updated>
    
    <content type="html"><![CDATA[<h1 id="PromptBERT-Improving-BERT-Sentence-Embeddings-with-Prompts"><a href="#PromptBERT-Improving-BERT-Sentence-Embeddings-with-Prompts" class="headerlink" title="PromptBERT: Improving BERT Sentence Embeddings with Prompts"></a>PromptBERT: Improving BERT Sentence Embeddings with Prompts</h1><p>在以前的工作中，原始的BERT在句子语义相似性方面的表现不佳，已经被广泛讨论。我们发现，不尽如人意的表现主要是由于静态 token 嵌入的偏差和无效的 BERT 层，而不是因为句子嵌入的高余弦相似度。</p><p>为此，我们提出了一种 prompt based 的句子嵌入方法，它可以减少 token 嵌入的偏差，使原来的BERT层更加有效。通过将句子嵌入任务重新表述为填空问题，我们的方法显著提高了原始BERT的性能。我们讨论了 prompt based 的句子嵌入的两种 prompt 表示方法和三种 prompt 搜索方法</p><p>此外，我们通过模板去噪技术提出了一个新的无监督训练目标，这大大缩短了有监督和无监督设置之间的性能差距。</p><p>在实验中，我们对我们的方法在非微调和微调的设置上进行评估。即使是一个非微调的方法，也可以在STS任务上超过微调的方法，如无监督的ConSERT。我们的微调方法在无监督和有监督的情况下都优于最先进的方法SimCSE。与SimCSE相比，在无监督设置下，我们在BERT和RoBERTa上分别取得了2.29和2.58分的改进。</p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>以前的研究将各向异性与解释原始BERT的不良性能联系起来（Li等人，2020；Yan等人，2021；Gao等人，2021）。各向异性使得 token 嵌入占据一个狭窄的锥体，导致任何句子对之间的高相似度 </p><p>Li 等人（2020）提出了一种归一化 flows 方法，将句子嵌入分布转化为平滑和各向同性的高斯分布，Yan等人（2021）提出了一个对比性框架来迁移句子表示。这些方法的目标是消除句子嵌入中的各向异性。然而，我们发现，各向异性并不是导致语义相似性差的主要原因。例如，在语义文本相似性任务中，对原始BERT的最后一层进行平均，甚至比对其静态token 嵌入进行平均更差，但最后一层的句子嵌入比静态 token 嵌入的各向异性要小。</p><p>根据这一结果，我们发现原始的 BERT层 实际上损害了句子嵌入的质量。然而，如果我们将静态 token 嵌入视为单词嵌入，与GloVe相比，它产生的结果仍然不能令人满意。受（Li等人，2020）的启发，他们发现 token 频率偏向其分布，我们发现分布不仅偏向频率，还偏向WordPiece（Wu等人，2016）中的大小写和子词。 </p><p>我们设计了一个简单的实验来测试我们的猜想，只需去除这些有偏的token（如高频子词和标点符号），并使用剩余token嵌入的平均值作为句子表示。它可以超越Glove，甚至取得与后处理方法BERT-flow（Li等人，2020）和BERT-whitening（Su等人，2021）相当的结果。</p><p>在这些发现的激励下，避免嵌入偏差可以提高句子表述的性能。然而，手动消除嵌入偏差是很费力的，而且如果句子太短，可能会导致一些有意义的词被遗漏。</p><p>受(Brown et al., 2020)的启发，将不同的NLP任务通过不同的 prompt 重新表述为填空问题，我们提出了一种基于 prompt 的方法，使用模板来获得BERT中的句子表述。</p><p>Prompt based 的方法可以避免嵌入偏差并利用原始BERT层。我们发现原始的BERT在句子嵌入的模板帮助下可以达到合理的性能，它甚至超过了一些基于BERT的方法，这些方法在下游任务中对BERT进行了微调。</p><p>我们的方法同样适用于微调的设置。目前的方法利用对比学习来帮助BERT学习更好的句子嵌入（Gao等人，2021；Yan等人，2021）。然而，无监督的方法仍然存在泄漏适当积极对的问题。Yan等人（2021）讨论了四种数据增强方法，但其性能似乎比直接使用BERT中的 dropout 作为噪声要差（Gao等人，2021）。</p><p>我们发现 prompt 可以提供一个更好的方法，通过不同模板的不同观点来生成正数对。为此，我们提出了一种基于prompt的对比学习方法，该方法带有模板去噪功能，可以在无监督的情况下利用BERT的力量，这大大缩短了有监督和无监督性能之间的差距。我们的方法在无监督和有监督的情况下都取得了最先进的结果。</p><h2 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h2><p>学习句子嵌入作为一个基本的NLP问题已经被大量研究。目前，如何在句子嵌入中利用BERT的力量已经成为一个新的趋势。许多工作（Li等人，2020年；Gao等人，2021年）在有监督和无监督的情况下都用BERT取得了强大的性能。在这些工作中，基于对比学习的方法取得了最先进的成果。这些工作（Gao等人，2021；Yan等人，2021）注意构建积极的句子对。Gao等人（2021）提出了一个新颖的对比性训练目标，直接使用内部 dropout 作为噪声来构建正向句对。Yan等人（2021）讨论了四种构建积极句对的方法。</p><p>虽然BERT在句子嵌入方面取得了巨大的成功，但原始BERT的表现并不令人满意。原始BERT的上下文令牌嵌入甚至比GloVe等词嵌入的表现还差。一种解释是原始BERT中的各向异性，这导致句子对具有高相似性。根据这一解释，BERT-flow（Li等人，2020）和 BERT-whitening（Su等人，2021）已被提出，通过对原始BERT的句子嵌入进行后处理来减少各向异性。</p><h2 id="Rethinking-the-Sentence-Embeddings-of-Original-BERT"><a href="#Rethinking-the-Sentence-Embeddings-of-Original-BERT" class="headerlink" title="Rethinking the Sentence Embeddings of Original BERT"></a>Rethinking the Sentence Embeddings of Original BERT</h2><p>以前的工作（Yan等人，2021年；Gao等人，2021年）解释了原始BERT的不良性能是由学习的各向异性的 token 嵌入空间限制的，其中 token 嵌入占据一个狭窄的锥体。然而，我们通过研究各向异性和性能之间的关系发现，各向异性并不是诱发不良语义相似性的关键因素。我们认为主要原因是无效的BERT层和静态 token 嵌入偏差。</p><h3 id="Observation-1-Original-BERT-layers-fail-to-improve-the-performance"><a href="#Observation-1-Original-BERT-layers-fail-to-improve-the-performance" class="headerlink" title="Observation 1: Original BERT layers fail to improve the performance"></a>Observation 1: Original BERT layers fail to improve the performance</h3><p>在本节中，我们通过比较两种句子嵌入方法来分析 BERT 层的影响：平均静态 token 嵌入（BERT层的输入）和平均最后层（BERT层的输出）。我们报告了句子嵌入的性能和它的句子水平各向异性。</p><p>为了测量各向异性，我们遵循（Ethayarajh，2019）的工作，测量句子嵌入中的句子水平各向异性。让 $s_i$ 是出现在语料库${s_1, …, s_n }$ 中的一个句子。该各向异性可按以下方式测量:</p><script type="math/tex; mode=display">\frac{1}{n^2-n} |\sum_i\sum_{j\neq i} cos(M(s_i), M(s_j))|</script><p>其中 M 定义为表示语句嵌入方法，它将原始句子映射到其嵌入，cos是余弦相似度。换句话说，M的各向异性是通过一组句子的平均余弦相似度来衡量的。</p><p>如果句子嵌入是各向同性的（即方向均匀），那么均匀随机抽样的句子之间的平均余弦相似度将是0（Arora等人，2016）。它越接近于1，句子的各向异性就越大。我们从维基百科语料库中随机抽取100,000个句子来计算各向异性。</p><p>我们比较了不同的预训练模型（Bert-base-uncased、Bert-base-cased和Roberta-base）和不同的句子嵌入方法（最后一层平均法、最后一个隐藏层token作为句子嵌入和静态token嵌入的平均法、直接对静态token嵌入的平均法）。我们在表1中显示了这些方法的spearman相关性和句子水平各向异性。</p><p><img src="https://s2.loli.net/2021/12/20/mHGx3YdhwRoKCfM.png" alt=""></p><p>如表1所示，我们发现bert-base-uncased和roberta-base中的BERT层明显损害了句子嵌入性能。即使在bert-base-cased中，BERT层的增益也是微不足道的，只有0.28的改善。我们还展示了每种方法的句子层面的各向异性。BERT层的性能下降似乎与句子水平各向异性无关。例如，最后一层的平均值比bert-base-uncased中的静态标记嵌入平均值更加各向同性。然而，静态标记嵌入平均数实现了更好的句子嵌入性能。</p><h3 id="Observation-2-Embedding-biases-harms-the-sentence-embeddings-performance"><a href="#Observation-2-Embedding-biases-harms-the-sentence-embeddings-performance" class="headerlink" title="Observation 2: Embedding biases harms the sentence embeddings performance."></a>Observation 2: Embedding biases harms the sentence embeddings performance.</h3><p>Li等人（2020）发现，token嵌入会对 token 频率产生偏差。Yan等人（2021）也研究了类似的问题。BERT静态令牌嵌入的各向异性对令牌频率很敏感。因此，我们研究了嵌入偏差是否会产生不理想的句子嵌入性能。我们观察到，token嵌入不仅对token频率有偏见，而且对WordPiece（Wu等人，2016）中的子词和大小写敏感。</p><p>如图1所示，我们在bert-base-uncased、bert-base-cased 和 roberta-base 的token embeddings 中直观地看到这些偏差。三种预训练模型的 token 嵌入受到 token 频率、子词和大小写的高度偏向。根据子词和大小写的偏差，token 嵌入可以大致分为三个区域：1）小写的词首token，2）大写的词首token和3）子词token。对于无大小写的预训练模型bert-base-uncased，token嵌入也可以大致分为两个区域。1）词首token，2）子词token。</p><p>对于频率偏差，我们可以观察到，在所有的模型中，高频率的token是聚集的，而低频率的 token 是稀疏地分散的（Yan等人，2021）。在BERT中，词首 token 比子词token 更容易受到频率的影响。然而，在RoBERTa中，子词 token 更容易受到影响。</p><p>以前的工作（Yan等人，2021；Li等人，2020）经常将 “token嵌入偏见 “的概念与token嵌入各向异性作为偏见的原因。然而，我们认为各向异性与偏见无关。偏差意味着嵌入的分布被一些不相关的信息，如token频率所干扰，这可以根据PCA直接可视化。对于各向异性，它意味着整个嵌入在高维向量空间中占据了一个狭窄的锥体，这不能被直接可视化。</p><p><img src="https://s2.loli.net/2021/12/21/M2gTN4HvDZxEkdf.png" alt=""></p><p>表2显示了图1中三个预训练模型的静态token embeddings各向异性，根据任意两个token embeddings之间的平均余弦相似度计算。与之前的结论相反（Yan等人，2021；Li等人，2020），我们发现只有Bert-base-uncased的静态令牌嵌入是高度各向异性的。像roberta-base的静态 token 嵌入是各向同性的，平均余弦相似度为0.0235。对于偏差，这些模型受到静态标记嵌入中的偏差的影响，这与各向异性无关。</p><p><img src="https://s2.loli.net/2021/12/21/GlATLnuCBDia6ye.png" alt=""></p><p>为了证明偏见的负面影响，我们用平均的静态 token 嵌入作为句子嵌入（没有BERT层）来展示偏见对句子嵌入的影响。在表3中的三个预训练模型上，消除嵌入偏差的结果相当可观。仅仅去除一组token，结果就可以分别提高9.22、7.08和11.76。roberta-base的最终结果可以超过后处理方法，如BERT-flow（Li等人，2020）和BERT-whitening（Su等人，2021），只使用静态 token 嵌入。</p><p><img src="https://s2.loli.net/2021/12/21/9cTUVYF72pzC8XO.png" alt=""></p><p>手动消除嵌入偏差是提高句子嵌入性能的一个简单方法。但是，如果句子太短，这不是一个适当的解决方案，可能会导致一些有意义的词被遗漏。</p><h2 id="Prompt-Based-Sentence-Embeddings"><a href="#Prompt-Based-Sentence-Embeddings" class="headerlink" title="Prompt Based Sentence Embeddings"></a>Prompt Based Sentence Embeddings</h2><p>受（Brown等人，2020）的启发，我们提出了一种 基于提示的句子方法来获得句子嵌入。通过将句子嵌入任务重新表述为掩码语言任务，我们可以通过利用大规模的知识有效地使用原始BERT层。我们还通过从[MASK] token 表示句子来避免嵌入偏差。</p><p>然而，与文本分类或问题回答任务不同，句子嵌入中的输出不是MLM分类头预测的标签 token，而是表示句子的向量。我们按照这两个问题来讨论基于提示的句子嵌入的实现。1）如何用提示表示句子，以及2）如何为句子嵌入找到一个合适的提示。基于这些，我们提出了一种基于提示的对比学习方法来微调句子嵌入的BERT。</p><h3 id="Represent-Sentence-with-the-Prompt"><a href="#Represent-Sentence-with-the-Prompt" class="headerlink" title="Represent Sentence with the Prompt"></a>Represent Sentence with the Prompt</h3><p>在本节中，我们将讨论两种用提示语表示一个句子的方法。例如，我们有一个模板”[X]意味着[MASK]”，其中[X]是一个放置句子的占位符，[MASK]代表[MASK]token。给定一个句子 $x<em>{in}$，我们用模板将 $x</em>{in}$ 映射到 $x<em>{prompt}$。然后，我们将$x</em>{prompt}$送入一个预先训练好的模型，以生成句子表示 $h$。</p><p>一种方法是使用 $[MASK]$ token 的隐藏向量作为句子表示:</p><script type="math/tex; mode=display">h = h_{[MASK]}</script><p>对于第二种方法，就像其他基于提示的任务一样，我们根据 $h_{[MASK]}$ 和MLM分类头得到top-k tokens，然后根据概率分布找到这些tokens的加权平均值。$h$ 可以被表述为:</p><script type="math/tex; mode=display">h = \frac{\sum_{v\in V_{top-k}}W_v P([MASK] = v|h_{[MASK]})}{\sum_{v\in V_{top-k}} P ([MASK]=v|h_{[MASK]})}</script><p>其中，v 是 top-k token 集 $V<em>{top-k}$ 中的BERT标记，$W_v$ 是 $v$ 的静态 token 嵌入，$P([MASK] = v|h</em>{[MASK]})$表示token $v$被MLM头预测为 $h_{[MASK]}$ 的概率。</p><p>第二种方法是将句子映射到 token 上，比第一种方法更常规。但它的缺点也很明显：1）如前所述，由于句子嵌入来自静态 token 嵌入的平均化，它仍然存在偏差。2）权重平均化使BERT在下游任务中很难进行微调。由于这些原因，我们用第一种方法来表示带有提示的句子。</p><h3 id="Prompt-Search"><a href="#Prompt-Search" class="headerlink" title="Prompt Search"></a>Prompt Search</h3><p>第二种方法是将句子映射到 token 上，比第一种方法更常规。但它的缺点也很明显：1）如前所述，由于句子嵌入来自静态 token 嵌入的平均化，它仍然存在偏差。2）权重平均化使BERT在下游任务中很难进行微调。由于这些原因，我们用第一种方法来表示带有提示的句子。</p><p>对于人工搜索，我们需要手工制作模板，鼓励将整个句子用 $h_{[MASK]} $ 表示。为了搜索模板，我们将模板分为两部分：关系token，表示 $[X]$ 和 $[MASK]$ 之间的关系；前缀token，包裹 $[X]$ 。然后，我们贪婪地搜索遵循关系 token 和前缀 token的模板。</p><p><img src="https://s2.loli.net/2021/12/21/7uzvhb3feKsIoEt.png" alt=""></p><p>表4中显示了一些贪婪搜索的结果。当涉及到句子嵌入时，不同的模板产生了极其不同的结果。与简单地连接 $[X]$ 和$[MASK]$ 相比，复杂的模板如这句话：” $[X]$ “意味着 $[MASK]$，可以提高34.10的spearman相关度。</p><p>对于基于T5的模板生成，Gao等人（2020）提出了一种新颖的方法，通过使用T5根据句子和相应的标签来自动生成模板。在GLUE基准测试中，生成的模板可以胜过人工搜索的模板（Wang等人，2018）。</p><p>然而，实现它的主要问题是缺乏 token 标签。Tsukagoshi等人（2021年）通过根据字典将定义句子分类到其单词，成功地将句子嵌入任务转化为文本分类任务。受此启发，我们使用单词和相应的定义来生成500个模板（例如，橙子：一种大而圆的多汁柑橘类水果，有坚韧的鲜红黄色的外皮）。然后，我们在STS-B开发集中对这些模板进行评估，与模板 “也叫[MASK]”的最佳spearman相关度为64.75。[X]”. 也许这就是句子嵌入和单词定义之间的差距。与人工搜索相比，这种方法不能产生更好的模板。</p><p>OptiPrompt（Zhong等人，2021）用连续模板取代了离散模板。为了优化连续模板，我们按照(Gao et al., 2021)的设置，使用无监督的对比学习作为训练目标，冻结整个BERT参数，连续模板由手工模板的静态 token 嵌入初始化。与输入的人工模板相比，连续模板可以将STS-B开发集的spearman相关度从73.44提高到80.90。</p><h3 id="Prompt-Based-Contrastive-Learning-with-Template-Denoising"><a href="#Prompt-Based-Contrastive-Learning-with-Template-Denoising" class="headerlink" title="Prompt Based Contrastive Learning with Template Denoising"></a>Prompt Based Contrastive Learning with Template Denoising</h3><p>最近，对比性学习成功地利用了句子嵌入中的BERT的力量。句子嵌入对比学习中的一个挑战是如何构建适当的正向实例。Gao等人（2021）直接将BERT中的dropout作为正例。Yan等人（2021）讨论了四种数据增强策略，如对抗性攻击、token shuffling、cutoff 和输入 token 嵌入中的dropout来构建正面实例。在基于提示的句子嵌入的激励下，我们提出了一种新的方法来合理地生成基于提示的正面实例。</p><p>这个想法是用不同的模板来表示同一个句子的不同观点，这有助于模型产生更合理的正向对。为了减少模板本身对句子表述的影响，我们提出了一种新的方法来去掉模板信息。给定句子 $x_i$，我们首先用模板计算出相应的句子嵌入$h_i$。然后，我们通过直接给BERT输入模板和相同的模板位置 id 来计算模板偏差 $\hat h_i$。例如，如果 $x_i$ 有5个 token，那么 [X] 后面的模板标记的位置id将被加上 5，以确保模板的位置id是相同的。最后，我们可以直接使用 $h_i - \hat h_i$ 作为去噪后的句子表示。关于模板去噪，更多细节可以在讨论中找到。</p><p>形式上，让 $h_i’$ 和 $h_i$ 表示不同模板的 $x_i$ 的句子嵌入，$\hat h_i’$和 $\hat h_i$ 分别表示 $x_i$ 的两个模板偏差，最终训练目标如下:</p><script type="math/tex; mode=display">l_i = -log \frac{e^{cos(h_i-\hat h_i, h'_i-\hat h'_i)/ \tau}}{\sum_{j=1}^N e^{cos(h_i-\hat h_i, h'_j-\hat h'_j)/ \tau}}</script><p>其中，$τ$ 是对比学习中的一个温度超参数，N 是小批量的大小。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;PromptBERT-Improving-BERT-Sentence-Embeddings-with-Prompts&quot;&gt;&lt;a href=&quot;#PromptBERT-Improving-BERT-Sentence-Embeddings-with-Prompts&quot; cl</summary>
      
    
    
    
    
    <category term="context detection" scheme="http://example.com/tags/context-detection/"/>
    
  </entry>
  
  <entry>
    <title>Parameter-Efficient Tuning by Manipulating Hidden States of Pretrained Language Models For Classification Tasks</title>
    <link href="http://example.com/2021/11/30/Parameter-Efficient-Tuning-by-Manipulating-Hidden-States-of-Pretrained-Language-Models-For-Classification-Tasks/"/>
    <id>http://example.com/2021/11/30/Parameter-Efficient-Tuning-by-Manipulating-Hidden-States-of-Pretrained-Language-Models-For-Classification-Tasks/</id>
    <published>2021-11-30T11:46:34.000Z</published>
    <updated>2021-11-30T15:46:44.472Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Parameter-Efficient-Tuning-by-Manipulating-Hidden-States-of-Pretrained-Language-Models-For-Classification-Tasks"><a href="#Parameter-Efficient-Tuning-by-Manipulating-Hidden-States-of-Pretrained-Language-Models-For-Classification-Tasks" class="headerlink" title="Parameter-Efficient Tuning by Manipulating Hidden States of Pretrained Language Models For Classification Tasks"></a>Parameter-Efficient Tuning by Manipulating Hidden States of Pretrained Language Models For Classification Tasks</h1><p>Parameter-Efficient tuning旨在通过优化一些引入的参数的同时，冻结 PLMs 来提取下游任务的知识。</p><p>连续的 prompt tuning 在输入的嵌入中预先加入一些可训练向量。是其中的一种方法，由于其有效性和效率而受到广泛关注。这个系列的方法可以被理解为对PLM内部的隐藏状态进行了非线性转换。</p><p>然而，一个自然的问题被忽略了：隐藏状态能否直接用于分类而不改变它们？在本文中，我们旨在通过提出一种简单的 tuning 方法来回答这个问题，这种方法只引入了三个可训练的向量。</p><p>首先，我们使用引入的向量整合不同层的隐藏状态。然后，我们将整合后的隐藏状态输入到一个特定任务的线性分类器中，以预测类别。</p><p>这个方案类似于ELMo利用隐藏状态的方式，只是他们将隐藏状态反馈给基于LSTM的模型。 虽然我们提出的tuning 方案很简单，但它取得了与 P-tuning 和 P-tuning v2等 prompt tuning 方法相当的性能，验证了原始隐藏状态确实包含分类任务的有用信息。此外，我们的方法在时间和参数数量上比  prompt tuning  有优势。</p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>为了将 PLM 重用于不同的任务，已经提出了越来越多的 parameter-efficient tuning 方法。 他们旨在通过仅优化少量额外参数，从冻结的 PLM 中挖掘特定于任务的信息。  </p><ul><li><p>Adapter tuning 建议将两个可训练的 Adapter 插入到每个 transformer 中，这些适配器由一些简单的变换组成。 虽然适配器达到了近乎 state-of-the-art 的性能，但它引入的额外参数数量仍然非常多，并且原始 transformer 的架构也需要修改。</p></li><li><p>《Few- shotqa: A simple framework for few-shot learning of question answering tasks using pre-trained text- to-text models》 试图规避预训练和 tuning 过程之间的错位，因其在 few-shot 情况下的优越性而受到广泛关注。</p></li><li><p>《Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing》包括离散prompt tuning 和连续prompt tuning，是最流行的方法。离散prompt tuning通常在输入句子中插入一些标记（出现在模型的词汇中），将任务重新表述为填空问题。然而，离散prompt tuning的调整涉及到巨大的人工努力，在高资源数据集上的表现更差，限制了其使用。连续 prompt tuning 不是插入离散的标记，而是在输入句子的嵌入中增加特定任务的可训练向量。在训练期间，只有这些特定任务的向量被优化。他们的实验表明，通过这些额外的向量，有可能从冻结的PLMs中获取知识。</p></li><li><p>《The power of scale for parameter-efficient prompt tuning》试图利用提示向量的意义，发现它们的词邻往往是相似的词，说明连续 prompt tuning 与离散 prompt tuning 完全不同。另外，如图1所示，与P-tuning将可训练向量预置到词嵌入中不同，我们尝试将这些向量预置到特定的 transformer 中。图2描述了四个任务的准确性。我们可以看到，将向量预置到任何一层，甚至最后一层，都可以取得类似的结果。我们从这个现象中得到两个启发。(i) 当可训练的向量被插入到最后一个 transformer 时，P-tuning甚至也能发挥作用。这是否意味着这些原始的隐藏状态已经包含了大部分甚至所有用于分类的信息？(ii) 当向量被预置到第0层时，可能无法获得最好的准确性。这与ELMo类似，表现为不同层对下游任务有不同的权重</p><p><img src="https://i.loli.net/2021/11/30/ZBlXyOH7vKtF48A.png" alt=""></p></li></ul><p>在本文中，通过提出一种只引入三个可训练向量的简单方法，表明分类信息可以很容易地提炼出来。</p><p>这个方法首先获得了输入的所有隐藏状态，并学习了一个softmax归一化的权重向量来堆叠跨层的隐藏状态。其次，一个软掩码向量被用来选择隐藏状态中对下游任务有用的维度子集。最后，进行仅由一个可训练向量组成的自我注意操作，以输出用于分类的状态。</p><p>我们发现，分类信息在表面，这意味着没有必要使用复杂的分类头，如LSTM，CNN。我们的分类头只包含一个线性转换，然后是一个softmax函数。</p><p>我们在各种任务上进行了实验，结果表明，我们的方法可以达到与P-tuning和P-tuning v2所取得的性能相当。这证实了原始的隐藏状态确实包含了分类所需的信息，而且这种信息可以通过简单的线性转换来提取。我们希望这一发现能够帮助推进对连续 prompt tuning  方案的理解。</p><h2 id="Preliminaries"><a href="#Preliminaries" class="headerlink" title="Preliminaries"></a>Preliminaries</h2><p>在这一节中，我们首先介绍了一些 tuning 方案的背景，介绍了ELMo和 transformer 家族语言模型如何应用于下游分类任务。</p><h3 id="ELMo"><a href="#ELMo" class="headerlink" title="ELMo"></a>ELMo</h3><p>ELMo 的骨干是 L 层双向LSTM。经过预训练，当有一个下游任务时，ELMo学习了一个特定任务的跨层隐藏状态的线性组合，并将这些隐藏状态输入到基于 LSTM 的模型，以输出一个输入的目标：</p><script type="math/tex; mode=display">e_{k} = \gamma\sum_{i=0}^{L} s_jh_{k,j}</script><script type="math/tex; mode=display">\hat y = Model ([e_1,e_2,...,e_n])</script><p>其中 $h<em>{k,j}$  是第 $j$ 层中第 $k$ 个token的隐藏状态。$h</em>{k,0}$是第 $k$ 个token词嵌入层表示。$(s_0,s_1,…,s_L)$ 是任务特定的softmax归一化权重的表示，它们在训练下游任务时被优化。这些权重允许模型根据下游任务的属性，利用不同层次的表征（例如，语法、语义）。$\gamma$ 是可训练标量，其用于辅助优化过程。$e_k$ 是第 $k$个词的最终加权嵌入。最后，$[e_1, e_2, …, e_n]$被输入到量身定做的模型（通常是一个复杂的网络，如LSTM），以预测标签或生成特定任务的目标句。</p><h3 id="The-Transformer-Family"><a href="#The-Transformer-Family" class="headerlink" title="The Transformer Family"></a>The Transformer Family</h3><p>在根据下游任务调整PLM时，最常用的方法叫做微调，把PLM和特定任务的分类器 $C$ 一起优化:</p><script type="math/tex; mode=display">min_{\theta,\beta} \sum_{x\in D} L(C_{\beta}(E_{\theta}(x)), y)</script><p>其中 $C、E$分别代表特定任务的分类头和编码器（一个PLM）。$β，θ$ 分别是 $C$ 和 $E$ 的参数。Fine tuning LM通常可以获得令人满意的性能。然而，在新数据按顺序出现的情况下，这种调整方案不再起作用。 因为当一个新的数据集出现时，我们要么重新训练所有的数据，要么为新的数据训练一个单独的模型。由于耗费大量时间和存储，这两种方法都是不可接受的。因此，研究人员试图通过引入一些可训练的参数，从冻结的PLM中提炼出知识。</p><p>Adapter tuning 和连续  prompt tuning 是两种普遍的方法。这里，我们只介绍第二种。有许多关于连续 prompt tuning 的工作，我们对其中的两个进行了详细介绍</p><ul><li><p>P-tuning 对于一个输入句子 $x=(x_1,x_2,…,x_n)$，P-tuning在 $x$ 的词嵌入矩阵中加入K个向量，用 $P（x）=[w_0,p_1,p_2,…,p_K,w_1,…,w_n]$表示。$w_0$ 是[CLS] token 的嵌入。$P(x)$ 被输入到PLM的其余各层以预测 $x$ 的标签，优化目标是:</p><script type="math/tex; mode=display">min_{\beta, p_{1,...K}} \sum_{x\in D} L(C_{\beta}(E(P(x))) ,y)</script><p>我们可以看到，在训练期间，只有预置的向量和分类器被优化。虽然P-tuning的想法受到离散 prompt tuning 的启发，但这两者并没有显示出任何共同的特征。例如，在将 $p_i,…, p_K$ 映射到词汇中最接近的词后，这些词往往是类似的词（如technology，technologies），这并没有显示出连续 prompt tuning 背后的机制是像离散 prompt tuning 那样利用PLM的语言建模特性。最近的一项工作（He et al., 2021）揭示了P-tuning和适配器之间的联系，他们发现P-tuning相当于原始隐藏状态和由预置向量产生的新隐藏状态的加权平均值。应该注意的一点是，这些向量是由数据集中的所有样本共享的。同样的新隐藏状态可以应用于所有不同的样本，这有点不可思议。一个可能的解释是，原始的隐藏向量已经包含了用于分类的信息，而这正是我们论文的重点。</p></li><li><p>P-tuning v2  是一种变种的P-tuning，可以扩展到困难的任务，与P-tuning相比，取得了更好的性能。与P-tuning不同的是，P-tuning将向量插入到单词嵌入矩阵中，而这些向量在后面几层的隐藏状态是根据前一层的表示来计算的，P-tuning v2利用多层提示，将一组可训练的向量插入到PLM的每层。换句话说，第 $l$ 层的原始隐藏状态会受到第 $l - 1$ 层的提示向量的影响。由于引入了更多的可训练向量，这种修改使得每个任务的容量更大。</p></li></ul><h2 id="Proposed-Approach"><a href="#Proposed-Approach" class="headerlink" title="Proposed Approach"></a>Proposed Approach</h2><p><img src="https://i.loli.net/2021/11/30/ZCm7KItPuDd8bpQ.png" alt=""></p><p>该方法直接操纵不同层的隐藏状态。与通过改变隐藏状态来提炼有用信息的 adapters 和 prompt tuning 方法不同，我们对原始隐藏状态进行操作。由于有许多方法可以整合这些隐藏状态，我们只介绍最简单的方法，由三部分组成。</p><h3 id="Layer-Level-Weighted-Addition"><a href="#Layer-Level-Weighted-Addition" class="headerlink" title="Layer-Level Weighted Addition"></a>Layer-Level Weighted Addition</h3><p>这一步与公式1类似，只是我们不使用标量 $\gamma $。形式上，给定输入x，我们首先获得隐藏状态:</p><script type="math/tex; mode=display">\{H_i\}_{i=0}^L = \{h_{i,0},..., h_{i,N}\}_{i=0}^L = E(x)</script><p>其中 $L$ 为tansformer 层数， 第 $0$ 层是词嵌入层，$N$ 是 $x$ 的长度。每个 $h_{i,j}$ 是一个 $d$ 维向量，每个 $H_i$ 是一个 $d×（N+1）$维矩阵。然后，我们给每个层分配一个权重，因为以前的工作表明，低层、中层、顶层捕捉的信息粒度不同，不同的下游任务可能对这些层有不同的关注。</p><p>我们通过引入第一个可训练向量 $v_1\in R^{L+1}$来实现这一目标:</p><script type="math/tex; mode=display">H = \{h_0, h_1,..., h_N\} = \sum_{i=0}^L s_i H_i , \ \ \ s = softmax(v_1)</script><h3 id="Subspace-Mining"><a href="#Subspace-Mining" class="headerlink" title="Subspace Mining"></a>Subspace Mining</h3><p>我们认为，对于一个d 维的隐藏状态，存在一个维度为 $d_1$ 的子空间，它包含下游任务的区分信息。用二进制掩码向量选择这样的子空间是一种选择，但它在优化方面有困难《 Masking as an efficient alternative to finetuning for pretrained language models》。在此，我们通过引入第二个可训练向量 $v_2\in R^d$ 来采用软屏蔽策略:</p><script type="math/tex; mode=display">H = m \otimes H , \ \ \ m = sigmoid(v_2)</script><p>如果下游的任务是一个序列标记 任务，如命名实体识别，H可以直接用于分类。然而，对于情感分类、自然语言推理等任务，应该进行进一步的处理步骤。</p><h3 id="Self-Attention"><a href="#Self-Attention" class="headerlink" title="Self-Attention"></a>Self-Attention</h3><p>使用 Self-Attention 来聚合矩阵 $H$ 。但是这种 Self-Attention  需要很多参数, 引入第三个可训练向量 $v_3\in R^d$ :</p><script type="math/tex; mode=display">h = H \cdot w , \ \ \ w=softmax(v_3\cdot H)</script><h3 id="Task-Specific-Classification"><a href="#Task-Specific-Classification" class="headerlink" title="Task-Specific Classification"></a>Task-Specific Classification</h3><p>有了 $h$ 和 $H$ ，我们可以把它们输入到特定任务的分类头。为了说明原始隐藏状态包含了大部分（如果不是全部）分类信息，而且这些信息都在表面，我们只进行了线性变换和softmax操作来输出标签，对于序列标签任务:</p><script type="math/tex; mode=display">y = argmax(softmax(WH))</script><p>对于情感分类 ：</p><script type="math/tex; mode=display">y = argmax(softmax(Wh))</script><p>在训练过程中，只有v1、v2、v3和w是被操作的。因此，与P-tuning和P-tuning v2相比，我们的方法在内存和时间方面更加有效，因为额外的参数不参与PLM内部的计算，而且输入长度也没有增加。在第4.2节，我们将提供一个详细的分析。</p><h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><p><img src="https://i.loli.net/2021/11/30/DsPSl6HW8bNpLAE.png" alt=""></p><p><img src="https://i.loli.net/2021/11/30/EDne5dYPKgl8vN4.png" alt=""></p><p>为了考察这些调谐方法在额外参数数量上的表现，我们把P-tuning中的提示向量数量减少到3个，把P-tuning v2中的提示向量数量减少到1个，结果见图4。我们可以发现Ours在整体上优于P-tuning，与P-tuning v2相当。我们还尝试增加Ours的参数数量，即引入多个V3来形成多头自关注，但发现性能没有改善。这可能是我们方法的一个缺点。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Parameter-Efficient-Tuning-by-Manipulating-Hidden-States-of-Pretrained-Language-Models-For-Classification-Tasks&quot;&gt;&lt;a href=&quot;#Parameter</summary>
      
    
    
    
    
    <category term="context detection" scheme="http://example.com/tags/context-detection/"/>
    
  </entry>
  
  <entry>
    <title>P-Tuning v2，Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks</title>
    <link href="http://example.com/2021/11/25/P-Tuning-v2-Prompt-Tuning-Can-BeComparable-to-Fine-tuning-Universally-Across-Scales-and-Tasks/"/>
    <id>http://example.com/2021/11/25/P-Tuning-v2-Prompt-Tuning-Can-BeComparable-to-Fine-tuning-Universally-Across-Scales-and-Tasks/</id>
    <published>2021-11-25T09:29:41.000Z</published>
    <updated>2021-12-12T15:01:56.511Z</updated>
    
    <content type="html"><![CDATA[<h1 id="P-Tuning-v2-Prompt-Tuning-Can-Be-Comparable-to-Fine-tuning-Universally-Across-Scales-and-Tasks"><a href="#P-Tuning-v2-Prompt-Tuning-Can-Be-Comparable-to-Fine-tuning-Universally-Across-Scales-and-Tasks" class="headerlink" title="P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks"></a>P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks</h1><p>Prompt tuning 只用冻结的语言模型来调整连续的prompts，大大减少了训练时每个任务的存储和内存使用。但</p><ul><li><p>prompt tuning 对于正常大小的预训练模型来说表现并不理想。</p></li><li><p>现有的 prompt tuning 方法不能处理困难的序列标记任务，缺乏普适性。</p></li></ul><p>P-Tuning-v2 与微调的性能相匹配，并且只有0.1%-3%的调整参数。</p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>微调，为目标任务更新整个模型参数集。虽然微调能获得良好的性能，但在训练过程中却很耗费内存，因为必须存储所有参数的梯度和优化器状态。</p><p>此外，微调需要在推理过程中为每个任务保留一份模型参数，这很不方便，因为预训练的模型通常很大。</p><p><strong>Prompting</strong> 另一方面，冻结PLMs的所有参数并使用自然语言 prompts 来查询语言模型。例如，对于情感分析，我们可以将一个样本与一个 prompts 串联起来 “这部电影是[MASK]”，并要求预训练的语言模型预测被mask的 token。然后，我们可以使用 “好 “和 “坏 “是被 MASK 的标记的预测概率来预测样本的标签。Prompting 完全不需要训练，只需存储一份模型参数。然而，与微调相比，提示 在许多情况下会导致次优的性能（Liu等人，2021b；Lester等人，2021）。</p><p><strong>Prompt tuning</strong> 是一种只调谐连续 prompts 的想法。具体来说，Liu等人（2021b）；Lester等人（2021）提出在输入词嵌入的原始序列中加入可训练的连续嵌入。这些连续嵌入（也称为连续 prompts ）类似于 prompting 中离散的手动签名 prompts。在训练过程中，只有连续的 prompts 被更新。虽然 prompt tuning 在许多任务上比 prompting 有提高 （Liu等人，2021b；Lester等人，2021），但当模型规模较小，特别是小于100亿个参数时，它仍然不如 fine-tuning（Lester等人，2021）。</p><p>从技术上讲，P-tuning v2可以被看作是 prefix-tuning  的优化版本，适用于NLU。最显著的改进来自于使用深度 prompt tuning，即对预训练模型的每一层应用连续的 prompt。深度 prompt tuning 增加了连续 prompt 的能力，并缩小了在各种设置中进行微调的差距，特别是对于小模型和困难任务。此外，还提出了一些优化和实施的细节，以进一步提高结果。</p><h2 id="Preliminaries"><a href="#Preliminaries" class="headerlink" title="Preliminaries"></a>Preliminaries</h2><h3 id="NLU-Tasks"><a href="#NLU-Tasks" class="headerlink" title="NLU Tasks"></a>NLU Tasks</h3><p>在这项工作中，将NLU的挑战分为两个系列：</p><ul><li>Simple NLU tasks ：涉及单一标签的分类。GLUE（Wang等人，2018）和Super- GLUE（Wang等人，2019）的大多数数据集，包括文本分类（如SST-2）、自然语言推理（NLI，如MNLI-m，RTE）、多选题回答（如BoolQ）等，都属于这一类。</li><li>Hard sequence NLU tasks ：涉及对一连串标签的分类。它们大多是与信息提取有关的问题，如开放式信息提取、命名实体识别、提取式问题回答和语义角色标签。</li></ul><h3 id="Prompt-Tuning"><a href="#Prompt-Tuning" class="headerlink" title="Prompt Tuning"></a>Prompt Tuning</h3><p>Prompt tuning（Lester等人，2021），或P-tuning（Liu等人，2021b），引入了可训练的连续prompts，作为骨干语言模型的参数被冻结时对NLU的自然语言 prompts 的替代。例如，让 $V$ 指的是语言模型 $M$ 的词汇表，$e$ 作为 $M$ 的嵌入函数。</p><p>要把一篇电影评论 x=”Amazing movie!” 分类为正面或负面，很自然地就会想到在评论中加入一个 prompts  “It is [MASK]”，并生成MASK token被预测为 “好 “或 “坏 “的条件概率作为分类。在这种情况下，prompt tokens  {“It”、”is”、”[MASK]”} 都属于模型的词汇表 $V$，而输入嵌入序列将是：</p><script type="math/tex; mode=display">[e(x), e("It"), e("is"), e("[MASK]")]</script><p>然而，由于模型 $M$ 在本质上是连续的，从优化的角度来看，人们永远不可能用离散的自然 prompts 来达到最佳效果。相反，P-tuning建议用可训练的连续 embeddings $[h_0, …, h_i]$ 代替 prompt tokens ，并将输入序列变成:</p><script type="math/tex; mode=display">[e(x), h_0,...,h_i, e("[MASK]")]</script><p>并因此可以进行不同的优化（参考图2（a））。在骨干预训练模型的参数被冻结的严格约束下，在简单的NLU任务和知识探测中，prompt tuning 已被证明具有与100亿参数模型的 fine-tuning 相当的性能。</p><h2 id="P-Tuning-v2"><a href="#P-Tuning-v2" class="headerlink" title="P-Tuning v2"></a>P-Tuning v2</h2><p><img src="https://i.loli.net/2021/11/25/hAoQrbPSGTtIsnz.png" alt=""></p><h3 id="Lack-of-Universality"><a href="#Lack-of-Universality" class="headerlink" title="Lack of Universality"></a>Lack of Universality</h3><p>在许多NLP应用中，Prompt tuning 和  P-tuning 已经被证明是相当有效的。然而，考虑到缺乏普遍性， P-tuning 还不是微调的全面替代方法。</p><h3 id="Lack-of-universality-across-scales"><a href="#Lack-of-universality-across-scales" class="headerlink" title="Lack of universality across scales"></a>Lack of universality across scales</h3><p> Lester等人（2021）表明，当模型规模超过100亿个参数时，prompt tuning 可以与微调相媲美。但是对于那些较小的模型（从100M到1B），prompt tuning和微调的表现有很大差异，这大大限制了prompt tuning的适用性。</p><h3 id="Lack-of-universality-across-tasks"><a href="#Lack-of-universality-across-tasks" class="headerlink" title="Lack of universality across tasks."></a>Lack of universality across tasks.</h3><p>尽管Lester等人（2021年）和 P-tuning 在GLUE和SuperGLUE等NLU基准上显示出优越性，但它们在另一大类序列NLU任务（即序列标签）上的有效性却没有得到验证。</p><p>首先，序列标签需要预测一连串的标签，而不是单一的标签。其次，序列标签通常预测的是无实际意义的标签，这对变成有效的言语者来说可能是个挑战。</p><h3 id="Deep-Prompt-Tuning"><a href="#Deep-Prompt-Tuning" class="headerlink" title="Deep Prompt Tuning"></a>Deep Prompt Tuning</h3><p><img src="https://i.loli.net/2021/11/25/42eZyjHrnuWAmNv.png" alt=""></p><p>Prefix-tuning（Li and Liang, 2021）最初是为自然语言生成（NLG）任务提出的，但我们发现它对NLU也非常有效。我们描述了一个适合NLU的 Prefix-tuning 版本。</p><p>在(Lester et al., 2021)和P-tuning中，连续 prompts 只被插入到输入嵌入序列中（参考图2(a)），用于 transformer’s 第一层。在接下来的  transformer 中，插入连续 prompts 的位置的嵌入是由之前的transformer 层计算出来的，这可能导致两个可能的优化挑战。</p><ul><li>可调整的参数数量有限。大多数语言模型目前只能支持512的最大序列长度（由于注意力的二次计算复杂性的成本）。如果我们另外扣除我们的上下文的长度（例如，要分类的句子），那么我们用连续提示来填充的长度是有限的。</li><li>在用非常深的 transformers 进行调整时，稳定性有限。随着 transformers 的不断深入，由于许多中间层的计算（具有非线性激活函数），来自第一个transformers 层的提示的影响可能是意想不到的，这使得我们的优化不是一个非常平稳的优化。</li></ul><p>鉴于这些挑战，P-tuning v2利用多层 prompts（即深度prompt tuning）作为 prefix-tuning（Li and Liang, 2021）中的提示（参见图2（b）），作为对P-tuning和Lester等人（2021）的重大改进。不同层的 prompt 作为前缀 tokens 添加到输入序列中，并独立于其他层（而不是由之前的 transformers 层计算）。一方面，通过这种方式，P-tuning v2 有更多的可调整的特定任务参数（从0.01%到0.1%-3%），以允许更多的每个任务容量，而它仍然比完整的预训练语言模型小得多；另一方面，添加到更深层的 prompt（例如图2中的LayerN Prompts）可以对输出预测产生更直接和显著的影响，而中间的transformers层更少。</p><h3 id="Optimization-and-Implementation"><a href="#Optimization-and-Implementation" class="headerlink" title="Optimization and Implementation"></a>Optimization and Implementation</h3><p><strong>Optimization：Reparameterization</strong>。以前的方法利用重新参数化功能来提高训练速度、鲁棒性和性能（例如，MLP的 prefix-tuning 和 LSTM的P调整）。然而，对于NLU任务，我们发现这种技术的好处取决于任务和数据集。对于一些数据集（如RTE和CoNLL04），MLP的重新参数化带来了比嵌入更稳定的改进；对于其他的数据集，重新参数化可能没有任何效果（如BoolQ），有时甚至更糟（如CoNLL12）。</p><p><img src="https://i.loli.net/2021/11/25/T1axhfKtEoXPZOR.png" alt=""></p><p><strong>Optimization: Prompt length</strong> Prompt length在 prompt tuning 方法的超参数搜索中起着核心作用。在我们的实验中，我们发现不同的理解任务通常以不同的 Prompt length 达到最佳性能，这与 prefix- tuning 的发现一致，不同的文本生成任务可能有不同的最佳 Prompt length。</p><p>从图3中，我们观察到，对于简单的NLU任务，通常，较短的prompts 就能获得最佳性能；对于困难的序列任务，通常，比100长的 prompts 语会有帮助。<br>我们还发现，重新参数化与 Prompt length 长度有着密切的联系。例如，在RTE、CoNLL04和BoolQ中，MLP的重新参数化比嵌入更早达到最佳结果。这一结论可能有助于对P-tuning的优化特性进行一些思考。</p><p><strong>Optimization: Multi-task learning.</strong> 多任务学习对我们的方法来说是可选的，但可能是相当有帮助的。一方面，连续prompts 的随机惯性给优化带来了困难，这可以通过更多的训练数据或与任务相关的无监督预训练来缓解（Gu等人，2021）；另一方面，连续 prompts 是跨任务和数据集的特定任务知识的完美载体。 我们的实验表明，在一些困难的序列任务中，多任务学习可以作为P-tuning v2的有益补充，表示为MPT-2。</p><p><strong>Implementation: [CLS] and token classification, rather than verbalizers.</strong>  Verbalizer 一直是 Prompt tuning 的核心组成部分，它将一类的labels变成有意义的词，以利用预训练语言模型head 。尽管它在少数情况下有潜在的必要性，但在全数据监督的情况下，verbalizer 不是必须的。它阻碍了 Prompt tuning 在我们需要无实际意义的标签和语义嵌入的场景中的应用。因此，P-tuning v2回到了传统的[CLS]标签分类（参照图2）范式，采用随机初始化的线性头。见第4.4节中的比较。</p><h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><p>在这项工作中，”prompt tuning”、”P-tuning”、”P-tuning v2 “和 “多任务P-tuning v2 “的所有结果都是通过冻结transformer的参数，只调整连续prompts。特定任务参数的比率（例如0.1%）是通过比较连续prompts 的参数和transformer的参数得出的。只有 “微调 “的结果是通过调整transformer的参数（不使用连续提示）得到的。</p><p>另外需要注意的是，我们的实验都是在全数据监督下的学习环境下进行的，而不是在少量的学习环境下进行的，这一点很重要，因为我们利用的一些特性（例如，使用具有线性head 的类标签而不是具有LM头的言语者）只可能在监督下进行。</p><p><img src="https://i.loli.net/2021/11/25/q12FUMtevPgoI3V.png" alt=""></p><h3 id="P-tuning-v2-Across-Scales"><a href="#P-tuning-v2-Across-Scales" class="headerlink" title="P-tuning v2: Across Scales"></a>P-tuning v2: Across Scales</h3><p>表1展示了P-tuning v2在不同模型规模下的表现。对于简单的NLU任务，如SST-2（单句分类），Lester等人（2021）和P-tuning在较小的规模下没有显示出明显的劣势。但是，当涉及到复杂的挑战，如自然语言推理（RTE）和多选题回答（BoolQ）时，它们的性能会非常差。相反，P-tuning v2在所有任务中以较小的规模与微调性能相匹配。令我们惊讶的是，P-tuning v2在RTE中的表现明显优于微调，特别是在BERT中。</p><p>就较大尺度（2B到10B）的GLM（Du等人，2021）而言，P-调谐&amp;Lester等人（2021）与精细调谐之间的差距逐渐缩小了。在10B尺度上，我们有一个类似于（Lester等人，2021）报告的观察结果，即及时调谐变得与精细调谐竞争。然而，P-tuning v2在所有尺度上都与微调相当，但与微调相比，只需要0.1%的任务特定参数。<br>此外，我们观察到，在一些数据集中，RoBERTa-large的性能比BERT-large差。部分原因是，我们根据经验发现及时调谐对超参数相当敏感，有时调谐会被困住。P-tuning v2在调谐过程中可以更加稳定和稳健。关于超参数的更多细节，请参考我们的代码库。</p><h3 id="P-tuning-v2-Across-Tasks"><a href="#P-tuning-v2-Across-Tasks" class="headerlink" title="P-tuning v2: Across Tasks"></a>P-tuning v2: Across Tasks</h3><p>在第4.2节中，我们讨论了P-tuning v2的一贯性，无论何种尺度，其性能都与微调相当。然而，GLUE和SuperGLUE的大多数任务都是相对简单的NLU问题。另一个重要的硬NLU挑战系列是序列标签，它与一些更高级的NLP应用有关，包括开放信息提取、阅读理解等。</p><p>为了评估P-tuning v2在这些硬NLU挑战上的能力，我们选择了三个典型的序列标签任务。名称实体识别、外部问题回答（QA）和语义角色标签（SRL），共八个数据集。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;P-Tuning-v2-Prompt-Tuning-Can-Be-Comparable-to-Fine-tuning-Universally-Across-Scales-and-Tasks&quot;&gt;&lt;a href=&quot;#P-Tuning-v2-Prompt-Tuning-</summary>
      
    
    
    
    
    <category term="context detection" scheme="http://example.com/tags/context-detection/"/>
    
  </entry>
  
  <entry>
    <title>PADA: A Prompt-based Autoregressive Approach for Adaptation to Unseen Domains </title>
    <link href="http://example.com/2021/11/23/PADA-A-Prompt-based-Autoregressive-Approach-for-Adaptation-to-Unseen-Domains/"/>
    <id>http://example.com/2021/11/23/PADA-A-Prompt-based-Autoregressive-Approach-for-Adaptation-to-Unseen-Domains/</id>
    <published>2021-11-23T01:49:35.000Z</published>
    <updated>2021-12-26T07:59:10.009Z</updated>
    
    <content type="html"><![CDATA[<h1 id="PADA-A-Prompt-based-Autoregressive-Approach-for-Adaptation-to-Unseen-Domains"><a href="#PADA-A-Prompt-based-Autoregressive-Approach-for-Adaptation-to-Unseen-Domains" class="headerlink" title="PADA: A Prompt-based Autoregressive Approach for Adaptation to Unseen Domains"></a>PADA: A Prompt-based Autoregressive Approach for Adaptation to Unseen Domains</h1><p>PADA: A Prompt-based Autoregressive Domain Adaptation algorithm, based on the T5 model</p><p>作者提出解决的是这个领域适应问题，即一个算法在几个源域上进行训练，然后应用于在训练时未知的未见过的领域的样本（更准确的说这其实是领域泛化问题）。</p><p>在训练时，没有任何样本，不管是有标签的还是无标签的，或者关于目标领域的任何其他知识。</p><p>给定一个测试样本，PADA首先生成一个独特的 prompt，然后以这个 prompt 为条件，在NLP任务方面给这个样本贴上标签。</p><p>prompt 是一个长度不受限制的序列，由预先定义的领域相关特征（DRFs）组成，这些特征是每个源域的特征。直观地说，prompt 是一个独特的签名，它将测试实例映射到源域所跨越的语义空间。</p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>NLP算法往往依赖于一个开创性的假设，即训练集和测试集来自相同的基础分布。不幸的是，这个假设往往不成立，因为文本可能来自许多不同的来源，每个来源都有独特的分布属性。由于超出训练分布的泛化仍然是一个基本的挑战，NLP算法在应用于非分布的应用时，会出现明显的退化。</p><p>领域适应（DA）明确地解决了上述挑战，努力改善NLP算法的 out-of-distribution 。DA算法在源领域的标注数据上进行训练，以有效地应用于各种目标领域。</p><p>多年来，人们为DA挑战付出了相当大的努力，专注于目标领域在训练时是已知的（例如，通过标记或未标记的数据），但仍未得到充分体现的各种情况（Roark和Bacchiani，2003；Daumé III和Marcu，2006；Reichart和Rappoport，2007；McClosky等人，2010；Rush等人，2012；Schnabel和Schütze，2014）。然而，对训练时未知的任何可能的目标领域的适应性挑战还没有得到充分的探索。</p><p>PADA具有独特的建模优势，因为目标感知算法通常需要为每个目标域训练一个单独的模型，导致整体解决方案效率低下。</p><p><strong>直观地说，通过整合来自几个源域的知识，可以实现对未见过的事物更好的泛化。</strong>PADA：基于 Prompt 的自回归领域适应算法，它利用自回归语言模型（T5），并包括一个适应于多个源领域的新型 Prompt 机制。给定一个来自任何未知领域的新样本，该模型首先生成属于熟悉的（源）领域并与给定样本相关的属性。然后，在模型执行下游任务时，生成的属性被用作 prompts。</p><p>为了产生有效的 prompts ，我们从以前关于 pivot features 的工作中得到启发（Blitzer等人，2006；Ziser和Reichart，2018a；Ben-David等人，2020），<strong>定义了领域相关特征（DRFs）的集合。DRFs是与源域之一密切相关的特征，编码了特定领域的语义。</strong>我们<strong>利用各个源域的DRFs，以跨越它们的共享语义空间</strong>。这些<strong>DRFs共同反映了源域之间的相似性和差异性，以及特定领域的知识</strong>。</p><h2 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h2><p>在DA研究中，有两种突出的设置：有监督的和无监督的。有监督的算法利用来自目标领域的稀缺标记的例子（Daumé III, 2007），而无监督的方法只假设源标记的数据和未标记的源和目标数据在手（Blitzer等人，2006）。</p><p>我们首先描述无监督DA的研究，重点是基于pivot-based的方法。然后，我们继续研究多源的DA方法，重点是专家混合模型。最后，我们描述了自回归语言模型和我们采用T5进行DA的独特方式。</p><h3 id="Unsupervised-Domain-Adaptation-UDA"><a href="#Unsupervised-Domain-Adaptation-UDA" class="headerlink" title="Unsupervised Domain Adaptation (UDA)"></a>Unsupervised Domain Adaptation (UDA)</h3><p>随着深度神经网络（DNN）建模的突破，DA社区的注意力已经被引向了表征学习方法。其中一项工作是采用基于DNN的自编码器来学习潜在的表征。这些模型在无标签的源数据和目标数据上进行训练，并有输入重建损失（Glorot等人，2011；Chen等人，2012；Yang和Eisenstein，2014；Ganin等人，2016）。</p><p>另一个分支采用 pivot 特征来弥补源域和目标域之间的差距（Blitzer等人，2006，2007；Pan等人，2010）。支点特征对感兴趣的任务很突出，在源域和目标域都很丰富。最近，Ziser和Reichart（2017，2018b）将这两种方法结合起来。后来，Han和Eisenstein（2019）提出了一种预训练方法，随后Ben-David等人（2020）提出了一种基于 pivot-based 的变体，用于预训练语境词嵌入。</p><p>最重要的是，UDA模型假定在训练过程中可以获得来自目标领域的无标签数据。我们认为这是对超越训练分布的泛化目标的一个轻微的放松。此外，这个定义在工程上有缺点，因为每个目标域都需要一个新的模型。为此，我们追求任何领域的适应性设置，即在训练时无法获得未标记的目标数据。</p><p>我们从 pivot-based 的模型中得到启发。pivot 的定义依赖于标记的 源域数据 和 未标记的源域 和 目标域数据。特别是，好的 pivot 是与任务标签相关的。相反，我们定义了任务变量DRF，这些特征与领域的身份高度相关。由于领域与单词高度相关，我们的DRFs在本质上是词汇性的。</p><p>虽然我们的方法可以在单一的源域中运行，但我们利用多个源域来促进对未知目标域的推广。我们接下来讨论多源DA。</p><h3 id="Multi-Source-Domain-Adaptation"><a href="#Multi-Source-Domain-Adaptation" class="headerlink" title="Multi-Source Domain Adaptation"></a>Multi-Source Domain Adaptation</h3><p>大多数现有的多源DA方法遵循无监督DA的设置定义，同时考虑一个以上的源域。一个突出的方法是融合几个来源的模型。早期的工作是为每个领域训练一个分类器，并假设所有的源领域对测试样本都是同等重要的（Li和Zong，2008；Luo等人，2008）。最近，基于对抗的方法使用未标记的数据，将源域与目标域对齐（Zhao等人，2018；Chen和Cardie，2018）。同时，Kim等人（2017年）和Guo等人（2018年）根据目标实例和每个源域之间的关系，明确地对专家混合模型（MoE）模型进行加权。然而，Wright和Augenstein（2020）在这项工作之后，在基于Transfomers的MoE上测试了各种加权方法，发现加权方法非常有效。</p><p>我们认识到所提出的MoE解决方案的两个局限性。首先，它是不可扩展的，因为它要求每个源域都有一个专家，导致模型参数随着源域数量的增加而增加（通常是线性的）。第二，领域专家是针对特定领域的知识进行调整的。然而，测试实例可能来自未知的领域，并可能反映出来源的复杂组合。为了解决这个问题，MoE使用启发式方法将专家的预测集合起来，例如简单的平均数或基于领域分类器预测的加权平均数。我们的结果表明，这种方法是次优的。</p><p>在这项工作中，我们训练一个模型，该模型在所有领域中共享其参数。此外，我们对适应任何目标领域感兴趣，这样在训练时就不需要知道关于潜在目标领域的信息。上述一些工作（Wright和Augenstein，2020年）事实上避免了利用目标数据，因此它们适合任何领域的设置，并形成了我们的两个基线。然而，与这些作品相比，我们认为这个定义是本研究的核心部分。</p><h3 id="Autoregressive-Language-Modeling"><a href="#Autoregressive-Language-Modeling" class="headerlink" title="Autoregressive Language Modeling"></a>Autoregressive Language Modeling</h3><p>以前的工作在训练基于Transformer（Vaswani等人，2017）的语言模型时主要考虑两种方法。第一种实现了经典的马尔科夫语言建模方法，通过训练Transformer解码器模型，根据其之前的上下文自动生成下一个词（Radford和Narasimhan，2018；Radford等人，2019）。第二种是将自回归语言建模方法作为一个掩盖的标记预测任务，通过训练Transformer的编码器来得出上下文的单词嵌入（Devlin等人，2019；Liu等人，2019；Sanh等人，2019）。当为一个新的任务微调模型时，一个自定义的解码器被实现，并与模型的预训练编码器联合训练。</p><p>最近提出了第三种方法，试图将以前的方法中的优点结合起来。它提出训练一个完整的Transformer（编码器-解码器）语言模型，从输入序列中自动渐进地生成屏蔽的、缺失的或扰乱的标记跨度，作为一个序列到序列的任务（Raffel等人，2020；Lewis等人，2020b）。最近，Raffel等人（2020）提出了T5，一个基于转化器的模型，提出了文本到文本的迁移学习方法。T5基本上将所有的任务视为生成性的，同时利用一个提示短语来表示正在执行的具体任务。结合其文本到文本的方法，T5在许多鉴别性和生成性任务中显示出其优越性，同时消除了对特定任务网络结构的需求。</p><p>T5的一个特别有趣和有用的特点是其 prompting 机制。prompt 短语通常用于指示模型要执行的任务，被作为前缀添加到所有与任务相关的输入实例中。最近的工作也探索了这种 prompt 机制，以使语言模型适应不同的目的（Brown等人，2020年），激发情感或话题相关的信息（Jiang等人，2020年；Sun和Lai，2020年；Shin等人，2020年），或作为一种有效的微调方法（Li和Liang，2021年）。在这项工作中，我们利用T5的提示机制，作为激发模型编码与每个测试例子相关的特定领域特征的方式。</p><h2 id="Any-Domain-Adaptation"><a href="#Any-Domain-Adaptation" class="headerlink" title="Any-Domain Adaptation"></a>Any-Domain Adaptation</h2><h3 id="DA-and-Transfer-Learning"><a href="#DA-and-Transfer-Learning" class="headerlink" title="DA and Transfer Learning"></a>DA and Transfer Learning</h3><p>一个预测任务被定义为 $T = {Y}$，其中 $Y$ 是任务的标签空间。定义 $X$ 为特征空间，$P(X)$ 是 $X$ 上的边缘分布，$P(Y)$ 对 $Y$ 的先验分布。domain 被定义为 $D^T={X, P(X), P(Y),P(Y|X)}$</p><p>DA是迁移学习的一个特殊案例，即过渡性转移学习，其中 $T_S$ 和 $T_T$，即源任务和目标任务，是相同的。</p><p>$D<em>S^T, D^{T}</em>{T}$ 是源域和目标域，至少有一个基础概率分布不同，即$P(X),P(Y) \ or \ P(Y|X)$。</p><p>DA 的目标是从一组源域 ${ D<em>{S_i}}^K</em>{i=1}$ 中学习一个函数 $f$ ，这个函数可以很好地泛化到一组目标域$ { D<em>{T_i} }^M</em>{i=1}$ </p><h3 id="The-Any-Domain-Setting"><a href="#The-Any-Domain-Setting" class="headerlink" title="The Any-Domain Setting"></a>The Any-Domain Setting</h3><p>我们专注于为一个给定的任务建立一个能够适应任何领域的算法。为此，我们假设在训练时对目标领域 $D_T$ 的了解为零。因此，我们稍微修改了无监督多源领域适应的经典设置，假设我们不知道或无法获得目标领域的标记或未标记数据。</p><p>我们只假设可以从K个源域中获得标记的训练数据  $ {D<em>{s_i}}$，其中 $D</em>{S_i} = {(x_t^{S_i}, y_t^{S_i})}$。目标是学习一个仅使用源域数据的模型，该模型可以很好地概括到一个未知的目标域。</p><h3 id="Any-Domain-Adaptation-and-Zero-Shot-Learning"><a href="#Any-Domain-Adaptation-and-Zero-Shot-Learning" class="headerlink" title="Any-Domain Adaptation and Zero-Shot Learning"></a>Any-Domain Adaptation and Zero-Shot Learning</h3><p>我们避免将我们的设置命名为 “Zero-Shot DA”，因为我们认为Zero-Shot学习是一个过载的术语，而且它的用法在不同的作品中是不同的。一方面，GPT-3的作者（Brown等人，2020）用这个术语来表示向未知目标任务 $T^T$和未知领域 $D^T$的转变。</p><p>另一方面，Kodirov等人（2015）假设任务/标签空间漂移，而目标域在训练期间是已知的，Blitzer等人（2009）假设可以访问来自包括目标域在内的各种领域的无标签数据，而Peng等人（2018）使用来自目标域的不同任务数据。我们的问题设置与上述作品不同，但在某种程度上都可以被描述为 “Zero-shot”。在我们看来，这些差异应该被澄清，因此我们为我们的设置提出了一个指定的术语。</p><h2 id="Prompt-based-Autoregressive-DA"><a href="#Prompt-based-Autoregressive-DA" class="headerlink" title="Prompt-based Autoregressive DA"></a>Prompt-based Autoregressive DA</h2><p>正如前面第2节所讨论的，我们认识到基于MoE的方法所提出的解决方案有两个主要限制。(1) 它是不可扩展的。训练的参数总数，对于单个模型来说已经很大了，随着源域数量的增加而线性增长，因为需要为每个域分别训练一个专家模型。自然，这也增加了整体的训练时间；（2）在这种方法中，每个领域都要训练一个单独的模型。直观地说，针对特定领域的专家被调整为针对特定领域的知识，有时会牺牲跨领域的知识，因为跨领域的知识强调不同领域之间的关系。此外，由于领域的划分往往是任意的（例如考虑dvd和电影领域之间的差异），我们不希望将我们的模型严格限制在一个特定的分区，而是鼓励对领域边界采取更宽松的方法。</p><p>因此，我们提出一个单一的模型来编码来自多个领域的信息。我们的模型是这样设计的：<strong>来自新的未知领域的测试样本可以触发模型中最相关的参数</strong>。这样，<strong>我们允许我们的模型在各领域之间共享信息</strong>，<strong>并在测试时使用最相关的信息</strong>。我们的模型受到最近关于自回归语言模型 prompt 机制的研究启发。最近的工作显示了prompt 机制在激发这些模式方面的有效性（§2），尽管不是在DA的背景下。</p><p>我们首先（第4.1节）描述了我们模型的一般结构，然后（第4.2节）介绍了形成我们prompt的领域相关特征。</p><h3 id="The-Model"><a href="#The-Model" class="headerlink" title="The Model"></a>The Model</h3><p>一个多任务模型，<strong>有一个为DRF生成训练的生成头和一个为谣言检测训练的鉴别头</strong>。标记的文字表示DRF，标记的文字表示域名。黑色箭头（→）表示第一个推理步骤，红色箭头（→）表示第二个推理步骤。提出的模型是在4个不同的源域上训练的。Ferguson, Germanwings-crash, Ottawa-shooting, and Sidney-siege，而测试实例来自Charlie-Hebdo域。这些模型识别出例子的来源是悉尼围城，并将其与<strong>3个DRF相关联：人质、咖啡馆和枪手</strong>。</p><p><img src="https://i.loli.net/2021/11/23/mtD8MgoxRXGOSJz.png" alt=""></p><p>我们提出了基于提示的领域适应自回归算法（PADA，图2a）。PADA采用了一个预先训练好的T5语言模型，并<strong>学习生成特定样本的领域相关特征（DRFs），以促进准确的任务预测。</strong>这是通过<strong>一个两步多任务机制实现</strong>的，<strong>首先生成一个DRF集以形成一个prompt，然后预测任务标签。</strong></p><p>形式上，假设一个输入样本  $ (x_i, yi) \sim S_i $ ，这样 $x_i$ 是输入文本，$y_i$ 是任务label，$S_i$是这个例子的领域。</p><p> <strong>对于输入的 $x_i$，PADA被训练成首先生成 $N_i$，即域名</strong>，然后是 $R_i$，即 $x_i$ 的DRF签名，<strong>并根据这个 prompt 来预测标签$y_i$。</strong>在测试时，<strong>当模型遇到一个来自未知领域的例子时，它会产生一个 prompt，该 prompt 可能由一个或多个域名以及一个或多个源域的DRF集的特征组成，并基于该 prompt 预测任务标签。</strong></p><p><img src="https://i.loli.net/2021/11/23/ot5qEnNY1HCzx4K.png" alt=""></p><p>考虑到图1中的例子，它描述了一个情感分类模型，在餐馆、家庭家具、电子设备和电影等源域上进行训练。该模型观察到一个来自航空公司领域的测试例子，这是一个以前没有见过的领域，模型不知道其名称。该模型首先生成最适合这个例子的训练域的名称，在这个例子中是餐馆。然后，它继续生成 “食物 “和 “椅子”，这两个词分别与餐馆和家庭家具领域有关。最后，鉴于这一 prompt，该模型预测了该例子的（负面）情绪。</p><p><strong>为了将 prompt 生成任务与判别分类任务分开，我们在一个多任务框架内训练我们的模型</strong>。<strong>根据样本的prompt，PADA被训练成执行两个任务。一个是生成 prompt，由例子领域的DRF集的特征组成，另一个是预测样本的标签。</strong></p><p>对<strong>于第一个生成任务，模型接收带有特殊prompt “域：”的例子，这为模型生成 $N_i$ 和 $R_i$ 提供了条件。</strong>请注意，$R_i$是一组从 $S_i$ 的DRF集衍生出来的特征，如第4.2节所述，训练的样本被自动注释了它们的 $R_i$。对于第二个判别性任务，模型收到一个 prompt ，由 $N_i$ 和 $R_i$ 组成，其任务是预测 $y_i$。</p><p>按照T5的多任务训练协议，我们对每个任务的样本进行混合。为此，我们定义了一个任务比例混合参数 $α$。 训练集中的每个例子都以 $α$ 的概率形成生成性任务的样本，以 $1-α$ 的概率形成鉴别性任务的样本。$α$ 的值越大，模型对生成性任务的训练就越多。</p><p>PADA以生成的 prompt 为条件进行分类。为了评估这一条件的效果，我们还考虑了一个更简单的PADA变体，它联合执行分类和生成任务，但不使用生成任务的输出作为分类任务的 prompt 。我们把这个变体命名为PADA-NC，以强调判别任务不以生成部分的输出为条件。PADA和PADA-NC之间的区别在图2中得到了强调。</p><p>我们方法的核心是<strong>巧妙地选择每个领域的DRF集</strong>。我们接下来讨论这些特征和它们的选择过程。</p><h3 id="Domain-Related-Features"><a href="#Domain-Related-Features" class="headerlink" title="Domain Related Features"></a>Domain Related Features</h3><p><strong>对于每个领域，我们定义DRF集，使这些特征为该领域提供一个语义签名</strong>。重要的是，<strong>如果两个领域有共同的语义，例如餐馆和烹饪领域，我们希望它们的DRFs在语义上是重叠的</strong>。<strong>由于每个训练样本的 prompt 由其领域的DRF集的特征子集组成，我们也应该决定一个 prompt 生成规则，可以用其相关的特征来注释这些训练样本。</strong></p><p>为了反映该领域的语义，DRF应该经常出现在该领域。<strong>此外，相对于所有其他领域，它们在该特定领域中应该是非常普遍的。尽管DRF在一个特定的领域中很突出，但它也可以与其他领域相关。例如，考虑图2中的例子。人质 “这个词与 “Charlie-Hebdo “领域高度相关，而且确实是其DRFs之一。然而，这个词也与 “Sydney-Siege “域相关</strong>，这是Rumour Detection数据集的另一个域（Zubiaga等人，2016）。此外，<strong>由于这两个领域都与类似的事件有关，前者的DRF集包含恐怖分子的特征，后者的DRF集包含枪手的特征</strong>，这并不令人惊讶。<strong>这些特征的相似性促进了我们模型中的参数共享。</strong></p><p>我们<strong>对每个源域的DRF集定义如下。让第 $j$ 个源域（$S_j$）的样本（文本）被标记为1，所有其他域（ $S\setminus S_j$ ）的例子被标记为 0。</strong>我们首先<strong>计算所有 tokens 和这个二元变量之间的相互信息（MI）</strong>，<strong>并选择 MI 得分最高的 $l$ 个token。</strong>注意，<strong>MI标准可能会促进与（ $S\setminus S_j$ ）高度相关的标记</strong>，<strong>而不是与 $S_j$ 。</strong>因此，<strong>我们根据以下条件来过滤 $l$ 个token:</strong></p><script type="math/tex; mode=display">\frac{C_{S\setminus S_j}(n)}{C_{S_j}(n)} \le \rho , C_{S_j}(n) \gt 0</script><p>其中 $C<em>{S_j}(n)$ 是 $S_j$ 中n-gram $n$ 的计数， $C</em>{S\setminus S_j}(n)$ 是在所有源域中除了 $ S_j$ 的 n-gram 计数，$ρ$ 是 n-gram 频率比参数。</p><p>直观地说，<strong>$ρ$ 越小，我们就越确定这个n-gram与 $S_j$ 特别相关，与其他领域相比。由于 $S_j$ 中的样本数量远远小于  $S\setminus S_j$  中的样本数量，</strong>我们选择 $ρ≥1$ ，但不允许它过大。因此，这个标准允许与 $S_j$ 相关但也与其他源域相关的特征成为 $S_j$ 的DRF集的一部分。我们用 $R_j$ 来表示第 $j$ 个域的DRF集。</p><p>给定一个来自领域 $j$ 的训练样本 $i$ ，我们<strong>从 $R_j$ 中选择与该样本最相关的 $m$ 个特征来形成其 prompt</strong>。为此，我们计算DRF特征的T5嵌入 和 每个样本的T5嵌入 之间的欧几里得距离。然后，我们根据分数对这个列表进行排序，并选择最重要的 $m$ 个特征。（在这个计算中，我们考虑了T5在其预训练期间学到的非语境嵌入。在我们的实验中，我们只考虑单字（单词）作为DRFs。）</p><p>总而言之，我们<strong>针对特定领域的 DRF 集提取和训练样本的 prompt 注释的方法，展示了三个有吸引力的特性</strong>。首先，<strong>每个样本都有它自己独特的prompt</strong> 。其次，<strong>我们的 prompt 将每个训练样本映射到其领域的语义空间。</strong>最后，<strong>特定领域的DRF集可能会在其语义上重叠，要么包括相同的token，要么包括具有类似含义的token。</strong>这样，<strong>与单独的域名相比，它们提供了一个更细微的领域签名。</strong>在<strong>推理阶段，模型可以生成一个特定的样本prompt，该提示由不同源域的DRF集的特征组成</strong>，这一点后来被使用。</p><h2 id="Experimental-Setup"><a href="#Experimental-Setup" class="headerlink" title="Experimental Setup"></a>Experimental Setup</h2><p>我们的主要模型是PADA：这个<strong>多任务模型首先生成域名和领域相关的特征，形成一个prompt，然后用这个prompt来预测任务标签</strong>。我们将其与两种类型的模型进行比较。(a) 基于T5的基线，对应于多源DA工作中提出的想法，以及其他最近的最先进的模型；以及(b) 使用PADA特定部分的消融模型，以强调其组成部分的重要性。</p><h3 id="Baseline-Models"><a href="#Baseline-Models" class="headerlink" title="Baseline Models"></a>Baseline Models</h3><ul><li><em>Content-CRF</em> ： 一个为谣言检测而训练的CRF模型。每个预测都以相关的推文以及之前的推文为条件，同时结合了基于内容和社会特征。</li><li><em>Transformer-based Mixture of Experts</em>： 对于每个源域，在该域的训练集上训练一个单独的基于变压器的DistilBERT专家模型（Sanh等人，2019），并在所有源域的数据上训练另一个模型。在测试时，计算这些模型的类别概率的平均值，并选择最高概率的类别。这个模型被Wright和Augenstein（2020）命名为MoE-avg，并证明了在谣言检测方面取得了最先进的性能（该论文将CCRF的重新结果报告为其之前的最先进性能）。</li><li><em>T5-MoE</em> ：一个基于T5的MoE集合模型。对于每个源域，一个单独的预训练的T5模型在该域的训练集上进行微调（即一个领域专家模型）。在推理过程中，模型的最终预测是用Tr-MoE中相同的平均程序决定的。</li><li><em>T5-No-Domain-Adaptation (T5-NoDA)</em> ：一个预先训练好的T5模型，它向PADA（见下文）中使用的同一任务分类器提供信息，以预测任务标签。 在每个DA设置中，该模型是在所有源域的训练数据上训练的。</li><li><em>T5-Domain-Adversarial-Network (T5-DAN)</em> ：一个将T5-NoDA与对抗性领域分类器整合的模型，以学习领域不变的表征（Ganin和Lempitsky，2015）。</li><li><em>T5-Invariant-Risk-Minimization (T5-IRM)</em> ：一个基于T5的模型，它对每个领域有不同的最佳线性分类器的特征分布进行惩罚。IRM（Arjovsky等人，2019）是一个成熟的机器学习基线，用于超越多源分布的泛化（Koh等人，2020）。该模型是在所有源域的训练数据上训练的。</li><li><em>T5-UpperBound (T5-UB)</em> ：一个与T5-NoDA结构相同的域内模型。它在所有领域的训练数据上进行训练，在每个领域的开发数据上进行测试。我们将其性能视为所有DA设置中平均目标性能的上限，对于我们设置中的任何基于T5的模型。</li></ul><h3 id="Ablation-Models"><a href="#Ablation-Models" class="headerlink" title="Ablation Models"></a>Ablation Models</h3><ul><li>PADA-DN 我们的PADA模型的一个简化变体，它只给输入文本分配一个域名作为prompt。由于域名在测试时是未知的，我们为每个测试样本创建多个变体，每个变体都有一个训练域名作为prompt。对于模型的最终预测，我们遵循与Tr-MoE和T5-MoE相同的平均化过程。</li><li>PADA-NC 一个类似于PADA的多任务模型，只是它同时生成特定于样本的域名和DRF prompt并预测任务标签。这个模型不以提示为条件进行任务预测。</li></ul><h3 id="Implementation-Details"><a href="#Implementation-Details" class="headerlink" title="Implementation Details"></a>Implementation Details</h3><p>对于所有实现的模型，我们都使用了 “Hugging-Face “ Transformers库。基于T5的文本分类模型没有遵循Raffel等人（2020）最初描述的程序。相反，我们在T5编码器之上添加了一个简单的 1D-CNN分类器 来预测任务标签（图2）。</p><p>该分类器中的过滤器数量为32个，过滤器大小为9。基于T5的模型的生成部分与原始T5的生成部分相同。我们基于T5的特征预测模型将序列标记作为一个序列到序列的任务，采用Raffel等人（2020）的文本到文本方法，为每个输入标记生成一个’B’（开始）、’I’（进入）或’O’（退出）标记。 除了这一变化外，这些模型与基于T5的文本分类模型完全相同。</p><p>我们对所有的文本分类模型进行5个 epochs 的训练，对所有的序列标签模型进行60个 epoch的训练，并根据开发数据的表现制定早期停止的标准。我们对所有模型使用交叉熵损失函数，用ADAM优化器（Kingma和Ba，2015）优化其参数。我们对文本分类采用32个批处理规模，对序列标签采用24个批处理规模，预热比为0.1，学习率为5 e10-5。所有基于T5的模型的最大输入和输出长度被设定为128个符号。我们对较短的序列进行填充，并将较长的序列截断到最大输入长度。</p><p>对于PADA，我们调整α（例子比例—混合物，见§4.1）参数，考虑到{0.1, 0.25, 0.5, 0.75, 0.9}的数值范围。）选择的数值是 αrumour = 0.75，αmnli = 0.1和αabsa = 0.1。对于每个例子，我们选择与之最相关的前m = 5个DRF，对其进行提示。</p><p>对于基于T5的模型的生成部分，我们用Diverse Beam Search算法（Vijayaku- mar等人，2016）进行推理，考虑以下超参数。我们产生了5个候选人，使用10个波束大小，5个波束组，多样性惩罚值为1.5。DRF提取程序（§4.2）的l和ρ参数被调整为1000和1.5，适用于所有领域。</p><h2 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h2><p>Binary-F1测量的是正类的F1得分。它对正类感兴趣的不平衡数据集很有用。在谣言检测数据集中，34%的例子属于正类。</p><p><img src="https://i.loli.net/2021/11/23/z4rZXTJYnOytFRE.png" alt=""></p><p>表2显示了我们的结果。 PADA在10个设置中的6个中优于所有的模型，在Rumour Detection和MNLI中分别比T5-NoDA的平均性能提高了3.5%和1.3%，T5-NoDA是不属于我们PADA框架的最佳模型。此外，在10个设置中的9个中，PADA模型是表现最好的模型之一。有趣的是，不执行任何DA的T5-NoDA的性能超过了所有不属于PADA系列的模型，包括MoE模型（平均和大多数模型之间的比较）。</p><p>虽然不同任务之间的性能提升不同，但它们部分源于每个任务中源域和目标域之间的不同性能差距。回顾一下，我们认为T5-UB在谣言检测（82.8%）和MNLI（80.8%）的开发集上的表现，是任何基于T5的模型在所有DA设置中平均目标表现的上限。当考虑到这个上限和T5-NoDA之间的差距时（Rumour Detection为65.8%，MNLI为78.3%），PADA将Rumour Detection的错误率降低了21%，MNLI为52%。事实上，PADA在这两项任务中获得的改进是巨大的。</p><p>虽然不同任务之间的性能提升不同，但它们部分源于每个任务中源域和目标域之间的不同性能差距。回顾一下，我们认为T5-UB在谣言检测（82.8%）和MNLI（80.8%）的开发集上的表现，是任何基于T5的模型在所有DA设置中平均目标表现的上限。当考虑到这个上限和T5-NoDA之间的差距时（Rumour Detection为65.8%，MNLI为78.3%），PADA将Rumour Detection的错误率降低了21%，MNLI为52%。事实上，PADA在这两项任务中获得的改进是巨大的。<br>与MoE相比，PADA的优势并不局限于改进预测。特别是，对于PADA，我们训练一个单一的模型，而对于MoE，我们为每个源域训练一个独特的模型，因此MoE框架中的参数数量随着源域的数量而线性增加。例如，在我们的设置中，Tr-MoE训练了五个DistilBERT模型（每个源域一个，所有源域一个），导致5 - 66M = 330M参数。相比之下, PADA模型保留了T5的220M参数, 而不考虑源域的数量。</p><p>我们的研究结果显示，在10个环境中的9个中，PADA及其变体PADA-DN和PADA-NC优于所有其他模型。特别是，PADA在10个环境中的7个环境中优于非PADA模型，PADA-NC在6个环境中优于这些模型，而PADA-DN在5个环境中优于这些模型。此外，PADA在所有的谣言检测设置中和5个MNLI设置中的3个中优于PADA-DN变体，而其PADA-NC变体在10个设置中的8个中优于PADA-DN。这些结果突出了我们设计选择的重要性。(a) 在特定例子的提示中包括DRFs，使它们能够表达源域和测试例子之间的关系（PADA vs PADA-DN）；以及(b) 利用自回归组件，其中生成的DRF提示被任务分类组件使用（PADA vs PADA-NC）。</p><h3 id="Performance-Shifts-between-Source-and-Target"><a href="#Performance-Shifts-between-Source-and-Target" class="headerlink" title="Performance Shifts between Source and Target"></a>Performance Shifts between Source and Target</h3><p><img src="https://i.loli.net/2021/11/23/x1Lza6UsSTZbhk4.png" alt=""></p><p>当DA方法提高了模型在目标域的性能时，这可能会导致源域和目标域之间的性能差距增加或减少。如果一个模型在其源训练域和未见过的目标域的表现相似，其源域的表现也可以为其未来在这些未见过的域的表现提供一个重要的指示。因此，在我们的设置中，如果未来的目标域是未知的，我们认为这种性能的稳定性是一个理想的属性。</p><p>图3显示了三个热图，描述了每个模型在源域和目标域之间的性能变化。如第6节所述，我们通过计算所有源域开发样本的F1得分和目标域测试集的表现来衡量每个模型的域内性能。然后，我们计算源域和目标域性能指标之间的差异，并对实验中表现最好的模型进行重新定位。总的趋势是明确的：PADA不仅在目标域表现更好，而且它还大大减少了源-目标性能的差距。虽然不是DA模型的T5-NoDA引发了最大的平均绝对性能转变—Rumour Detection为17%，MNLI为4.3%，Aspect Prediction为34%，但PADA的平均绝对性能转变分别为8.7%、3.5%和26%。</p><h2 id="Discussion"><a href="#Discussion" class="headerlink" title="Discussion"></a>Discussion</h2><p>我们解决了在训练时不知道目标域的情况下的多源域适应问题。这种设置的有效模型可以应用于任何目标域，对目标域没有任何数据再要求，而且模型参数的数量不会随着源或目标域的数量而增加。我们的算法PADA利用了T5自回归语言模型的提示机制，将测试例子映射到源域所跨越的语义空间。<br>我们对三个任务和十四个多源适应性设置的实验结果表明，与强大的替代方案相比，我们的方法是有效的，同时也表明了模型组件和我们的设计选择的重要性。此外，与MoE范式相比，PADA提供了一个统一的模型，即为每个源域训练一个模型。从直觉上讲，这种方法似乎也更符合认知规律—一个单一的模型试图使自己适应新的输入领域，而不是在每个领域采用一个独立的模型。<br>PADA的提示生成机制自然受到它所训练的源域集的限制。这可能会产生次优的DRF，而这些测试例子来自于与任何源域在语义上极不相关的领域。此外，我们没有直接用主要预测任务来优化提示生成过程，这也可能导致次优的DRF生成。在未来的工作中，我们希望改进我们方法的这些方面，并探索在一个单一模型中容纳多个任务和领域的自然扩展。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;PADA-A-Prompt-based-Autoregressive-Approach-for-Adaptation-to-Unseen-Domains&quot;&gt;&lt;a href=&quot;#PADA-A-Prompt-based-Autoregressive-Approach-</summary>
      
    
    
    
    
    <category term="context detection" scheme="http://example.com/tags/context-detection/"/>
    
  </entry>
  
  <entry>
    <title>二叉树刷题1</title>
    <link href="http://example.com/2021/11/19/%E4%BA%8C%E5%8F%89%E6%A0%91%E5%88%B7%E9%A2%981/"/>
    <id>http://example.com/2021/11/19/%E4%BA%8C%E5%8F%89%E6%A0%91%E5%88%B7%E9%A2%981/</id>
    <published>2021-11-19T11:17:33.000Z</published>
    <updated>2021-11-26T01:55:29.841Z</updated>
    
    <content type="html"><![CDATA[<h1 id="二叉树刷题1"><a href="#二叉树刷题1" class="headerlink" title="二叉树刷题1"></a>二叉树刷题1</h1><p>[TOC]</p><h2 id="树的基础"><a href="#树的基础" class="headerlink" title="树的基础"></a>树的基础</h2><h3 id="102-二叉树的层序遍历"><a href="#102-二叉树的层序遍历" class="headerlink" title="102. 二叉树的层序遍历"></a><a href="https://leetcode-cn.com/problems/binary-tree-level-order-traversal/">102. 二叉树的层序遍历</a></h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> List&lt;List&lt;Integer&gt;&gt; levelOrder(TreeNode root) &#123;</span><br><span class="line">        List&lt;List&lt;Integer&gt;&gt; res = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        <span class="keyword">if</span>(root == <span class="keyword">null</span>) <span class="keyword">return</span> res;</span><br><span class="line"></span><br><span class="line">        Queue&lt;TreeNode&gt; queue = <span class="keyword">new</span> LinkedList&lt;&gt;();</span><br><span class="line">        queue.offer(root);</span><br><span class="line">        <span class="keyword">while</span>(!queue.isEmpty())&#123;</span><br><span class="line">            List&lt;Integer&gt; level = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">            <span class="keyword">int</span> currentLevelSize = queue.size();</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>; i&lt;= currentLevelSize; ++i)&#123;</span><br><span class="line">                TreeNode node = queue.poll();</span><br><span class="line">                level.add(node.val);</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span>(node.left!=<span class="keyword">null</span>)&#123;</span><br><span class="line">                    queue.offer(node.left);</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span>(node.right!=<span class="keyword">null</span>)&#123;</span><br><span class="line">                    queue.offer(node.right);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            res.add(level);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="107-二叉树的层序遍历-II"><a href="#107-二叉树的层序遍历-II" class="headerlink" title="107. 二叉树的层序遍历 II"></a><a href="https://leetcode-cn.com/problems/binary-tree-level-order-traversal-ii/">107. 二叉树的层序遍历 II</a></h3><p>从根节点开始搜索，每次遍历同一层的全部节点，使用一个列表存储该层的节点值。</p><p>如果要求从上到下输出每一层的节点值，做法很直观，在遍历完一层节点之后，将存储该层节点值的列表添加到结果列表的尾部。</p><p>但这道题要求从下到上输出每一层，只要对上述操作稍作修改即可；在遍历完一层节点之后，将存储该节点值的列表添加到结果列表的头部。</p><p>为了降低在结果列表的头部添加一层节点值的列表的时间复杂度，结果列表可以使用链表的结构，在链表头部添加一层节点值的列表的时间复杂度是 O(1)O(1)。在 Java 中，由于我们需要返回的 List 是一个接口，这里可以使用链表实现；而 C++ 或 Python 中，我们需要返回一个 vector 或 list，它不方便在头部插入元素（会增加时间开销），所以我们可以先用尾部插入的方法得到从上到下的层次遍历列表，然后再进行反转。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> List&lt;List&lt;Integer&gt;&gt; levelOrderBottom(TreeNode root) &#123;</span><br><span class="line">        List&lt;List&lt;Integer&gt;&gt; res = <span class="keyword">new</span> LinkedList&lt;&gt;();</span><br><span class="line">        <span class="keyword">if</span>(root == <span class="keyword">null</span>) <span class="keyword">return</span> res;</span><br><span class="line"></span><br><span class="line">        Queue&lt;TreeNode&gt; queue = <span class="keyword">new</span> LinkedList&lt;&gt;();</span><br><span class="line">        queue.offer(root);</span><br><span class="line">        <span class="keyword">while</span>(!queue.isEmpty())&#123;</span><br><span class="line">            List&lt;Integer&gt; level = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">            <span class="keyword">int</span> size = queue.size();</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;size;i++)&#123;</span><br><span class="line">                TreeNode node = queue.poll();</span><br><span class="line">                level.add(node.val);</span><br><span class="line">                TreeNode left = node.left, right =node.right;</span><br><span class="line">                <span class="keyword">if</span>(left!=<span class="keyword">null</span>)&#123;</span><br><span class="line">                    queue.offer(left);</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span>(right!=<span class="keyword">null</span>)&#123;</span><br><span class="line">                    queue.offer(right);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            res.add(<span class="number">0</span>, level);</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="二叉树的遍历"><a href="#二叉树的遍历" class="headerlink" title="二叉树的遍历"></a>二叉树的遍历</h2><h3 id="前中后序"><a href="#前中后序" class="headerlink" title="前中后序"></a>前中后序</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> List&lt;Integer&gt; <span class="title">preorderTraversal</span><span class="params">(TreeNode root)</span> </span>&#123;</span><br><span class="line">        List&lt;Integer&gt; res = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        preorder(root, res);</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">preorder</span><span class="params">(TreeNode root, List&lt;Integer&gt; res)</span></span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(root == <span class="keyword">null</span>) <span class="keyword">return</span>;</span><br><span class="line">        res.add(root.val);</span><br><span class="line">        preorder(root.left, res);</span><br><span class="line">        preorder(root.right, res);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>迭代</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> List&lt;Integer&gt; <span class="title">preorderTraversal</span><span class="params">(TreeNode root)</span> </span>&#123;</span><br><span class="line">        List&lt;Integer&gt; res = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        <span class="keyword">if</span>(root==<span class="keyword">null</span>) <span class="keyword">return</span> res;</span><br><span class="line"></span><br><span class="line">        Deque&lt;TreeNode&gt; stack = <span class="keyword">new</span> LinkedList&lt;&gt;();</span><br><span class="line">        TreeNode node = root;</span><br><span class="line">        <span class="keyword">while</span>(!stack.isEmpty() || node!=<span class="keyword">null</span>)&#123;</span><br><span class="line">            <span class="keyword">while</span>(node!=<span class="keyword">null</span>)&#123;</span><br><span class="line">                res.add(node.val);</span><br><span class="line">                stack.push(node);</span><br><span class="line">                node = node.left;</span><br><span class="line">            &#125;</span><br><span class="line">            node = stack.pop();</span><br><span class="line">            node = node.right;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> List&lt;Integer&gt; <span class="title">inorderTraversal</span><span class="params">(TreeNode root)</span> </span>&#123;</span><br><span class="line">        List&lt;Integer&gt; res = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        <span class="keyword">if</span>(root==<span class="keyword">null</span>) <span class="keyword">return</span> res;</span><br><span class="line">        Deque&lt;TreeNode&gt; stack = <span class="keyword">new</span> LinkedList&lt;&gt;();</span><br><span class="line">        TreeNode node = root;</span><br><span class="line">        <span class="keyword">while</span>(!stack.isEmpty() || node!=<span class="keyword">null</span>)&#123;</span><br><span class="line">            <span class="keyword">while</span>(node!=<span class="keyword">null</span>)&#123;</span><br><span class="line">                stack.push(node);</span><br><span class="line">                node = node.left;</span><br><span class="line">            &#125;</span><br><span class="line">            node = stack.pop();</span><br><span class="line">            res.add(node.val);</span><br><span class="line">            node = node.right;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">  </span><br><span class="line">   <span class="function"><span class="keyword">public</span> List&lt;Integer&gt; <span class="title">postorderTraversal</span><span class="params">(TreeNode root)</span> </span>&#123;</span><br><span class="line">        List&lt;Integer&gt; res = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        <span class="keyword">if</span>(root==<span class="keyword">null</span>) <span class="keyword">return</span> res;</span><br><span class="line"></span><br><span class="line">        Deque&lt;TreeNode&gt; stack = <span class="keyword">new</span> LinkedList&lt;&gt;();</span><br><span class="line">        TreeNode prev = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">while</span>(root!=<span class="keyword">null</span> || !stack.isEmpty())&#123;</span><br><span class="line">            <span class="keyword">while</span>(root!=<span class="keyword">null</span>)&#123;</span><br><span class="line">                stack.push(root);</span><br><span class="line">                root = root.left;</span><br><span class="line">            &#125;</span><br><span class="line">            root = stack.pop();</span><br><span class="line">            <span class="keyword">if</span>(root.right==<span class="keyword">null</span> || root.right==prev)&#123;</span><br><span class="line">                res.add(root.val);</span><br><span class="line">                prev = root;</span><br><span class="line">                root = <span class="keyword">null</span>;</span><br><span class="line">            &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                stack.push(root);</span><br><span class="line">                root = root.right;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><h3 id="112-路径总和"><a href="#112-路径总和" class="headerlink" title="112. 路径总和"></a><a href="https://leetcode-cn.com/problems/path-sum/">112. 路径总和</a></h3><h4 id="DFS"><a href="#DFS" class="headerlink" title="DFS"></a>DFS</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">hasPathSum</span><span class="params">(TreeNode root, <span class="keyword">int</span> sum)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(root==<span class="keyword">null</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(root.left==<span class="keyword">null</span> &amp;&amp; root.right==<span class="keyword">null</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span> root.val == sum;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> hasPathSum(root.left, sum - root.val) || hasPathSum(root.right, sum - root.val);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="BFS"><a href="#BFS" class="headerlink" title="BFS"></a>BFS</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">hasPathSum</span><span class="params">(TreeNode root, <span class="keyword">int</span> sum)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(root == <span class="keyword">null</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        Queue&lt;TreeNode&gt; queNode = <span class="keyword">new</span> LinkedList&lt;TreeNode&gt;();</span><br><span class="line">        Queue&lt;Integer&gt; queVal = <span class="keyword">new</span> LinkedList&lt;Integer&gt;();</span><br><span class="line">        queNode.offer(root);</span><br><span class="line">        queVal.offer(root.val);</span><br><span class="line">        <span class="keyword">while</span>(!queNode.isEmpty())&#123;</span><br><span class="line">            TreeNode now = queNode.poll();</span><br><span class="line">            <span class="keyword">int</span> temp = queVal.poll();</span><br><span class="line">            <span class="keyword">if</span>(now.left == <span class="keyword">null</span> &amp;&amp; now.right==<span class="keyword">null</span>)&#123;</span><br><span class="line">                <span class="keyword">if</span>(temp==sum)&#123;</span><br><span class="line">                    <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span>(now.left != <span class="keyword">null</span>)&#123;</span><br><span class="line">                queNode.offer(now.left);</span><br><span class="line">                queVal.offer(now.left.val + temp);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span>(now.right !=<span class="keyword">null</span>)&#123;</span><br><span class="line">                queNode.offer(now.right);</span><br><span class="line">                queVal.offer(now.right.val + temp);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="113-路径总和-II"><a href="#113-路径总和-II" class="headerlink" title="113. 路径总和 II"></a><a href="https://leetcode-cn.com/problems/path-sum-ii/">113. 路径总和 II</a></h3><p>问完成一件事情的所有解决方案，一般采用回溯算法（<strong>深度优先遍历</strong>）完成。做回溯算法问题一般先画图，好在这就是一个树形问题，题目已经给我们画好了示意图。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> List&lt;List&lt;Integer&gt;&gt; pathSum(TreeNode root, <span class="keyword">int</span> targetSum) &#123;</span><br><span class="line">        List&lt;List&lt;Integer&gt;&gt; res = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        <span class="keyword">if</span>(root == <span class="keyword">null</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span> res;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        Deque&lt;Integer&gt; path = <span class="keyword">new</span> ArrayDeque&lt;&gt;();</span><br><span class="line">        dfs(root, targetSum, path,res);</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">dfs</span><span class="params">(TreeNode node, <span class="keyword">int</span> sum, Deque&lt;Integer&gt; path, List&lt;List&lt;Integer&gt;&gt; res)</span></span>&#123;</span><br><span class="line">        <span class="comment">// 递归终止条件1</span></span><br><span class="line">        <span class="keyword">if</span>(node == <span class="keyword">null</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 递归终止条件2</span></span><br><span class="line">        <span class="keyword">if</span>(node.val == sum &amp;&amp; node.left==<span class="keyword">null</span> &amp;&amp; node.right==<span class="keyword">null</span>)&#123;</span><br><span class="line">            <span class="comment">//当前节点的值还没添加到列表中，所以要先添加，再移除</span></span><br><span class="line">            path.addLast(node.val);</span><br><span class="line">            res.add(<span class="keyword">new</span> ArrayList&lt;&gt;(path));</span><br><span class="line">            path.removeLast();</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        path.addLast(node.val);</span><br><span class="line">        dfs(node.left, sum-node.val, path, res);</span><br><span class="line">        <span class="comment">// 进入左右分支的 path 是一样的，这里不用写下面两行，因为一定会调用到 path.removeLast();</span></span><br><span class="line">        <span class="comment">// path.removeLast();</span></span><br><span class="line">        <span class="comment">// path.addLast(node.val);</span></span><br><span class="line">        dfs(node.right, sum-node.val, path, res);</span><br><span class="line">        path.removeLast();</span><br><span class="line">    &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 由于先减去了当前非空节点的值，递归终止条件写 sum==0</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">dfs</span><span class="params">(TreeNode node, <span class="keyword">int</span> sum, Deque&lt;Integer&gt; path, List&lt;List&lt;Integer&gt;&gt; res)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 递归终止条件 1：遇到空结点不再递归调用</span></span><br><span class="line">        <span class="keyword">if</span> (node == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 沿途结点必须选择，这个时候要做两件事：1、sum 减去这个结点的值；2、添加到 path 里</span></span><br><span class="line">        sum -= node.val;</span><br><span class="line">        path.addLast(node.val);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 递归终止条件 2：遇到叶子结点，sum 恰好为 0，说明从根结点到叶子结点的路径是一个符合要求的解</span></span><br><span class="line">        <span class="keyword">if</span> (sum == <span class="number">0</span> &amp;&amp; node.left == <span class="keyword">null</span> &amp;&amp; node.right == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="comment">// path 全局只有一份，必须做拷贝</span></span><br><span class="line">            res.add(<span class="keyword">new</span> ArrayList&lt;&gt;(path));</span><br><span class="line">            <span class="comment">// 注意：这里 return 之前必须重置</span></span><br><span class="line">            path.removeLast();</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        pathSum(node.left, sum, path, res);</span><br><span class="line">        pathSum(node.right, sum, path, res);</span><br><span class="line">        <span class="comment">// 递归完成以后，必须重置变量</span></span><br><span class="line">        path.removeLast();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="437-路径总和-III"><a href="#437-路径总和-III" class="headerlink" title="437. 路径总和 III"></a><a href="https://leetcode-cn.com/problems/path-sum-iii/">437. 路径总和 III</a></h3><h4 id="法一-深度优先遍历"><a href="#法一-深度优先遍历" class="headerlink" title="法一 深度优先遍历"></a>法一 深度优先遍历</h4><p>穷举所有可能，访问每一个节点node，检测以 node 为起始点且向下延伸的路径有多少种。递归遍历每个节点的所有可能的路径，然后将这些路径数目加起来即为返回结果。</p><ul><li>首先定义 $rootSum(p, val)$ 表示以节点 $p$ 为起点向下且满足路径总和为 $val$ 的路径数目。我们队二叉树上每个节点 $p$ 求出 $rootSum(p,targetSum)$，然后对这些路径数目求和为返回结果</li><li>对节点 $p$ 求 $rootSum(p, targetSum)$时，以当前节点 $p$ 为目标路径的起点递归向下进行搜索。假设当前的节点$p$的值为$val$ ，对左子树和右子树进行递归搜索</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">pathSum</span><span class="params">(TreeNode root, <span class="keyword">int</span> targetSum)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(root == <span class="keyword">null</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">int</span> ret = rootSum(root, targetSum);</span><br><span class="line">        ret += pathSum(root.left, targetSum);</span><br><span class="line">        ret += pathSum(root.right, targetSum);</span><br><span class="line">        <span class="keyword">return</span> ret;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">rootSum</span><span class="params">(TreeNode root, <span class="keyword">int</span> targetSum)</span></span>&#123;</span><br><span class="line">        <span class="keyword">int</span> ret = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">if</span>(root == <span class="keyword">null</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">int</span> val = root.val;</span><br><span class="line">        <span class="keyword">if</span>(val == targetSum)&#123;</span><br><span class="line">            ret++;</span><br><span class="line">        &#125;</span><br><span class="line">        ret += rootSum(root.left, targetSum-val);</span><br><span class="line">        ret += rootSum(root.right, targetSum-val);</span><br><span class="line">        <span class="keyword">return</span> ret;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="方法二-前缀和"><a href="#方法二-前缀和" class="headerlink" title="方法二 前缀和"></a>方法二 前缀和</h4><p>上一解法存在许多重复计算，定义节点的前缀和为：由根节点到当前节点的路径上所有节点的和。</p><p>利用先序遍历二叉树，记录下根节点 $root$ 到当前节点 $p$ 的路径上除当前节点以外所有节点的前缀和，在已保存的路径前缀和中查找是否存在前缀和刚好等于当前节点到根节点的前缀和 $curr - targetSum$</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">pathSum</span><span class="params">(TreeNode root, <span class="keyword">int</span> targetSum)</span> </span>&#123;</span><br><span class="line">      Map&lt;Integer, Integer&gt; prefix = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">      <span class="comment">// 前缀和为0的一条路径</span></span><br><span class="line">      prefix.put(<span class="number">0</span>,<span class="number">1</span>);</span><br><span class="line">      <span class="comment">// 前缀和的递归回溯</span></span><br><span class="line">      <span class="keyword">return</span> recursionPathSum(root, prefix, targetSum, <span class="number">0</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">recursionPathSum</span><span class="params">(TreeNode node, Map&lt;Integer,Integer&gt; prefix, <span class="keyword">int</span> target, <span class="keyword">int</span> currSum)</span></span>&#123;</span><br><span class="line">      <span class="keyword">if</span>(node==<span class="keyword">null</span>)&#123;</span><br><span class="line">          <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">int</span> res = <span class="number">0</span>;</span><br><span class="line">      currSum += node.val;</span><br><span class="line"></span><br><span class="line">      <span class="comment">//---核心代码</span></span><br><span class="line">      <span class="comment">// 看看root到当前节点这条路上是否存在节点前缀和加target为currSum的路径</span></span><br><span class="line">      <span class="comment">// 当前节点-&gt;root节点反推，有且仅有一条路径，如果此前有和为currSum-target,而当前的和又为currSum,两者的差就肯定为target了</span></span><br><span class="line">      <span class="comment">// currSum-target相当于找路径的起点，起点的sum+target=currSum，当前点到起点的距离就是target</span></span><br><span class="line">      res += prefix.getOrDefault(currSum - target, <span class="number">0</span>);</span><br><span class="line">      <span class="comment">// 更新路径上当前节点前缀和的个数</span></span><br><span class="line">      prefix.put(currSum, prefix.getOrDefault(currSum, <span class="number">0</span>)+<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">      <span class="comment">// 进入下一层</span></span><br><span class="line">      res += recursionPathSum(node.left, prefix, target, currSum);</span><br><span class="line">      res += recursionPathSum(node.right, prefix, target, currSum);</span><br><span class="line"></span><br><span class="line">      <span class="comment">// 回到本层，恢复状态，去除当前节点的前缀和数量</span></span><br><span class="line">      prefix.put(currSum, prefix.get(currSum) - <span class="number">1</span>);</span><br><span class="line">      <span class="keyword">return</span> res;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><h3 id="129-求根节点到叶节点数字之和"><a href="#129-求根节点到叶节点数字之和" class="headerlink" title="129. 求根节点到叶节点数字之和"></a><a href="https://leetcode-cn.com/problems/sum-root-to-leaf-numbers/">129. 求根节点到叶节点数字之和</a></h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">sumNumbers</span><span class="params">(TreeNode root)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> dfs(root, <span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">dfs</span><span class="params">(TreeNode root, <span class="keyword">int</span> prevSum)</span></span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(root==<span class="keyword">null</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">int</span> sum = prevSum * <span class="number">10</span> + root.val;</span><br><span class="line">        <span class="keyword">if</span>(root.left == <span class="keyword">null</span> &amp;&amp; root.right==<span class="keyword">null</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span> sum;</span><br><span class="line">        &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">            <span class="keyword">return</span> dfs(root.left, sum) + dfs(root.right, sum);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="100-相同的树"><a href="#100-相同的树" class="headerlink" title="100. 相同的树"></a><a href="https://leetcode-cn.com/problems/same-tree/">100. 相同的树</a></h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isSameTree</span><span class="params">(TreeNode p, TreeNode q)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(p == <span class="keyword">null</span> &amp;&amp; q == <span class="keyword">null</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        &#125;<span class="keyword">else</span> <span class="keyword">if</span>(p==<span class="keyword">null</span> || q==<span class="keyword">null</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125;<span class="keyword">else</span> <span class="keyword">if</span>(p.val != q.val)&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">            <span class="keyword">return</span> isSameTree(p.left, q.left) &amp;&amp; isSameTree(p.right, q.right);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;二叉树刷题1&quot;&gt;&lt;a href=&quot;#二叉树刷题1&quot; class=&quot;headerlink&quot; title=&quot;二叉树刷题1&quot;&gt;&lt;/a&gt;二叉树刷题1&lt;/h1&gt;&lt;p&gt;[TOC]&lt;/p&gt;
&lt;h2 id=&quot;树的基础&quot;&gt;&lt;a href=&quot;#树的基础&quot; class=&quot;headerl</summary>
      
    
    
    
    
    <category term="LeetCode" scheme="http://example.com/tags/LeetCode/"/>
    
  </entry>
  
</feed>
