<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Coding-Zuo</title>
  
  <subtitle>Coding And Studying</subtitle>
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2021-05-18T03:07:03.491Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>Coding-Zuo</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>从01背包问题一维优化到多重背包问题二进制、单调队列优化总结</title>
    <link href="http://example.com/2021/05/17/%E4%BB%8E01%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98%E4%B8%80%E7%BB%B4%E4%BC%98%E5%8C%96%E5%88%B0%E5%A4%9A%E9%87%8D%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98%E4%BA%8C%E8%BF%9B%E5%88%B6%E3%80%81%E5%8D%95%E8%B0%83%E9%98%9F%E5%88%97%E4%BC%98%E5%8C%96%E6%80%BB%E7%BB%93/"/>
    <id>http://example.com/2021/05/17/%E4%BB%8E01%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98%E4%B8%80%E7%BB%B4%E4%BC%98%E5%8C%96%E5%88%B0%E5%A4%9A%E9%87%8D%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98%E4%BA%8C%E8%BF%9B%E5%88%B6%E3%80%81%E5%8D%95%E8%B0%83%E9%98%9F%E5%88%97%E4%BC%98%E5%8C%96%E6%80%BB%E7%BB%93/</id>
    <published>2021-05-17T03:45:22.000Z</published>
    <updated>2021-05-18T03:07:03.491Z</updated>
    
    <content type="html"><![CDATA[<h1 id="从01背包问题一维优化到多重背包问题二进制、单调队列优化总结"><a href="#从01背包问题一维优化到多重背包问题二进制、单调队列优化总结" class="headerlink" title="从01背包问题一维优化到多重背包问题二进制、单调队列优化总结"></a>从01背包问题一维优化到多重背包问题二进制、单调队列优化总结</h1><p>背包问题很经典，但从来都没有从头到尾总结过。</p><p>01背包问题，是给一个容量大小为V的背包和N件物品，每件物品有各自的价值w，且每个物品只能被选择1次。要求在有限的背包容量下，装入物品总价值最大。</p><p>多重背包问题的变动是，每个物品不止可以选择1次了，但要求还是在有限容量下装入最大的价值。</p><p>相当于问题除了给出背包容量V，每种物品的价值W，之外，还给了每种物品的可选数量S</p><p>多重背包问题的做法有</p><ul><li><p>将多重背包问题拆分为01背包问题，每种物品的每个我都选择一下0或1选与不选，这种做法时间复杂度较高。</p><p>适用数据范围为：</p><p>$0&lt;N,V≤1000$<br>$0&lt;v_i,w_i≤1000$ (因为题目一般的可解计算量为$10^7$ )</p></li><li><p>范围超了有，二进制优化方法</p><p>适用数据范围为：</p><p>$0&lt;N \le 1000$</p><p>$0&lt;V \le 2000$</p><p>$0&lt;v_i,w_i,s_i≤2000$</p></li><li><p>再大还有单调队列优化方法</p><p>适用数据范围为：</p><p>$0&lt;N \le 1000$</p><p>$0&lt;V \le 20000$</p><p>$0&lt;v_i,w_i,s_i≤20000$</p></li></ul><h2 id="01背包问题"><a href="#01背包问题" class="headerlink" title="01背包问题"></a>01背包问题</h2><p>题目：<a href="https://www.acwing.com/problem/content/2/">https://www.acwing.com/problem/content/2/</a></p><p>不断对第i个物品做出决策，[0-1] 代表选与不选两种抉择</p><p><img src="https://i.loli.net/2021/05/17/xM8coeUv3Guh1LX.png" alt=""></p><p>将状态$f[i][j]$优化到一维$f[j]$，实际上只需要做一个等价变形。</p><p>为什么可以这样变形呢？我们定义的状态$f[i][j]$可以求得任意合法的 $i$ 与 $j$ 最优解，但题目只需要求得最终状态$f[n][m]$，因此我们只需要一维的空间来更新状态。</p><ol><li>状态$f[j]$ 定义：N件物品，背包容量 $j$ 下的最优解</li><li>注意枚举背包容量 $j$ 必须从 $V$ 开始</li><li>为什么一维情况下枚举背包容量需要逆序？ 在2维情况下，状态 $f[i][j]$ 是由上一轮 $i-1$ 的状态得来的， $f[i][j]$ 与 $f[i-1][j]$ 是相互独立的。而优化到1维后，如果还是正序遍历，则有 $f[较小体积]$ 更新到 $f[较大体积]$， 则有可能本应该用第 $i-1$ 轮的状态却用的是第 $i$ 轮的状态</li><li>例如，一维状态第$i$ 轮对体积为3的物品进行决策，则$f[7]$ 由 $f[4]$ 更新而来，这里的$f[4]$ 正确应该是 $f[i-1][4]$，但从后小岛大枚举 $j$ 这里的 $f[4]$ 在第 $i$ 轮却成了 $f[i][4]$。 当逆序枚举背包容量 $j$ 时， 我们求$f[7]$ 同样由 $f[4]$ 更新。这里的 $f[4]$ 还没有在第 $i$ 轮计算，所以实际计算的 $f[4]$ 仍是 $f[i-1][4]$</li><li>简单来说，一维情况下正序更新状态 $f[j]$ 需要用到前面计算的状态已经被污染，逆序则不会有这样的问题</li><li>状态转移方程为 $f[j] = max(f[j], f[j-v[i]]+ w[i])$</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span></span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Scanner sc = <span class="keyword">new</span> Scanner(System.in);</span><br><span class="line">        <span class="keyword">int</span> N = sc.nextInt();</span><br><span class="line">        <span class="keyword">int</span> V = sc.nextInt();</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">int</span>[] v=<span class="keyword">new</span> <span class="keyword">int</span>[N+<span class="number">1</span>];</span><br><span class="line">        <span class="keyword">int</span>[] w=<span class="keyword">new</span> <span class="keyword">int</span>[N+<span class="number">1</span>];</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>;i&lt;=N;i++)&#123;</span><br><span class="line">            v[i] = sc.nextInt();</span><br><span class="line">            w[i] = sc.nextInt();</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">         <span class="comment">//dp1(v,w, N, V);// 无优化数组</span></span><br><span class="line">       dp2(v,w, N, V);<span class="comment">// 优化为1维数组</span></span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">dp1</span><span class="params">(<span class="keyword">int</span>[] v,<span class="keyword">int</span> [] w, <span class="keyword">int</span> N, <span class="keyword">int</span> V)</span></span>&#123;</span><br><span class="line">        <span class="keyword">int</span>[][] dp = <span class="keyword">new</span> <span class="keyword">int</span>[N+<span class="number">1</span>][V+<span class="number">1</span>];</span><br><span class="line">        dp[<span class="number">0</span>][<span class="number">0</span>]= <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>;i&lt;=N;i++)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">1</span>;j&lt;=V;j++)&#123;</span><br><span class="line">                <span class="keyword">if</span>(j&lt;v[i]) dp[i][j]=dp[i-<span class="number">1</span>][j];</span><br><span class="line">                <span class="keyword">else</span>&#123;</span><br><span class="line">                    dp[i][j] = Math.max(dp[i-<span class="number">1</span>][j], dp[i-<span class="number">1</span>][j-v[i]]+w[i]);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(dp[N][V]);</span><br><span class="line">    &#125;</span><br><span class="line">  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">dp2</span><span class="params">(<span class="keyword">int</span>[] v,<span class="keyword">int</span> [] w, <span class="keyword">int</span> N, <span class="keyword">int</span> V)</span></span>&#123;</span><br><span class="line">          <span class="keyword">int</span>[] dp = <span class="keyword">new</span> <span class="keyword">int</span>[V+<span class="number">1</span>];</span><br><span class="line">          dp[<span class="number">0</span>]= <span class="number">0</span>;</span><br><span class="line">          <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>;i&lt;=N;i++)&#123;</span><br><span class="line">              <span class="keyword">for</span>(<span class="keyword">int</span> j=V;j&gt;=v[i];j--)&#123;</span><br><span class="line">                  <span class="comment">// if(j&lt;v[i]) dp[j]=dp[j];</span></span><br><span class="line">                  <span class="comment">// else&#123;</span></span><br><span class="line">                  dp[j] = Math.max(dp[j], dp[j-v[i]]+w[i]);</span><br><span class="line">                  <span class="comment">// &#125;</span></span><br><span class="line">              &#125;</span><br><span class="line">          &#125;</span><br><span class="line">          System.out.println(dp[V]);</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>还可以优化输入</p><p>处理数据时，我们是一个物品一个物品，一个体积一个体积的去枚举</p><p>因此可以不必开两个数组去记录体积和价值，而是边输入边处理。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span></span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Scanner sc = <span class="keyword">new</span> Scanner(System.in);</span><br><span class="line">        <span class="keyword">int</span> N = sc.nextInt();</span><br><span class="line">        <span class="keyword">int</span> V = sc.nextInt();</span><br><span class="line">        <span class="keyword">int</span>[] f=<span class="keyword">new</span> <span class="keyword">int</span>[V+<span class="number">1</span>];</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>;i&lt;=N;i++)&#123;</span><br><span class="line">            <span class="keyword">int</span> v = sc.nextInt();</span><br><span class="line">            <span class="keyword">int</span> w = sc.nextInt();</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j = V;j &gt;= v;j--)&#123;</span><br><span class="line">                f[j] = Math.max(f[j], f[j-v]+w);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(f[V]);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="多重背包问题1"><a href="#多重背包问题1" class="headerlink" title="多重背包问题1"></a>多重背包问题1</h2><p>题目：<a href="https://www.acwing.com/problem/content/4/">https://www.acwing.com/problem/content/4/</a></p><p>多重背包问题，在给出每个物品的体积V和价值W的基础上，让每个物品不只可选1次</p><p>完全背包和01背包的区别是完全背包中每个物品可以用无限次，而多重背包不是无限次用。</p><p>最直接也最耗时的思路是，所有的可选的物品种类和次数都询问一次选或不选，也就是当成01背包问题来做。</p><p>但也比01背包问题多了一个数量级, 相对暴力</p><p><img src="https://i.loli.net/2021/05/18/UWfLp2TGBw4jPvn.png" alt=""></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.Scanner;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Scanner scanner = <span class="keyword">new</span> Scanner(System.in);</span><br><span class="line">        <span class="keyword">int</span> N = scanner.nextInt();</span><br><span class="line">        <span class="keyword">int</span> V = scanner.nextInt();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">int</span>[] f = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">110</span>];</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; N; i++) &#123;</span><br><span class="line">            <span class="keyword">int</span> v = scanner.nextInt();</span><br><span class="line">            <span class="keyword">int</span> w = scanner.nextInt();</span><br><span class="line">            <span class="keyword">int</span> s = scanner.nextInt();</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> j = V; j &gt;= <span class="number">0</span>; j--) &#123;</span><br><span class="line">                <span class="keyword">for</span> (<span class="keyword">int</span> k = <span class="number">1</span>; k &lt;= s &amp;&amp; k * v &lt;= j; k++) &#123;</span><br><span class="line">                    f[j] = Math.max(f[j], f[j - k * v] + k * w);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        System.out.println(f[V]);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="多重背包问题2"><a href="#多重背包问题2" class="headerlink" title="多重背包问题2"></a>多重背包问题2</h2><p>题目：<a href="https://www.acwing.com/problem/content/5/">https://www.acwing.com/problem/content/5/</a></p><p>这道题和多重背包问题1其实是一样的，只不过数量级有变化，要求你用二进制优化的方法来解。</p><p>那么什么是二进制优化法？</p><p>上一道题是将每种物品拆成单份的01背包去求解的</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"> 即 v,w,s = v,w,7 时：</span><br><span class="line"> 正常拆分：-&gt; (v,w)，(v,w)，(v,w)，(v,w)，(v,w)，(v,w)，(v,w)</span><br><span class="line"> 二进制拆分：-&gt; (v,w),(v&lt;&lt;1,w&lt;&lt;1),(v&lt;&lt;2,w&lt;&lt;2)</span><br><span class="line"></span><br><span class="line"> 7 : 1 ,2, 4</span><br><span class="line"> 0</span><br><span class="line"> 1</span><br><span class="line"> 2</span><br><span class="line"> 3 = 1+2</span><br><span class="line"> 4</span><br><span class="line"> 5= 1+4</span><br><span class="line"> 6 =2+4</span><br><span class="line"> 7=1+2+4</span><br><span class="line"> &lt;p&gt;</span><br><span class="line"> s - 1 -2 - 4 - 8  ....</span><br><span class="line"> 减 2的幂  减到不能减为止 用s - (1+2+4+8...)</span><br><span class="line"> 就可以把物品分成log(s)份 而不是s份</span><br><span class="line"> &lt;p&gt;</span><br><span class="line"> log(2000)=11</span><br><span class="line"> 1000*11*2000 = 2*10^7</span><br><span class="line"> 所以将每个物品拆成log份</span><br><span class="line"> </span><br><span class="line"> 模拟</span><br><span class="line">1 2 4 8 16 32 64 128 256 512 1024</span><br><span class="line">这十一个数可以拼凑出0-2047间的所有整数</span><br><span class="line">1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16................</span><br><span class="line">1 2 1+2 4 4+1 4+2 4+2+1 8 8+1 8+2 8+2+1 8+4 8+4+1 8+4+2 8+4+2+1 16................</span><br><span class="line">所以在使用二进制将si个i物品拆包组装成一个个大包之后我们总归可以通过01背包的枚举方式来得到一个正确的i物品选用数量，比如说应该选67件i物品，那么体现成我们选取了 价值为64w的物品一件 + 价值为2w的物品一件 + 价值为1*w的物品一件</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>为什么这么拆有用？</p><p>上一题的状态转移方程是</p><script type="math/tex; mode=display">\begin{equation}\begin{split}  f[j] &= max(f[j-1], f[j-v[i]]+w[i], f[j-2*v[i]]+2*w[i],... ) \\    \end{split}\end{equation}</script><p>我们首先确认三点：</p><p>（1）我们知道转化成01背包的基本思路就是：判断每件物品我是取了你好呢还是不取你好。</p><p>（2）我们知道任意一个实数可以由二进制数来表示，也就是$2^0 - 2^k$其中一项或几项的和。</p><p>（3）这里多重背包问的就是每件物品取多少件可以获得最大价值。</p><p>如果仍然不是很能理解的话，取这样一个例子:要求在一堆苹果选出n个苹果。我们传统的思维是一个一个地去选，选够n个苹果就停止。这样选择的次数就是n次</p><p>二进制优化思维就是：现在给出一堆苹果和10个箱子，选出n个苹果。将这一堆苹果分别按照1,2,4,8,16,…..512分到10个箱子里，那么由于任何一个数字x ∈[1,1024]<br>都可以从这10个箱子里的苹果数量表示出来，但是这样选择的次数就是 ≤10次 。</p><p>这样利用二进制优化，时间复杂度就从$O(n^3)降到O(n^2logS)$,从$4<em>10^9$降到了$2</em>10^7$。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.Scanner;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span></span>&#123;</span><br><span class="line">   Scanner scanner = <span class="keyword">new</span> Scanner(System.in);</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">run1</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">int</span> N = scanner.nextInt();</span><br><span class="line">        <span class="keyword">int</span> V = scanner.nextInt();</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">int</span>[] v_arr = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">12010</span>];</span><br><span class="line">        <span class="keyword">int</span>[] w_arr = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">12010</span>];</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">int</span> cnt = <span class="number">0</span>; <span class="comment">// 分组的组别</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>;i&lt;=N;i++)&#123;</span><br><span class="line">            <span class="keyword">int</span> v = scanner.nextInt();</span><br><span class="line">            <span class="keyword">int</span> w = scanner.nextInt();</span><br><span class="line">            <span class="keyword">int</span> s = scanner.nextInt();</span><br><span class="line">            <span class="keyword">int</span> k =<span class="number">1</span>; <span class="comment">//组别里的类别个数</span></span><br><span class="line">            <span class="keyword">while</span>(k&lt;=s)&#123;</span><br><span class="line">                cnt++; <span class="comment">//组别先增加</span></span><br><span class="line">                v_arr[cnt] = v*k; <span class="comment">//整体体积</span></span><br><span class="line">                w_arr[cnt] = w*k; <span class="comment">//整体价值</span></span><br><span class="line">                s-=k;   </span><br><span class="line">                k*=<span class="number">2</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//剩余一组</span></span><br><span class="line">            <span class="keyword">if</span>(s&gt;<span class="number">0</span>)&#123;</span><br><span class="line">                cnt++;</span><br><span class="line">                v_arr[cnt]= v*s;</span><br><span class="line">                w_arr[cnt]= w*s;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">int</span>[] f = <span class="keyword">new</span> <span class="keyword">int</span>[V+<span class="number">1</span>];</span><br><span class="line">        N = cnt;</span><br><span class="line">        <span class="comment">// 01背包</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>;i&lt;=N;i++)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j=V;j&gt;=v_arr[i];j--)&#123;</span><br><span class="line">                f[j] = Math.max(f[j] , f[j-v_arr[i]]+w_arr[i]);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(f[V]);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">new</span> Main().run1();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="多重背包问题3"><a href="#多重背包问题3" class="headerlink" title="多重背包问题3"></a>多重背包问题3</h2><p>题目：<a href="https://www.acwing.com/problem/content/description/6/">https://www.acwing.com/problem/content/description/6/</a></p><p>$0&lt;N \le 1000$</p><p>$0&lt;V \le 20000$</p><p>$0&lt;v_i,w_i,s_i≤20000$</p><p>如果还以上面的二进制优化来做，复杂度为 $1000 <em> log(20000) </em> 20000 = 3*10^8$  会超时。</p><script type="math/tex; mode=display">\begin{equation}\begin{split}  原: f[j]=max(f[j],f[[j-kv[i]]+kw[i]);\\    \end{split}\end{equation}</script><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>;i&lt;=N;i++)  <span class="comment">//第一重循环</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>;j&lt;=V;j++)  <span class="comment">//第二重循环</span></span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> k = <span class="number">0</span>; k &lt;= s[i] &amp;&amp; k * v[i] &lt;= j; k ++ )  <span class="comment">//第三重循环</span></span><br></pre></td></tr></table></figure><p>考虑到对于每次层 $i，j$  只与 j % v+kv 有关，k 的范围 $[0,s]$</p><p>优化二三重循环,将每一层 j 按 j%v 分成v组，节省了第二重循环中 $ j+v…j+kv$ 的时间，将两重循环优化为遍历一次 m；</p><p>$f[i][j]=max(f[i][j],f[i-1][j-kv[i]]+k*w[i]) $相当于求每一组在s个范围内的最大值，单调队列O（1）时间即可；</p><p>时间复杂度应该是O(NV)</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.Scanner;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span></span>&#123;</span><br><span class="line">   Scanner scanner = <span class="keyword">new</span> Scanner(System.in);</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">run1</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">int</span> N = scanner.nextInt();</span><br><span class="line">        <span class="keyword">int</span> V = scanner.nextInt();</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">int</span>[] v_arr = <span class="keyword">new</span> <span class="keyword">int</span>[V+<span class="number">1</span>];</span><br><span class="line">        <span class="keyword">int</span>[] w_arr = <span class="keyword">new</span> <span class="keyword">int</span>[V+<span class="number">1</span>];</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">int</span>[] f = <span class="keyword">new</span> <span class="keyword">int</span>[V+<span class="number">1</span>];</span><br><span class="line">        <span class="keyword">int</span>[] g = <span class="keyword">new</span> <span class="keyword">int</span>[V+<span class="number">1</span>];</span><br><span class="line">        <span class="keyword">int</span>[] q = <span class="keyword">new</span> <span class="keyword">int</span>[V+<span class="number">1</span>];</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>;i&lt;=N;i++)&#123;</span><br><span class="line">            <span class="keyword">int</span> v = scanner.nextInt();</span><br><span class="line">            <span class="keyword">int</span> w = scanner.nextInt();</span><br><span class="line">            <span class="keyword">int</span> s = scanner.nextInt();</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>;j&lt;v;j++)&#123;</span><br><span class="line">                <span class="keyword">int</span> hh,tt;</span><br><span class="line">                hh=<span class="number">0</span>,tt=-<span class="number">1</span>;</span><br><span class="line">                <span class="keyword">for</span>(<span class="keyword">int</span> k=j;k&lt;=m;k+=vi)&#123;</span><br><span class="line">                    g[k] = f[k];<span class="comment">//每次f[k]都可能会更新， 预先保存f[i-1, k]的值 </span></span><br><span class="line">                    <span class="keyword">if</span>(hh&lt;=tt&amp;&amp;(k-q[hh])/vi&gt;si) hh++;<span class="comment">//保证保证不超前si个</span></span><br><span class="line">                    <span class="keyword">while</span>(hh&lt;=tt&amp;&amp;g[q[tt]]+(k-q[tt])/vi*wi &lt;f[k]) tt--;<span class="comment">//单调队列入队方法</span></span><br><span class="line">                    q[++tt] = k;</span><br><span class="line">                    f[k] = g[q[hh]]+(k-q[hh])/vi*wi;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">new</span> Main().run1();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;从01背包问题一维优化到多重背包问题二进制、单调队列优化总结&quot;&gt;&lt;a href=&quot;#从01背包问题一维优化到多重背包问题二进制、单调队列优化总结&quot; class=&quot;headerlink&quot; title=&quot;从01背包问题一维优化到多重背包问题二进制、单调队列优化总结&quot;&gt;</summary>
      
    
    
    
    
    <category term="刷题" scheme="http://example.com/tags/%E5%88%B7%E9%A2%98/"/>
    
  </entry>
  
  <entry>
    <title>Adam &amp; AdamW 原论文</title>
    <link href="http://example.com/2021/05/16/Adam-AdamW-%E5%8E%9F%E8%AE%BA%E6%96%87/"/>
    <id>http://example.com/2021/05/16/Adam-AdamW-%E5%8E%9F%E8%AE%BA%E6%96%87/</id>
    <published>2021-05-16T11:00:29.000Z</published>
    <updated>2021-05-16T11:18:13.019Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Adam-amp-AdamW-原论文"><a href="#Adam-amp-AdamW-原论文" class="headerlink" title="Adam &amp; AdamW 原论文"></a>Adam &amp; AdamW 原论文</h1><hr><h1 id="Adam"><a href="#Adam" class="headerlink" title="Adam"></a>Adam</h1><p>一种基于低阶矩估计的随机目标函数一阶梯度优化算法。该方法也适用于非平稳目标和具有非常强噪声和/或稀疏梯度的问题。特点有：实现简单、计算高效、低内存要求、对梯度的对角重新缩放不变，并且很适合于数据和/或参数较大的问题。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Adam-amp-AdamW-原论文&quot;&gt;&lt;a href=&quot;#Adam-amp-AdamW-原论文&quot; class=&quot;headerlink&quot; title=&quot;Adam &amp;amp; AdamW 原论文&quot;&gt;&lt;/a&gt;Adam &amp;amp; AdamW 原论文&lt;/h1&gt;&lt;hr&gt;
</summary>
      
    
    
    
    
    <category term="ML&amp;DL" scheme="http://example.com/tags/ML-DL/"/>
    
  </entry>
  
  <entry>
    <title>GPT-GNN: Generative Pre-Training of Graph Neural Networks</title>
    <link href="http://example.com/2021/05/15/GPT-GNN-Generative-Pre-Training-of-Graph-Neural-Networks/"/>
    <id>http://example.com/2021/05/15/GPT-GNN-Generative-Pre-Training-of-Graph-Neural-Networks/</id>
    <published>2021-05-15T14:24:59.000Z</published>
    <updated>2021-05-16T07:25:28.520Z</updated>
    
    <content type="html"><![CDATA[<h1 id="GPT-GNN-Generative-Pre-Training-of-Graph-Neural-Networks"><a href="#GPT-GNN-Generative-Pre-Training-of-Graph-Neural-Networks" class="headerlink" title="GPT-GNN: Generative Pre-Training of Graph Neural Networks"></a>GPT-GNN: Generative Pre-Training of Graph Neural Networks</h1><p>Self-Supervised Learning分成两种方法:一种是生成式模型，一种是判别式模型(对比学习)。</p><p>以输入图片信号为例，生成式模型，输入一张图片，通过Encoder编码和Decoder解码还原输入图片信息，监督信号是输入输出尽可能相似。判别式模型，输入两张图片，通过Encoder编码，监督信号是判断两张图是否相似(例如，输入同一个人的两张照片，判断输入相似，输出1；输入两个人的照片，判断输入不相似，输出0)。</p><h2 id="文章贡献"><a href="#文章贡献" class="headerlink" title="文章贡献"></a>文章贡献</h2><p>继上一文 <a href="https://coding-zuo.github.io/2021/05/12/Strategies-for-Pre-training-Graph-Neural-Networks/">Strategies for Pre-training Graph Neural Networks</a> 对预训练GNN做了大规模的实验，并提出提出了一种结合节点级和图级表示的预训练方法，优化了单单使用一种级别做预训练后产生的负迁移效果。</p><p>又以生成式自监督的方式，来在预训练阶段捕捉图数据的结构信息和语义信息。分别是边生成任务和属性生成任务。</p><p>它们联合优化等价于最大化整个属性图的概率似然，这样预训练模型可以捕捉到节点属性与图结构之间的内在依赖关系。</p><p>预训练的GNN网络目标主要是异质单个(大规模)图上预训练，并进行节点级迁移。</p><p>然后优化了预训练模型可以让其处理大规模的图采样子图，采用的是通过自适应的嵌入队列，减轻负采样带来的不准确损失。</p><p>接下来主要介绍两种自监督任务和这个优化方法。</p><h2 id="行文逻辑"><a href="#行文逻辑" class="headerlink" title="行文逻辑"></a>行文逻辑</h2><p>通过行文逻辑，学习怎么写论文。</p><p>首先作者先是说GNN有用，预训练GNN刚刚被证明有用！接下来从充分利用无标签数据做无监督任务说，大规模的图数据标记成本昂贵。NLP的数据也一样标注昂贵，所以有了bert那样的预训练语言模型，并且提高了下游任务性能。同样在cv领域也是。</p><p>列举了GAE、GraphRNN、半监督GCN等图生成技术，但他们不适合用于预训练GNN。因为：首先，它们大多只关注于生成无属性的图结构，而没有定义节点属性与图结构之间的底层模式，图结构是GNNs中卷积聚合的核心。其次，它们被设计用来处理迄今为止的小图形，限制了它们在大规模图形上进行预训练的潜力。</p><p>然后介绍了下预训练和finetuning的流程，就不多说了。</p><p>然后切入正题介绍他的贡献，上文介绍过。</p><hr><p>然后是准备工作和相关工作，介绍GNN的传统机制，信息传递和信息聚合的基本原理，不多介绍。</p><p>和GNN发展历史，其中有一个Graph Infomax 最近可能要学习一下，最大化了从GNNs获得的节点表示和图pooling表示之间的互信息，也就是节点级和图级。作者认为其，在纯监督学习环境下表现出改进，但学习任务通过强迫附近节点具有相似的嵌入来实现，而忽略了图的丰富语义和高阶结构。</p><p>介绍预训练在cv和nlp的成功。不过我最近听说cv圈有一篇文章，最近2021的有一篇预训练CNN其效果并不比基于transformer的模型差。</p><p>介绍生成预训练任务的数学定义，之后是具体细节和模型方法，再到实验结论等等。</p><h2 id="关于生成式预训练任务的框架流程"><a href="#关于生成式预训练任务的框架流程" class="headerlink" title="关于生成式预训练任务的框架流程"></a>关于生成式预训练任务的框架流程</h2><p>形式上给出图数据 $G = (V,E,X)$  和GNN模型 $f_{\theta}$</p><p>我们通过这个GNN将此图上的可能性建模为 $p(G;θ)$ ——-表示G中的节点是如何属性化和连接其他节点的(可以理解为先验知识)。</p><p>其目的是通过最大化图的似然，得到参数 $θ^∗=max_{θ}p(G;θ)$ 来预先训练广义神经网络模型。</p><p>那么问题变成了如何对 $p(G;\theta)$ 进行适当的建模。</p><p>现在大多的现有图生成方法都是遵循自回归方式来分解目标概率分布，也就是图中的节点是按顺序来的，并且边是通过将每个新到达的节点连接到现有节点来生成的。什么是自回归？</p><script type="math/tex; mode=display">X_t = c+\sum_{i=1}^p\phi_iX_{t-i}+\epsilon_t</script><p>如上式，c 为常数项，$\epsilon$ 为随机误差，概况来说就是X的当前期值等于一个或数个前期值的线性组合加常数项和睡觉误差。</p><p>类似的作者也通过一个排列向量 $\pi$ 来确定节点顺序，其中 $i^{\pi}$ 表示向量中第i个位置的节点id。因此，图的分布$p(G;\theta)$ 等价于所有可能排列上的期望似然：</p><script type="math/tex; mode=display">p(G;\theta) = \mathbb{E}_{\pi} [p_{\theta}(X^{\pi},E^{\pi})]</script><p>其中$X^{\pi} \in R^{|V|\times d}$ ，$E$ 是边集 ，$E_{i}^{\pi}$ 表示所有连接节点$i^{\pi}$ 的边。</p><p>为简单起见，假设观察到任何节点排序 $π$ 的概率相等，并且在下面的章节中说明一个排列的生成过程时也省略了下标 $π$。给定一个排列顺序，我们可以将对数似然率自动回归分解-每次迭代生成一个节点，如下所示：</p><script type="math/tex; mode=display">logp_{\theta}(X,E) = \sum_{i=1}^{|V|}logp_{\theta}(X_i,E_i|X_{\lt i},E_{\lt i})</script><p>在第i步，使用所有 i 之前已生成的节点，他们的属性和边分别是 $X<em>{\lt i}$ ，$E</em>{\lt i}$ ，给定 $X<em>{\lt i}$ $E</em>{\lt i}$ 生成节点 i 的概率log加和。</p><p>从本质上讲，等式中的目标。描述了属性图的自回归生成过程。问题变成：如何对条件概率 $p<em>θ(X_i，E_i|X</em>{&lt;i}，E_{&lt;i})$ 建模？</p><h3 id="因式分解属性图生成"><a href="#因式分解属性图生成" class="headerlink" title="因式分解属性图生成"></a>因式分解属性图生成</h3><p>为了计算 $p<em>{\theta}(X_i,E_i|X</em>{\lt i},E_{\lt i})$ ，一种天真的解决方案可以是简单地假设 $X_i$ 和 $E_i$是独立的，即 :</p><script type="math/tex; mode=display">p_{\theta}(X_i,E_i|X_{\lt i},E_{\lt i}) = p_{\theta}(X_i|X_{\lt i},E_{\lt i}) \cdot p_{\theta}(E_i|X_{\lt i},E_{\lt i})</script><p>然而通过这样的分解，对于每个节点，其属性和连接之间的依赖性被完全忽略。</p><p>然而，被忽略的依赖性是属性图的核心性质，也是GNNs中卷积聚集的基础。因此，这种天真的分解不能为训练前的GNN提供信息指导。</p><p>就比如，物以类聚人以群分，我和相似的人右边是因为我们有相似的属性。</p><p>为了解决这个问题，作者提出了属性图生成过程的依赖感知分解机制。具体地说，当估计一个新节点的属性时，我们会得到它的结构信息，反之当估计一个新的结构边信息时，我们会考虑到它的属性信息。在该过程中，可以将生成分解为两个耦合部分：</p><ul><li>1.给出观测边的边，生成节点属性</li><li>2.给出观测边和1中已经生成的节点属性，生成剩余的边</li></ul><p>通过这种方式，模型可以捕获每个节点的属性和结构之间的依赖关系。</p><p>正式的定义如何建模，定义一个变量 $o$ , 表示$E_i$内所有观测边的索引向量。</p><p>$E_{i,o}$ 是已观测的边，$\lnot o$表示要生成的所有mask边的索引。通过所有的已观测边来重写条件概率作为一个期望似然如下：</p><p><img src="https://i.loli.net/2021/05/16/qIjAo2HyNkF5WcS.png" alt=""></p><p>这里的理解非常重要，第一个等式中，把 $E<em>i$ 拆成了$E</em>{i,¬o}$和 $E_{i,o}$ ，也就是说指定了哪些边是观测边，哪些边是masked边。需要注意的是，当o确定下来了，$\lnot o$ 也是确定的。因此等式外面加上了对o的累加，这里可以理解为类似于全概率公司去对所有可能的o求和。</p><p>此外，这里要注意  $E<em>i, E</em>{&lt;i},E<em>{i,o},E</em>{i,\lnot o}$  四个符号分别表示什么：</p><ul><li>现在位于step i，$E_{&lt;i}$ 是指在step i 之前生成的边</li><li>$E_i$ 指在step i 将会生成的边 (与节点i 相连，有好多边)</li><li>将 $E<em>i$ 的边生成过程拆分成一件生成的和将要生成的两部分，即 $E</em>{i,o},E_{i,\lnot o}$</li></ul><p>在第二个等式中，把p 看成是概率分布，写作对于o 期望的形式。</p><p>最后把 $X<em>i$ 和 $E</em>{i,\lnot o}$ 看做独立的过程，拆成两个概率分布。</p><p>这种分解的优势在于，没有忽略 $X<em>i$ 和 $E</em>{i,o}$ 的联系。第一项表示given观测边，聚合目标节点i的邻居信息来生成其属性$X<em>i$ 。第二项表示given观测边和刚生成的属性$X_i$，预测$E</em>{i,¬o}$中的边是否存在。</p><p><img src="https://i.loli.net/2021/05/16/hTuqivsBcRC1fon.png" alt=""></p><p>如上图所示，给出一个例子。对于academic图，我们要去生成一个paper node，它的属性为title。我们要去生成一个paper node，它的属性为title，并且其和author，publish venue，reference相连。上图中的实线部分为已经观测到的边，首先生成节点的属性，即title。然后基于author1，author2，author3和刚生成的节点属性title，预测剩下的边，即虚线部分。</p><h3 id="高效的属性和边生成"><a href="#高效的属性和边生成" class="headerlink" title="高效的属性和边生成"></a>高效的属性和边生成</h3><p>出于效率考虑希望：</p><ul><li>对于输入图只跑一次GNN就能计算节点属性生成和边生成过程的loss</li><li>希望节点属性生成和边生成能同时运行</li></ul><p>然而边生成需要用到节点属性信息，如果两个生成过程同时进行，会导致信息泄露。为避免这个问题，将节点分成两种类型：</p><ul><li>属性生成节点，mask住这些节点的属性，用一个公用的dummy token，并学习一个共享向量$X^{init}$来代替 和$X_i$ 维度相同。</li><li>边生成节点，对于这些节点，保留他们的属性。</li></ul><p>需要注意的是，同一个节点在不同阶段扮演不同的角色，可能是属性生成节点也可能是边生成节点。只在某一阶段，一个节点有一个确定的角色。</p><p>在graph上训练GNN 来生成各个节点的embedding，用$h<em>{attr}$ 和 $h</em>{edge}$ 来分别表示属性生成节点和边生成节点的embedding。由于属性生成节点的属性被mask了，因此$h<em>{attr}$中包含的信息通畅会少于 $h</em>{edge}$。</p><p>因此，在GNN的message passing过程中，只使用$h_{edge}$ 作为向其他节点发送的信息。 也就是说，对于每个节点，其聚合邻居 $h_edge$ 的信息和自身信息来生成新的embedding。之后使用不同的decoder来生成节点属性和边。（注意，节点的embedding和节点属性不是一回事。通俗理解，在GNN中节点的属性是input，节点的embedding是hidden layer。）</p><p>对于属性生成，用$Dec^{Attr}(\cdot)$ 来表示decoder，输入$h_{attr}$ 来生成节点属性。decoder的选择依赖于节点属性的类型，如果是text类型的节点属性，可以使用LSTM等。如果节点属性是vector，可以使用MLP。</p><p>定义一个距离函数来度量生成属性和真实属性之间的差异，对于text类型属性，可以使用perplexity困惑度，对于vector属性，可以使用L2距离。因此，可以计算属性生成过程中的loss</p><script type="math/tex; mode=display">L_i^{Attr} = Distance(Dec^{Attr}(h_i^{Attr}, X_i))</script><p>最小化生成属性和真实属性之间的差异，等价于对generate attribute做MLE，也就是最大化 $p<em>{\theta}(X_i|E</em>{i,o},X<em>{&lt;i},E</em>{&lt;i})$ 从而捕捉了图中的节点属性信息。</p><p>对于边生成过程，假设每条边的生成过程和其他边是独立的，由此对likelihood分解：</p><script type="math/tex; mode=display">p_{\theta} (E_{i,\lnot o}|E_{i,o},X_{\le i},E_{\le i}) = \prod_{j^+\in E_{i,\lnot o}} p_{\theta}(j^+|E_{i,o},X_{\le i},E_{\le i})</script><p>得到$h_{edge}$ 后，如果节点i和节点j相连，则使用</p><script type="math/tex; mode=display">Dec^{Edge} (h_i^{Edge},h_j^{Edge})</script><p>进行建模，$Dec^{Edge}$ 是一个pairwise score function</p><p>loss定义为：</p><script type="math/tex; mode=display">L_i^{Edge} = - \sum_{j^+\in E_{i,\lnot o}} log \frac{exp(Dec^{Edge}(h_i^{Edge},h_{j^+}^{Edge}))}{\sum_{j\in S_i^-\bigcup{j^+} }exp(Dec^{Edge}(h_i^{Edge},h_j^{Edge}))}</script><p>$S_i^-$ 是指没有和节点i相连的节点</p><p>下面是作者给出的属性图生成过程的说明性示例。</p><p><img src="https://i.loli.net/2021/05/16/i8IYhQ2NbSfEAKe.png" alt=""></p><ul><li>a) 对于input graph 确定排列 $\pi$</li><li>b) 随机挑选一部分与节点i相连的边作为已观测的$E<em>{i,o}$ ,剩下的作为masked edges $E</em>{i,\lnot o}$ 并删除masked edges</li><li>c) 把节点分为属性生成节点和边生成节点</li><li>d) 计算节点 3，4，5的embedding，包括他们的属性生成节点和边生成节点。</li><li>d)-e) 通过对每个节点并行进行节点属性预测和masked预测来训练一个GNN模型</li></ul><p>具体算法流程：</p><p><img src="https://i.loli.net/2021/05/16/tGbrz7QJfmKEhdw.png" alt=""></p><p>输入一个属性图，每次采样一个子图 $\hat G$作为训练的实例进行训练。首先决定permutation order π。同时，我们希望能够并行化训练，只做一次前向传播，就能得到整个图的embedding，由此可以同时计算所有节点的loss。因此，根据permutation order π来移除边，也就是使每个节点只能从更低order的节点处获得信息。<br> 之后，需要决定哪些边被mask。对于每个节点，获得其所有的出边，随机挑选一部分边被mask住，这一过程对应上述line4。<br> 之后，对节点进行划分，得到整个图中节点的embedding，用于之后loss的计算，对应line5。<br> line 7-9进行loss的计算。<br> line 8中，通过整合采样图中未连接的节点和Q中以前计算的节点embedding来选择负样本，这种方式能够减轻对于采样图优化和对于整个图优化的差距。<br> 在line11-12中，优化模型并更新Q。</p><h2 id="GPT-GNN-对于异质的大图"><a href="#GPT-GNN-对于异质的大图" class="headerlink" title="GPT-GNN 对于异质的大图"></a>GPT-GNN 对于异质的大图</h2><p>对于异构图，即包含不同类型的点和边的图，唯一的不同在于不同类型的点和边采用不同的decoder。<br> 对于大规模的图，可以采样子图来进行训练，即上述算法流程中Sampler的作用。为了计算 $L_{edge}$ 这一loss，需要遍历输入图的所有节点。然而，我们只能在采样的子图上计算这个loss。为了缓解这一差异，提出了adaptive queue，其中存储了之前采样的子图的节点embedding作为负样本。每次采样一个新的子图时，逐步更新这个队列，增加新的节点embedding，移除旧的节点embedding。通过引入adaptive queue，不同采样子图中的节点也能为全局的结构提供信息。</p><h2 id="实验效果"><a href="#实验效果" class="headerlink" title="实验效果"></a>实验效果</h2><p><img src="https://i.loli.net/2021/05/16/xER1ftIsSWcaK72.png" alt=""></p><p><img src="https://i.loli.net/2021/05/16/ZNcLJsHUqRGOhCk.png" alt=""></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;GPT-GNN-Generative-Pre-Training-of-Graph-Neural-Networks&quot;&gt;&lt;a href=&quot;#GPT-GNN-Generative-Pre-Training-of-Graph-Neural-Networks&quot; class=</summary>
      
    
    
    
    
    <category term="GNN" scheme="http://example.com/tags/GNN/"/>
    
  </entry>
  
  <entry>
    <title>Strategies for Pre-training Graph Neural Networks</title>
    <link href="http://example.com/2021/05/12/Strategies-for-Pre-training-Graph-Neural-Networks/"/>
    <id>http://example.com/2021/05/12/Strategies-for-Pre-training-Graph-Neural-Networks/</id>
    <published>2021-05-12T09:10:47.000Z</published>
    <updated>2021-05-12T15:56:43.849Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Strategies-for-Pre-training-Graph-Neural-Networks"><a href="#Strategies-for-Pre-training-Graph-Neural-Networks" class="headerlink" title="Strategies for Pre-training Graph Neural Networks"></a>Strategies for Pre-training Graph Neural Networks</h1><p>目前深度学习各个领域的预训练都搞的热火朝天，GNN也是肯定要搞的。那么预训练之后下一个热潮会是什么呢？</p><p>ICLR2020 首次系统的探索了大规模GNN预训练</p><p>提出了一种结合节点级和图级表示的预训练方法来训练模型。</p><p>在节点级，使用了两种自监督方法，即上下文预测和属性预测。</p><p>在图形级，使用有监督的图级属性预测和结构相似性预测</p><p>同时作者建立了两个新的预训练数据集，2M graph的化学数据集和一个有395K graph的生物数据集。</p><p>接下来介绍作者这么做的理由</p><h2 id="发现"><a href="#发现" class="headerlink" title="发现"></a>发现</h2><p>因为对于特定任务的有标签数据是很稀少的，但无标签数据却有很多，所以为了充分利用无标签数据，各种自监督方法开始兴起。</p><p>所以作者分别在图级和节点级层面上提出了两大类预测方法</p><ul><li>属性预测：属性mask(节点)、有监督的属性预测(图级)</li><li>结构预测：上下文预测(节点)、结构相似性预测(图级)</li></ul><p>以往的一些研究表明(Xu et al., 2017; Ching et al., 2018; Wang et al., 2019),一个成功的迁移学习不仅仅是增加与下游任务来自同一领域的标注好的预训练数据集的数量。相反，它需要大量的领域专业知识来仔细选择与感兴趣的下游任务相关的示例和目标标签。否则，知识从相关的预训练任务转移到新的下游任务可能会损害泛化，这被称为负迁移(Rosenstein等人，2005年)，并极大地限制了预训练模型的适用性和可靠性。</p><p>作者研究发现朴素的策略要么在整个图的层面上预先训练GNN，要么在单个节点层面上预先训练GNN，所给出的改进有限，甚至可能导致许多下游任务的负迁移。在只有图级的预训练下大约有1/4的任务出现了负迁移。</p><p><img src="https://i.loli.net/2021/05/12/z5CEtxbX9Tj1WwN.png" alt=""></p><p>图(a.i)当仅使用节点级预训练时，可以很好地分离不同形状的节点(语义上不同的节点)，但汇集节点级嵌入创建的结果，图嵌入是不可分离的(图嵌入由+和−表示)</p><p>图(a.ii)仅在图级预训练的情况下，图嵌入可以很好地分离，但是单个节点的嵌入并不一定捕获它们特定于领域的语义。</p><p>图(a.iii) 高质量的节点嵌入使得不同类型的节点能够很好地分开，同时嵌入空间也是可组合的。这允许对整个图形进行准确和健壮的表示，并允许将预先训练的模型健壮地传输到各种下游任务。</p><h2 id="预训练策略"><a href="#预训练策略" class="headerlink" title="预训练策略"></a>预训练策略</h2><p>在预训练策略的技术核心是在单个节点以及整个图的级别预先训练。这一概念鼓励GNN在两个级别捕获特定域的语义。</p><h3 id="节点级预训练"><a href="#节点级预训练" class="headerlink" title="节点级预训练"></a>节点级预训练</h3><p>两种自监督方法，上下文预测和属性mask。</p><p><img src="https://i.loli.net/2021/05/12/RFS46a2tozyNGkp.png" alt=""></p><p>图(a)在上下文预测中，子图是所选中心节点周围的K跳邻域，其中K是GNN层的数量，上图中设置为K=2。环境定义为中心节点r1-和r2-Hop之间的周围图结构，上图中使用r1=1和r2=4。</p><p>图(b) 在属性mask中，输入节点/边属性(例如，分子图中的原子类型)被随机mask，并且要求GNN预测它们。</p><h4 id="上下文预测：利用图结构的分布性"><a href="#上下文预测：利用图结构的分布性" class="headerlink" title="上下文预测：利用图结构的分布性"></a>上下文预测：利用图结构的分布性</h4><p>使用子图来预测其周围的图结构。目标是预先训练GNN，以便它将出现在类似结构上下文中的节点映射到附近的嵌入。</p><p>通过三个步骤：</p><ul><li><p>邻居节点和上下文图</p><p>对于每个节点v，定义v的邻居和上下文图。因为GNN信息聚合的是K层邻居，所以节点v的嵌入$h_v$ 依赖于距离v至多k跳节点。上下文图由两个超参数r1和r2来描述，并且它表示远离v的r1跳和r2跳之间的子图(即它是宽度为r2−r1的环)。并且r1&lt;K，以便在邻域和上下文图之间共享一些节点，我们将这些节点称为上下文锚节点。这些锚节点提供关于邻居图和上下文图如何彼此连接的信息。</p></li><li><p>使用一个辅助GNN把上下文编码成固定向量</p><p>由于图的组合性，直接预测上下文图是很困难的。这与自然语言处理不同，在自然语言处理中，单词来自固定和有限的词汇表。为了实现上下文预测，将上下文图编码为固定长度的向量。为此，引入一个上下文GNN作为辅助编码，就是图中的GNN‘。首先用其获得上下文图中的节点嵌入，然后对上下文锚点的嵌入进行平均，得到固定长度的上下文嵌入。对于图G中的节点v，将其对应的上下文嵌入表示为$c^G_v$</p></li><li><p>负采样</p><p>主要的GNN编码邻居节点获取节点的embedding—— $h_v^{(K)}$ ，上下文GNN编码上下文图获取上下文embedding——$c^G_v$。学习目标是一个二分类：是否特定邻域和特定上下文图是否属于同一节点。</p><script type="math/tex; mode=display">\sigma(h^{(k)T}_v c_{v'}^{G'}) \approx 1 \{\text{v and v' are the same nodes}\}</script></li></ul><p>  让v‘=v并且G’=G(即正例)，或者我们从随机选择的图G‘中随机抽样v’(即负例)。</p><h4 id="属性mask-利用图属性的分布性"><a href="#属性mask-利用图属性的分布性" class="headerlink" title="属性mask:利用图属性的分布性"></a>属性mask:利用图属性的分布性</h4><p>目标是通过学习图结构上节点/边属性的分布规律来获取领域知识。</p><p>属性mask有节点mask和属性mask两类</p><p>工作原理：掩蔽节点/边缘属性，然后让GNN基于相邻结构预测这些属性，这参考了bert的mask。</p><p>具体地说，通过用特殊的屏蔽指示符替换输入节点/边属性(例如分子图中的原子类型)来随机屏蔽它们。然后应用GNNs来获得相应的节点/边嵌入(边嵌入:为边的端点的节点嵌入之和来获得)。</p><p>最后，在嵌入的基础上应用线性模型来预测被mask的节点/边属性。有趣的是bert的mask其实相当于在全连通的token图上应用了消息传递。</p><p>在图结构数据中是对非全连通图进行操作，目的是捕捉节点/边属性在不同图结构上的分布规律。</p><h3 id="图级别预训练"><a href="#图级别预训练" class="headerlink" title="图级别预训练"></a>图级别预训练</h3><p>我们的目标是确保节点和图嵌入都是高质量的，以便图嵌入是健壮的，并且可以跨下游任务传输。</p><p>有两个用于图级预训练的选项：预测整个图的特定于域的属性(监督标签)，或者预测图结构。</p><h4 id="有监督的图级属性预测"><a href="#有监督的图级属性预测" class="headerlink" title="有监督的图级属性预测"></a>有监督的图级属性预测</h4><p>由于图形级表示 $h_G$ 直接用于对下游预测任务进行微调，希望将特定于域的信息直接编码成 $h_G$。</p><p>考虑了一种对图表示进行预训练的实用方法：图级多任务监督预训练，用于联合预测单个图的不同监督标签集。例如，在分子性质预测中，我们可以预先训练GNN来预测到目前为止实验测量的分子的所有性质。在蛋白质功能预测中，目标是预测给定的蛋白质是否具有给定的功能，我们可以预先训练GNN来预测到目前为止已经验证的各种蛋白质功能的存在。</p><p>重要的是，单独进行大量的多任务图级预训练可能无法给出可转移的图级表示。(问题来了)</p><p>这是因为一些有监督的预训练任务可能与下游感兴趣的任务无关，甚至会损害下游的绩效（负迁移）。一种解决办法是选择“真正相关的”有监督的训练前任务，只对这些任务进行训练前GNN训练。然而，这样的解决方案成本极高，因为选择相关任务需要大量的领域专业知识，并且需要针对不同的下游任务分别进行预训练。</p><p>为了缓解这个问题，作者的见解是，多任务监督的预训练只提供图形级的监督；因此，创建图形级嵌入的本地节点嵌入可能没有意义。这种无用的节点嵌入可能会加剧负迁移问题，因为许多不同的预训练任务在节点嵌入空间中更容易相互干扰。受此启发，在执行图级预训练之前，先通过上文描述的节点级预训练方法在单个节点级别对GNN进行正则化。正如作者所料，组合策略产生了更多可转移的图形表示。并且在没有专家选择监督的预训练任务的情况下稳健地改善了下游性能。</p><h4 id="结构相似性预测"><a href="#结构相似性预测" class="headerlink" title="结构相似性预测"></a>结构相似性预测</h4><p>目标是对两个图的结构相似性进行建模</p><p>此类任务的示例包括对图形编辑距离进行建模(Bai等人，2019年)或预测图形结构相似性(Navarin等人，2018年)。</p><p>这里好像作者感觉比较难没有全部实现，留到了以后的工作中</p><h3 id="总体预训练策略"><a href="#总体预训练策略" class="headerlink" title="总体预训练策略"></a>总体预训练策略</h3><p>预训练策略是首先进行节点级的自监督预训练，然后进行图级多任务监督的预训练。当GNN预训练完成后，我们对下游任务的预训练GNN模型进行微调。具体地说，我们在图级表示的基础上添加线性分类器来预测下游的图标签。随后以端到端的方式微调整个模型，即预先训练的GNN和下游线性分类器。</p><h2 id="进一步相关工作"><a href="#进一步相关工作" class="headerlink" title="进一步相关工作"></a>进一步相关工作</h2><p>关于图中单个节点的无监督表示学习的文献非常丰富，大致分为两类。</p><p>第一类是使用基于局部随机行走的目标的方法(Grover&amp;Leskovec，2016；Perozzi等人，2014；Don等人，2015)以及例如通过预测边的存在来重建图的邻接矩阵的方法。</p><p>在第二类中是诸如Deep Graph Infomax的方法，其训练最大化局部节点表示和聚集的全局图表示之间的互信息的节点编码器。(基于对比学习互信息的最近也要研究研究)</p><p>这两种方法都鼓励附近的节点具有相似的嵌入表示，最初是针对节点分类和链路预测提出和评估的。然而，这对于图级预测任务来说可能是次优的，在图级预测任务中，捕捉局部邻域的结构相似性通常比捕捉图中节点的位置信息更重要</p><p>所以该预训练策略既考虑了节点级的预训练任务，也考虑了图级的预训练任务，并且正如在实验中所显示的，为了使预训练模型获得良好的性能，必须同时使用这两种类型的任务。</p><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p><img src="https://i.loli.net/2021/05/12/cFBosvWCfURYdhx.png" alt=""></p><p>阴影单元格表示负迁移，即预训练模型的ROC-AUC比未预训练模型的ROC-AUC差。借此说明两个级别共用的重要性。</p><p><img src="https://i.loli.net/2021/05/12/HvFtBiY5RadqGMw.png" alt=""></p><p>在有无预培训的情况下测试不同GNN架构的ROC-AUC(%)性能。</p><p>这里表达能力越强的结构预训练效果越好，表达能力较弱的GNN收益较小，甚至有时未负。这一发现证实了先前的观察结果(例如，Erhan等人)。(2010))，使用富有表现力的模型对于充分利用预培训至关重要，当用于表达能力有限的模型(如GCN、GraphSAGE和GAT)时，预培训甚至会影响性能。</p><p>并且GAT的表现反而下降了不少。作者认为GAT属于表达能力有限的模型，还有人认为GAT attention的参数比较多，模型结构比较复杂导致。</p><p><img src="https://i.loli.net/2021/05/12/kFYCKXIvcU2iLeZ.png" alt=""></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Strategies-for-Pre-training-Graph-Neural-Networks&quot;&gt;&lt;a href=&quot;#Strategies-for-Pre-training-Graph-Neural-Networks&quot; class=&quot;headerlink&quot; t</summary>
      
    
    
    
    
    <category term="GNN" scheme="http://example.com/tags/GNN/"/>
    
  </entry>
  
  <entry>
    <title>Meta Learning(李宏毅)</title>
    <link href="http://example.com/2021/05/09/Meta-Learning-%E6%9D%8E%E5%AE%8F%E6%AF%85/"/>
    <id>http://example.com/2021/05/09/Meta-Learning-%E6%9D%8E%E5%AE%8F%E6%AF%85/</id>
    <published>2021-05-09T15:15:57.000Z</published>
    <updated>2021-05-16T11:03:17.552Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Meta-Learning"><a href="#Meta-Learning" class="headerlink" title="Meta Learning"></a>Meta Learning</h1><p>李宏毅：<a href="https://www.bilibili.com/video/BV15b411g7Wd?p=57&amp;spm_id_from=pageDriver">https://www.bilibili.com/video/BV15b411g7Wd?p=57&amp;spm_id_from=pageDriver</a></p><p>一个不错的科普：<a href="https://www.bilibili.com/video/BV1KB4y1c7gg?from=search&amp;seid=2922012165894972973">https://www.bilibili.com/video/BV1KB4y1c7gg?from=search&amp;seid=2922012165894972973</a></p><h2 id="什么是元学习"><a href="#什么是元学习" class="headerlink" title="什么是元学习"></a>什么是元学习</h2><p>Meta Learning = Learn to Learn (学习如何去做学习这件事)</p><p>机器在学习了很多task后，在获得过去的任务下所汲取的经验后，学习到了更多的学习技巧，成为了一个更厉害的学习者。</p><p>从而有一个新任务，他可以学的更快更好。</p><p>比如：task1你教机器去学语音识别，task2你教他去做图片识别，那么task3你让他去学习文字识别，那么他可能学的会更好。</p><p>元学习的输入是训练数据，输出的是可以用于下一个任务的function，function也就是万能函数模拟器神经网络的模型参数</p><script type="math/tex; mode=display">\begin{equation}\begin{split}  f^* = F(D_{train})    \end{split}\end{equation}</script><p>其中F 代表元学习算法，D是数据，f就是function。理解下图：</p><p><img src="https://i.loli.net/2021/05/09/rMLgmoSywHJcq5u.png" alt=""></p><h3 id="和机器学习的区别"><a href="#和机器学习的区别" class="headerlink" title="和机器学习的区别"></a>和机器学习的区别</h3><p>机器学习：定义一系列function—-&gt;定一个function好坏的指标——-&gt; 用gradient decent找到一个最好的function</p><p>元学习(也是找一个function)：定义一系列大Function——-&gt;定一个评价大Function好坏的指标——-&gt;找到一个最好的大Function</p><h3 id="和终身学习-Life-long-learning-有些像？"><a href="#和终身学习-Life-long-learning-有些像？" class="headerlink" title="和终身学习(Life-long learning)有些像？"></a>和终身学习(Life-long learning)有些像？</h3><p><a href="https://blog.csdn.net/zyy617532750/article/details/104217399">持续/终身学习</a>：是让同一个模型可以同时学会很多任务技能</p><p>而元学习是不同的任务仍然有不同的模型，我们期待的是模型通过以前的学习经历可以让他在未来别的任务上学的好。</p><h2 id="元学习过程"><a href="#元学习过程" class="headerlink" title="元学习过程"></a>元学习过程</h2><h3 id="定义一系列学习算法"><a href="#定义一系列学习算法" class="headerlink" title="定义一系列学习算法"></a>定义一系列学习算法</h3><p>为什么是一系列学习算法，其实不同的模型参数、不同的结构、不同的学习参数的组合都是不同的学习算法。</p><p><img src="https://i.loli.net/2021/05/09/P6iANVszETHWB37.png" alt=""></p><p>以梯度下降法为例，首先定义一个网络结构，初始化一个参数，通过训练数据计算一个梯度g，再通过学习率更新参数。</p><p>迭代多次最后得到最终参数$\hat \theta$</p><p>但上图中红色框框内的都是人为定义的。元学习就是想让这红框内的东西，不让人来设计，让机器根据先验知识来自己学习设计。</p><h3 id="评估function参数好坏"><a href="#评估function参数好坏" class="headerlink" title="评估function参数好坏"></a>评估function参数好坏</h3><p>让模型先学一些任务，去解一些问题看看。</p><p>比如Task1：用一些$D<em>{train}$ 数据去训练模型得到$f_1$ ,再用Task1的$D</em>{test}$ 去衡量 $f_1$ 得到一个loss $l_1$</p><p>一个任务不够，再多找些任务来</p><p>Task2：用一些$D<em>{train}$ 数据去训练模型得到$f_2$ ,再用Task2的$D</em>{test}$ 去衡量 $f_2$得到一个loss $l_2$</p><p>最后得到评价F好坏的Loss：</p><script type="math/tex; mode=display">\begin{equation}\begin{split}  L(F) &= \sum_{n=1}^Nl_n\\ F^* &= argmin_FL(F)    \end{split}\end{equation}</script><p>N 为任务数</p><p>meta learning 通常会把task的Train叫做Suppot set，Test叫做Query set</p><h2 id="MAML-Model-Agnostic-Meta-Learning"><a href="#MAML-Model-Agnostic-Meta-Learning" class="headerlink" title="MAML(Model Agnostic Meta-Learning)"></a>MAML(Model Agnostic Meta-Learning)</h2><p>学一个初始化的参数</p><script type="math/tex; mode=display">\begin{equation}\begin{split}  L(\phi) = \sum_{n=1}^N l^n(\hat \theta^n)    \end{split}\end{equation}</script><p>$\phi$ 输入的初始化参数，$\hat \theta^n$ 在第n个task上学出来的model，$\hat \theta^n$ 取决于$\phi$ </p><p>$l^n(\hat \theta^n)$: 把$\hat \theta^n$这组参数拿到第n个task的测试集中去看看效果怎么样</p><p>怎么确定初始化的参数好不好，就用初始化参数到不同task上去做训练</p><p>最小化$L(\phi)$ : $\phi \gets \phi-\alpha ▽_{\phi}L(\phi)$</p><h3 id="和迁移学习-Transfer-learning-预训练有些像？"><a href="#和迁移学习-Transfer-learning-预训练有些像？" class="headerlink" title="和迁移学习(Transfer learning) 预训练有些像？"></a>和迁移学习(Transfer learning) 预训练有些像？</h3><p>迁移学习：某一个任务的数据很少，但另外一个任务的数据多。就把model预训练在多的数据上，再fine-tuning在少的数据上。</p><p>他的loss function：</p><script type="math/tex; mode=display">\begin{equation}\begin{split}   L(\phi) = \sum_{n=1}^N l^n(\phi)    \end{split}\end{equation}</script><p>在MAML里面loss是用$\phi$ 训练完后的model计算出来的，是训练过后的model</p><p>在pretrain里是用现在这个model直接去下游任务中衡量表现怎么样。</p><p>有的文章把预训练改成MAML的形式，以缓解预训练任务和下游任务直接目标不同产生的gap。</p><p>在MAML中，我们不在意$\phi$ 在training task上的表现，在意的是用$\phi$ 训练出来的$\hat \theta^n$的表现如何</p><p>（面向的是<strong>学习的过程</strong>，并不是<strong>学习的结果</strong>）</p><p><img src="https://i.loli.net/2021/05/10/7V2Uua4g8e9R1tk.png" alt=""></p><p><img src="https://i.loli.net/2021/05/10/epRfZzxlFTgSjVI.png" alt=""></p><p>如上图虽然$\phi$ 本身表现不够好，但$\phi$经过训练以后可以变得很强 (潜力如何)</p><p>而pretrain在意的是现在这个$\phi$表现的怎么样，是在找寻在所有task都最好的$\phi$, 并不保证训练以后会得到好的 $ \hat \theta^n$ （现在表现如何）</p><p>并且MAML只训练很少的步数，因为</p><ul><li>为了快速</li><li>希望在训练一步就得到很好的结果</li><li>在使用算法模型时可以多update</li><li>为了适应Few-shot learning </li></ul><h3 id="Toy-Example"><a href="#Toy-Example" class="headerlink" title="Toy Example"></a>Toy Example</h3><p>每一个任务：</p><ul><li>给一个目标sin函数 $y = a sin(x+b)$ 其中 a、b 都是随机数，每一组 a、b 对应一条正弦曲线</li><li>从目标函数中采样k个点</li><li>使用采样点去估计目标函数</li></ul><p>希望拟合的y越好越好。随机采样不同的a和b就可以得到不同的任务。</p><p><img src="https://i.loli.net/2021/05/10/9YnTfrxqoBDgVCU.png" alt=""></p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a href="https://zhuanlan.zhihu.com/p/367684934">元学习-总结</a></p><p><a href="https://zhuanlan.zhihu.com/p/108503451">元学习（Meta-learning）——李宏毅老师教学视频笔记</a></p><p><a href="https://zhuanlan.zhihu.com/p/181709693">[meta-learning] 对MAML的深度解析</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Meta-Learning&quot;&gt;&lt;a href=&quot;#Meta-Learning&quot; class=&quot;headerlink&quot; title=&quot;Meta Learning&quot;&gt;&lt;/a&gt;Meta Learning&lt;/h1&gt;&lt;p&gt;李宏毅：&lt;a href=&quot;https://www.b</summary>
      
    
    
    
    
    <category term="ML&amp;DL" scheme="http://example.com/tags/ML-DL/"/>
    
  </entry>
  
  <entry>
    <title>Learning to Pre-train Graph Neural Networks</title>
    <link href="http://example.com/2021/05/08/Learning-to-Pre-train-Graph-Neural-Networks/"/>
    <id>http://example.com/2021/05/08/Learning-to-Pre-train-Graph-Neural-Networks/</id>
    <published>2021-05-08T14:19:46.000Z</published>
    <updated>2021-05-10T12:18:03.591Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Learning-to-Pre-train-Graph-Neural-Networks"><a href="#Learning-to-Pre-train-Graph-Neural-Networks" class="headerlink" title="Learning to Pre-train Graph Neural Networks"></a>Learning to Pre-train Graph Neural Networks</h1><h2 id="动机与挑战"><a href="#动机与挑战" class="headerlink" title="动机与挑战"></a>动机与挑战</h2><p>图神经网络也是有预训练模型的，预训练之所以可以提升，可以解释为获取了有用的先验知识，并迁移到任务中。</p><p>常规的GNN预训练步骤和其他网络一样分为两个步骤：</p><ul><li>在大量未标记的图数据上预先训练GNN模型，其导出编码固有图属性的通用可转移知识</li><li>在特定于任务的图形数据上对预先训练的GNN模型进行微调，以使通用知识适用于下游任务。</li></ul><p>但之前有人已经研究过直接进行fine-tuning效果不提反降，产生负迁移效果。应该是出自(Strategies for Pre-training Graph Neural Networks 如何解决的以后看了这篇论文再说) </p><p>而这篇文章的主要想解决的是由于预训练和fine-tuning优化目标的不同，两者之间存在明显差距，损害了模型的泛化效果。</p><p>引出了第一个挑战：如何缩小不同优化目标带来的差距？ —-&gt;&gt;元学习思想</p><p>那GNN的预训练模型的特点是不仅要考虑局部的节点级先验知识还要获取图级别的全局先验知识 (现有方法要么只考虑节点级的预训练，或者仍然需要用有监督的图级预训练)</p><p>引出了第二个挑战：如何利用完全未标记的图数据同时保留节点级和图形级信息？</p><p>提出了L2P-GNN，计了节点级和图级的双重自适应机制，并且是完全自监督的方式。</p><h2 id="设计"><a href="#设计" class="headerlink" title="设计"></a>设计</h2><h3 id="GNN"><a href="#GNN" class="headerlink" title="GNN"></a>GNN</h3><p>首先定义一个图 $G = (V,E,X,Z)$ , 其中 $V$ 是节点、$E$ 是边、$X \in R ^{|V|\times d_v}$ 是节点特征、 $Z \in R^{|E|\times d_e}$ 是边的特征。</p><p>GNN 一般包含两个关键的计算，一个是聚合信息的操作AGGREGATE，另一个是更新操作UPDATE</p><p>节点表示：节点v的l层表示由下式给出：</p><script type="math/tex; mode=display">\begin{equation}\begin{split}  h_v^l &= \Psi (\psi, A, X,Z)^l\\ &= \text{UPDATAE}(h_v^{l-1}, AGGREGATE(\{(h_v^{l-1}, h_u^{l-1}, z_{uv}): u\in N_v\}))\end{split}\end{equation}</script><p>其中 $z_{uv}$ 是u到v的边特征向量，A是邻接矩阵 ，$N_v$ 是v的邻居节点。$\Psi$ 是聚合和更新操作的定义，$\psi$ 是可学习参数。</p><p>图级的表示：通常用READOUT </p><script type="math/tex; mode=display">\begin{equation}\begin{split}  h_G = \Omega(w ; H^l) = \text{READOUT} (\{h_v^l| v\in V\})    \end{split}\end{equation}</script><p>其中$H^l = [h_v^l]$ 是节点级表达矩阵。READOUT的典型实现有sum、max、mean池化，或者用其他复杂一点的方法。</p><h3 id="常规GNN的预训练"><a href="#常规GNN的预训练" class="headerlink" title="常规GNN的预训练"></a>常规GNN的预训练</h3><ol><li>预训练：定义 $D^{pre}$ 为预训练图数据，$L^{pre}$ 预训练的loss ，优化目标为：</li></ol><script type="math/tex; mode=display">\theta_0 = argmin_{\theta}  L^{pre} (f_\theta; D^{pre})</script><ol><li>fine-tuning：目标是，在对下游任务的训练集图数据$D^{tr}$进行微调之后，最大化下游测试集图数据$D^{te}$上的表现 </li></ol><p>所谓的微调根据预先训练的参数$\theta<em>0$来初始化模型，并且用在(通常是批处理的)$D</em>{tr}$上的多步梯度下降来更新GNN模型 $f_{\theta}$。</p><script type="math/tex; mode=display">\theta_1 = \theta_0 - \eta ▽_{\theta_0} L^{fine}(f_{\theta_0};D^{tr})</script><p>其中 $ \eta$ 学习率</p><p>可见常规的预训练和finetuing是解耦的，参数$\theta_0$ 和下游没有适应性的联系形式。</p><p>为此，作者提出通过构建预训练阶段来模拟下游任务的微调过程，从而直接优化预训练模型对下游任务的快速适应性。</p><h3 id="新的预训练方法"><a href="#新的预训练方法" class="headerlink" title="新的预训练方法"></a>新的预训练方法</h3><p>其实就是元学习的思想 参考上文 <a href="https://coding-zuo.github.io/2021/05/09/Meta-Learning-%E6%9D%8E%E5%AE%8F%E6%AF%85/">Meta Learning(李宏毅)</a></p><p>现有$G\in D^{pre}$ 从中采样一些子图 定义为$D^{tr}<em>{T_G}$ 作为模拟下游任务$T_G$的训练数据——元学习中的support sets，再采样一些子图作为$D^{te}</em>{T_G}$ 作为模拟的验证集——元学习中的query sets。</p><script type="math/tex; mode=display">\theta_0 = argmin_{\theta} \sum_{G\in D^{pre}} L^{pre}(f_{\theta - \alpha ▽_{\theta}L^{pre}(f_{\theta}; D^{tr}_{T_G})}; D^{te}_{T_G})</script><p>$\theta - \alpha ▽<em>{\theta}L^{pre}(f</em>{\theta}; D^{tr}<em>{T_G})$ 相当于在$D^{tr}</em>{T_G}$ 预训练的测试集先进行了一次fine-tuning</p><p>作者认为：因此，预培训输出$θ_0$并不是为了直接优化任何特定任务的训练或测试数据。相反，θ0通常是最佳的，因为它允许快速适应新任务。</p><p>我认为：这类似元学习的思想，还可以从元知识的角度来描述。还有一个点，这个预训练数据集和下游任务相不相关呢？如果相关度不大会不会有用，如果相关会不会更好？</p><h2 id="L2P-GNN"><a href="#L2P-GNN" class="headerlink" title="L2P_GNN"></a>L2P_GNN</h2><p>两个特点：</p><ul><li>从局部和全局角度捕捉图形中的结构和属性</li><li>套用MAML获得元学习的先验知识可以适应新的任务或图表</li></ul><h3 id="任务实施"><a href="#任务实施" class="headerlink" title="任务实施"></a>任务实施</h3><p>定义每个任务的图数据随机采样得到 $T_G = (S_G,Q_G)$ , $S_G$ 为Support set ，$Q_G$ 为Query set</p><p><img src="/Users/zuoyuhui/Library/Application Support/typora-user-images/image-20210510173143614.png" alt=""></p><p>多个任务的支持集合查询集为: $S_G =(S_G^1,S_G^2,…,S_G^k) ,Q_G =(Q_G^1,Q_G^2,…,Q_G^k)$</p><p>在给定父任务和子任务的情况下，作者设计了一个节点级聚集和图级汇集的自监督基本GNN模型，分别学习节点和图的表示。其核心思想是利用无标签图数据的内在结构作为节点级和图级的自我监督。</p><p>节点级：自监督预测u和v节点有边链接的目标函数</p><script type="math/tex; mode=display">L^{node}(\psi;S_G^c) = \sum_{(u,v)\in S_G^e} -ln(\sigma(h_u^Th_v)) -ln(\sigma(-h_u^Th_{v'}))</script><p>其中 $v’$ 是负采样节点，是没有和u有边的节点。</p><p>图级：通过图池化获得图表达$h<em>G$，每个任务的支持集图表达为 $h</em>{S_G^c} = \Omega(w;{h_u|\forall u,\exists v:(u,v) \in S_G^c})$</p><script type="math/tex; mode=display">L^{graph} (w; S_G) = \sum_{c=1}^k -log(\sigma(h_{S_G^c}^T h_G)) -log(\sigma(-h^T_{S_G^c}h_{G'}))</script><p>两个级别的loss综合到一起：</p><script type="math/tex; mode=display">L_{T_G}(\theta;S_G) = L^{graph}(w;S_G) + \frac{1}{k} \sum_{c=1}^k L^{node}(\psi;S_G^c)</script><p>其中$\theta = {\psi,w}$ 是可学习参数，就是可迁移的先验知识</p><h3 id="双重适应-图级和节点级"><a href="#双重适应-图级和节点级" class="headerlink" title="双重适应(图级和节点级)"></a>双重适应(图级和节点级)</h3><p><img src="https://i.loli.net/2021/05/10/ahQdOwrHvFgKIxy.png" alt=""></p><p>节点级：支持loss采用一个或几个梯度下降步骤，以获得子任务的适应先验 $ψ$。例如，当使用一个具有节点级学习率$α$的梯度更新时:</p><script type="math/tex; mode=display">\psi' = \psi - \alpha \frac{\partial\sum_{c=1}^k L^{node}(\psi;S_G^c)}{\partial\psi}</script><p>图级：</p><script type="math/tex; mode=display">w' = \psi - \beta \frac{\partial  L^{graph}(w;S_G^c)}{\partial w}</script><p>所有任务的更新参数过程</p><script type="math/tex; mode=display">\theta \gets \theta - \gamma\frac{\partial\sum_{G\in D^{pre}}L_{T_G}(\theta';Q_G) }{\partial \theta}</script><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>实验的主要目的：要验证有没有缩小预训练和微调的gap图级和节点级预训练策略是否奏效</p><p>作者对预训练的GNN模型在下游任务微调前后（命名为model-P和model-F）进行了对比分析，并考虑了三个比较视角：model-P和model-F参数之间的中心核对齐相似性（CKA），训练损失（delta损失）和下游任务测试性能（delta RUC-AUC或Micro-F1）的变化。</p><p><img src="https://i.loli.net/2021/05/10/wiGa9eSAcgNy62u.png" alt=""></p><p>如图所示，观察到L2P-GNN参数在微调前后的CKA相似性通常比基线的CKA相似性小，这表明L2P-GNN经历了更大的变化，以便更好地适应下游任务。</p><p>CKA 是测量神经网络表示相似性的，可以对迁移学习任务进行评估，值越小越相似。</p><p>此外，L2P-GNN的训练损失变化较小，说明L2P-GNN通过快速适应可以很容易地达到新任务的最优点。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><h3 id="GNN预训练的论文"><a href="#GNN预训练的论文" class="headerlink" title="GNN预训练的论文"></a>GNN预训练的论文</h3><p>Hu, W.; Liu, B.; Gomes, J.; Zitnik, M.; Liang, P.; Pande, V. S.; and Leskovec, J. 2020. Strategies for Pre-training Graph Neural Networks. In <em>Proceedings of ICLR</em>.</p><p>Hu, Z.; Fan, C.; Chen, T.; Chang, K.; and Sun, Y. 2019. Pre-Training Graph Neural Networks for Generic Structural Feature Extraction. <em>CoRR</em> abs/1905.13728.</p><p>Navarin, N.; Tran, D. V.; and Sperduti, A. 2018. Pre-training Graph Neural Networks with Kernels. <em>CoRR</em> abs/1811.06930.</p><h3 id="元学习"><a href="#元学习" class="headerlink" title="元学习"></a>元学习</h3><p>Finn, C.; Abbeel, P.; and Levine, S. 2017. Model-agnostic meta-learning for fast adaptation of deep networks. In <em>Pro- ceedings of ICML</em>, 1126–1135.</p><p>Lu, Y.; Fang, Y.; and Shi, C. 2020. Meta-learning on Hetero- geneous Information Networks for Cold-start Recommenda- tion. In <em>Proceedings of KDD</em>, 1563–1573.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Learning-to-Pre-train-Graph-Neural-Networks&quot;&gt;&lt;a href=&quot;#Learning-to-Pre-train-Graph-Neural-Networks&quot; class=&quot;headerlink&quot; title=&quot;Learni</summary>
      
    
    
    
    
    <category term="GNN" scheme="http://example.com/tags/GNN/"/>
    
  </entry>
  
  <entry>
    <title>DP——最大子序和</title>
    <link href="http://example.com/2021/05/06/DP%E2%80%94%E2%80%94%E6%9C%80%E5%A4%A7%E5%AD%90%E5%BA%8F%E5%92%8C/"/>
    <id>http://example.com/2021/05/06/DP%E2%80%94%E2%80%94%E6%9C%80%E5%A4%A7%E5%AD%90%E5%BA%8F%E5%92%8C/</id>
    <published>2021-05-06T01:30:10.000Z</published>
    <updated>2021-05-06T03:21:31.900Z</updated>
    
    <content type="html"><![CDATA[<h1 id="DP——最大子序和"><a href="#DP——最大子序和" class="headerlink" title="DP——最大子序和"></a>DP——最大子序和</h1><p><a href="https://www.acwing.com/problem/content/137/">https://www.acwing.com/problem/content/137/</a></p><p>输入一个长度为 n 的整数序列，从中找出一段长度不超过 m 的连续子序列，使得子序列中所有数的和最大。</p><p><strong>注意：</strong> 子序列的长度至少是 1。</p><h4 id="输入格式"><a href="#输入格式" class="headerlink" title="输入格式"></a>输入格式</h4><p>第一行输入两个整数 n,m。</p><p>第二行输入 n 个数，代表长度为 n 的整数序列。</p><p>同一行数之间用空格隔开。</p><h4 id="输出格式"><a href="#输出格式" class="headerlink" title="输出格式"></a>输出格式</h4><p>输出一个整数，代表该序列的最大子序和。</p><h4 id="数据范围"><a href="#数据范围" class="headerlink" title="数据范围"></a>数据范围</h4><p>1≤n,m≤300000</p><h4 id="输入样例："><a href="#输入样例：" class="headerlink" title="输入样例："></a>输入样例：</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">6 4</span><br><span class="line">1 -3 5 1 -2 3</span><br></pre></td></tr></table></figure><h4 id="输出样例："><a href="#输出样例：" class="headerlink" title="输出样例："></a>输出样例：</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">7</span><br></pre></td></tr></table></figure><h2 id="解"><a href="#解" class="headerlink" title="解"></a>解</h2><p><img src="https://i.loli.net/2021/05/06/QHsdPGY1q7FrtpB.png" alt=""></p><p>状态转移方程：集合代表的喊一声所有以i结尾的子段，如果i=3的话，那么集合可能是{1,num[i]}、{1,-3,num[i]}、{1,5,num[i]}、{num[i]} ，目标是求这些集合中的最大值，因为每个集合都有num[i]可先不考虑num[i]。</p><p>所以只要考虑f[i-1]+num[i] ,和只有num[i]的集合的最大值。</p><p>也就是考虑f[i-1]和0谁最大。</p><p>最终的答案是所有集合的值取最大</p><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><p>LeetCode53 不限制最大子序列长度</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">maxSubArray</span><span class="params">(<span class="keyword">int</span>[] num)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> last = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> res = Integer.MIN_VALUE;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; num.length; i++) &#123;</span><br><span class="line">            <span class="keyword">int</span> now = Math.max(last, <span class="number">0</span>) + num[i];</span><br><span class="line">            res = Math.max(res, now);</span><br><span class="line">            last = now;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>acwing 135 限制最大子序列长度</p><p>不同的是，对于每一个i，要求前面长度为m这个段内，求一个最小值</p><p><img src="https://i.loli.net/2021/05/06/KfOS1Mzt4GxnoUd.png" alt=""></p><script type="math/tex; mode=display">max\{Sum_i - Sum_j\} , i-m 到 i-1</script><p>可以用一个队列来维护m个数</p><p>每次i向后移动，就插入一个数同时队首出列</p><ul><li>用一个单调队列</li><li>把没用的数删去</li><li>变成单调递增的序列</li><li>用$0(1)$ 把 min或max找出</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span></span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">run</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">int</span> n = jin.nextInt();</span><br><span class="line">        <span class="keyword">int</span> m = jin.nextInt();</span><br><span class="line">        nums.add(<span class="number">0</span>);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span> ; i &lt; n ; i++) nums.add(jin.nextInt());</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span> ; i &lt;= n ; i++) nums.set(i, nums.get(i)+nums.get(i-<span class="number">1</span>));</span><br><span class="line"></span><br><span class="line">        <span class="keyword">int</span> res = Integer.MIN_VALUE;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= n ; i++)&#123;</span><br><span class="line">            <span class="keyword">while</span>(!queue.isEmpty() &amp;&amp; i - queue.peekFirst() &gt; m) queue.removeFirst();</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (!queue.isEmpty()) res = Math.max(res, nums.get(i) - nums.get(queue.peekFirst())); <span class="comment">// why not peekF -1 ?</span></span><br><span class="line">            <span class="keyword">else</span> res = Math.max(res, nums.get(i));                                              <span class="comment">// 差点漏掉了</span></span><br><span class="line">            <span class="keyword">while</span>(!queue.isEmpty() &amp;&amp; nums.get(i) &lt;= nums.get(queue.peekLast())) queue.removeLast();</span><br><span class="line">            queue.offerLast(i);</span><br><span class="line">        &#125;</span><br><span class="line">        res = Math.max(res, nums.get(n) - nums.get(queue.peekFirst()-<span class="number">1</span>));</span><br><span class="line">        System.out.println(res);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    List&lt;Integer&gt; nums = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">    Deque&lt;Integer&gt; queue = <span class="keyword">new</span> LinkedList&lt;&gt;();</span><br><span class="line">    <span class="keyword">private</span> Scanner jin = <span class="keyword">new</span> Scanner(System.in);</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;<span class="keyword">new</span> Main().run();&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;DP——最大子序和&quot;&gt;&lt;a href=&quot;#DP——最大子序和&quot; class=&quot;headerlink&quot; title=&quot;DP——最大子序和&quot;&gt;&lt;/a&gt;DP——最大子序和&lt;/h1&gt;&lt;p&gt;&lt;a href=&quot;https://www.acwing.com/problem/co</summary>
      
    
    
    
    
    <category term="刷题" scheme="http://example.com/tags/%E5%88%B7%E9%A2%98/"/>
    
  </entry>
  
  <entry>
    <title>海华阅读理解比赛复盘</title>
    <link href="http://example.com/2021/05/01/%E6%B5%B7%E5%8D%8E%E9%98%85%E8%AF%BB%E7%90%86%E8%A7%A3%E6%AF%94%E8%B5%9B%E5%A4%8D%E7%9B%98/"/>
    <id>http://example.com/2021/05/01/%E6%B5%B7%E5%8D%8E%E9%98%85%E8%AF%BB%E7%90%86%E8%A7%A3%E6%AF%94%E8%B5%9B%E5%A4%8D%E7%9B%98/</id>
    <published>2021-05-01T02:29:30.000Z</published>
    <updated>2021-05-01T07:08:15.275Z</updated>
    
    <content type="html"><![CDATA[<h1 id="海华阅读理解比赛复盘"><a href="#海华阅读理解比赛复盘" class="headerlink" title="海华阅读理解比赛复盘"></a>海华阅读理解比赛复盘</h1><p>比赛详情、EMA、Baseline，本文主要记录提分点和模型改进的验证</p><p>参考上文 <a href="https://coding-zuo.github.io/2021/04/06/%E6%B5%B7%E5%8D%8E%E4%B8%AD%E6%96%87%E9%98%85%E8%AF%BB%E7%90%86%E8%A7%A3%E6%AF%94%E8%B5%9B%E6%A2%B3%E7%90%86-%E5%A4%9A%E5%8D%A1%E5%B9%B6%E8%A1%8C-transformers/">海华中文阅读理解比赛梳理/多卡并行/transformers</a></p><p><a href="https://github.com/Coding-Zuo/MRC_multiChoice">github</a></p><h2 id="数据增强"><a href="#数据增强" class="headerlink" title="数据增强"></a>数据增强</h2><p>数据增强的办法很多参考 <a href="https://zhuanlan.zhihu.com/p/145521255">https://zhuanlan.zhihu.com/p/145521255</a></p><p>我只采用了句子乱序和数据回译，都是将增强数据和原始数据挨着放到数据集中，在训练的时候停用shuffle。(可能有其他方法：每条数据根据概率来选择性增强)，我这种可能会让数据集臃肿，质量下降。</p><h3 id="句子乱序"><a href="#句子乱序" class="headerlink" title="句子乱序"></a>句子乱序</h3><p>没有提分，也没有降很多。</p><p>原因参考：<a href="https://zhuanlan.zhihu.com/p/107594976">从知觉谈中文乱序不影响阅读的原因</a></p><p>代码：<a href="https://github.com/Coding-Zuo/MRC_multiChoice/blob/main/train/data_process.py">https://github.com/Coding-Zuo/MRC_multiChoice/blob/main/train/data_process.py</a> 中的data_enhancement_sentence_order</p><h3 id="数据回译"><a href="#数据回译" class="headerlink" title="数据回译"></a>数据回译</h3><p>和句子乱序一样和回译到的数据和原始数据挨着放到数据集，没有提分，可能是回译到的数据质量不好。</p><p>使用的是百度API，百度限制一个账户免费200万字符，如果超了就多注册几个账户薅羊毛。</p><p>代码：<a href="https://github.com/Coding-Zuo/MRC_multiChoice/blob/main/TranslateAPI.py">https://github.com/Coding-Zuo/MRC_multiChoice/blob/main/TranslateAPI.py</a></p><h3 id="在训练集上打伪标签"><a href="#在训练集上打伪标签" class="headerlink" title="在训练集上打伪标签"></a>在训练集上打伪标签</h3><p>由于时间问题，没有直接提交伪标签训练的结果，就直接模型融合。验证集有提高。</p><p>用训练好的模型去inference测试集，取了模型认为有百分之85概率认为是正确答案的数据打上伪标签，加入到训练集训练。</p><h2 id="优化训练"><a href="#优化训练" class="headerlink" title="优化训练"></a>优化训练</h2><h3 id="EMA"><a href="#EMA" class="headerlink" title="EMA"></a>EMA</h3><p>滑动平均exponential moving average</p><p>没有提分，反而效果变差。具体原因，还在探索，可能和优化方法有关？</p><p>我一直使用的都是adamw，<a href="https://www.cnblogs.com/tfknight/p/13425532.html">比较Adam 和Adamw</a> <a href="https://zhuanlan.zhihu.com/p/39543160">一文告诉你Adam、AdamW、Amsgrad区别和联系</a>，AdamW是在Adam+L2正则化的基础上进行改进的算法。</p><p>可以和sgd搭配看看效果。(这方面因为时间问题没有尝试充足)</p><p><a href="https://blog.csdn.net/weixin_43002433/article/details/113531466">PyTorch指数移动平均(EMA)手册</a></p><p>指数移动平均EMA是用于估计变量的局部均值的，它可以使变量的更新不只取决于当前时刻的数据。</p><p>而是加权平均了近期一段时间内的历史数据，是的变量的更新更平滑，不易受到某次异常值的影响。</p><h3 id="labelSmoothing"><a href="#labelSmoothing" class="headerlink" title="labelSmoothing"></a>labelSmoothing</h3><p>精度提升不明显，但是缓解了验证集的loss上升。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LabelSmoothingCrossEntropy</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, eps=<span class="number">0.1</span>, reduction=<span class="string">&#x27;mean&#x27;</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(LabelSmoothingCrossEntropy, self).__init__()</span><br><span class="line">        self.eps = eps</span><br><span class="line">        self.reduction = reduction</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, output, target</span>):</span></span><br><span class="line">        c = output.size()[-<span class="number">1</span>]</span><br><span class="line">        log_preds = F.log_softmax(output, dim=-<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">if</span> self.reduction == <span class="string">&#x27;sum&#x27;</span>:</span><br><span class="line">            loss = -log_preds.<span class="built_in">sum</span>()</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            loss = -log_preds.<span class="built_in">sum</span>(dim=-<span class="number">1</span>)</span><br><span class="line">            <span class="keyword">if</span> self.reduction == <span class="string">&#x27;mean&#x27;</span>:</span><br><span class="line">                loss = loss.mean()</span><br><span class="line">        <span class="keyword">return</span> loss * self.eps / c + (<span class="number">1</span> - self.eps) * F.nll_loss(log_preds, target, reduction=self.reduction)</span><br></pre></td></tr></table></figure><h3 id="对抗训练"><a href="#对抗训练" class="headerlink" title="对抗训练"></a>对抗训练</h3><p>提升两个点以上</p><p>可参考我的 <a href="https://coding-zuo.github.io/adversary/index.html">ppt</a> 和以前文章</p><p>主要使用了fgm和pgd两个，都有提升的效果</p><p>但有时候pgd并没有提升，可能是在有些参数和加了伪标签的数据情况下，学习困难？</p><h3 id="早停"><a href="#早停" class="headerlink" title="早停"></a>早停</h3><p>bert的早停不太好控制，有时候一两个epoch之后还会更新，可能跟参数有关。</p><h2 id="模型改进"><a href="#模型改进" class="headerlink" title="模型改进"></a>模型改进</h2><h3 id="尝试用LongFormer"><a href="#尝试用LongFormer" class="headerlink" title="尝试用LongFormer"></a>尝试用LongFormer</h3><p>因为文本比较长，但因为没有时间测试而没有跑，不过已经基本调通，日后跑一跑。</p><h3 id="复现DUMA"><a href="#复现DUMA" class="headerlink" title="复现DUMA"></a>复现DUMA</h3><p>用co-attention 来分别处理 bert输出的文章编码和问题答案对编码，分别送到co-attention中。</p><p>我的方法是分别为文章和问题答案设置一个maxlen， 多的截掉，因为我机器只能最大总长度跑到400，而数据文章又比较长，可能这也会导致学习瓶颈的出现。</p><p>我的另一个实现想法但是没有时间做的是，把文章和问题答案拼在一起用sep分割送入bert，输出时只要找到sep的timesteps进行分割，对于得到的两个不等长的向量，在经过对其。送入co-attention。</p><p>训练刚开始有一个比较好的提分劲头，但随着深入训练后期效果乏力。可能是因为参数没有调好？DUMA那篇论文没有复现细节。</p><h3 id="尝试其他比赛前排模型"><a href="#尝试其他比赛前排模型" class="headerlink" title="尝试其他比赛前排模型"></a>尝试其他比赛前排模型</h3><p><img src="https://i.loli.net/2021/05/01/f1QIsuWtSVXCcBx.png" alt=""></p><p>移植后问题：训练集准确率很低，具体问题还需探究。</p><h3 id="尝试在bert后加self-attention层"><a href="#尝试在bert后加self-attention层" class="headerlink" title="尝试在bert后加self-attention层"></a>尝试在bert后加self-attention层</h3><p>用pool_output,投入自注意力，没有明显提升</p><p>在bert后加多层线性也没有明显提升。不过可以尝试加highway network。</p><h2 id="模型融合"><a href="#模型融合" class="headerlink" title="模型融合"></a>模型融合</h2><p>组合不同参数和结构的打包模型，用argmax的方法融合了九个，达到最好的51.7分，晋级分数最终为52分，遗憾落榜。</p><p>还尝试用实现vote投票来融合，并没有最终提交。</p><p>以后将会尝试实现bert的stacking融合。</p><h2 id="遇到的难题"><a href="#遇到的难题" class="headerlink" title="遇到的难题"></a>遇到的难题</h2><ol><li><p>bert换成roberta后始终不收敛，因为没有经验，学习率试过1e-5, 1e-6, 2e-5,和不同batch32、64、128进行组合都不收敛(浪费了很多时间)。最终发现学习率在1e-5,2e-5 ,batch 在8或16才会收敛。</p><p>并参照roberta论文附录中的参数，收敛了，但是效果没有达到预期，不过听说好多人也是用了roberta。</p></li></ol><p><img src="https://i.loli.net/2021/05/01/7vZQHiFus6DqJI2.png" alt=""></p><ol><li>调参没经验，浪费了很多时间。</li></ol><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>用了将近一个月的时间来做这个比赛，对模型训练体系、模型理解、微调下游任务、多卡并行、对抗训练。还有好多理论需要通过实践来加深理解。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;海华阅读理解比赛复盘&quot;&gt;&lt;a href=&quot;#海华阅读理解比赛复盘&quot; class=&quot;headerlink&quot; title=&quot;海华阅读理解比赛复盘&quot;&gt;&lt;/a&gt;海华阅读理解比赛复盘&lt;/h1&gt;&lt;p&gt;比赛详情、EMA、Baseline，本文主要记录提分点和模型改进的验证&lt;/p</summary>
      
    
    
    
    
    <category term="DataGame" scheme="http://example.com/tags/DataGame/"/>
    
  </entry>
  
  <entry>
    <title>阅读理解文献梳理</title>
    <link href="http://example.com/2021/04/29/%E9%98%85%E8%AF%BB%E7%90%86%E8%A7%A3%E6%96%87%E7%8C%AE%E6%A2%B3%E7%90%86/"/>
    <id>http://example.com/2021/04/29/%E9%98%85%E8%AF%BB%E7%90%86%E8%A7%A3%E6%96%87%E7%8C%AE%E6%A2%B3%E7%90%86/</id>
    <published>2021-04-29T08:49:50.000Z</published>
    <updated>2021-05-10T07:14:59.431Z</updated>
    
    <content type="html"><![CDATA[<h1 id="阅读理解文献梳理"><a href="#阅读理解文献梳理" class="headerlink" title="阅读理解文献梳理"></a>阅读理解文献梳理</h1><h2 id="多跳QA"><a href="#多跳QA" class="headerlink" title="多跳QA"></a>多跳QA</h2><h3 id="模型在任务中学习的多跳推理行为。"><a href="#模型在任务中学习的多跳推理行为。" class="headerlink" title="模型在任务中学习的多跳推理行为。"></a>模型在任务中学习的多跳推理行为。</h3><p>QFE (Nishida et al., 2019) regards evidence extraction as a query-focused summarization task, and reformulates the query in each hop.    将证据提取作为以查询为中心的摘要任务，并在每一跳中重构查询。—— HGN</p><p>Kosuke Nishida, Kyosuke Nishida, Masaaki Nagata, Atsushi Otsuka, Itsumi Saito, Hisako Asano, and Junji Tomita. 2019. Answering while summarizing: Multi-task learning for multi-hop qa with evidence extraction. In <em>ACL</em>.</p><hr><p> DecompRC (Min et al., 2019b) decomposes a compositional question into simpler sub-questions and leverages single-hop MRC mod- els to answer the sub-questions.  将作文问题分解为更简单的子问题，并利用单跳MRC模型答复子问题—— HGN</p><p>Sewon Min, Victor Zhong, Luke Zettlemoyer, and Han- naneh Hajishirzi. 2019b. Multi-hop reading compre- hension through question decomposition and rescor- ing. In <em>ACL</em>.</p><hr><p>A neural modular network is also proposed in Jiang and Bansal (2019b), where neural modules are dynamically assembled for more interpretable multi-hop rea- soning.一种神经模块网络，其中神经模块被动态地组装起来，以便更好地解释多跳推理。—— HGN</p><p>Yichen Jiang and Mohit Bansal. 2019b. Self- assembling modular networks for interpretable multi-hop reasoning. In <em>EMNLP</em>.</p><hr><p>其他</p><p>Jifan Chen and Greg Durrett. 2019. Understanding dataset design choices for multi-hop reasoning. In <em>NAACL</em>.—— HGN</p><p>Sewon Min, Eric Wallace, Sameer Singh, Matt Gard- ner, Hannaneh Hajishirzi, and Luke Zettlemoyer. 2019a. Compositional questions do not necessitate multi-hop reasoning. In <em>ACL</em>.—— HGN</p><p>Yichen Jiang and Mohit Bansal. 2019a. Avoiding rea- soning shortcuts: Adversarial evaluation, training, and model development for multi-hop qa. In <em>ACL</em>.—— HGN</p><hr><h3 id="与GNN相关的"><a href="#与GNN相关的" class="headerlink" title="与GNN相关的"></a>与GNN相关的</h3><p>Coref-GRN (Dhingra et al., 2018) construct an entity graph based on co-reference reso- lution or sliding windows.基于共引用解决方案或滑动窗口构建实体图。—— HGN</p><p>Bhuwan Dhingra, Qiao Jin, Zhilin Yang, William W Cohen, and Ruslan Salakhutdinov. 2018. Neural models for reasoning over multiple mentions using coreference. In <em>NAACL</em>.</p><hr><p>Entity-GCN (De Cao et al., 2019) considers three different types of edges that connect different entities in the entity graph.考虑连接实体图中不同实体的三种不同类型的边。—— HGN</p><p>Nicola De Cao, Wilker Aziz, and Ivan Titov. 2019. Question answering by reasoning across documents with graph convolutional networks. In <em>NAACL</em>.</p><hr><p><strong>(已读)</strong>HDE-Graph (Tu et al., 2019) enriches information in the entity graph by adding document nodes and creating interactions among documents, entities and answer candidates.通过添加文档节点并在文档、实体和候选答案之间创建交互，丰富了实体图中的信息。——HGN</p><hr><p><strong>(已读)</strong>Cognitive Graph QA employs an MRC model to predict answer spans and possible next-hop spans, and then organizes them into a cognitive graph.使用MRC模型预测答案跨度和可能的下一跳跨度，然后将它们组织到认知图中。——HGN</p><hr><p>DFGN (Xiao et al., 2019) constructs a dynamic entity graph, where in each reasoning step irrelevant en- tities are softly masked out and a fusion module is designed to improve the interaction between the entity graph and documents.构建了一个动态实体图，在每个推理步骤中，不相关的实体被软屏蔽，并设计了一个融合模块来改善实体图与文档之间的交互性。——HGN</p><p>Yunxuan Xiao, Yanru Qu, Lin Qiu, Hao Zhou, Lei Li, Weinan Zhang, and Yong Yu. 2019. Dynamically fused graph network for multi-hop reasoning. In <em>ACL</em>.</p><hr><p><strong>(已读)</strong>SAE (Tu et al., 2020) defines three types of edge in the sentence graph based on the named entities and noun phrases appearing in the question and sentences 根据问题和句子中出现的命名实体和名词短语，定义句子图中的三种边——HGN</p><hr><p>C2F Reader (Shao et al., 2020) uses graph attention or self-attention on entity graph, and argues that this graph may not be necessary for multi-hop reasoning. 在实体图上使用图注意或自我注意，并认为该图对于多跳推理可能不是必需的。——HGN</p><p>Nan Shao, Yiming Cui, Ting Liu, Wang, and Guop- ing Hu Hu. 2020. Is graph structure necessary for multi-hop reasoningt. <em>arXiv preprint arXiv:2004.03096</em>.</p><hr><p>Asai et al. (2020) proposes a new graph-based recurrent method to find evidence documents as reasoning paths, which is more focused on information retrieval.提出了一种新的基于图的递归方法来寻找证据文档作为推理路径，更侧重于信息检索。——HGN</p><p>Akari Asai, Kazuma Hashimoto, Hannaneh Hajishirzi, Richard Socher, and Caiming Xiong. 2020. Learning to retrieve reasoning paths over wikipedia graph for question answering. In <em>ICLR</em>.</p><hr><p><strong>(已读)</strong>HGN 2020 提出的模型构建了一个层次图，有效地探索了不同粒度之间的关系，并使用不同的节点来执行不同的任务。</p><h2 id="GNN"><a href="#GNN" class="headerlink" title="GNN"></a>GNN</h2><h3 id="GNN结构机制"><a href="#GNN结构机制" class="headerlink" title="GNN结构机制"></a>GNN结构机制</h3><ul><li>GCN</li><li>SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS(ICLR 2017)</li><li>GAT</li><li>GraphSage</li><li>MPGNN</li><li>HGN</li><li>HAN</li></ul><h3 id="预训练GNN"><a href="#预训练GNN" class="headerlink" title="预训练GNN"></a>预训练GNN</h3><p>Hu, W.; Liu, B.; Gomes, J.; Zitnik, M.; Liang, P.; Pande, V. S.; and Leskovec, J. 2020. Strategies for Pre-training Graph Neural Networks. In <em>Proceedings of ICLR</em>.——L2P-GNN</p><p>提出了不同的策略来预训练图神经网络的节点和图级，虽然在图级需要标记的数据。</p><hr><p>Hu, Z.; Fan, C.; Chen, T.; Chang, K.; and Sun, Y. 2019. Pre-Training Graph Neural Networks for Generic Structural Feature Extraction. <em>CoRR</em> abs/1905.13728..——L2P-GNN</p><p>使用三个非监督任务预先培训图形编码器，以捕获图形的不同方面。</p><hr><p>Navarin, N.; Tran, D. V.; and Sperduti, A. 2018. Pre-training Graph Neural Networks with Kernels. <em>CoRR</em> abs/1811.06930..——L2P-GNN</p><p>利用图内核进行预培训</p><h2 id="元学习及应用"><a href="#元学习及应用" class="headerlink" title="元学习及应用"></a>元学习及应用</h2><p>Finn, C.; Abbeel, P.; and Levine, S. 2017. Model-agnostic meta-learning for fast adaptation of deep networks. In <em>Pro- ceedings of ICML</em>, 1126–1135.</p><p>Lu, Y.; Fang, Y.; and Shi, C. 2020. Meta-learning on Hetero- geneous Information Networks for Cold-start Recommenda- tion. In <em>Proceedings of KDD</em>, 1563–1573.</p><h2 id="预训练语言模型"><a href="#预训练语言模型" class="headerlink" title="预训练语言模型"></a>预训练语言模型</h2><ul><li>ALBERT</li><li>Roberta</li><li>Bert</li><li>LongFormer</li></ul><h2 id="对抗训练"><a href="#对抗训练" class="headerlink" title="对抗训练"></a>对抗训练</h2><ul><li>FGM</li><li>PGD</li><li>FreeLB</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;阅读理解文献梳理&quot;&gt;&lt;a href=&quot;#阅读理解文献梳理&quot; class=&quot;headerlink&quot; title=&quot;阅读理解文献梳理&quot;&gt;&lt;/a&gt;阅读理解文献梳理&lt;/h1&gt;&lt;h2 id=&quot;多跳QA&quot;&gt;&lt;a href=&quot;#多跳QA&quot; class=&quot;headerlink&quot; </summary>
      
    
    
    
    
    <category term="GNN&amp;nlp" scheme="http://example.com/tags/GNN-nlp/"/>
    
  </entry>
  
  <entry>
    <title>Hierarchical Graph Network for Multi-hop Question Answering</title>
    <link href="http://example.com/2021/04/29/Hierarchical-Graph-Network-for-Multi-hop-Question-Answering/"/>
    <id>http://example.com/2021/04/29/Hierarchical-Graph-Network-for-Multi-hop-Question-Answering/</id>
    <published>2021-04-29T05:19:33.000Z</published>
    <updated>2021-05-05T11:13:16.766Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Hierarchical-Graph-Network-for-Multi-hop-Question-Answering"><a href="#Hierarchical-Graph-Network-for-Multi-hop-Question-Answering" class="headerlink" title="Hierarchical Graph Network for Multi-hop Question Answering"></a>Hierarchical Graph Network for Multi-hop Question Answering</h1><p><a href="https://arxiv.org/pdf/1911.03631.pdf">https://arxiv.org/pdf/1911.03631.pdf</a></p><p>这篇文章也是HotpotQA数据集上的关于解决多跳问答场景的，在干扰项排行榜和全维基排行榜都曾是前列。</p><p>多跳QA和HotpotQA数据集 : <a href="https://coding-zuo.github.io/2021/03/23/HotpotQA%E6%95%B0%E6%8D%AE%E9%9B%86/">HotpotQA数据集：A Dataset for Diverse, Explainable Multi-hop Question Answering</a></p><p>其特点是</p><ul><li>通过在问题、段落、句子、实体等不同粒度上构建层次图(HGN)</li><li>通过HGN这种节点粒度层次可以区分，进一步进行多任务推理：段落选择、支持句预测、实体抽取、最终答案预测</li></ul><h2 id="如何构图"><a href="#如何构图" class="headerlink" title="如何构图"></a>如何构图</h2><p>首先来介绍下作者是如何构图的。</p><p><img src="https://i.loli.net/2021/05/01/sux1NI4eMgf2bcz.png" alt=""></p><p>段落由句子组成，每个句子包含多个实体。这个图自然是以层次结构编码的，它也激发了作者构建层次图的动机。</p><p>四种节点类型：</p><ul><li>问题节点Q</li><li>实体节点E</li><li>段落节点P：对于每个段落节点，在段落中的所有句子之间添加边。</li><li>句子节点S：对于每个句子节点，提取句子中的所有实体，并在段落句子节点和这些实体节点之间添加边。</li></ul><p>七种边类型：</p><ul><li>问题节点和定位段落节点有边</li><li>问题节点和问题中的实体节点有边</li><li>段落节点和段落中的句子节点有边</li><li>句子节点与其链接的段落节点之间的边(超链接链接)</li><li>句子节点和句子中所提取的实体节点有边</li><li>段落和段落之间有边(论文是取和问题最相关的前两个段落)</li><li>存在同一个段落的句子节点</li></ul><h2 id="挑战与动机"><a href="#挑战与动机" class="headerlink" title="挑战与动机"></a>挑战与动机</h2><p>HotpotQA的方案一般是先用一个检索器去找到包含正确答案的段落。然后在用MRC模型去选择段落去预测答案。</p><p>目前的挑战：即使通过多个段落成功地确认了推理链，如何从分散的段落中收集不同粒度级别的证据共同回答并支持事实预测，仍然是一个关键的挑战。</p><p>作者认为多跳阅读推理直观的步骤：</p><ul><li>找到与问题相关的段落</li><li>在段落中选择强有力的证据</li><li>从获得的证据中查明正确答案</li></ul><p>作者也是这么实现的，并创新的采用了多个层级的粒度信息去构图推理。</p><h2 id="HGN"><a href="#HGN" class="headerlink" title="HGN"></a>HGN</h2><p><img src="https://i.loli.net/2021/05/05/6eL2w9WqRcPdIMj.png" alt=""></p><p>模型包含四个模块：图构造模块、上下文编码模块、图推理模块、多任务预测模块</p><h3 id="图构造模块"><a href="#图构造模块" class="headerlink" title="图构造模块"></a>图构造模块</h3><p>就是构造上文的七种边四种节点，形成层级图</p><p>一共要考虑两步：</p><ul><li><p>选择相关段落：</p><p>第一跳：用预训练模型加一个二分类判断段落中是否包含支撑事实，</p><p>如果返回多个段落则选择排名靠前的两个作为段落节点。</p><p>如果标题匹配没有结果，则进一步搜索段落中包含问题实体的。</p><p>如果还是搜索失败，将会从段落排序中选择排名最高的段落。</p><p>确定第一跳后：下一步就是段落中找到可以通向其他相关段落的事实和实体(不再依赖实体链接，这可能会很引入噪音，而是在第一跳段落中使用超链接来发现第二跳段落。)</p></li></ul><ul><li>添加表示所选段落内的句子/实体之间的连接的边。</li></ul><h3 id="上下文编码模块"><a href="#上下文编码模块" class="headerlink" title="上下文编码模块"></a>上下文编码模块</h3><p>给出构建的层次图，下一步是获得所有图节点的初始表示。首先将所有选定的段落合并到上下文C中，将其与问题Q连接起来，输入Roberta。</p><p>$C = {c<em>0,c_1,…,c</em>{n-1}} \in \text{R}^{n\times d } , Q ={q<em>0,q_1,…,q</em>{m-1}}\in \text{R}^{m\times d}$</p><p>问题Q随后是一个双向注意力层。(2017. Bidirectional attention flow for machine comprehension. <em>ICLR</em>.)</p><p>在上下文表示C之上用BiLSTM，并且从BILSTM的输出中提取不同节点的表示，表示为$M∈R^{n×2d}$。</p><p>在BiLSTM后通过预测开始和结束位置来得到句子和实体节点。</p><p>$p_i$ 第i段落节点、$s_i$ 第i句子节点、 $e_i$ 第i个实体节点、q 问题节点 $\in \text{R}^d$</p><script type="math/tex; mode=display">\begin{equation}\begin{split}  p_i &= MLP_1 ([M[P^{(i)}_{start}][d:]; M[P^{(i)}_{end}][:d] ])\\  s_i &= MLP_2 ([M[S^{(i)}_{start}][d:]; M[S^{(i)}_{end}][:d] ])\\  e_i &= MLP_3 ([M[E^{(i)}_{start}][d:]; M[E^{(i)}_{end}][:d] ])\\  q &= \text{max-pooling}(Q)    \end{split}\end{equation}</script><h3 id="图推理模块"><a href="#图推理模块" class="headerlink" title="图推理模块"></a>图推理模块</h3><p>获得层次图所需要的节点：</p><ul><li>段落节点：$P = {p<em>i}^{n_p}</em>{i=1} , n_p=4$   </li><li>句子节点：$S = {s<em>i}^{n_s}</em>{i=1}, n_s=40$</li><li>实体节点：$E = {e<em>i}^{n_e}</em>{i=1}, n_e=60$</li></ul><p>定义图的临界矩阵为$H =  {q,P,S,E} \in \text{R}^{g\times d }  , g= n_p+n_s+n_e+1$</p><p> 经过GAT后，得到更新过后的每个节点表示$P’,S’,E’,q’$</p><p>为了让图信息进一步提取上下文答案跨度，这里还用更新后的节点表示H‘和之前的上下文表示M，通过一个门控注意力机制，用于答案跨度的预测。</p><p>具体表示为：</p><script type="math/tex; mode=display">\begin{equation}\begin{split}  C &= Relu(MW_m) \cdot Relu(H'W'_m)^T\\ \hat H &= Softmax(C)\cdot H'\\ G &= \sigma([M;\hat H]W_s) \cdot Tanh([M;\hat H]W_t)    \end{split}\end{equation}</script><p>其中：$W_m \in \text{R}^{2d\times 2d}$ ，$W’_m \in \text{R}^{2d\times 2d}$ ，$W_s \in \text{R}^{4d\times 4d}$ , $W_t\in \text{R}^{4d\times 4d}$</p><h3 id="多任务预测模块"><a href="#多任务预测模块" class="headerlink" title="多任务预测模块"></a>多任务预测模块</h3><ul><li>基于段落节点的段落选择</li><li>基于句子节点的支撑事实预测</li><li>基于实体节点和上下文G表示的答案预测</li></ul><p>最终目标函数</p><script type="math/tex; mode=display">\begin{equation}\begin{split}  \text{L}_{joint} = \text{L}_{start} +\text{L}_{end} + \lambda_1\text{L}_{para} + \lambda_2\text{L}_{sent} + \lambda_3\text{L}_{entity} + \lambda_4 \text{L}_{type}    \end{split}\end{equation}</script><p>其中$\lambda_{1,2,3,4}$ 超参数权重</p><p>$L_{type}$ 是预测答案类型的损失</p><h2 id="错误分析"><a href="#错误分析" class="headerlink" title="错误分析"></a>错误分析</h2><p><img src="https://i.loli.net/2021/05/05/ephOUw7zXAcK3bH.png" alt=""></p><p>作者在这分析了模型的弱点(为将来的工作提供了见解)，在dev集中随机抽样了100个答案f1为0的示例。</p><p>作者总结了六类错误</p><ul><li><p>Annotation批注：数据集中提供的批注不正确 </p><p>上图第一行：“Tonka”和“101只斑点狗”是在同一个十年上映的吗？数据集给的答案和实际情况不一样？这种应该是数据集错误吧， 这种错误占了9%。这种问题应该不是模型的弱点吧？</p></li><li><p>Multiple-Answers：问题可能有多个正确答案，但数据集中只提供一个答案</p><p>迈克尔·J·亨特取代了成为哪家机构管理员的律师？答案EPA是预测答案的缩写，这种问题也比较难解决，占了24%是比重最多的。</p></li><li><p>Discrete Reasoning:  这种类型的错误经常出现在“比较”题中，需要离散推理才能正确回答问题； 16%</p><p>在Mastodon和Hole这两个乐队中，哪个成员更多？ 可能是已知这两个乐队人数，要比较这两个数的大小</p></li><li><p>Commonsense &amp; External Knowledge： 要回答这类问题，需要常识或外部知识</p><p>迷你专辑Code#01的艺人第二次延长演出的名字是什么？</p></li><li><p>Multi-hop：模型不能进行多跳推理，从错误的段落中找到最终答案 16%</p><p>这部根据5：15出现的摇滚歌剧改编的电影是谁导演的？</p></li><li><p>MRC:  模型正确地找到了支持段落和句子，但预测了错误的答案跨度。 20%</p><p>艾达·洛夫莱斯，第一位计算机程序员，在“恰尔德·拜伦”中与拜伦勋爵有什么关系？答案是他的女儿，模型回答成紧张的关系，说明模型没有完全理解问题中的关系。</p></li></ul><p>可以看出HGN对于阅读理解的进行鲁棒性的回答还是有所不足，面对相同答案的多样性还有进一步的改进空间。</p><p>对于句子理解和推理定位还不够特别准确。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Hierarchical-Graph-Network-for-Multi-hop-Question-Answering&quot;&gt;&lt;a href=&quot;#Hierarchical-Graph-Network-for-Multi-hop-Question-Answering&quot; </summary>
      
    
    
    
    
    <category term="GNN&amp;nlp" scheme="http://example.com/tags/GNN-nlp/"/>
    
  </entry>
  
  <entry>
    <title>二分模板</title>
    <link href="http://example.com/2021/04/29/%E4%BA%8C%E5%88%86%E6%A8%A1%E6%9D%BF/"/>
    <id>http://example.com/2021/04/29/%E4%BA%8C%E5%88%86%E6%A8%A1%E6%9D%BF/</id>
    <published>2021-04-29T01:23:15.000Z</published>
    <updated>2021-04-29T03:17:35.583Z</updated>
    
    <content type="html"><![CDATA[<h1 id="二分模板"><a href="#二分模板" class="headerlink" title="二分模板"></a>二分模板</h1><p><a href="https://www.acwing.com/problem/content/791/">https://www.acwing.com/problem/content/791/</a></p><p>二分的本质不是单调性, 单调性的题目一定可以二分, 可以二分的题目不一定有单调性</p><p>二分的本质是边界<br>二分法用于查找, 每次都选择答案所在的区间再次进行查找, 当区间长度为 1时, 就是答案</p><p><img src="https://i.loli.net/2021/04/29/Hy4vGqOtus8lQXp.png" alt=""></p><ol><li>根据 check(mid)来判断 r和 l的取值范围</li><li>根据取值范围选择 mid是否有 + 1操作<ul><li>mid归于左边, r = mid, mid选择 不 +1</li><li>mid归于右边, l = mid, mid选择 +1</li></ul></li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.BufferedReader;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.io.InputStreamReader;</span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> 模板<span class="title">_</span>二分 </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        BufferedReader input = <span class="keyword">new</span> BufferedReader(<span class="keyword">new</span> InputStreamReader(System.in));</span><br><span class="line">        <span class="keyword">int</span>[] line1 = Arrays.asList(input.readLine().split(<span class="string">&quot; &quot;</span>)).stream().mapToInt(Integer::parseInt).toArray();</span><br><span class="line">        <span class="keyword">int</span> n = line1[<span class="number">0</span>];</span><br><span class="line">        <span class="keyword">int</span> q = line1[<span class="number">1</span>];</span><br><span class="line">        <span class="keyword">int</span>[] line2 = Arrays.asList(input.readLine().split(<span class="string">&quot; &quot;</span>)).stream().mapToInt(Integer::parseInt).toArray();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (q-- != <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">int</span> target = Integer.parseInt(input.readLine());</span><br><span class="line">            <span class="comment">// 查找左边界 用第一个模板</span></span><br><span class="line">            <span class="keyword">int</span> index_l = bsearch_1(line2, <span class="number">0</span>, n - <span class="number">1</span>, target);</span><br><span class="line">            <span class="keyword">if</span> (line2[index_l] != target) &#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;-1 -1&quot;</span>);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                System.out.print(index_l + <span class="string">&quot; &quot;</span>);</span><br><span class="line">                <span class="comment">// 查找右边界 用第二个模板</span></span><br><span class="line">                <span class="keyword">int</span> index_r = bsearch_2(line2, <span class="number">0</span>, n - <span class="number">1</span>, target);</span><br><span class="line">                System.out.print(index_r + <span class="string">&quot;\n&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">bsearch_1</span><span class="params">(<span class="keyword">int</span>[] arr, <span class="keyword">int</span> l, <span class="keyword">int</span> r, <span class="keyword">int</span> target)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">while</span> (l &lt; r) &#123;</span><br><span class="line">            <span class="keyword">int</span> mid = l + r &gt;&gt; <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">if</span> (arr[mid] &gt;= target) &#123;</span><br><span class="line">                r = mid;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                l = mid + <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> l;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">bsearch_2</span><span class="params">(<span class="keyword">int</span>[] arr, <span class="keyword">int</span> l, <span class="keyword">int</span> r, <span class="keyword">int</span> target)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">while</span> (l &lt; r) &#123;</span><br><span class="line">            <span class="keyword">int</span> mid = l + r + <span class="number">1</span> &gt;&gt; <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">if</span> (arr[mid] &lt;= target) &#123;</span><br><span class="line">                l = mid;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                r = mid - <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> l;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;二分模板&quot;&gt;&lt;a href=&quot;#二分模板&quot; class=&quot;headerlink&quot; title=&quot;二分模板&quot;&gt;&lt;/a&gt;二分模板&lt;/h1&gt;&lt;p&gt;&lt;a href=&quot;https://www.acwing.com/problem/content/791/&quot;&gt;https://</summary>
      
    
    
    
    
    <category term="刷题" scheme="http://example.com/tags/%E5%88%B7%E9%A2%98/"/>
    
  </entry>
  
  <entry>
    <title>归并排序模板</title>
    <link href="http://example.com/2021/04/28/%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F%E6%A8%A1%E6%9D%BF/"/>
    <id>http://example.com/2021/04/28/%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F%E6%A8%A1%E6%9D%BF/</id>
    <published>2021-04-28T01:16:02.000Z</published>
    <updated>2021-04-28T02:06:37.453Z</updated>
    
    <content type="html"><![CDATA[<h1 id="归并排序模板"><a href="#归并排序模板" class="headerlink" title="归并排序模板"></a>归并排序模板</h1><p>分治思想</p><p><img src="https://i.loli.net/2021/04/28/8g1qixHscOBTv6Q.png" alt=""></p><ol><li><p>确定分界点：$mid = (l+r)/2$</p></li><li><p>先递归分成左右两边</p></li><li><p>将两个有序数组合并成一个有序序列——归并</p><p>使用两个指针：这个过程时间复杂度为$O(n)$</p></li></ol><p><img src="https://i.loli.net/2021/04/28/d23pUiKgLOswDZm.png" alt=""></p><p>整体时间复杂度$O(nlogn)$</p><p>因为分层用了$logn$次</p><p><img src="https://i.loli.net/2021/04/28/WeSTDRHymJbg5KN.png" alt=""></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.BufferedReader;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.io.InputStreamReader;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> 模板<span class="title">_</span>归并排序 </span>&#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        BufferedReader input = <span class="keyword">new</span> BufferedReader(<span class="keyword">new</span> InputStreamReader(System.in));</span><br><span class="line">        <span class="keyword">int</span> n = Integer.parseInt(input.readLine());</span><br><span class="line">        <span class="keyword">int</span>[] q = <span class="keyword">new</span> <span class="keyword">int</span>[n];</span><br><span class="line">        String[] linelist = input.readLine().split(<span class="string">&quot; &quot;</span>);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; linelist.length; i++) &#123;</span><br><span class="line">            q[i] = Integer.parseInt(linelist[i]);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        merge_sort(q, <span class="number">0</span>, q.length - <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; q.length; i++) &#123;</span><br><span class="line">            System.out.print(q[i]);</span><br><span class="line">            System.out.print(<span class="string">&quot; &quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">merge_sort</span><span class="params">(<span class="keyword">int</span>[] q, <span class="keyword">int</span> l, <span class="keyword">int</span> r)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (l &gt;= r) <span class="keyword">return</span>;</span><br><span class="line">        <span class="comment">// 确定分界点</span></span><br><span class="line">        <span class="keyword">int</span> mid = l + ((r - l) &gt;&gt; <span class="number">1</span>);</span><br><span class="line">        <span class="comment">// 递归</span></span><br><span class="line">        merge_sort(q, l, mid);</span><br><span class="line">        merge_sort(q, mid + <span class="number">1</span>, r);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">int</span>[] tmp = <span class="keyword">new</span> <span class="keyword">int</span>[r - l + <span class="number">1</span>]; <span class="comment">// 辅助数组</span></span><br><span class="line">        <span class="comment">// 归并</span></span><br><span class="line">        <span class="keyword">int</span> k = <span class="number">0</span>; <span class="comment">// 表示tmp中有多少个数</span></span><br><span class="line">        <span class="comment">// 两个指针</span></span><br><span class="line">        <span class="keyword">int</span> i = l, j = mid + <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">while</span> (i &lt;= mid &amp;&amp; j &lt;= r) &#123;</span><br><span class="line">            <span class="keyword">if</span> (q[i] &lt;= q[j]) &#123;</span><br><span class="line">                tmp[k++] = q[i++];</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                tmp[k++] = q[j++];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 剩余</span></span><br><span class="line">        <span class="keyword">while</span> (i &lt;= mid) tmp[k++] = q[i++];</span><br><span class="line">        <span class="keyword">while</span> (j &lt;= r) tmp[k++] = q[j++];</span><br><span class="line">        <span class="comment">// 放回</span></span><br><span class="line">        <span class="keyword">for</span> (i = l, j = <span class="number">0</span>; i &lt;= r; i++, j++) q[i] = tmp[j];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;归并排序模板&quot;&gt;&lt;a href=&quot;#归并排序模板&quot; class=&quot;headerlink&quot; title=&quot;归并排序模板&quot;&gt;&lt;/a&gt;归并排序模板&lt;/h1&gt;&lt;p&gt;分治思想&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2021/04/28/8g</summary>
      
    
    
    
    
    <category term="刷题" scheme="http://example.com/tags/%E5%88%B7%E9%A2%98/"/>
    
  </entry>
  
  <entry>
    <title>Ubantu18.04安装NVIDIA驱动+cuda10.1+cuDNN+Tensorflow2.1.0</title>
    <link href="http://example.com/2021/04/26/Ubantu18-04%E5%AE%89%E8%A3%85NVIDIA%E9%A9%B1%E5%8A%A8-cuda10-1-cuDNN-Tensorflow2-1-0/"/>
    <id>http://example.com/2021/04/26/Ubantu18-04%E5%AE%89%E8%A3%85NVIDIA%E9%A9%B1%E5%8A%A8-cuda10-1-cuDNN-Tensorflow2-1-0/</id>
    <published>2021-04-26T02:18:40.000Z</published>
    <updated>2021-04-26T02:31:39.722Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Ubantu18-04安装NVIDIA驱动-cuda10-1-cuDNN-Tensorflow2-1-0"><a href="#Ubantu18-04安装NVIDIA驱动-cuda10-1-cuDNN-Tensorflow2-1-0" class="headerlink" title="Ubantu18-04安装NVIDIA驱动-cuda10-1-cuDNN-Tensorflow2-1-0"></a>Ubantu18-04安装NVIDIA驱动-cuda10-1-cuDNN-Tensorflow2-1-0</h1><p>注意：TensorFlow2.1 要求 你的GPU算力要达到3.5，检查自己GPU算力</p><h2 id="安装和卸载NVIDIA驱动"><a href="#安装和卸载NVIDIA驱动" class="headerlink" title="安装和卸载NVIDIA驱动"></a>安装和卸载NVIDIA驱动</h2><p>首先要确保驱动已经卸载干净</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get purge nvidia*</span><br><span class="line">sudo apt-get autoremove</span><br></pre></td></tr></table></figure><p>检查自己GPU版本，之后到官网去下载，这种办法安装比较稳妥，其他网络安装办法有时候出错不知道咋回事。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lshw -numeric -C display</span><br></pre></td></tr></table></figure><p><img src="https://i.loli.net/2021/04/26/tDVckAHU8B7dnla.png" alt=""></p><p>下载驱动网址：<a href="https://www.nvidia.cn/Download/index.aspx?lang=cn">https://www.nvidia.cn/Download/index.aspx?lang=cn</a></p><p><img src="https://i.loli.net/2021/04/26/ruzlX3qQ6Ndat9I.png" alt=""></p><p>禁用Nouveau</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">Nouveau驱动禁用方法：</span><br><span class="line"></span><br><span class="line">sudo gedit &#x2F;etc&#x2F;modprobe.d&#x2F;blacklist.conf</span><br><span class="line">或者</span><br><span class="line">sudo vim &#x2F;etc&#x2F;modprobe.d&#x2F;blacklist.conf</span><br><span class="line"> </span><br><span class="line">在最后两行添加：</span><br><span class="line"> </span><br><span class="line">blacklist nouveau</span><br><span class="line">options nouveau modeset&#x3D;0     &#x2F;&#x2F; 禁用nouveau第三方驱动，之后也不需要改回来</span><br><span class="line"> </span><br><span class="line">执行</span><br><span class="line"> </span><br><span class="line">sudo update -initramfs -u   &#x2F;&#x2F; 更新内核</span><br></pre></td></tr></table></figure><p>关闭lightdm</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">sudo service lightdm stop</span><br><span class="line"></span><br><span class="line">　sudo init 3 # 遇见X Server报错执行 </span><br><span class="line"></span><br><span class="line"> rm -rf &#x2F;tmp&#x2F;.X*</span><br><span class="line"></span><br><span class="line"> .&#x2F;NVIDIA-Linux-x86_64-418.165.02.run #开始安装驱动 遇见continue就continue 遇见ok就ok</span><br></pre></td></tr></table></figure><p><img src="https://i.loli.net/2021/04/26/Wf7Imlx8PyKqtUG.png" alt=""></p><h2 id="安装cuda10-1"><a href="#安装cuda10-1" class="headerlink" title="安装cuda10.1"></a>安装cuda10.1</h2><p><a href="https://tensorflow.google.cn/install/source#linux">https://tensorflow.google.cn/install/source#linux</a></p><p>在这个网站上对好版本，版本不对可不行，全是坑 </p><p><a href="https://developer.nvidia.com/cuda-toolkit-archive">https://developer.nvidia.com/cuda-toolkit-archive</a> 选择版本</p><p>然后在这里下载cuda 我用的是deb的办法也是本地下载后安装的。<strong>（我这个网络可能是不行，总是apt-get update 总是报错 所以这个方法没成功用runfile成功了。。。）参考一下吧</strong> </p><p><img src="https://i.loli.net/2021/04/26/wVXLYjvD5zHTNRu.png" alt=""></p><p>安装</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo dpkg -i cuda-repo-ubuntu1804-10-0-local-10.0.130-410.48_1.0-1_amd64.deb</span><br><span class="line">sudo apt-key add &#x2F;var&#x2F;cuda-repo-&lt;version&gt;&#x2F;7fa2af80.pub</span><br><span class="line">sudo dpkg -i cuda-repo-ubuntu1804-10-0-local-10.0.130-410.48_1.0-1_amd64.deb</span><br><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install cuda</span><br></pre></td></tr></table></figure><p>添加环境变量：</p><p>打开 .bashrc</p><p> sudo vim ~/.bashrc</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export CUDA_HOME&#x3D;&#x2F;usr&#x2F;local&#x2F;cuda </span><br><span class="line">export PATH&#x3D;$PATH:$CUDA_HOME&#x2F;bin </span><br><span class="line">export LD_LIBRARY_PATH&#x3D;&#x2F;usr&#x2F;local&#x2F;cuda-10.1&#x2F;lib64$&#123;LD_LIBRARY_PATH:+:$&#123;LD_LIBRARY_PATH&#125;&#125;</span><br></pre></td></tr></table></figure><p>source ~/.bashrc</p><p>nvcc -V</p><h2 id="runfile安装cuda"><a href="#runfile安装cuda" class="headerlink" title="runfile安装cuda"></a>runfile安装cuda</h2><p>下载runfile</p><p><img src="https://i.loli.net/2021/04/26/7G8c26kofdjJQBh.png" alt=""></p><p><img src="https://i.loli.net/2021/04/26/LI4shCiMqcKaNQB.png" alt=""></p><p>一定要取消掉driver 此处！！！，因为已经装了驱动了</p><p><img src="https://i.loli.net/2021/04/26/5CmNy6BrOIiDlkp.png" alt=""></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim ~&#x2F;.bashrc</span><br></pre></td></tr></table></figure><p>我们在文件最后一行添加：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ export PATH&#x3D;&#x2F;usr&#x2F;local&#x2F;cuda-10.1&#x2F;bin:&#x2F;usr&#x2F;local&#x2F;cuda-10.1&#x2F;NsightCompute-2019.1$&#123;PATH:+:$&#123;PATH&#125;&#125;</span><br><span class="line">$ export LD_LIBRARY_PATH&#x3D;&#x2F;usr&#x2F;local&#x2F;cuda-10.1&#x2F;lib64\</span><br><span class="line">                         $&#123;LD_LIBRARY_PATH:+:$&#123;LD_LIBRARY_PATH&#125;&#125;</span><br></pre></td></tr></table></figure><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source ~/.bashrc</span><br></pre></td></tr></table></figure><p><img src="https://i.loli.net/2021/04/26/VDZRTx76oi8MeuK.png" alt=""></p><h2 id="安装TensorFlow2-1-0-gpu"><a href="#安装TensorFlow2-1-0-gpu" class="headerlink" title="安装TensorFlow2.1.0_gpu"></a>安装TensorFlow2.1.0_gpu</h2><p>这上面虽然没写2.1.0_gpu 可是还得得装gpu版</p><p><img src="https://i.loli.net/2021/04/26/LNxBI3jmDrcGUVT.png" alt=""></p><p>完成后 </p><p>conda install cudatoolkit=10.1</p><p><img src="https://img2020.cnblogs.com/blog/1225390/202010/1225390-20201031135739329-731523260.png" alt=""></p><h2 id="安装cuDNN"><a href="#安装cuDNN" class="headerlink" title="安装cuDNN"></a>安装cuDNN</h2><p><a href="https://developer.nvidia.com/cudnn">https://developer.nvidia.com/cudnn</a></p><p>去下载对应版本，但是要登录一下</p><p>解压后</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo cp cuda&#x2F;include&#x2F;cudnn.h &#x2F;usr&#x2F;local&#x2F;cuda&#x2F;include</span><br><span class="line">sudo cp cuda&#x2F;lib64&#x2F;libcudnn* &#x2F;usr&#x2F;local&#x2F;cuda&#x2F;lib64</span><br><span class="line">sudo chmod a+r &#x2F;usr&#x2F;local&#x2F;cuda&#x2F;include&#x2F;cudnn.h </span><br><span class="line">sudo chmod a+r &#x2F;usr&#x2F;local&#x2F;cuda&#x2F;lib64&#x2F;libcudnn*</span><br></pre></td></tr></table></figure><p>以配置cuDNN环境。</p><p>通过</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat &#x2F;usr&#x2F;local&#x2F;cuda&#x2F;include&#x2F;cudnn.h | grep CUDNN_MAJOR -A 2</span><br></pre></td></tr></table></figure><p>查看cuDNN版本</p><p>over</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Ubantu18-04安装NVIDIA驱动-cuda10-1-cuDNN-Tensorflow2-1-0&quot;&gt;&lt;a href=&quot;#Ubantu18-04安装NVIDIA驱动-cuda10-1-cuDNN-Tensorflow2-1-0&quot; class=&quot;headerl</summary>
      
    
    
    
    
    <category term="GPU" scheme="http://example.com/tags/GPU/"/>
    
  </entry>
  
  <entry>
    <title>快速排序模板</title>
    <link href="http://example.com/2021/04/26/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%E6%A8%A1%E6%9D%BF/"/>
    <id>http://example.com/2021/04/26/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%E6%A8%A1%E6%9D%BF/</id>
    <published>2021-04-26T01:56:51.000Z</published>
    <updated>2021-05-14T03:12:20.106Z</updated>
    
    <content type="html"><![CDATA[<p>快速排序模板</p><p><img src="https://i.loli.net/2021/04/26/voAgqKV12i9Rxuz.png" alt=""></p><ol><li>先确定分界点：$q[l] 、 q[(l+r)/2]、 q[r]$ 或随机</li><li>调整区间：小于等于x的在左半边，大于等于x的在右半边 (如何去调整)</li><li>递归处理左右两段</li></ol><h2 id="由数据反推算法复杂度和算法内容"><a href="#由数据反推算法复杂度和算法内容" class="headerlink" title="由数据反推算法复杂度和算法内容"></a>由数据反推算法复杂度和算法内容</h2><p><img src="https://i.loli.net/2021/05/14/i9EQsUqAYdW1rcB.png" alt=""></p><h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><p>暴力：</p><ul><li>声明两个数组 a[] 、b[]</li><li>将$q[l~r]$ 遍历 </li><li>如果 $q[i] \le x$ 放到a[]中   </li><li>如果 $q[i] \ge x$ 放到b[]中   </li><li>再将a、b数组放回q中</li></ul><p>优美：</p><p>用两个指针，swap</p><p><a href="https://blog.csdn.net/qq_42369555/article/details/82745923">关于JAVA中IO流类：BufferredReader的简单用法</a></p><p>bufferreader要比scanner快</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> code;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.BufferedReader;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.io.InputStreamReader;</span><br><span class="line"><span class="keyword">import</span> java.util.Collections;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> 快排模板 </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        BufferedReader input = <span class="keyword">new</span> BufferedReader(<span class="keyword">new</span> InputStreamReader(System.in));</span><br><span class="line">        <span class="keyword">int</span> n = Integer.parseInt(input.readLine());</span><br><span class="line">        <span class="keyword">int</span>[] q = <span class="keyword">new</span> <span class="keyword">int</span>[n];</span><br><span class="line">        String[] linelist = input.readLine().split(<span class="string">&quot; &quot;</span>);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; linelist.length; i++) &#123;</span><br><span class="line">            q[i] = Integer.parseInt(linelist[i]);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        quick_sort(q, <span class="number">0</span>, q.length - <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; q.length; i++) &#123;</span><br><span class="line">            System.out.print(q[i]);</span><br><span class="line">            System.out.print(<span class="string">&quot; &quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">quick_sort</span><span class="params">(<span class="keyword">int</span>[] q, <span class="keyword">int</span> l, <span class="keyword">int</span> r)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (l &gt;= r) <span class="keyword">return</span>;</span><br><span class="line">        <span class="keyword">int</span> x = q[l];</span><br><span class="line">        <span class="keyword">int</span> i = l - <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">int</span> j = r + <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">while</span> (i &lt; j) &#123;</span><br><span class="line">            <span class="keyword">do</span> i++; <span class="keyword">while</span> (q[i] &lt; x);</span><br><span class="line">            <span class="keyword">do</span> j--; <span class="keyword">while</span> (q[j] &gt; x);</span><br><span class="line">            <span class="keyword">if</span> (i &lt; j) &#123;</span><br><span class="line">                <span class="keyword">int</span> t = q[i];</span><br><span class="line">                q[i] = q[j];</span><br><span class="line">                q[j] = t;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        quick_sort(q, l, j);</span><br><span class="line">        quick_sort(q, j + <span class="number">1</span>, r);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;快速排序模板&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://i.loli.net/2021/04/26/voAgqKV12i9Rxuz.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;先确定分界点：$q[l] 、 q[(l+r)/2]、 q[r]$ 或随机&lt;/li&gt;</summary>
      
    
    
    
    
    <category term="刷题" scheme="http://example.com/tags/%E5%88%B7%E9%A2%98/"/>
    
  </entry>
  
  <entry>
    <title>DP分析——石子合并</title>
    <link href="http://example.com/2021/04/24/DP%E5%88%86%E6%9E%90%E2%80%94%E2%80%94%E7%9F%B3%E5%AD%90%E5%90%88%E5%B9%B6/"/>
    <id>http://example.com/2021/04/24/DP%E5%88%86%E6%9E%90%E2%80%94%E2%80%94%E7%9F%B3%E5%AD%90%E5%90%88%E5%B9%B6/</id>
    <published>2021-04-24T02:19:10.000Z</published>
    <updated>2021-04-24T04:39:01.339Z</updated>
    
    <content type="html"><![CDATA[<h1 id="DP分析——石子合并"><a href="#DP分析——石子合并" class="headerlink" title="DP分析——石子合并"></a>DP分析——石子合并</h1><p>设有 NN 堆石子排成一排，其编号为 1，2，3，…，N。</p><p>每堆石子有一定的质量，可以用一个整数来描述，现在要将这 N 堆石子合并成为一堆。</p><p>每次只能合并相邻的两堆，合并的代价为这两堆石子的质量之和，合并后与这两堆石子相邻的石子将和新堆相邻，合并时由于选择的顺序不同，合并的总代价也不相同。</p><p>例如有 4 堆石子分别为 <code>1 3 5 2</code>， 我们可以先合并 1、2堆，代价为 4，得到 <code>4 5 2</code>， 又合并 1，2 堆，代价为 9，得到 <code>9 2</code> ，再合并得到 11，总代价为 4+9+11=244+9+11=24；</p><p>如果第二步是先合并 2，3 堆，则代价为 7，得到 <code>4 7</code>，最后一次合并代价为 11，总代价为 4+7+11=22。</p><p>问题是：找出一种合理的方法，使总的代价最小，输出最小代价。</p><h4 id="输入格式"><a href="#输入格式" class="headerlink" title="输入格式"></a>输入格式</h4><p>第一行一个数 N 表示石子的堆数 N。</p><p>第二行 N 个数，表示每堆石子的质量(均不超过 1000)。</p><h4 id="输出格式"><a href="#输出格式" class="headerlink" title="输出格式"></a>输出格式</h4><p>输出一个整数，表示最小代价。</p><h4 id="数据范围"><a href="#数据范围" class="headerlink" title="数据范围"></a>数据范围</h4><p>1≤N≤300     1≤N≤300</p><h4 id="输入样例："><a href="#输入样例：" class="headerlink" title="输入样例："></a>输入样例：</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">4</span><br><span class="line">1 3 5 2</span><br></pre></td></tr></table></figure><h4 id="输出样例："><a href="#输出样例：" class="headerlink" title="输出样例："></a>输出样例：</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">22</span><br></pre></td></tr></table></figure><h2 id="解"><a href="#解" class="headerlink" title="解"></a>解</h2><p><img src="https://i.loli.net/2021/04/24/CqE9QcaxYBzZKRw.png" alt=""></p><p><img src="https://i.loli.net/2021/04/24/gPlOsK5oXFcWutE.png" alt=""></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DP_</span>石子合并 </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Scanner scanner = <span class="keyword">new</span> Scanner(System.in);</span><br><span class="line">        <span class="keyword">int</span> N = scanner.nextInt();</span><br><span class="line">        <span class="keyword">int</span>[] s = <span class="keyword">new</span> <span class="keyword">int</span>[N + <span class="number">1</span>];  <span class="comment">//前缀和</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= N; i++) &#123;</span><br><span class="line">            s[i] = scanner.nextInt();</span><br><span class="line">            s[i] += s[i - <span class="number">1</span>];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">int</span>[][] dp = <span class="keyword">new</span> <span class="keyword">int</span>[N + <span class="number">1</span>][N + <span class="number">1</span>];</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> len = <span class="number">2</span>; len &lt;= N; len++) &#123;<span class="comment">//先枚举区间长度</span></span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i + len - <span class="number">1</span> &lt;= N; i++) &#123;<span class="comment">//再枚举区间左端点</span></span><br><span class="line">                <span class="keyword">int</span> j = i + len - <span class="number">1</span>; <span class="comment">//右端点</span></span><br><span class="line">                dp[i][j] = <span class="number">100000000</span>;</span><br><span class="line">                <span class="keyword">for</span> (<span class="keyword">int</span> k = i; k &lt; j; k++) &#123;</span><br><span class="line">                    dp[i][j] = Math.min(dp[i][j], dp[i][k] + dp[k + <span class="number">1</span>][j] + s[j] - s[i - <span class="number">1</span>]);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(dp[<span class="number">1</span>][N]);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>$O(n^3)$ </p><hr><h1 id="最长公共子序列"><a href="#最长公共子序列" class="headerlink" title="最长公共子序列"></a>最长公共子序列</h1><p>给定两个长度分别为 N 和 M 的字符串 A 和 B，求既是 A 的子序列又是 B 的子序列的字符串长度最长是多少。</p><h4 id="输入格式-1"><a href="#输入格式-1" class="headerlink" title="输入格式"></a>输入格式</h4><p>第一行包含两个整数 N 和 M。</p><p>第二行包含一个长度为 N 的字符串，表示字符串 A。</p><p>第三行包含一个长度为 M 的字符串，表示字符串 B。</p><p>字符串均由小写字母构成。</p><h4 id="输出格式-1"><a href="#输出格式-1" class="headerlink" title="输出格式"></a>输出格式</h4><p>输出一个整数，表示最大长度。</p><h4 id="数据范围-1"><a href="#数据范围-1" class="headerlink" title="数据范围"></a>数据范围</h4><p>1≤N,M≤1000       1≤N,M≤1000</p><h4 id="输入样例：-1"><a href="#输入样例：-1" class="headerlink" title="输入样例："></a>输入样例：</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">4 5</span><br><span class="line">acbd</span><br><span class="line">abedc</span><br></pre></td></tr></table></figure><h4 id="输出样例：-1"><a href="#输出样例：-1" class="headerlink" title="输出样例："></a>输出样例：</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">3</span><br></pre></td></tr></table></figure><h2 id="解-1"><a href="#解-1" class="headerlink" title="解"></a>解</h2><p>最坏情况下 aaaa,aaaaa，A中所有都是由 $2^n$ 个不同子序列。</p><p><img src="https://i.loli.net/2021/04/24/oxH4yliYPD23LeQ.png" alt=""></p><p><img src="https://i.loli.net/2021/04/24/dVY9UmoHTticMPC.png" alt=""></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Scanner scanner = <span class="keyword">new</span> Scanner(System.in);</span><br><span class="line">        <span class="keyword">int</span> N = scanner.nextInt();</span><br><span class="line">        <span class="keyword">int</span> M = scanner.nextInt();</span><br><span class="line">        String strA = <span class="string">&quot; &quot;</span> + scanner.next();</span><br><span class="line">        String strB = <span class="string">&quot; &quot;</span> + scanner.next();</span><br><span class="line"><span class="comment">//        char[] A = strA.toCharArray();</span></span><br><span class="line"><span class="comment">//        char[] B = strB.toCharArray();</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">int</span>[][] dp = <span class="keyword">new</span> <span class="keyword">int</span>[N + <span class="number">1</span>][M + <span class="number">1</span>];</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= N; i++) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">1</span>; j &lt;= M; j++) &#123;</span><br><span class="line">                dp[i][j] = Math.max(dp[i - <span class="number">1</span>][j], dp[i][j - <span class="number">1</span>]);</span><br><span class="line">                <span class="keyword">if</span> (strA.charAt(i) == strB.charAt(j)) &#123;</span><br><span class="line">                    dp[i][j] = Math.max(dp[i][j], dp[i - <span class="number">1</span>][j - <span class="number">1</span>] + <span class="number">1</span>);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(dp[N][M]);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;DP分析——石子合并&quot;&gt;&lt;a href=&quot;#DP分析——石子合并&quot; class=&quot;headerlink&quot; title=&quot;DP分析——石子合并&quot;&gt;&lt;/a&gt;DP分析——石子合并&lt;/h1&gt;&lt;p&gt;设有 NN 堆石子排成一排，其编号为 1，2，3，…，N。&lt;/p&gt;
&lt;p&gt;每</summary>
      
    
    
    
    
    <category term="刷题" scheme="http://example.com/tags/%E5%88%B7%E9%A2%98/"/>
    
  </entry>
  
  <entry>
    <title>Select, Answer and Explain-Interpretable Multi-hop Reading Comprehension over Multiple Documents</title>
    <link href="http://example.com/2021/04/22/Select-Answer-and-Explain-Interpretable-Multi-hop-Reading-Comprehension-over-Multiple-Documents/"/>
    <id>http://example.com/2021/04/22/Select-Answer-and-Explain-Interpretable-Multi-hop-Reading-Comprehension-over-Multiple-Documents/</id>
    <published>2021-04-21T16:47:09.000Z</published>
    <updated>2021-04-22T05:12:11.538Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Select-Answer-and-Explain-Interpretable-Multi-hop-Reading-Comprehension-over-Multiple-Documents"><a href="#Select-Answer-and-Explain-Interpretable-Multi-hop-Reading-Comprehension-over-Multiple-Documents" class="headerlink" title="Select, Answer and Explain: Interpretable Multi-hop Reading Comprehension over Multiple Documents"></a>Select, Answer and Explain: Interpretable Multi-hop Reading Comprehension over Multiple Documents</h1><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>选择、回答和解释(SAE)系统解决多文档RC问题。</p><p>首先主要创新，用文档分类器过滤掉与答案无关的文档，从而减少分散注意力的信息量。</p><p>然后将所选择的答案相关文档输入到模型以联合预测答案和支持句子。</p><p>该模型在答案预测的表征层和支持句子预测的句子层都设置了多任务学习目标，</p><p>并在这两个任务之间进行了基于注意力的交互，对模型进行了优化。</p><p>关键词：过滤无关文档、多任务学习、混合注意力交互</p><p><img src="https://i.loli.net/2021/04/22/yArGlY6zuT7eMsW.png" alt=""></p><h2 id="在HotpotQA中什么是gold-doc"><a href="#在HotpotQA中什么是gold-doc" class="headerlink" title="在HotpotQA中什么是gold doc"></a>在HotpotQA中什么是gold doc</h2><p>HotpotQA通过为答案提供支持句来鼓励可解释的QA模型，这些支持句通常来自多个文档，如果文档包含答案或包含对答案的支持句，则称为“黄金文档”。</p><p>应答文本，它可以是一段文本或“是/否”。</p><p>作者从答案和支持句标签导出GOLD文档标签。我们使用 $D_i$ 表示文档 i：如果Di是黄金文档，则标记为1，否则标记为0。还将答案类型标记为以下注释之一：“Span”、“Yes”和“No”。</p><h2 id="选择gold-doc-过滤文档"><a href="#选择gold-doc-过滤文档" class="headerlink" title="选择gold doc(过滤文档)"></a>选择gold doc(过滤文档)</h2><p>答案预测和支持句预测的上游任务。将分类排名最靠前的文档作为预测的黄金文档 gold doc。</p><p><img src="https://i.loli.net/2021/04/22/EapiyjuwNbPt49l.png" alt=""></p><p>做文档过滤最直接做法就是采用bert的CLS摘要向量，做交叉熵分类</p><script type="math/tex; mode=display">\begin{equation}\begin{split}  L = -\sum_{i=0}^n t_ilogP(D_i) + (1-t_i) log(1-P(D_i))    \end{split}\end{equation}</script><p>$t_i$ 是 $D_i$ 的标签，n是文档数，$P(D_i)$ 是文档i在标签 $t_i$ 中的概率。</p><p>这种简单的方法的缺点：单独处理每个文档，而不考虑下游多跳推理任务所必需的文档间交互和关系。</p><p>为解决此问题，作者提出了一个新的模型，如图上图CLS后，加了一层多头注意力层。</p><p>意在：增加对从不同文档生成的“CLS”标记的关注的动机是鼓励文档间的交互。文档间交互对于文档间的多跳推理至关重要。</p><p>优化：采用了新的成对学习排序损失。还将问题从分类问题描述为两两学习排序问题，</p><p>通过将文档与所有其他文档进行比较，该模型能够更好地将一小部分黄金文档与睡觉分散注意力的文档区分开来。</p><p>给每个文档一共分数 $S(.)$</p><p>如果 $D_i$ 是gold doc $S(D_i) = 1 $, 否则 $S(D_i) = 0$</p><p>然后，标记每对输入文档：给定一对输入文档 $(D_i，D_j)$，标签 $l$设置为：</p><script type="math/tex; mode=display">\begin{equation}\begin{split}  l_{i,j} = \begin{cases} 1, &if\ S(D_i) \gt S(D_j) \\ 0 , &if\  S(D_i) \le S(D_j)\end{cases}    \end{split}\end{equation}</script><p>还认为包含答案范围的文档对于下游任务更重要。因此，如果$D_i$是包含答案跨度的黄金文献，$S(D_i)=2$。</p><p>再将MHSA输出传递给双线性层来输出每对文档的概率，双线性层基于二元交叉熵进行训练，如下所示：</p><script type="math/tex; mode=display">\begin{equation}\begin{split}  L = - \sum_{i=0,j=0}^n \sum_{j\neq i} l_{i,j} logP(D_i,D_j) + (1-l_{i,j}) log(1-P(D_i,D_j))    \end{split}\end{equation}</script><p>相关性定义为$ R_i=􏰅\sum_j^n(P(D_i，D_j)&gt;0.5)$。将来自该相关性排序的前k个排序的文档作为的过滤文档。</p><h2 id="答案和解释"><a href="#答案和解释" class="headerlink" title="答案和解释"></a>答案和解释</h2><p>模型采用多任务学习的方式进行训练，以联合预测答案和对黄金文档的支持意义。</p><p>基于GNN构建多跳推理图，将上下文语句嵌入作为节点，而不是像以往的工作那样以实体作为节点，直接输出带有答案预测的支持语句。</p><p>为什么不用NER因为作者认为：</p><p>目前GNN在QA任务中的应用通常需要实体作为图形节点，并且通过在具有上下文信息的节点上进行消息传递来实现推理。这仅在预定义的一组目标实体可用时才有可能。否则，需要使用命名实体识别(NER)工具来提取实体，这可能会导致图推理中的冗余实体和噪声实体。如果答案不是命名实体，则需要进一步处理以定位最终答案。</p><p> token-level and sentence-level 多任务学习</p><p>基于一种新的混合注意池机制</p><p>将GNN中使用的上下文语句嵌入归结到令牌表示上。注意力权重是根据令牌表示上的答案广度日志和自我注意输出来计算的。这种基于注意力的交互能够利用“回答”和“解释”任务之间的互补信息。</p><h3 id="答案预测"><a href="#答案预测" class="headerlink" title="答案预测"></a>答案预测</h3><p>针对bert输出的每一个$H_i$ 用两层MLP做答案起始位置预测 $L$ 为长度</p><script type="math/tex; mode=display">\begin{equation}\begin{split}  \hat Y &= f_{span} (H^i) \in R^{L\times2}\\ L ^{span} &= \frac{1}{2}(CE(\hat Y[:,0], y^{start}) + CE(\hat Y[:,1], y^{end}))    \end{split}\end{equation}</script><p>其中$\hat Y$的第一行是起始位置的逻辑，第二行是结束位置的逻辑。$y^{star}t$和 $y^{end}$ 是范围 [0，L-1] 中的开始位置和结束位置的标签。CE表示交叉熵损失函数。</p><h3 id="支持句预测"><a href="#支持句预测" class="headerlink" title="支持句预测"></a>支持句预测</h3><p>预测输入上下文中的句子是否为答案预测的支持证据。为了实现句子级预测，我们首先获得$H_i$中每个句子的序列表示。$H_i$ 是bert的token输出。</p><script type="math/tex; mode=display">\begin{equation}\begin{split}  S^j - H[j^s:j^e,:] \in R^{L^j\times d}    \end{split}\end{equation}</script><p>$S^j$是表示语句 j 内的标记嵌入的矩阵( 这里省略了样本索引i)。 $j^s$ 和 $j^e$ 定义了开始和结束位置，$L_j$ 是语句$j$ 的长度。</p><h3 id="多任务"><a href="#多任务" class="headerlink" title="多任务"></a>多任务</h3><p>答案预测任务和支持句预测任务可以相辅相成。</p><p>据观察，答案预测任务总是可以帮助支持句子预测任务，因为有答案的句子总是一条证据；</p><p>但反过来情况不是一样的，因为可能有多个支持句子，概率最高的句子可能不包含答案</p><p>所以答案预测任务总 可以帮助支持句子预测任务，因为有答案的句子总是一个证据；</p><p>反之亦然，因为可能有多个支持句子，概率最高的句子可能不包含答案。</p><p>因此，为了揭示这两个互补任务之间的相互作用，提出了一种基于注意力的总结句子表示法，以引入来自回答预测的互补信息。</p><p>注意力权重的计算方法如下：在Sj上用自我注意计算一部分注意力，另一部分来自答案预测任务的起始位置日志和结束位置日志的总和。</p><script type="math/tex; mode=display">\begin{equation}\begin{split}  \alpha^j &= \sigma(f_{att}(S^j) + \hat Y[j^s:j^e,0] + \hat Y[j^s:j^e,1])\\ s^j &= \sum^{L^j}_{k=0} \alpha^j_k S^j[k,:] \in R^{1\times d}    \end{split}\end{equation}</script><p>Sj是表示语句j 的标记嵌入的矩阵</p><p>$f_{att}$ 是一个两层MLP输出size为1，$\sigma$是softmax</p><p>$α_j ∈ R^{L^j×1}$表示句子j的每个token上的关注度权重。</p><h3 id="构建GNN"><a href="#构建GNN" class="headerlink" title="构建GNN"></a>构建GNN</h3><p>接下来，在语句嵌入Sj上建立GNN模型，以显式地促进对预测gold doc中所有语句的多跳推理，从而更好地利用复杂的关系信息。使用语句嵌入Sj来初始化图的节点特征。采用基于多关系图卷积网络(GCN)的消息传递策略来更新图的节点特征，并将最终的节点特征输入到MLP中，得到每个句子的分类。</p><p><img src="https://i.loli.net/2021/04/22/kfrJdNaDZBqyAhV.png" alt=""></p><p>根据问题和句子中出现的命名实体和名词短语设计了三种类型的边：</p><ul><li>如果两个节点最初来自同一文档，则在这两个节点之间添加一条边(上图中的实节点)</li><li>如果表示两个节点的句子在问题中都具有命名实体或名词短语(可以是不同的)，则在来自不同文档的两个节点之间添加边。(图中的虚线)</li><li>如果表示两个节点的句子具有相同的命名实体或名词短语，则在来自不同文档的两个节点之间添加一条边。(图中的虚线)</li></ul><p>第一种类型的边的动机是希望GNN掌握每个文档中呈现的全局信息。</p><p>第二类和第三类边，为了以更好地捕捉这种跨文档推理路径。跨文档推理是通过从问题中的实体跳到未知的桥梁实体或比较问题中两个实体的属性来实现的 。</p><p>对于消息传递，使用具有门控机制的多关系GCN。</p><p>假设 $h^0_j$ 表示从语句嵌入 $S_j$的初始节点嵌入，则一跳(或一层)之后的节点嵌入计算可表示为:</p><script type="math/tex; mode=display">\begin{equation}\begin{split}  h_j^{k+1} &= act(u_j^k) \odot g^k_j + h^k_j \odot (1-g^k_j) \\ u^k_j &= f_s(h^k_j) + \sum_{r\in R} \frac{1}{|N_j^r|} \sum_{n\in N^r_j} f_r(h_n^k)\\ g_j^k &= sigmoid (f_g([u_j^k; h^k_j]))     \end{split}\end{equation}</script><p>其中R 是一些列边类型， $N^r_j$ 是边类型为r的 j 节点的邻居。</p><p>$h^k_n$ 是节点n的第k层节点表示。</p><p>$f_r、f_s、f_g$中的每一个都定义了输入节点表示上的变换，并且可以使用MLP来实现。</p><p>门控$g_j^k$ 是由0和1之间的值组成的向量，用于控制来自计算的更新$u^k_j$ 或来自原始节点表示的信息。</p><p>函数$act$表示非线性激活函数。</p><p>最后得到每个节点的最终表示 $h_j$ 后用两层MLP 最终预测 。</p><p>$\hat y^{sp}<em>j = sigmoid(f</em>{sp}(h_j))$ </p><p>除了支持句子预测任务之外，还在GNN输出之上添加了另一个任务，以说明“Yes/No”类型的问题。</p><p>预测任务描述为3类(“Yes”、“No”和“span”)分类</p><p>引入：</p><p>$h = \sum_j a_jh_j$</p><p>$a = \sigma(\hat y^{sp})$</p><p>$\hat y^{ans} = f_{ans}(h)$</p><p>最终loss表达为：</p><script type="math/tex; mode=display">\begin{equation}\begin{split}  L = \gamma L^{span} + BCE(\hat y^{sp}, y^{sp}) + CE(\hat y^{ans}, y^{ans})    \end{split}\end{equation}</script><p>$BCE()$ 二元交叉熵函数</p><p>为了考虑不同损失的尺度差异，在跨度损失中加入了一个权重γ。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Select-Answer-and-Explain-Interpretable-Multi-hop-Reading-Comprehension-over-Multiple-Documents&quot;&gt;&lt;a href=&quot;#Select-Answer-and-Explain</summary>
      
    
    
    
    
    <category term="GNN&amp;nlp" scheme="http://example.com/tags/GNN-nlp/"/>
    
  </entry>
  
  <entry>
    <title>DP分析法--01背包问题</title>
    <link href="http://example.com/2021/04/20/DP%E5%88%86%E6%9E%90%E6%B3%95%E2%80%94%E2%80%9401%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98/"/>
    <id>http://example.com/2021/04/20/DP%E5%88%86%E6%9E%90%E6%B3%95%E2%80%94%E2%80%9401%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98/</id>
    <published>2021-04-20T01:14:15.000Z</published>
    <updated>2021-04-24T02:15:41.794Z</updated>
    
    <content type="html"><![CDATA[<h1 id="DP分析法—01背包问题"><a href="#DP分析法—01背包问题" class="headerlink" title="DP分析法—01背包问题"></a>DP分析法—01背包问题</h1><p>从集合角度来分析DP问题，DP问题的题目一般都是从有限集中求得最值的问题。</p><p><img src="https://i.loli.net/2021/04/20/SlgJ96RzdyGp5fw.png" alt=""></p><p><a href="https://www.acwing.com/problem/content/2/">01背包问题</a></p><p>有 N 件物品和一个容量是 V 的背包。每件物品只能使用一次。</p><p>第 i 件物品的体积是 $v_i$，价值是 $w_i$。</p><p>求解将哪些物品装入背包，可使这些物品的总体积不超过背包容量，且总价值最大。<br>输出最大价值。</p><h4 id="输入格式"><a href="#输入格式" class="headerlink" title="输入格式"></a>输入格式</h4><p>第一行两个整数，N，V，用空格隔开，分别表示物品数量和背包容积。</p><p>接下来有 N 行，每行两个整数 $v_i,w_i$，用空格隔开，分别表示第 i 件物品的体积和价值。</p><h4 id="输出格式"><a href="#输出格式" class="headerlink" title="输出格式"></a>输出格式</h4><p>输出一个整数，表示最大价值。</p><h4 id="数据范围"><a href="#数据范围" class="headerlink" title="数据范围"></a>数据范围</h4><p>0&lt;N,V≤10000&lt;N,V≤1000<br>0&lt;vi,wi≤10000&lt;vi,wi≤1000</p><h4 id="输入样例"><a href="#输入样例" class="headerlink" title="输入样例"></a>输入样例</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">4 5</span><br><span class="line">1 2</span><br><span class="line">2 4</span><br><span class="line">3 4</span><br><span class="line">4 5</span><br></pre></td></tr></table></figure><h4 id="输出样例："><a href="#输出样例：" class="headerlink" title="输出样例："></a>输出样例：</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">8</span><br></pre></td></tr></table></figure><h2 id="解"><a href="#解" class="headerlink" title="解"></a>解</h2><p>最多$2^N$, 从$2^N$ 个方案里找总价值最大的方案。——有限集合的最值问题</p><p>状态表示：</p><ul><li><p>选择问题一般$f(i,j)$ 第一维表示前i个物品,第二维是限制 (经验)</p></li><li><p>集合：所有只考虑前i个物品，且总体积不超过j的选法的集合。</p></li><li>属性：集合中每一个方案的最大价值Max</li></ul><p>状态计算：</p><ul><li>所有不选第i个物品的方案 $f(i-1,j)$</li><li>所有选择第i个物品的方案 $f(i-1,j-v_i) + w_i$</li><li>$Max(f(i-1,j), f(i-1,j-v_i)+w_i)$</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.Scanner;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="comment">// 读入数据的代码</span></span><br><span class="line">        Scanner reader = <span class="keyword">new</span> Scanner(System.in);</span><br><span class="line">        <span class="comment">// 物品的数量为N</span></span><br><span class="line">        <span class="keyword">int</span> N = reader.nextInt();</span><br><span class="line">        <span class="comment">// 背包的容量为V</span></span><br><span class="line">        <span class="keyword">int</span> V = reader.nextInt();</span><br><span class="line">        <span class="comment">// 一个长度为N的数组，第i个元素表示第i个物品的体积；</span></span><br><span class="line">        <span class="keyword">int</span>[] v = <span class="keyword">new</span> <span class="keyword">int</span>[N + <span class="number">1</span>] ;</span><br><span class="line">        <span class="comment">// 一个长度为N的数组，第i个元素表示第i个物品的价值；</span></span><br><span class="line">        <span class="keyword">int</span>[] w = <span class="keyword">new</span> <span class="keyword">int</span>[N + <span class="number">1</span>] ;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">1</span> ; i &lt;= N ; i++)&#123;</span><br><span class="line">            <span class="comment">// 接下来有 N 行，每行有两个整数:v[i],w[i]，用空格隔开，分别表示第i件物品的体积和价值</span></span><br><span class="line">            v[i] = reader.nextInt();</span><br><span class="line">            w[i] = reader.nextInt();</span><br><span class="line">        &#125;</span><br><span class="line">        reader.close() ;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 正式工作的代码</span></span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">        定义一个二阶矩阵dp[N+1][V+1],</span></span><br><span class="line"><span class="comment">        这里之所以要N+1和V+1，是因为第0行表示只能选择第0个物品的时候，即没有物品的时候</span></span><br><span class="line"><span class="comment">        第0列表示背包的体积为0的时候，即不能装任何东西的时候</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">        dp[i][j]表示在 只能选择前i个物品，背包容量为j的情况下，背包中物品的最大价值</span></span><br><span class="line"><span class="comment">        对于dp[i][j]有两种情况：</span></span><br><span class="line"><span class="comment">        1. 不选择当前的第i件物品/第i件物品比背包容量要大，则dp[i][j] = dp[i-1][j]</span></span><br><span class="line"><span class="comment">        2. 选择当前的第i件物品（潜在要求第i件物品体积小于等于背包总容量），则能装入的物品最大价值为：</span></span><br><span class="line"><span class="comment">            当前物品的价值 加上 背包剩余容量在只能选前i-1件物品的情况下的最大价值</span></span><br><span class="line"><span class="comment">            dp[i][j] = dp[i-1][j-v[i]] + w[i]</span></span><br><span class="line"><span class="comment">        dp[i][j]在两种情况中选择比较大的情况作为当前的最优解；</span></span><br><span class="line"><span class="comment">        即：</span></span><br><span class="line"><span class="comment">        if(j &gt;= v[i]):</span></span><br><span class="line"><span class="comment">            dp[i][j] = max(dp[i-1][j], dp[i-1][j-v[i]] + w[i])</span></span><br><span class="line"><span class="comment">        else:</span></span><br><span class="line"><span class="comment">            dp[i][j] = dp[i-1][j]</span></span><br><span class="line"><span class="comment">        */</span></span><br><span class="line">        <span class="keyword">int</span>[][] dp = <span class="keyword">new</span> <span class="keyword">int</span>[N+<span class="number">1</span>][V+<span class="number">1</span>];</span><br><span class="line">        dp[<span class="number">0</span>][<span class="number">0</span>] = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= N; i++)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>; j &lt;= V; j++)&#123;</span><br><span class="line">                <span class="keyword">if</span>(j &gt;= v[i])&#123;</span><br><span class="line">                    dp[i][j] = Math.max(dp[i-<span class="number">1</span>][j], dp[i-<span class="number">1</span>][j-v[i]] + w[i]);</span><br><span class="line">                &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                    dp[i][j] = dp[i-<span class="number">1</span>][j];</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(dp[N][V]);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>优化后</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.Scanner;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="comment">// 读入数据的代码</span></span><br><span class="line">        Scanner reader = <span class="keyword">new</span> Scanner(System.in);</span><br><span class="line">        <span class="comment">// 物品的数量为N</span></span><br><span class="line">        <span class="keyword">int</span> N = reader.nextInt();</span><br><span class="line">        <span class="comment">// 背包的容量为V</span></span><br><span class="line">        <span class="keyword">int</span> V = reader.nextInt();</span><br><span class="line">        <span class="comment">// 一个长度为N的数组，第i个元素表示第i个物品的体积；</span></span><br><span class="line">        <span class="keyword">int</span>[] v = <span class="keyword">new</span> <span class="keyword">int</span>[N + <span class="number">1</span>] ;</span><br><span class="line">        <span class="comment">// 一个长度为N的数组，第i个元素表示第i个物品的价值；</span></span><br><span class="line">        <span class="keyword">int</span>[] w = <span class="keyword">new</span> <span class="keyword">int</span>[N + <span class="number">1</span>] ;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">1</span> ; i &lt;= N ; i++)&#123;</span><br><span class="line">            <span class="comment">// 接下来有 N 行，每行有两个整数:v[i],w[i]，用空格隔开，分别表示第i件物品的体积和价值</span></span><br><span class="line">            v[i] = reader.nextInt();</span><br><span class="line">            w[i] = reader.nextInt();</span><br><span class="line">        &#125;</span><br><span class="line">        reader.close() ;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 正式算法的代码</span></span><br><span class="line">        <span class="comment">// 将dp优化为一维数组</span></span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">        注意，这里第二层循环的时候，还是小到大循环的话，那么</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">        dp[i][j] = Math.max(dp[i-1][j], dp[i-1][j-v[i]] + w[i])</span></span><br><span class="line"><span class="comment">        实际上变成了</span></span><br><span class="line"><span class="comment">        dp[i][j] = Math.max(dp[i][j], dp[i][j-v[i]] + w[i]);</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">        因为i-1的值已经在前面被更新过了，覆盖了</span></span><br><span class="line"><span class="comment">        为了避免这个问题，所以要逆序更新，即先更新第i个，然后更新第i-1个，从而保证第i-1个不被覆盖</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">        如果不逆序的话，输出结果为10，dp数组实际为：</span></span><br><span class="line"><span class="comment">        0 0 0 0 0 0 </span></span><br><span class="line"><span class="comment">        0 2 4 6 8 10</span></span><br><span class="line"><span class="comment">        0 2 4 6 8 10</span></span><br><span class="line"><span class="comment">        0 2 4 6 8 10</span></span><br><span class="line"><span class="comment">        0 2 4 6 8 10</span></span><br><span class="line"><span class="comment">        */</span></span><br><span class="line">        <span class="keyword">int</span>[] dp = <span class="keyword">new</span> <span class="keyword">int</span>[V+<span class="number">1</span>];</span><br><span class="line">        dp[<span class="number">0</span>] = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= N; i++)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j = V; j &gt;= v[i]; j--)&#123;</span><br><span class="line">                dp[j] = Math.max(dp[j], dp[j-v[i]] + w[i]);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// for(int j = 0; j &lt;= V; j++)&#123;</span></span><br><span class="line">            <span class="comment">//     System.out.print(dp[j]);</span></span><br><span class="line">            <span class="comment">//     System.out.print(&quot; &quot;);</span></span><br><span class="line">            <span class="comment">// &#125;</span></span><br><span class="line">            <span class="comment">// System.out.print(&quot;\n&quot;);</span></span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(dp[V]);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">o1bagSolutionOptimization</span><span class="params">(<span class="keyword">int</span>[] weight, <span class="keyword">int</span>[] value, <span class="keyword">int</span> bagWeight)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> num = weight.length;</span><br><span class="line">    <span class="keyword">int</span>[] dp = <span class="keyword">new</span> <span class="keyword">int</span>[bagWeight + <span class="number">1</span>];</span><br><span class="line">    dp[<span class="number">0</span>] = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= num; i++) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> j = bagWeight; j &gt;= <span class="number">1</span>; j--) &#123;</span><br><span class="line">            <span class="keyword">if</span> (j &gt;= weight[i - <span class="number">1</span>]) &#123;</span><br><span class="line">                dp[j] = Math.max(dp[j], dp[j - weight[i - <span class="number">1</span>]] + value[i - <span class="number">1</span>]);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dp[bagWeight];</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    Scanner sc = <span class="keyword">new</span> Scanner(System.in);</span><br><span class="line">    <span class="keyword">int</span> itemsNumber = sc.nextInt();</span><br><span class="line">    <span class="keyword">int</span> bagWeight = sc.nextInt();</span><br><span class="line">    <span class="keyword">int</span>[][] arr = <span class="keyword">new</span> <span class="keyword">int</span>[itemsNumber][<span class="number">2</span>];</span><br><span class="line">    <span class="keyword">int</span>[] weight = <span class="keyword">new</span> <span class="keyword">int</span>[itemsNumber];</span><br><span class="line">    <span class="keyword">int</span>[] value = <span class="keyword">new</span> <span class="keyword">int</span>[itemsNumber];</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; itemsNumber; i++) &#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; <span class="number">2</span>; j++) &#123;</span><br><span class="line">            arr[i][j] = sc.nextInt();</span><br><span class="line">        &#125;</span><br><span class="line">        weight[i] = arr[i][<span class="number">0</span>];</span><br><span class="line">        value[i]=   arr[i][<span class="number">1</span>];</span><br><span class="line">    &#125;</span><br><span class="line">    System.out.println(o1bagSolutionOptimization(weight, value, bagWeight));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="完全背包问题"><a href="#完全背包问题" class="headerlink" title="完全背包问题"></a>完全背包问题</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> 完全背包问题 </span>&#123;</span><br><span class="line">    <span class="comment">// 完全背包和01背包的区别是完全背包中每个物品可以用无限次</span></span><br><span class="line"><span class="comment">// 01背包：f[i][j] = max(f[i-1][j], f[i-1][j-v]+w)</span></span><br><span class="line"><span class="comment">// 完全背包：f[i][j] = max(f[i-1][j], f[i][j-v]+w)</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        Scanner reader = <span class="keyword">new</span> Scanner(System.in);</span><br><span class="line">        <span class="keyword">int</span> N = reader.nextInt();</span><br><span class="line">        <span class="keyword">int</span> V = reader.nextInt();</span><br><span class="line">        <span class="keyword">int</span>[] v = <span class="keyword">new</span> <span class="keyword">int</span>[N + <span class="number">1</span>];</span><br><span class="line">        <span class="keyword">int</span>[] w = <span class="keyword">new</span> <span class="keyword">int</span>[N + <span class="number">1</span>];</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= N; i++) &#123;</span><br><span class="line">            v[i] = reader.nextInt();</span><br><span class="line">            w[i] = reader.nextInt();</span><br><span class="line">        &#125;</span><br><span class="line">        reader.close();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">int</span>[] dp = <span class="keyword">new</span> <span class="keyword">int</span>[V + <span class="number">1</span>];</span><br><span class="line">        dp[<span class="number">0</span>] = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= N; i++) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt;= V; j++) &#123;</span><br><span class="line">                <span class="keyword">if</span> (j &gt;= v[i]) &#123;</span><br><span class="line">                    dp[j] = Math.max(dp[j], dp[j - v[i]] + w[i]);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(dp[V]);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// int nativeDp(int n,int m)&#123;</span></span><br><span class="line">    <span class="comment">//     int[] f = new int[maxN];</span></span><br><span class="line">    <span class="comment">//     for(int i=1;i&lt;=n;i++)&#123;</span></span><br><span class="line">    <span class="comment">//         for(int j=m;j&gt;=v[i];j--)&#123;</span></span><br><span class="line">    <span class="comment">//             for(int k=0;k*v[i]&lt;=j;k++)&#123;</span></span><br><span class="line">    <span class="comment">//                 f[j] = Math.max(f[j], f[j-k*v[i]]+k*w[i]);</span></span><br><span class="line">    <span class="comment">//             &#125;</span></span><br><span class="line">    <span class="comment">//         &#125;</span></span><br><span class="line">    <span class="comment">//     &#125;</span></span><br><span class="line">    <span class="comment">// &#125;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;DP分析法—01背包问题&quot;&gt;&lt;a href=&quot;#DP分析法—01背包问题&quot; class=&quot;headerlink&quot; title=&quot;DP分析法—01背包问题&quot;&gt;&lt;/a&gt;DP分析法—01背包问题&lt;/h1&gt;&lt;p&gt;从集合角度来分析DP问题，DP问题的题目一般都是从有限集中求</summary>
      
    
    
    
    
    <category term="刷题" scheme="http://example.com/tags/%E5%88%B7%E9%A2%98/"/>
    
  </entry>
  
  <entry>
    <title>LongFormer:The Long-Document Transformer</title>
    <link href="http://example.com/2021/04/18/LongFormer-The-Long-Document-Transformer/"/>
    <id>http://example.com/2021/04/18/LongFormer-The-Long-Document-Transformer/</id>
    <published>2021-04-18T06:40:10.000Z</published>
    <updated>2021-04-18T16:00:17.349Z</updated>
    
    <content type="html"><![CDATA[<h1 id="LongFormer-The-Long-Document-Transformer"><a href="#LongFormer-The-Long-Document-Transformer" class="headerlink" title="LongFormer:The Long-Document Transformer"></a>LongFormer:The Long-Document Transformer</h1><p>主要记录一些Longfromer的原理和使用时的细节。</p><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>针对的问题：</p><ul><li>基于Transformer的模型，由于self-attention的操作，导致不能处理很长的序列。</li><li>self-attention的处理规模和序列长度是成二次关系的。</li></ul><p><img src="https://i.loli.net/2021/04/18/3YtkrO18p2dAvmV.png" alt=""></p><p>因为self-attention对于每个token都要计算打分，也就是缩放点积中的$QK^T$ 矩阵运算。</p><p>这相当于对每个token之间都照顾到了注意信息。</p><p>每个token代表一个小格，自注意力机制的QK都是自己，所以是个正方形。</p><p>为解决这个问题，作者引入了三种具有随序列长度线性缩放的注意机制，将规模缩减成线性。</p><p>分别是局部窗口注意和任务激活的全局注意力。</p><p>并且还提供了LongFormer的预训练模型。</p><p>定义了生成结构为Long-Forward-Encoding-Decoder(LED) </p><h2 id="引入-amp-相关工作"><a href="#引入-amp-相关工作" class="headerlink" title="引入&amp;相关工作"></a>引入&amp;相关工作</h2><p>熟知的Bert等预训练模型，最大长度为512，多的就要截断，这样可能会潜在地导致重要的跨分区信息丢失问题。</p><p>然而当时已有的针对解决长文本的方法，都是基于自回归语言模型的。</p><p>而LongFormer是可以应用于迁移学习环境中的文档级NLP任务的。</p><p><img src="https://i.loli.net/2021/04/18/KNJa3dZx6fCG8eH.png" alt=""></p><p>之后可能会读几篇。ltr从左到右的模型，其受益于双向语境(自回归或从左到右的语言建模被粗略地定义为在给定输入序列中的先前符号/字符的情况下估计现有符号/字符的概率分布)。</p><p>spare代表模型通过稀疏性来进行优化。</p><p>Generating long se-quences with sparse transformers.其使用由BlockSparse提供的大小为8x8的块的扩展滑动窗口的形式，但没有探索预训练设置。等等</p><h2 id="LongFormer"><a href="#LongFormer" class="headerlink" title="LongFormer"></a>LongFormer</h2><p>原始Transformer的自注意力机制有$O(n^2)$ 的时间和空间内存复杂度。</p><p>为了解决这个问题，作者根据指定相互关注的输入位置对的“注意模式”来稀疏完整的自我注意矩阵</p><p>与full self-attention不同的是，提出的注意力模式与输入序列成线性关系，这使得它对较长的序列是有效的。</p><h3 id="注意力模式"><a href="#注意力模式" class="headerlink" title="注意力模式"></a>注意力模式</h3><h4 id="滑动窗口-Sliding-Window"><a href="#滑动窗口-Sliding-Window" class="headerlink" title="滑动窗口 (Sliding Window)"></a>滑动窗口 (Sliding Window)</h4><p>设固定窗口大小为 w，transformer层数为$l$, token的每边 $\frac{1}{2}w$  计算复杂度为$O(n\times w)$</p><p><img src="https://i.loli.net/2021/04/18/XaDokntURBWdNSe.png" alt=""></p><p>作者认为：根据应用程序的不同，为每个图层使用不同的w值可能有助于在效率和模型表达能力之间取得平衡。</p><h4 id="空洞滑窗-Dilated-Sliding-Window"><a href="#空洞滑窗-Dilated-Sliding-Window" class="headerlink" title="空洞滑窗(Dilated Sliding Window)"></a>空洞滑窗(Dilated Sliding Window)</h4><p>类似于CNN的空洞卷积</p><p>空洞尺寸 $d$ 感受野是 $l\times d\times w$</p><p><img src="https://i.loli.net/2021/04/18/SxDhujGwCVIvt2g.png" alt=""></p><p>在多头注意力中，每个注意力头部计算不同的注意力分数。</p><p>作者发现，每个头具有不同扩张配置设置的话效果会好：</p><p>允许一些没有空洞的头部专注于局部语境，而另一些带空洞的则专注于更长的语境，从而提高了性能。</p><h4 id="全局注意力-Global-Attention"><a href="#全局注意力-Global-Attention" class="headerlink" title="全局注意力(Global Attention)"></a>全局注意力(Global Attention)</h4><p><img src="https://i.loli.net/2021/04/18/tVGNpUa3o9gIluf.png" alt=""></p><p>例如对于QA，问题和文档连接在一起，允许模型通过自我关注将问题与文档进行比较。</p><p>有时需要使用特殊的全局CLS作为整体的表达，所以就需要再这某些个关键点地方计算全局注意力，关注每一个token。其他的还是滑窗的形式。</p><p>我们在几个预先选择的输入位置添加了“全局关注”。</p><p>由于这样的记号token的数量相对于n很小，并且与n无关，因此组合的局部和全局注意的复杂度仍然是O(N)。</p><p>这时，计算打分函数就可以分为两组QKV，分别是全局的$Q_g,K_g,V_g$ 和 滑窗局部的 $Q_s,K_s,V_s$</p><p>昂贵的运算是矩阵乘法 $QK^T$，因为Q和K都具有n(序列长度)投影。对于LongFormer，空洞滑动窗口注意只计算固定数量$QK^T$的对角线。</p><p>在实现的时候主要用到了带状乘法。还定制了特别的CUDA内核。。</p><h3 id="对于自回归的语言模型"><a href="#对于自回归的语言模型" class="headerlink" title="对于自回归的语言模型"></a>对于自回归的语言模型</h3><p>可以使用空洞滑动窗口注意力，并且可以跨层使用不同尺寸的窗口，效果可能更佳。</p><p>对较低层使用较小的窗口大小，并在移动到较高层时增加窗口大小</p><p>这允许顶层了解整个序列的较高级别表示，同时使较低层捕获本地信息。此外，它还在效率和性能之间取得平衡。</p><p>(窗口大小越小，非零值越少，计算开销越小)</p><p>(窗口大小越大，表示能力更丰富，通常会带来性能提升)</p><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>和训练长文本的模型进行对比 ，BPC值越小越好</p><p><img src="https://i.loli.net/2021/04/18/Oxo2A1SCsaIeDL8.png" alt=""></p><h2 id="在QA上的Finetuning"><a href="#在QA上的Finetuning" class="headerlink" title="在QA上的Finetuning"></a>在QA上的Finetuning</h2><p>分别采用了我比较关注的多文档数据集 WikiHop/HotpotQA(干扰榜)/TriviaQA</p><p>将问题和文档连接成一个长序列放入Longformer，最后加一个预测层。</p><p><img src="https://i.loli.net/2021/04/18/lqTB5cSPrD8Z3w7.png" alt=""></p><h3 id="WikiHop"><a href="#WikiHop" class="headerlink" title="WikiHop"></a>WikiHop</h3><p>数据特点：</p><ul><li><p>候选答案个数由2个到79个不等。</p></li><li><p>文章段落数量由3段到63段不等</p></li></ul><p>数据集不为多跳推理链提供任何中间注释，需要模型代之以从间接答案监督中推断它们。</p><p>数据预处理：</p><p>将问题和答案与特殊令牌连接在一起</p><p>$ [q] question [/q] [ent] candidate1 [/ent] … [ent] candidateN [/ent] $</p><p>上下文也是使用文档分隔符进行间隔</p><p>$&lt;/s&gt; context1 &lt;/s&gt; … &lt;/s&gt; contextM &lt;/s&gt;$</p><p>在准备好输入数据后，从每个模型的顶层开始计算活动。获取问题和答案候选并将它们连接到尽可能多的上下文直到模型序列长度(Roberta为512，LongFormer为4,096)，在模型中运行序列，收集输出激活，并重复，直到用尽所有上下文(除了LongFormor-Large之外的所有模型，由于存储器要求，我们只包括第一个4,096长度的序列)。然后，将所有块的所有激活连接成一个长序列。在Longformer的下，使用全局注意力来关注整个问答候选序列。</p><p>最终预测，对每个[ent] 附加一个线性层，输出一个logit，最后平均所有候选答案的logits。 用softmax和交叉熵得出最终答案。</p><p>优化策略：</p><p>Adam、Linear warmup超过200梯度更新对于最大LR，然后linear decay剩余训练。</p><p>使用梯度累积最终batch达到32</p><p>其他超参Dropout weight decay 都和Roberta相同。</p><p>对LR[2e-5，3e-5，5e-5]和epoch[5，10，15]进行网格搜索。</p><p>LR=3e-5，15个epoch是最好的Longform-Base配置。</p><h3 id="TriviaQA"><a href="#TriviaQA" class="headerlink" title="TriviaQA"></a>TriviaQA</h3><p>TriviaQA有超过10万个问题、答案、文档。</p><p>文档是维基百科文章，答案是文章中提到的命名实体。</p><p>回答问题的跨度没有注释，但可以使用简单的文本匹配找到它。</p><p>数据预处理：</p><p>$[s] question [/s]document [/s]$</p><p>在所有问题符号上都使用全局注意力。</p><h2 id="HotpotQA"><a href="#HotpotQA" class="headerlink" title="HotpotQA"></a>HotpotQA</h2><p>使用两阶段首先确定相关段落，然后确定最终答案范围和证据。</p><p>这主要是因为首先删除分散注意力的段落，可以降低最终认识和范围检测的噪声，这一点也被发现非常重要此数据集中最新的最新方法。</p><p>数据预处理：</p><p>$[CLS] [q] question [/q] ⟨t⟩ title1 ⟨/t⟩ sent1,1 [s] sent1,2 [s] …⟨t⟩ title2 ⟨/t⟩ sent2,1 [s] sent2,2 [s] …$</p><p>使用全局注意力来问句标记、段落计时开始标记以及句子标记。</p><p>在段落标题顶部增加了前馈层，用于预测相关段落的开始标记，以及用于预测证据句子的句子标记。</p><p>在对第一阶段模型进行训练后，预测了训练集和开发集的相关段落得分。然后，保留最多5个原始得分高于预先指定的阈值(-3.0)的段落，并从上下文中删除其他段落。然后，根据得到的缩短上下文训练第二阶段模型。</p><p>将跨度、问题分类、句子和段落损失结合起来，使用线性损失组合对模型进行多任务训练。</p><p>使用ADAM优化器对模型进行了训练，并进行了线性warmup(1000步)和线性衰减。我们使用最小超参数调整，使用3E-5和5E-5的LR和3到7的epoch，发现LR为3E-5和5个历元的模型效果最好。</p><p><img src="https://i.loli.net/2021/04/19/LuOCHUx1eMPwDW9.png" alt=""></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;LongFormer-The-Long-Document-Transformer&quot;&gt;&lt;a href=&quot;#LongFormer-The-Long-Document-Transformer&quot; class=&quot;headerlink&quot; title=&quot;LongFormer:T</summary>
      
    
    
    
    
    <category term="nlp" scheme="http://example.com/tags/nlp/"/>
    
  </entry>
  
  <entry>
    <title>Kaggle上传dataset的方法</title>
    <link href="http://example.com/2021/04/15/Kaggle%E4%B8%8A%E4%BC%A0dataset%E7%9A%84%E6%96%B9%E6%B3%95/"/>
    <id>http://example.com/2021/04/15/Kaggle%E4%B8%8A%E4%BC%A0dataset%E7%9A%84%E6%96%B9%E6%B3%95/</id>
    <published>2021-04-15T04:34:33.000Z</published>
    <updated>2021-04-15T04:50:41.636Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Kaggle快速上传dataset的方法"><a href="#Kaggle快速上传dataset的方法" class="headerlink" title="Kaggle快速上传dataset的方法"></a>Kaggle快速上传dataset的方法</h1><h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p>从国内上传到有cdn的地方(如GitHub), 再在kaggle的kernel上下载下来，直接上传dataset。</p><h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><p>首先需要掌握kaggle-api的使用，kaggle-api是kaggle官方提供的命令行工具，可以从命理完成比赛数据的下载、dataset下载上传，获取榜单等操作。</p><p><a href="https://github.com/Kaggle/kaggle-api">https://github.com/Kaggle/kaggle-api</a></p><p>本地安装：pip install kaggle</p><p>Kaggle已经安装好了，不用再安装</p><p>步骤1：下载账户API json</p><p><a href="https://www.kaggle.com/me/account">https://www.kaggle.com/me/account</a></p><p>步骤2：在页面创建一个dataset</p><p><a href="https://www.kaggle.com/datasets">https://www.kaggle.com/datasets</a></p><p>步骤3：下载dataset的metadata</p><p>运行：kaggle datasets metadata shopee-models</p><p>步骤4：下载数据集并上传到dataset</p><p>完整代码：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将API json文件写到这里</span></span><br><span class="line">!mkdir /root/.kaggle</span><br><span class="line">lines = <span class="string">&#x27;&#x27;</span><span class="string">&#x27;&#123;&quot;username&quot;:&quot;写你的用户名&quot;,&quot;key&quot;:&quot;写你的key&quot;&#125;&#x27;</span><span class="string">&#x27;&#x27;</span></span><br><span class="line">with open(<span class="string">&#x27;/root/.kaggle/kaggle.json&#x27;</span>, <span class="string">&#x27;w&#x27;</span>) as up:    </span><br><span class="line">up.write(lines)</span><br><span class="line"><span class="comment"># 创建文件夹，写入dataset的metadata</span></span><br><span class="line">!mkdir hubmapkidneysegmentation</span><br><span class="line">lines = <span class="string">&#x27;&#x27;</span><span class="string">&#x27;&#123;</span></span><br><span class="line"><span class="string">&quot;id&quot;: &quot;finlay/shopee-models&quot;,</span></span><br><span class="line"><span class="string">&quot;id_no&quot;: 122348,</span></span><br><span class="line"><span class="string">&quot;title&quot;: &quot;shopee_models&quot;,</span></span><br><span class="line"><span class="string">&quot;subtitle&quot;: &quot;&quot;,</span></span><br><span class="line"><span class="string">&quot;description&quot;: &quot;&quot;,</span></span><br><span class="line"><span class="string">&quot;keywords&quot;: [],</span></span><br><span class="line"><span class="string">&quot;resources&quot;: []</span></span><br><span class="line"><span class="string">&#125;&#x27;</span><span class="string">&#x27;&#x27;</span></span><br><span class="line">with open(<span class="string">&#x27;hubmapkidneysegmentation/dataset-metadata.json&#x27;</span>, <span class="string">&#x27;w&#x27;</span>) as up:</span><br><span class="line">up.write(lines)</span><br><span class="line"><span class="comment"># 下载文件，这里用axel多线程下载，直接用wget也可以的。</span></span><br><span class="line">!apt-get install axel</span><br><span class="line">!axel -n 12 https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b7-dcc49843.pth -o hubmapkidneysegmentation/baseline_fold0_densenet_224_epoch50.pth</span><br><span class="line"><span class="comment"># 上传文件，这里会覆盖上传</span></span><br><span class="line">!kaggle datasets version -p ./hubmapkidneysegmentation -m <span class="string">&quot;Updated data fcn&quot;</span></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Kaggle快速上传dataset的方法&quot;&gt;&lt;a href=&quot;#Kaggle快速上传dataset的方法&quot; class=&quot;headerlink&quot; title=&quot;Kaggle快速上传dataset的方法&quot;&gt;&lt;/a&gt;Kaggle快速上传dataset的方法&lt;/h1&gt;&lt;</summary>
      
    
    
    
    
    <category term="DataGame" scheme="http://example.com/tags/DataGame/"/>
    
  </entry>
  
  <entry>
    <title>DUMA: Reading Comprehension with Transposition Thinking</title>
    <link href="http://example.com/2021/04/14/DUMA-Reading-Comprehension-with-Transposition-Thinking/"/>
    <id>http://example.com/2021/04/14/DUMA-Reading-Comprehension-with-Transposition-Thinking/</id>
    <published>2021-04-14T04:21:00.000Z</published>
    <updated>2021-04-18T16:04:16.645Z</updated>
    
    <content type="html"><![CDATA[<h1 id="DUMA-Reading-Comprehension-with-Transposition-Thinking"><a href="#DUMA-Reading-Comprehension-with-Transposition-Thinking" class="headerlink" title="DUMA: Reading Comprehension with Transposition Thinking"></a>DUMA: Reading Comprehension with Transposition Thinking</h1><p>DUMA：DUal Multi-head Co-Attention model</p><p>这是一篇针对解决多项选择任务的MRC网络结构。题目中的Transposition Think，被作者赋义为分别从文章和问题的角度来考虑对方的关注点。</p><p>主要特点：</p><ul><li>基于预训练语言模型(得到表示编码，替代复杂的匹配网络)</li><li>衔接多层co-attention(从三元组中捕捉关系)</li></ul><p>多项选择任务可以抽象为(文章P，问题q，选项a) 三元组。</p><p>针对多项选择的特点多项选择MRC尤其依赖于匹配网络的设计，它被认为是有效地捕捉文章、问题和答案三元组之间的关系。(不能只考虑推理如何做的更好，还要考虑答案出现的关键位置也就是匹配网络的作用)</p><p>文中总结的人在做阅读理解题时的特点：</p><ul><li>快速通读文章的整体内容，问题和回答选项，以建立全局印象，然后进行换角度思考过程。</li><li>根据问答选项的特有信息，重新考虑文章的细节，收集问答选项的支持证据。</li><li>根据文章中的特有信息，重新考虑问题和答案选项，以确定正确的选项，排除错误的选项。</li></ul><p>当人们重读文章时，他们倾向于根据对问答选项的印象提取关键信息，重读问答选项时也是如此</p><hr><h2 id="DUMA"><a href="#DUMA" class="headerlink" title="DUMA"></a>DUMA</h2><p>多项选择问题可以定义模型需要学习一个概率分布$F(A_1,A_2,…,A_t|P,Q)$</p><p><img src="https://i.loli.net/2021/04/14/IE9asGiRTlLJNV2.png" alt=""></p><p>Encoder 接受文本输入生成一个全局序列表达，这个过程类似人类第一次阅读整个内容以获得总体印象。</p><p>Decoder则收集所有信息的答案预测以选择正确答案选项。</p><p>DUMA层位于encoder和decoder之间，意在模仿人类转换思考角度的过程，从问题文章和关键词中捕捉关系信息。</p><h3 id="Encoder"><a href="#Encoder" class="headerlink" title="Encoder"></a>Encoder</h3><p>作者用的是PrLMs，其将文章、问题和所有不同的候选答案拼接作为输入。</p><p>$P=[p_1,p_2,..,p_m]$    ， $Q=[q_1,q_2,…,q_n]$ ,   $A=[a_1,a_2,…,a_k]$</p><script type="math/tex; mode=display">\begin{equation}\begin{split}  E = Enc(P \oplus Q \oplus A ) \end{split}\end{equation}</script><p>这个输入到预训练的方式可能会遇到点问题，一般预训练语言模型比如bert都会限制一个输入的大小，如果文章过长的话，模型看不到问题和选项可能会导致训练效果不佳。可以改为 Q、A、P的形式，因为一般Q和A都比较短。</p><p>$E = [e<em>1,e_2,…,e</em>{m+n+k}]$  </p><p>$e<em>i$ 为固定维度$d</em>{model}$ 的向量，是各自的token。</p><h3 id="Dual-Multi-head-Co-Attention"><a href="#Dual-Multi-head-Co-Attention" class="headerlink" title="Dual Multi-head Co-Attention"></a>Dual Multi-head Co-Attention</h3><p>使用双多头共同注意模型来计算文章和问答的attention表征。(可堆叠k层)</p><p>其实就是一个多头co-attention，定义一个Q、K、V (Q不是上面的问题Q)</p><p>先从E中分离出$E^P = [e^P<em>1,e^P_2,…,E^P</em>{t<em>p}]$、$E^{QA} = [e^{qA},e^{qA},…,E^{qA}</em>{t_{q_a}}]$</p><p>使用两种计算attention的方法：</p><ul><li><p>$E^P$ 做Query ，$E^{QA}$ 做 Key和Value</p></li><li><p>$E^{QA}$ 做Query ，$E^{P}$ 做 Key和Value</p></li></ul><script type="math/tex; mode=display">\begin{equation}\begin{split}  Attention(E^P,E^{QA},E^{QA}) &= softmax(\frac{E^P(E^{QA})^T}{\sqrt{d_k}})E^{QA}\\ head_i &= Attention(E^PW^Q_i,E^{QA}W^K_i)\\ MIIA(E^P, E^{QA}, E^{QA}) &= Concat(head_1,head_2,...,head_h) W^O\\ MHA_1 &= MHA(E^P, E^{QA}, E^{QA}) \\ MHA_2 &= MHA(E^{QA}, E^{P}, E^P) \\ DUMA (E^P, E^{QA}) &= Fuse(MHA_1,MHA_2)\\    \end{split}\end{equation}</script><p>其中$W<em>i^Q \in R^{d</em>{model} \times d<em>q}$ 、 $W_i^K \in R^{d</em>{model} \times d<em>k}$、  $W_i^V \in R^{d</em>{model} \times d<em>q}$ 、$W_i^O \in R^{hd_v \times d</em>{model}}$  : h 头数</p><p>$MHA$: 多头注意力</p><p>$Fuse$ 函数先使用均值池化来汇集$MHA(·)$的序列输出，然后再聚合两个池化的输出。</p><p>后文实验了三种聚合方法 元素乘法  元素相加  concat</p><p>表示在决定哪个是最佳答案选项之前，对所有关键信息进行混合。</p><h3 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h3><script type="math/tex; mode=display">\begin{equation}\begin{split}  O_i &= DUMA(E^P, E^{QA_i}) \\ L(A_r|P,Q) &= -log\frac{exp(W^TO_r)}{\sum_{i=1}^s exp(W^TO_i)} \end{split}\end{equation}</script><p>s 是选项数量</p><h2 id="Multi-choice-MRC数据集"><a href="#Multi-choice-MRC数据集" class="headerlink" title="Multi-choice MRC数据集"></a>Multi-choice MRC数据集</h2><p>DREAM and RACE</p><p><img src="https://i.loli.net/2021/04/14/63cBOaFhfGIgd58.png" alt=""></p><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p><img src="https://i.loli.net/2021/04/14/3tQ1BCvzHSo9bTU.png" alt=""></p><p><img src="https://i.loli.net/2021/04/14/NchfAZRWxCIuQeS.png" alt=""></p><p><img src="https://i.loli.net/2021/04/14/d6JDXcVaTEmZPLF.png" alt=""></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;DUMA-Reading-Comprehension-with-Transposition-Thinking&quot;&gt;&lt;a href=&quot;#DUMA-Reading-Comprehension-with-Transposition-Thinking&quot; class=&quot;hea</summary>
      
    
    
    
    
    <category term="nlp" scheme="http://example.com/tags/nlp/"/>
    
  </entry>
  
</feed>
