<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Coding-Zuo</title>
  
  <subtitle>Coding And Studying</subtitle>
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2022-02-10T01:29:16.040Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>Coding-Zuo</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>MetaPrompting: Learning to Learn Better Prompts</title>
    <link href="http://example.com/2022/02/10/MetaPrompting-Learning-to-Learn-Better-Prompts/"/>
    <id>http://example.com/2022/02/10/MetaPrompting-Learning-to-Learn-Better-Prompts/</id>
    <published>2022-02-10T01:25:14.000Z</published>
    <updated>2022-02-10T01:29:16.040Z</updated>
    
    <content type="html"><![CDATA[<h1 id="MetaPrompting-Learning-to-Learn-Better-Prompts"><a href="#MetaPrompting-Learning-to-Learn-Better-Prompts" class="headerlink" title="MetaPrompting: Learning to Learn Better Prompts"></a>MetaPrompting: Learning to Learn Better Prompts</h1>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;MetaPrompting-Learning-to-Learn-Better-Prompts&quot;&gt;&lt;a href=&quot;#MetaPrompting-Learning-to-Learn-Better-Prompts&quot; class=&quot;headerlink&quot; title=&quot;</summary>
      
    
    
    
    
    <category term="context detection" scheme="http://example.com/tags/context-detection/"/>
    
  </entry>
  
  <entry>
    <title>28实现strStr()——KMP</title>
    <link href="http://example.com/2022/01/08/28%E5%AE%9E%E7%8E%B0strStr-%E2%80%94%E2%80%94KMP/"/>
    <id>http://example.com/2022/01/08/28%E5%AE%9E%E7%8E%B0strStr-%E2%80%94%E2%80%94KMP/</id>
    <published>2022-01-08T14:20:11.000Z</published>
    <updated>2022-01-08T16:01:57.610Z</updated>
    
    <content type="html"><![CDATA[<h1 id="28实现strStr-——KMP"><a href="#28实现strStr-——KMP" class="headerlink" title="28实现strStr()——KMP"></a>28实现strStr()——KMP</h1><h4 id="28-实现-strStr"><a href="#28-实现-strStr" class="headerlink" title="28. 实现 strStr()"></a><a href="https://leetcode-cn.com/problems/implement-strstr/">28. 实现 strStr()</a></h4><h2 id="朴素解法"><a href="#朴素解法" class="headerlink" title="朴素解法"></a>朴素解法</h2><p>枚举原串 ss 中的每个字符作为【发起点】，每次从原串中的【发起点】和匹配串的首位，开始尝试匹配：</p><ul><li>匹配成功：返回本次匹配的原串【发起点】</li><li>匹配失败：枚举原串的下一个【发起点】，重新尝试匹配</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">Strstr</span><span class="params">(String haystack, String needle)</span></span>&#123;</span><br><span class="line"> <span class="keyword">int</span> n = haystack.length(), m = needle.length();</span><br><span class="line">   <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;n;i++)&#123;</span><br><span class="line">     <span class="keyword">boolean</span> flag = <span class="keyword">true</span>;</span><br><span class="line">      <span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>; j&lt;m ; j++)&#123;</span><br><span class="line">         <span class="keyword">if</span>(haystack.charAt(i+j) != needle.charAt(j))&#123;</span><br><span class="line">            flag = <span class="keyword">false</span>;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">         &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span>(flag)&#123;</span><br><span class="line">         <span class="keyword">return</span> i;</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>时间复杂度： 枚举复杂度为 $O(n-m)$ , 构造比较时间复杂度为 $O(m)$,  整体复杂度 $O((n-m)*m)$</p><h2 id="KMP"><a href="#KMP" class="headerlink" title="KMP"></a>KMP</h2><p>KMP 算法是一个快速查找匹配串的算法，他的作用是：如何快速在【原字符串】中找到【匹配字符串】。</p><p>上述的朴素解法，不考虑剪枝的话是 $O(m*n)$ 的，而KMP算法的复杂度为 $O(m+n)$</p><p>KMP 之所以能够在 $O(m+n)$ 复杂度内完成查找，是因为其能在【非完全匹配】的过程中提取到有效信息进行复用，以减少【重复匹配】的消耗。</p><h3 id="1-匹配过程"><a href="#1-匹配过程" class="headerlink" title="1. 匹配过程"></a>1. 匹配过程</h3><p>在模拟KMP匹配过程之前，先建立两个概念：</p><ul><li>前缀：对于字符串 【abcxxxxefg】，我们称abc属于abcxxxefg的某个前缀</li><li>后缀：对于字符串【abcxxxxefg】，我们称efg属于abcxxxefg的某个后缀</li></ul><p>然后我们假设原串为 【abeababeabf】，匹配串为【abeabf】：</p><p><img src="https://s2.loli.net/2022/01/08/yCL6O3uYGrhkXQD.png" alt=""></p><p>我们可以先看看如果不使用KMP，会如何进行匹配（不使用substring函数的情况下）</p><p>首先在【原串】和【匹配串】分别各有一个指针指向当前匹配的位置。</p><p>首次匹配的【发起点】是一个字符 a。显然，后面的【abeab】都是匹配的，两个指针会同时往右移动（黑标）</p><p>在都能匹配上【abeab】的部分，【朴素匹配】和【KMP】并无不同。</p><p>知道出现第一个不同位置（红标）：</p><p><img src="https://s2.loli.net/2022/01/08/wDoqETL34KWGxAk.png" alt=""></p><p>接下来，是【朴素匹配】和【KMP】出现不同的地方：</p><p>朴素匹配的逻辑：</p><ul><li>将原串的指针移动至本次【发起点】的下一个位置（b字符处）；匹配串的指针移动至起始位置。</li><li>尝试匹配，发现对不上，原串的指针会一直往后移动，直到能够匹配串对上位置</li></ul><p><img src="https://s2.loli.net/2022/01/08/uaIlOkmJLrXvgZB.png" alt=""></p><p>也就是说，对于【朴素匹配】而言，一旦匹配失败，将会将原串指针调整至下一个【发起点】，匹配串的指针调整至起始位置，然后重新尝试匹配。</p><p>这也就不难理解为什么【朴素匹配】的复杂度是 $O(m*n)$ 了</p><p>然后看看KMP匹配过程：</p><p>首先匹配串会坚持已经匹配成功的部分中是否存相同的【前缀】和【后缀】。如果存在，则跳转到【前缀】的下一个位置继续往下匹配：</p><p><img src="https://s2.loli.net/2022/01/08/kRogifeQTH61vbV.png" alt=""></p><p>跳转到下一匹配位置后，尝试匹配，发现两个指针的字符对不上，并且此时匹配串指针前面不存在相同的【前缀】和【后缀】，这个时候只能回到匹配串的起始位置重新开始：</p><p><img src="https://s2.loli.net/2022/01/08/1yzKgLvdOjqGm4k.png" alt=""></p><p><strong>到这里，你应该清楚 KMP 为什么相比于朴素解法更快：</strong></p><ul><li>因为KMP利益已匹配的部分中相同的【前缀】和【后缀】来加速下一次匹配</li><li>因为KMP的原串指针不会进行回溯（没有朴素匹配中回到下一个【起发点】的过程）</li></ul><p>第一点很直观，也很好理解。</p><p>我们可以把重点放在第二点上，原串不回溯至「发起点」意味着什么？</p><p>其实是意味着：随着匹配过程的进行，原串指针不断的右移，我们本质上是不断地在否决一些【不可能】的方案。</p><p>当我们的原串指针从 $i$ 位置后移到 $j$ 位置，不仅仅代表这【原串】下标范围 $[i,j)$ 的字符与【匹配串】匹配或者不匹配，更是在否决那些以【原串】下标范围为 $[i,j)$ 为【匹配发起点】的子集。</p><h3 id="2-分析实现"><a href="#2-分析实现" class="headerlink" title="2. 分析实现"></a>2. 分析实现</h3><p>先分析一下复杂度，如果严格按照上述解法的话，最坏情况下我们需要扫描整个原串，</p><p>复杂度为$O(n)$，同时在每一次匹配失败时，去检查已匹配部分的相同【前缀】和【后缀】，跳转到对应的位置，如果不匹配则再检查前面部分是否有相同【前缀】和【后缀】，再跳转到相应的位置。。。这部分的复杂度是$O(m^2)$，因此整体的复杂度是 $O(n<em>m^2)$，而我们的朴素解法是 $O(m</em>n)$ 的</p><p>说明还有些性质我们没有用到。</p><p>显然，扫描完整原串操作是不可避免的，我们可以优化的只能是【检测已匹配部分的相同前缀和后缀】这一过程。</p><p>再进一步，我们检测【前缀】和【后缀】的目的其实是【为了确定匹配串中的下一段开始匹配的位置】。</p><p>同时，我们发现对于匹配串的任意一个位置而言，由该位置发起的下一个匹配点位置其实与原串无关。</p><p>举个例子，对于匹配串【abcabd】的字符 d 而言，由它发起的下一个匹配点跳转必然是字符 c 的位置。因为字符d位置的相同【前缀】和【后缀】字符ab的下一位置就是字符 c</p><p>可见从匹配串某个位置跳转到下一个匹配位置这一过程是与原串无关的，我们将这一过程称为找 next 点。</p><p>显然我们可以预处理出 next 数组，数组中每个位置的值就是该下标应该跳转的目标位置（next 点）</p><p>当我们进行了这一步优化后，复杂度是多少？</p><p>预处理next数组的复杂度未知，匹配过程最多扫描完整个原串，复杂度为 $O(n)$</p><p>因此如果我们希望整个KMP过程是 $O(m+n)$ 的话，那么我们需要再 $O(m)$ 的复杂度内预处理出 next数组</p><p>所以我们的重点在于如何在 $O(m)$ 复杂度内处理next数组</p><h3 id="3-next数组的构建"><a href="#3-next数组的构建" class="headerlink" title="3.next数组的构建"></a>3.next数组的构建</h3><p>如何用 $O(m)$ 的复杂度内被预处理处理的</p><p>假设有匹配串 【aaabbab】，我们来看看对应的next 是如何被构建出来的。</p><p><img src="https://s2.loli.net/2022/01/08/sqSABkMG5FCDpg6.png" alt=""></p><p><img src="https://s2.loli.net/2022/01/08/cz6heiI8jwYflEF.png" alt=""></p><p><img src="https://s2.loli.net/2022/01/08/kbvGnaBTPiFxjEC.png" alt=""></p><p><img src="https://s2.loli.net/2022/01/08/Dx1ZiwKHc9Rh3T6.png" alt=""></p><p>这就是整个 <code>next</code> 数组的构建过程，时空复杂度均为 O(m)。</p><p>至此整个 KMP 匹配过程复杂度是 O(m + n) 的。</p><h3 id="4-代码实现"><a href="#4-代码实现" class="headerlink" title="4.代码实现"></a>4.代码实现</h3><p>在实际编码时，通常我会往原串和匹配串头部追加一个空格（哨兵）。</p><p>目的是让 j 下标从 0 开始，省去 j 从 -1 开始的麻烦。</p><p>整个过程与上述分析完全一致，一些相关的注释我已经写到代码里。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">strStr</span><span class="params">(String ss, String pp)</span></span>&#123;</span><br><span class="line">     <span class="keyword">if</span>(pp.isEmpty()) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">     <span class="comment">// 分别读取原串和匹配串的长度</span></span><br><span class="line">     <span class="keyword">int</span> n = ss.length(), m = pp.length();</span><br><span class="line">     <span class="comment">// 原串和匹配串前面都加空格，使其下标从 1 开始</span></span><br><span class="line">     ss = <span class="string">&quot; &quot;</span> + ss;</span><br><span class="line">     pp = <span class="string">&quot; &quot;</span> + pp;</span><br><span class="line"></span><br><span class="line">     <span class="keyword">char</span>[] s = ss.toCharArray();</span><br><span class="line">     <span class="keyword">char</span>[] p = pp.toCharArray();</span><br><span class="line"></span><br><span class="line">     <span class="comment">// 构建 next 数组，数组长度为匹配串的长度 （next数组是和匹配串相关的）</span></span><br><span class="line">     <span class="keyword">int</span>[] next = <span class="keyword">new</span> <span class="keyword">int</span>[m+<span class="number">1</span>];</span><br><span class="line">     <span class="comment">// 构建过程 i=2，j=0 开始，i小于等于匹配串长度【构造 i 从 2 开始】</span></span><br><span class="line">     <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">2</span>, j=<span class="number">0</span>; i&lt;=m; i++)&#123;</span><br><span class="line">         <span class="comment">// 匹配不成功的话，j=next(j)</span></span><br><span class="line">         <span class="keyword">while</span>(j&gt;<span class="number">0</span> &amp;&amp; p[i]!=p[j+<span class="number">1</span>])&#123;</span><br><span class="line">             j = next[j];</span><br><span class="line">         &#125;</span><br><span class="line">         <span class="comment">// 匹配成功的话，先让j++</span></span><br><span class="line">         <span class="keyword">if</span>(p[i] == p[j+<span class="number">1</span>])&#123;</span><br><span class="line">             j++;</span><br><span class="line">         &#125;</span><br><span class="line">         <span class="comment">// 更新next[i]，结束本次循环，i++</span></span><br><span class="line">         next[i] = j;</span><br><span class="line">     &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">     <span class="comment">// 匹配过程，i=1,j=0开始，i小于等于原串长度，【匹配i从1开始】</span></span><br><span class="line">     <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>,j=<span class="number">0</span>; i &lt;= n; i++)&#123;</span><br><span class="line">         <span class="comment">//匹配不成功 j=next(j)</span></span><br><span class="line">         <span class="keyword">while</span>(j&gt;<span class="number">0</span> &amp;&amp; s[i]!=p[j+<span class="number">1</span>])&#123;</span><br><span class="line">             j=next[j];</span><br><span class="line">         &#125;</span><br><span class="line">         <span class="comment">//匹配成功的话，先让j++,结束本次循环后i++</span></span><br><span class="line">         <span class="keyword">if</span>(s[i] == p[j+<span class="number">1</span>])&#123;</span><br><span class="line">             j++;</span><br><span class="line">         &#125;</span><br><span class="line">         <span class="comment">// 整一段匹配成功直接返回下标</span></span><br><span class="line">         <span class="keyword">if</span>(j==m)&#123;</span><br><span class="line">             <span class="keyword">return</span> i-m;</span><br><span class="line">         &#125;</span><br><span class="line">     &#125;</span><br><span class="line">     <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;28实现strStr-——KMP&quot;&gt;&lt;a href=&quot;#28实现strStr-——KMP&quot; class=&quot;headerlink&quot; title=&quot;28实现strStr()——KMP&quot;&gt;&lt;/a&gt;28实现strStr()——KMP&lt;/h1&gt;&lt;h4 id=&quot;28-实现-s</summary>
      
    
    
    
    
    <category term="LeetCode" scheme="http://example.com/tags/LeetCode/"/>
    
  </entry>
  
  <entry>
    <title>Exploring Low-dimensional Intrinsic Task Subspace via Prompt Tuning</title>
    <link href="http://example.com/2022/01/04/Exploring-Low-dimensional-Intrinsic-Task-Subspace-via-Prompt-Tuning/"/>
    <id>http://example.com/2022/01/04/Exploring-Low-dimensional-Intrinsic-Task-Subspace-via-Prompt-Tuning/</id>
    <published>2022-01-04T07:04:20.000Z</published>
    <updated>2022-01-04T14:00:34.654Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Exploring-Low-dimensional-Intrinsic-Task-Subspace-via-Prompt-Tuning"><a href="#Exploring-Low-dimensional-Intrinsic-Task-Subspace-via-Prompt-Tuning" class="headerlink" title="Exploring Low-dimensional Intrinsic Task Subspace via Prompt Tuning"></a>Exploring Low-dimensional Intrinsic Task Subspace via Prompt Tuning</h1><p>预训练的语言模型（PLM）如何学习通用的表征，并有效地适应广泛的NLP任务的差异很大的表面上？</p><p>在这项工作中，我们从经验上发现了一些证据，表明PLM对各种任务的适应性可以被重新参数化，即在一个共同的低维内在任务子空间中只优化几个自由参数。这可能有助于我们理解为什么PLMs 可以帮助我们理解为什么PLM可以很容易地适应各种NLP任务的 小规模的数据。</p><p>具体来说，为了找到这样一个子空间并考察其普遍性，我们借助最近在prompt tuning方面的成功经验，将多个NLP任务的软提示分解到同一个低维非线性子空间中，然后我们只通过调谐子空间中的参数来学习使PLM适应未见的任务或数据。</p><p>我们把这个管道称为 <em>intrinsic prompt tuning</em>（IPT）。在实验中，我们研究了不同的少量NLP任务，并令人惊讶地发现，在用100个随机任务找到的5维子空间中，只需调整5个自由参数，我们就可以对100个看过的任务（使用不同的训练数据）和20个未看过的任务分别恢复87%和65%的完整提示调谐性能，显示了所发现的内在任务子空间的巨大通用能力。</p><p>除了作为一种分析工具，IPT还可以进一步带来实际的好处，如提高提示调谐的稳定性。</p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>预训练的语言模型（PLMs）在各种自然语言处理（NLP）任务中表现出了优势（Han等人，2021a；Qiu等人，2020）。</p><p>在海量数据上预训练巨大的参数后，PLM可以通过全参数微调甚至参数高效的调谐方法，有效地适应不同的下游NLP任务，与模型规模相比，数据规模较小。然而，这种适应背后的机制仍然不清楚。PLM如何通过与任务无关的预训练目标来学习普遍的表征，并轻松适应差异很大的不同NLP任务？为了理解PLM如何能以较小的代价普遍地进行适应，在本文中，我们假设PLM适应各种下游任务的优化问题可以被重新参数化，即在同一个低维参数子空间中只优化几个自由参数，我们称之为内在任务子空间（图1）。</p><p><img src="https://s2.loli.net/2022/01/04/xGiLDu9VXqZPfsh.png" alt=""></p><p>具体来说，这里的适应性是指优化可调整的适应性参数，使PLM能够适应某个下游任务，这通常是一个非常高维的优化问题。例如，在传统的微调中，自适应参数是所有的PLM参数和分类头，其数量超过了数亿。然而，Aghajanyan等人（2021）表明，对PLM单一任务的适应可以重新参数化，只需在低维子空间中优化数百个自由参数，然后将调整后的参数随机投射回全部参数空间。这激发了我们的假设，即对多个任务的适应可以被重新参数化为同一低维内在任务子空间的优化。如果这个假设成立，特定任务优化子空间的存在解释了PLMs的普遍性，而低维度解释了为什么适应性可以用相对较小的数据完成。从这个角度来看，PLMs是一个通用的压缩框架，它将各种任务的学习复杂性从非常高的维度压缩到低维度。如果这个假设成立，特定任务的优化子空间的存在解释了PLMs的普遍性，而低维度解释了为什么适应性可以用相对较小的数据完成。从这个角度来看，PLMs是一个通用的压缩框架，它将各种任务的学习复杂性从非常高的维度压缩到低维度。</p><p>为了找到该假设的证据，我们需要开发寻找PLM的内在任务子空间的方法。自然，子空间应该包含各种任务的适应性解决方案（即可调整的适应性参数），因此我们可以通过使用多个任务训练适应性参数的低维分解来近似子空间，然后考察我们是否能在找到的子空间中学习未见过的任务。然而，训练所有PLM参数的分解（微调的情况）在计算上是难以实现的，因为投影到子空间的参数将是数百个PLM。</p><p>Prompt tuning（PT）提供了一个参数高效的替代方案，其适应性参数，即软提示，只有几万个。然而，PT可以在理解（Lester等人，2021；Liu等人，2021b）和生成（Li和Liang，2021）任务上达到接近微调的性能。此外，PT没有结构上的偏差，因为调整后的软提示仅限于输入嵌入，因此与其他参数有效的调整方法如适配器（Houlsby等人，2019）相比，分解它们在直觉上更容易。</p><p>在实验中，我们通过PT在 few-shot 学习设置下探索共同的内在子空间，这保证了各种任务的数据规模是平衡的。我们将本文使用的经验方法命名为IPT，由两个阶段组成：multi-task subspace finding（MSF）和 intrinsic subspace tuning（IST）。在MSF阶段，<strong>我们首先为多个任务获得优化的软提示，然后通过首先将它们投射到低维子空间，然后用反向投射重建它们来学习一个自动编码器。</strong>优化的自动编码器定义了所需的内在子空间。在IST期间，我们只在MSF通过反投影找到的低维子空间中为未见过的数据和任务训练少数自由参数。</p><p>令人惊讶的是，我们发现内在的任务子空间可能不仅存在，而且维度极低。我们研究了不同的few-shot NLP任务，发现在一个由100个随机任务用MSF找到的5维子空间中，对于100个看过的任务（使用不同的训练数据）和20个未看过的任务，我们可以用IST分别恢复87%和65%的完整PT性能。此外，我们研究了IPT在不同任务类型以及训练任务和数据数量下的有效性。我们还表明，发现的内在任务子空间和IPT有一些实际用途，如分析任务差异和提高提示调谐稳定性。我们鼓励未来的工作探索如何更好地找到内在任务子空间，并从PLM适应性的低维重新参数化中获得灵感，开发先进的技术。</p><h2 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h2><h3 id="PLM-Fine-tuning-and-Prompt-tuning"><a href="#PLM-Fine-tuning-and-Prompt-tuning" class="headerlink" title="PLM, Fine-tuning and Prompt tuning."></a>PLM, Fine-tuning and Prompt tuning.</h3><p>随着BERT以来的成功（Devlin等，2019），预训练的语言模型（Radford等，2018；Yang等，2019；Liu等，2019；Raffel等，2019）给NLP带来了新的范式，即预训练一个大规模的模型作为通用骨干，然后将PLM适应特定的下游任务。下游适应的主流方式是微调，即增加特定任务的分类头，用下游任务的监督数据调整所有PLM参数。</p><p>最近，研究人员发现，通过将下游任务铸造成预训练任务的形式，并在输入中加入一些提示标记，包括人类设计的可解释提示（Brown等人，2020；Schick和Schütze，2021a，b；Han等人，2021b；Ding等人，2021；Hu等人，2021）和自动搜索的提示（Jiang等人，2020；Shin等人，2020；Gao等人，2021），也可以取得很好的效果。按照这一研究思路，提示被从词汇表中的标记扩展到可训练的嵌入，即软提示（Li and Liang, 2021; Hambardzumyan et al., 2021; Zhong et al., 2021; Qin and Eisner, 2021; Liu et al., 2021b; Lester et al., 2021）。此外，一些工作（Li and Liang, 2021; Qin and Eisner, 2021; Lester et al., 2021）证明，只有调整软提示并保持PLM参数冻结，才能在各种任务中取得良好的表现。特别是，Lester等人（2021）表明，随着PLM规模的增长，提示调整和微调之间的差距越来越小，最后消失了。</p><p>在这项工作中，我们试图朝着解开这些现象的方向迈出一步，即PLM如何能够学习通用能力，以适应各种任务的少量数据和可调整的参数。</p><h3 id="Intrinsic-Dimensionality"><a href="#Intrinsic-Dimensionality" class="headerlink" title="Intrinsic Dimensionality"></a>Intrinsic Dimensionality</h3><p>本质维度（ID）是表示某些数据或近似函数所需的最小变量数。Li等人（2018）提出通过将神经网络的所有可训练参数随机投射到线性子空间来测量神经网络优化的目标函数的ID，并找到满意的解决方案（如可以达到90%的性能）出现的最小尺寸。在此之后，Aghajanyan等人（2021）表明，PLM微调在许多NLP任务上的ID可以低于数千，而且预训练隐含地优化了下游任务的ID，这也是这项工作的动机。他们的方法中使用的随机线性投影不涉及生成低维子空间的任何额外训练，因此，在子空间中成功找到解决方案为有效的低维重参数化的存在提供了充分的证据。</p><p>随机线性投影不可避免地引入了多余的任务相关信息，并使生成的子空间在重新参数化任务适应方面不紧凑。考虑到存在性已经给出，而我们要研究的假设是低维子空间是否是普遍的，我们采用更强的子空间寻找方法，并使用来自不同下游任务的监督来训练适应性参数的非线性低维分解。</p><h3 id="Unifying-Different-NLP-Tasks"><a href="#Unifying-Different-NLP-Tasks" class="headerlink" title="Unifying Different NLP Tasks."></a>Unifying Different NLP Tasks.</h3><p>尽管各种NLP任务在表面上差别很大，但长期以来，人们一直试图将不同的NLP任务统一为相同的形式（Sun等人，2021），从而用类似的技术来处理它们，特别是在提示方法（Liu等人，2021a）成功地将各种任务投向PLM的预训练任务的形式之后。本文的分析可能有助于我们理解如何能做到这一点，以及如何从内在任务子空间的角度更好地统一不同的任务。</p><h2 id="Methodology"><a href="#Methodology" class="headerlink" title="Methodology"></a>Methodology</h2><p>我们首先在第3.1节中介绍了微调和软提示调谐的基本前提，然后在第3.2节中介绍了我们提出的分析管道本征提示调谐（IPT），包括两个训练阶段。(1）多任务子空间查找（MSF）和（2）内在子空间调整（IST）。在图2中，我们将微调、提示调谐和我们的IPT的范式可视化。</p><p><img src="https://s2.loli.net/2022/01/04/N3dlADSeVj5c8BE.png" alt=""></p><h3 id="Preliminaries"><a href="#Preliminaries" class="headerlink" title="Preliminaries"></a>Preliminaries</h3><p>假设我们得到一系列 NLP任务 ${T<em>1, T_2, …, T</em>{|T|}}$，在不丧失一般性的情况下，按照Raffel等人（2019）的做法，我们假设每个任务 $T<em>i$ 都被投射为统一格式的条件生成。$T_i = {X_i, Y_i}$ 其中输入 $X_i$ 和目标 $Y_i$都由一系列token组成，$X_i = {w_1,w_2,…,w</em>{|X|}}$， $Y<em>i = {y_1,y_2,…,y</em>{|Y<em>i|}}$ 。目标是学习一个映射函数 $F：X_i→Y_i$，事实上的方法是用PLM $M$ 对 $F$ 进行建模，它首先将输入$X_i = {w_1, w_2, …, w</em>{|X<em>i|}}$转换为嵌入$E_i = {w_1, w_2, …, w</em>{|X<em>i|}}∈R^{|X_i|\times d}$，其中去掉了隐藏的大小，然后将 $E_i$ 编码为隐藏的表示 $H_i = {h_1, h_2, …, h</em>{|X_i|}}∈R^{|Xi|×d}$，最后以 $H_i$ 为条件对 $Y_i$进行解码。 目标是优化以下目标:</p><script type="math/tex; mode=display">L_{LM}^i = -\frac{1}{Y_i} \prod_{j=1}^{|Y_i|} p(y_j |w_1,...,w_{|X_i|}, y_1,...,y_{j-1})</script><p>在传统的微调中，$M$ 的所有参数（$θ<em>M$）都参与了优化。最近，及时调谐（Lester等人，2021年）作为一种有效的替代方法出现了，它的调谐参数非常少。是一种有效的替代方法，其可调谐的参数非常少。从形式上看，提示调谐通过在 $H_i$之前添加一系列由 $θ_P$ 参数化的可调谐向量 $P_i = {p_1, p_2, …, p_n}$，将额外的信息引入输入$X_i$，即修改后的输入嵌入 $E* = {p_1,p_2,…,p_n;w_1,w_2,…,w</em>{|X_i|} }\in R^{n+|X_i|\times d} $。在提示调谐过程中，$θ_M$保持固定，只有 $θ_P$被更新，满足 $|θ_P| = n\times d &lt;&lt; |\theta_M|$的条件。</p><h3 id="Intrinsic-Prompt-Tuning"><a href="#Intrinsic-Prompt-Tuning" class="headerlink" title="Intrinsic Prompt Tuning"></a>Intrinsic Prompt Tuning</h3><p>为了验证我们的假设，即PLM对各种下游任务的适应可以被重新参数化为低维内在任务子空间内的优化，我们提出了一个名为内在提示调谐（IPT）的两阶段管道。第一阶段是多任务子空间寻找（MSF），旨在寻找具有多任务 prompts 的内在任务子空间，这些 prompts 是由一个具有投影函数和反投影函数的自动编码器定义的。第二个内在子空间调整（IST）阶段是只在子空间中调整参数，然后用反投影函数将其恢复到 soft prompts 中。</p><h4 id="Multi-task-Subspace-Finding"><a href="#Multi-task-Subspace-Finding" class="headerlink" title="Multi-task Subspace Finding"></a>Multi-task Subspace Finding</h4><p>在MSF期间，我们试图通过学习矩阵 $P_i\in R^{n×d}$的分解，找到一个低维度 $d_I$ 的令人满意的内在任务子空间，这是下游任务 $T_i$ 的训练 soft-prompt。受文本自动编码器的启发（Bowman等人，2016），该分解包括一个投影函数 $Proj(-)$将$P_i$投射到 $d_I$维的子空间，以及一个反投影函数$Proj_b(-)$将 $d_I$ 维的向量投射回 soft-prompt 中以处理 $T_i$，我们重建 $P_i$如下:</p><script type="math/tex; mode=display">p*_i = Proj_b(Proj(P_i)),  L^i_{AE} = ||P^*_i - P_i||_2^2</script><p>其中，$Proj(-)$用单层FFN实现，$Projb(-)$用两层感知器实现，参数如下:</p><script type="math/tex; mode=display">Proj_b(d_i) = W_2(tanh(W_1d_i + b_1)) + b_2</script><p>其中 $W<em>1\in R^{d’_I\times d_I}, b_1\in R^{d_I’},W_2\in R^{N\times d\times d’_I}, b_2\in R^{n\times d}$ 是可训练的参数。此外，为某项任务的 prompt $P_i$ 找到分解，本质上是一个矩阵，这在某种程度上是微不足道的。由于我们想在MSF中找到的理想的内在任务子空间应该适用于广泛的任务，所以我们引入了多任务训练，同时将训练任务的重构 soft-prompt 的任务导向语言建模损失 $L</em>{LM}$作为目标函数。通过联合优化重建损失和面向任务的损失，子空间可以获得重新参数化各种任务适应的能力。MSF的总体训练目标显示如下:</p><script type="math/tex; mode=display">L_{\theta_{proj}} = \frac{1}{T_{train}} \sum_{i=1}^{|T_{train}|}(L_{LM}^i + \alpha L_{AE}^i)</script><p>其中 $α$ 表示控制两个损失之间比例的超参数，$θ_{proj}$表示 $Proj$ 和 $Proj_b$的参数。在MSF期间，我们只对 Proj 和 Projb 进行优化，而对其他参数保持固定。通过引入下游任务监督和非线性，我们可以有效地找到比随机线性子空间更多的不冗余和更强的子空间。</p><h3 id="Intrinsic-Subspace-Tuning"><a href="#Intrinsic-Subspace-Tuning" class="headerlink" title="Intrinsic Subspace Tuning."></a>Intrinsic Subspace Tuning.</h3><p>在这个阶段，我们要评估MSF找到的子空间是否可以推广到未见过的训练数据或未见过的任务。如果答案是肯定的，我们可以说，我们成功地找到了内在的任务子空间，在一定程度上重新参数化了PLM对各种任务的适应性。具体来说，我们只保留在MSF期间学到的Projb，并保持 Projb 和 M 都是固定的，然后对于每个任务，我们不进行香草prompt tuning，而只tune 子空间中的 $d_I$ 自由参数（$θ_d$），并将 $d_I$ 参数与 Projb 投影到 soft-prompt 中，目标函数可以表述为：</p><script type="math/tex; mode=display">L_{\theta_d}^i = L_{LM}^i</script><h2 id="Experiment-and-Analysis"><a href="#Experiment-and-Analysis" class="headerlink" title="Experiment and Analysis"></a>Experiment and Analysis</h2><p>在本节中，我们首先在第4.1节中描述了实验设置，包括任务和相应的数据集、评价指标和本文的训练细节。然后，我们在第4.2节和第4.3节介绍实验结果和分析。</p><h3 id="Experimental-Settings"><a href="#Experimental-Settings" class="headerlink" title="Experimental Settings"></a>Experimental Settings</h3><p><strong>Tasks and Datasets.</strong> 为了在实验中覆盖广泛而多样的NLP任务，我们从CrossFit Gym（Ye等人，2021年）的数据库中随机选择了各种各样的 few-shot NLP任务T（共120个）。<strong>few-shot 的设置确保了各种任务的数据规模是平衡的，因此MSF发现的子空间不会轻易偏向数据丰富的任务。</strong></p><p>简单介绍一下，CrossFit Gym由各种类型的少数NLP任务组成，包括文本分类（如情感分析和自然语言推理）、问题回答（如机器阅读理解和多选题回答）、条件生成（如总结和对话）等等。如第3.1节所述，所有任务都按照Raffel等人（2019）和Khashabi等人（2020）的做法处理成统一的序列到序列的格式，以便于用统一的文本到文本的PLM处理它们。例如，一个多选QA任务的输入被表述为: $Question: <question> Context: <context> Candidates:<candidates>$ 而PLM预计将从<candidates>生成正确的答案跨度。每个任务 $T<em>i\in T$可以 表示为一个 $(D^i</em>{train} , D^i<em>{train} , D^i</em>{train})$的元组，其中 $D<em>{train}/D</em>{dev}$ 的大小被设置为K，以确保 few-shot 设置。对于分类和回归任务，K=16，而对于其他类别的任务，K=32。我们在第6节中列出任务细节。</p><p><strong>Evaluation Metrics.</strong> 由于不同的任务有不同的评估协议（例如，通常判别性任务的F1分数和生成性任务的BLEU），我们引入平均绝对性能（$E<em>{abs}$）和平均相对性能（$E</em>{rel}$）作为主要评估指标。具体来说，让$T = {T<em>1, …, T</em>{|T|}}$是要评估的任务，让 $E<em>{T_i}$ 表示 $T_i$ 对 IPT 的测试得分, $E</em>{abs} =\frac{1}{T}\sum<em>{T_i\in T} E</em>{T<em>i} , E</em>{rel} = \frac{1}{|T|} \sum<em>{T_i\in T} \frac{E</em>{T<em>i}}{E^*</em>{T<em>i}}$ ，其中 $E^*</em>{T<em>i}$ 定义为 prompt tuning$E</em>{T<em>i}^{PT}$或微调 $E</em>{T<em>i}^{FT}$后的性能。在本文中。我们使用 $E</em>{rel}$作为主要评价标准，选择 $E<em>{abs} $作为辅助标准。为了正确评估IPT实现的泛化能力，我们从T中随机抽取训练任务 $T</em>{train}$ 和测试任务$T<em>{test}$，满足 $T</em>{Train} \cap T_{test} = ∅$。</p><p>在多任务子空间查找（MSF）阶段，PLMs只在 $T<em>{train}$ 上进行训练，我们在 $T</em>{train}$ 上评估 $E<em>{abs}$ 和 $E</em>{rel}$，看看重建压缩到 $d<em>I $维子空间的提示会损失多少性能，这将为泛化到未见过的数据和任务提供一个经验上界。我们还用在MSF中学到的自动编码器重新构建 $T</em>{test}$ 的训练过的 soft-prompt，并测试其性能，以研究学到的自动编码器对未见过的 soft-prompt 的重建能力。</p><p>对于本征子空间调谐（IST）阶段，我们 首先对 $T<em>{train}$ 进行IST，使用与MSF中使用的 $D^i</em>{train} /D^i_{dev}$完全相同的方法，研究只在子空间中进行优化可以在多大程度上恢复性能。</p><p>之后，我们通过两个泛化挑战来评估IPT的泛化能力，看对各种任务的适应是否在很大程度上被重新参数化为所发现的子空间。(1) 未见过的数据挑战和 (2) 未见过的任务挑战。</p><ul><li>对于未见过的数据挑战，我们在 $T<em>{train}$ 上进行IST，使用不同的K-shot $D^{i’}</em>{train}/D^{i’}<em>{dev}$ 训练数据进行重新采样，同时保持 $D^i</em>{test}$ 保持不变。注意 $D^{i’}<em>{train}/D^{i’}</em>{dev} $ 和 $D^i<em>{train}/D^{i}</em>{dev}$ 形成的，符合i.i.d.假设。未见过的数据挑战是为了测试所学的子空间是否能推广到未见过的数据，这将导致不同的优化轨迹。</li><li>对于未见过的任务挑战，我们对通过IPT在 $T_{test}$上获得的 soft-prompt 进行评估，看看在发现的子空间中的优化能在多大程度上恢复PLM对未见过的任务的适应性，这将为我们的假设提供证据，即PLM的不同任务适应性的重新参数化子空间并不独立。                                                                      </li></ul><h3 id="Main-Results"><a href="#Main-Results" class="headerlink" title="Main Results"></a>Main Results</h3><p><img src="https://s2.loli.net/2022/01/04/R6cqt8gHLTFyVaS.png" alt=""></p><p>评估了三种任务拆分：随机、非cls和cls，详情列于表1。实验结果显示在图3（$E<em>{rel}$）、表2（$E</em>{abs}$）和表3（$E<em>{abs}$）。如前所述，我们选择 $E</em>{rel}$ 作为分析的主要标准。基于这些结果，我们研究了以下研究问题。</p><h4 id="Q1-PLM是否真的将各种任务适应性重新参数化，使之成为一个低维的任务子空间？"><a href="#Q1-PLM是否真的将各种任务适应性重新参数化，使之成为一个低维的任务子空间？" class="headerlink" title="Q1. PLM是否真的将各种任务适应性重新参数化，使之成为一个低维的任务子空间？"></a>Q1. PLM是否真的将各种任务适应性重新参数化，使之成为一个低维的任务子空间？</h4><p>从图3（a）的结果，我们可以看到。(1)对于未见过的数据挑战（$T<em>{train}^{diff}(IST)$），选择 训练 dI ≥ 5可以恢复80%以上的全 对于100个训练任务，在未见过的独立数据上使用IST的 prompt tuning 性能，可以恢复80%以上。 (2）对于未见过的任务挑战（$T</em>{test}(IST)$），我们只需调整5∼100个参数，也可以达到约60%的性能。从这些结果来看，我们可以说MSF发现的子空间中的低维重新参数化成功地恢复了 $T_{train}$ 的PLM适应性，并且在一定程度上也可以推广到未见过的任务，因此只需在这些子空间中调整几个自由参数就可以实现非微不足道的性能。</p><p>这为我们的假设提供了证据，即PLM将各种任务适应性重新参数化为同一个低维子空间，或者至少各种任务适应性的低维重新参数化子空间（Aghajanyan等人，2021）应该有一个实质性的交集，否则 $T<em>{train}$发现的子空间对 $T</em>{test}$来说几乎不可能起作用。</p><p>此外，在随机拆分中，我们可以看到，当 dI≥5 时，$T<em>{train}^{diff}(IST)$和 $T</em>{test}(IST)$ 的 $E^{(PT)}_{rel}$总是在同一水平上，这表明内在任务子空间的维度应该在 5 左右，这对于有上亿个参数的PLM来说是非常低的。</p><h4 id="Q2-What-limits-IPT"><a href="#Q2-What-limits-IPT" class="headerlink" title="Q2. What limits IPT?"></a>Q2. What limits IPT?</h4><p>虽然观察到了积极的证据，但考虑到对于未见过的任务只能恢复60%左右的表现，IPT的有效性仍然有限。从图3（a）和（b）的结果中，我们讨论了哪些因素可能会限制IPT的有效性，并为改进分析管道提供见解。</p><ol><li>当我们使用MSF的自动编码器（$T<em>{train}(MSF)$）直接重建软提示时，Ttrain的性能甚至优于虚构的 soft-prompt tuning，这表明：(1)MSF的管道可以通过在极低的维度上强制执行多任务技能共享来帮助改善 soft-prompt 的调谐。极低的维度，和 (2) 在子空间中至少存在足够好的解决方案，这些解决方案是由MSF找到的。足够好的解决方案，这些解决方案已经被MSF发现。然而，即使使用完全相同的训练数据，IST也不能找到这些好的解决方案，从而导致 $T</em>{train}(MSF)$ 和 $T_{train}^{same}(IST)$之间的差距，这表明所采用的优化算法的局限性会影响IST的性能。</li><li>从 $T<em>{train}(MSF)$ 和 $T</em>{test}(MSF)$ 的比较中，我们可以看出，直接重建未见过的任务的 soft prompt 的性能很差。这表明在MSF中训练的自动编码器的重构能力不能很好地推广到未见过的输入（soft-prompt），这可能在一定程度上限制了IPT。尽管如此，IST仍然可以在MSF找到的子空间内找到更好的解决方案。</li><li>从图3（a）和（b）的结果比较中，我们可以看到，fine-tuning( $E^{FT}<em>{rel}$)的相对性能总是比 prompt tuning（$E^{PT}</em>{rel}$）要差。这是因为 soft prompt 略逊于 few-shot 设置下的微调，而IPT的性能受 soft prompt 调谐的约束，因为MSF被设计为重构 soft prompt。理想情况下，$E^{FT}_{rel}$可以通过设计更先进的 prompt tuning算法来进一步改进。</li></ol><h4 id="Q3-How-is-the-influence-of-task-types"><a href="#Q3-How-is-the-influence-of-task-types" class="headerlink" title="Q3. How is the influence of task types?"></a>Q3. How is the influence of task types?</h4><p>按照CrossFit（Ye et al. 研究的任务分为两部分：cls（分类）。属于判别性任务，而Non-cls（非 分类），它们往往是生成性任务。从图3（c）-（f）的结果中，我们发现。与常识一致，它们之间存在着巨大的 它们之间的差异。(1) 在分类任务和非分类任务之间存在着巨大的概括性差距。当在MSF中只使用一种任务（cls或non-cls）时，发现的子空间对同种任务（$T^{in}<em>{test} (IST)$）工作良好，但对其他种类的任务（$T^{out}</em>{test}(IST)$）的概括性很差。(2) 当增加d时，非cls任务（图3(c)和(d)）在所有设置中的表现趋于下降，但cls表现（图3(e)和(f)）趋于增加。合理地讲，对于各种NLP任务来说，理想的内在子空间维度设置至少应该达到一个阈值（内在维度），以确保子空间可以被大幅描述，但也不应该太大，因为这可能导致过度参数化。因此，我们认为这表明，尽管是反直觉的，但对于非cls任务来说，最合适的内在子空间维度要远远小于cls任务。我们假设这可能来自于 few-shot 的设置，并将在未来进行探索。</p><h3 id="Analyses-and-Properties"><a href="#Analyses-and-Properties" class="headerlink" title="Analyses and Properties"></a>Analyses and Properties</h3><p><strong>Visualization of the Found Intrinsic Subspace</strong> 我们在图4中用PCA可视化了内在向量（由IST在发现的子空间中学习的自由参数组成的向量），从中我们可以看到：(1）分类任务群和非分类任务群之间存在着明显的分界线，表明它们是高度独立的，这与常识是一致的。这也解释了为什么在任何一个簇上学到的子空间对另一个簇的概括性很差。(2）未见过的任务 $T<em>{test}$ 的点与 $T</em>{train}$的点混合在一起，这表明发现的子空间普遍地对各种任务进行了重新参数化，因此PLM可以泛化到未见过的任务。(3) 从(c)和(d)中还可以看出，属于同一类别的点呈现出紧凑的集群。我们认为，学到的内在向量可以被看作是低维的任务表征，有助于分析各种NLP任务的相似性和差异性。</p><p><img src="https://s2.loli.net/2022/01/04/KnFhqdHP7LSrAcX.png" alt=""></p><p><strong>Impacts of the Number of Training Tasks.</strong></p><p>在MSF期间，自动编码器被优化，以重建各种训练任务的适应性参数，将其重新参数化为低维任务子空间。理想情况下，$T<em>{train}$的覆盖率会大大影响IPT在未见任务 $T</em>{test}$ 上的泛化能力。为了证明这一点，我们随机选择任务分区，在原始 $T<em>{train}$中只随机抽取 {20%、40%、60%、80%} 的任务来训练自动编码器，然后在相同的 $T</em>{test}$上评估未见过的任务挑战。结果如图5所示，从图中我们可以看出，随着训练任务数量的增加，发现的任务子空间的泛化能力普遍提高。这反映出，增加所见任务的覆盖面和多样性可以帮助IPT找到更多的通用子空间。</p><p><img src="https://s2.loli.net/2022/01/04/9orPjdyLE4lZDea.png" alt=""></p><p><strong>Impacts of the Number of Shots</strong> 虽然在本文中，我们主要研究的是 few-shot 的设置，以控制数据量的影响，但研究当有更多的训练数据时，IPT的能力是否会更强，也是很有意思的。在这里，我们通过将任务分区cls的 few-shot 增加一倍来进行初始试验，并进行实验，看看MSF和IST在T上的性能（$E^{PT}_{rel }$）。注意计算EPT时，K-shot和2K-shot实验的分母是不同的。</p><p>结果在图6中得到了体现。从中我们可以看到，在2K拍摄的情况下，MSF 和 IST 之间的差距在 2K-shot 设置中迅速缩小 当dI增长时，MSF和IST之间的差距迅速缩小，而在K-shot设置中则明显放缓。而在K-shot设置中则明显缓慢。这表明，涉及更多的监督可能有利于IST的优化。我们还发现，当增加dI时，2K-shot的$T^{same}_{ train}$ 增长非常接近100%，但从来没有超过它，这表明当有更多的数据可用时，联合重建多个任务的提示不会带来额外的好处，因为在K-shot设置中观察到。一般来说，我们认为探索IPT在数据丰富的情况下发现的子空间会有多强是很有意义的。</p><p><strong>Improving Prompt Tuning Stability with IPT</strong> 在表4中，我们显示了在10次运行中120个任务的测试分数的平均标准偏差（std），比较了IPT（dI=10）、微调和及时调整。我们观察到，prompt tuning是最不稳定的策略，具有最高的标准，而精调则表现得更为稳定。soft prompt tuning的不稳定性可能会影响这一技术的实际使用。直观地说，IPT试图找到低维的内在子空间，只用几个自由参数来学习新任务，这将有助于提高稳定性，IPT肯定会成为表4中最稳定的方法。</p><p><img src="https://s2.loli.net/2022/01/04/zpoeKD2Yf8q6mOM.png" alt=""></p><p>为了使IPT带来的稳定性优势实用化，我们建议使用IPT找到的解决方案作为香草 prompt tuning的初始化。具体来说，我们在 $T_{test}$上继续进行随机分区的实验，选择 $d_I=10$，并通过在IST期间在子空间中反推来初始化软提示。在IST期间在子空间中找到的解决方案进行初始化。与 prompt tuning 基线相比，其他细节保持不变。</p><p>我们观察到，以这种方式实现的标准方差明显低于香草 prompt tuning（1.65 v.s. 4.19) 而在这种方式下，我们可以实现103.4%的EPT，也就是说，性能也可以从59%（IST）提高。这表明，IPT和 prompt tuning可以进一步以两阶段的方式结合。这个实验还表明，尽管我们的IPT管道在本文中主要作为一个分析框架，但它也能带来实际的好处。我们将在未来探索IPT的更多实际用途。</p><h2 id="Discussion"><a href="#Discussion" class="headerlink" title="Discussion"></a>Discussion</h2><p>NLP任务是否可以被重新参数化到同一个子空间？</p><p>在本文中，我们发现了强有力的证据，通过压缩各种任务的适应性参数与下游监督，我们有可能找到一个极低维的子空间，其中包含次优但非琐碎的解决方案，以适应PLM的未见任务。尽管在MSF期间 $E^{PT}_{rel}$超过了100%，但我们注意到在IST期间，对看到的和未看到的任务的概括仍然远非完美（87%对EPT的65%），而且增加 $d_I $并没有明显改善性能。</p><p>尽管这可能与目前优化算法的不足有关，但基于目前的结果，我们不能直接得出结论，PLM的各种NLP任务改编可以在完全相同的子空间内进行重新参数化优化。然而，至少我们找到了有希望的经验结果，表明各种任务的低维重新参数化子空间有很大的交集，这可以通过MSF找到。而在这个交集子空间进行IST可以恢复每个任务的大部分性能。因此，我们鼓励未来的工作探索（1）是否存在在极低维的子空间中进行IST的更高效和有效的优化算法，以及（2）各种任务的内在子空间的联合是否也是低维的。</p><p>此外，还应该注意的是，通过IPT实现的极低维度（约5∼100）不应该被完全视为Aghajanyan等人（2021）和Li等人（2018）的内在维度，因为内在维度应该确保整个训练过程可以在该低维度上完成。用IPT实现的维度有可能作为内在维度的一个粗略下限。</p><p><strong>Relation to the scaling law.</strong> 最近，越来越多关于规模力量的案例被展示出来。人们发现，极其庞大的PLM往往更具有样本效率（Kaplan等人，2020年）、参数效率（Lester等人，2021年）和跨任务的可概括性（Wei等人，2021年）。我们认为这可以用本文的假设来解释：更大的或训练得更好的PLM的适应性可以更好地重新参数化到相同的低维子空间，这样跨任务的泛化应该更容易，更好的预训练带来更低的重新参数化尺寸（Aghajanyan等人，2021），因此更大的PLM应该需要更少的数据和可调整参数。</p><p>如果这个假设成立，我们认为应该开发类似于IPT的调整方法。较大的PLM提供了更强大的压缩框架，我们可以找到低维的内在任务子空间，并在这些子空间中训练各种下游任务，这将避免过度参数化造成的不稳定和巨大的泛化差距，而且对环境也更环保。</p><h2 id="Conclusion-and-Future-work"><a href="#Conclusion-and-Future-work" class="headerlink" title="Conclusion and Future work"></a>Conclusion and Future work</h2><p>在本文中，我们研究了这样一个假设：<strong>PLM对各种任务的适应性可以被重新参数化为同一低维内在任务子空间中的几个自由参数的优化。</strong>我们开发了一个名为IPT的分析管道，它首先通过联合压缩多个任务的适应性参数找到一个子空间，然后只在子空间中对未见过的数据和任务进行参数调整。IPT在极低维度上取得的非微妙的表现为该假设提供了积极的证据。我们还讨论了影响结果的因素和IPT的潜在实际用途。未来，我们将改进IPT框架，以更好地验证普遍的低维重参数化假设，并开发更多的实用技术，在低维子空间进行更有效的优化。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Exploring-Low-dimensional-Intrinsic-Task-Subspace-via-Prompt-Tuning&quot;&gt;&lt;a href=&quot;#Exploring-Low-dimensional-Intrinsic-Task-Subspace-via</summary>
      
    
    
    
    
    <category term="context detection" scheme="http://example.com/tags/context-detection/"/>
    
  </entry>
  
  <entry>
    <title>Unsupervised Domain Adaptation of a Pretrained Cross-Lingual Language Model</title>
    <link href="http://example.com/2021/12/27/Unsupervised-Domain-Adaptation-of-a-Pretrained-Cross-Lingual-Language-Model/"/>
    <id>http://example.com/2021/12/27/Unsupervised-Domain-Adaptation-of-a-Pretrained-Cross-Lingual-Language-Model/</id>
    <published>2021-12-27T11:39:54.000Z</published>
    <updated>2021-12-27T12:34:43.107Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Unsupervised-Domain-Adaptation-of-a-Pretrained-Cross-Lingual-Language-Model"><a href="#Unsupervised-Domain-Adaptation-of-a-Pretrained-Cross-Lingual-Language-Model" class="headerlink" title="Unsupervised Domain Adaptation of a Pretrained Cross-Lingual Language Model"></a>Unsupervised Domain Adaptation of a Pretrained Cross-Lingual Language Model</h1><p>最近的研究表明，在大规模的无标签文本上预训练跨语言语言模型，可以在各种跨语言和低资源任务中产生明显的性能改进。通过对一百种语言和TB级文本的训练，<strong>跨语言模型已被证明能有效地利用高资源语言来提高低资源语言的处理能力</strong>，并超过了单语言模型。在本文中，我们进一步研究了当预训练的跨语言模型需要适应新领域时的跨语言和跨领域（CLCD）设置。具体来说，我们提出了一种新的无监督的特征分解方法，该方法可以<strong>从纠缠在一起的预训练的跨语言表征中自动提取特定领域的特征和领域不变的特征</strong>，<strong>给定源语言中未标记的原始文本。我们提出的模型利用相互信息估计，将跨语言模型计算的表征分解为领域变量和领域特定部分</strong>。实验结果表明，我们提出的方法比最先进的预训练的跨语言模型在CLCD环境中取得了明显的性能改进。本文的源代码可在<a href="https://github.com/lijuntaopku/UFD。">https://github.com/lijuntaopku/UFD。</a></p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>深度学习的最新进展使各种NLP任务受益，并在大规模注释数据集可用时导致性能的显著改善。对于高资源语言，例如英语，许多任务收集足够的标记数据来建立深度神经模型是可行的。然而，对于许多语言来说，在大多数情况下可能不存在足够的数据来充分利用深度神经模型的进步。因此，人们提出了各种跨语言迁移学习方法，以利用高资源语言的标记数据来构建低资源语言的深度模型[Kim等人，2019；Lin等人，2019；He等人，2019；Vulic ́等人，2019]。尽管如此，大多数跨语言迁移学习研究的重点是减轻语言的歧视，而对领域差距的探索较少。在这项研究中，我们专注于一个更具挑战性的环境，即跨语言和跨领域（CLCD）转移，其中源语言的领域内标签数据不可用。</p><p>传统上，<strong>跨语言方法主要依靠从数据中提取语言不变的特征，将从源语言学到的知识转移到目标语言中</strong>。<strong>一种直接的方法是权重共享，它通过事先将输入文本映射到一个共享的嵌入空间</strong>，直接将在源语言上训练的<strong>模型参数重用</strong>到目标语言。然而，之前的重新搜索[Chen等人，2018]显示，<strong>权重共享不足以提取语言不变的特征</strong>，而这些特征可以在不同的语言中很好地通用。因此，我们提出了一种语言对抗训练策略，利用每种语言的非平行无标签文本，提取跨语言的不变特征。这样的策略在双语转换环境中表现良好，但<strong>不适合从多种语言中提取语言不变量特征</strong>，因为<strong>所有源语言共享的特征可能过于稀疏，无法保留有用的信息。</strong></p><p>最近，规模化的预训练跨语言模型，例如多语言的BERT[Devlin等人，2019]和XLM[Conneau和Lample，2019；Conneau等人，2019]，在各种跨语言任务中表现出非常有竞争力的性能，甚至在低资源语言上超过了预训练的单语言模型。通过采用平行文本（未为任何特定任务标记）和所有语言共享的子词词汇，这些预训练的跨语言模型可以有效地将来自多种语言的输入文本编码到一个单一的表示空间，这是一个由多种语言（超过一百种）共享的特征空间。虽然在提取语言不变的特征方面有很好的通用性，但跨语言的预训练方法在<strong>提取领域不变的特征方面没有具体的策略</strong>。在我们的CLCD设置中，<strong>语言不变量和领域不变量的特征都需要被提取</strong>。</p><p>为了解决上述跨语言预训练模型[Conneau等，2019]在CLCD场景中的局限性，我们提出了一种无监督的特征分解（UFD）方法，它只利用源语言中的未标记数据。具体来说，我们提出的方法受到最近提出的无监督表示学习方法[Hjelm等人，2019]的启发，<strong>通过结合互信息最大化和最小化</strong>，<strong>可以同时提取领域不变的特征和领域特定的特征</strong>。与以往的跨语言迁移学习方法相比，我们提出的模型保持了跨语言预训练模型的优点，即对百余种语言具有良好的泛化能力，并且只需要源语言中的未标记数据进行领域适应，适用于更多的跨语言迁移场景。</p><p>我们在一个基准的跨语言感官分类数据集上评估了我们的模型，即亚马逊评论[Pretten- hofer and Stein, 2010]，它涉及多种语言和领域。实验结果表明，随着预训练的XLM跨语言模型的增强，我们提出的UFD模型（在源语言的一些未标记的原始文本上训练）和一个简单的Lin-ear分类器（在源语言和源领域的小型标记数据集上训练）胜过那些能够获得强大的跨语言监督（如商业MT系统）或多尖端源语言的标记数据集的最先进模型。此外，将我们提出的UFD策略与源语言中未标记的15万个实例集结合起来，可以持续获得超过强大的预训练XLM模型的收益，该模型是在100种语言和TB级文本上训练的。广泛的实验进一步证明，在预训练的跨语言语言模型上的无监督特征分解优于在超过1亿句话上训练的特定领域语言模型。</p><h2 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h2><h3 id="Problem-Definition-amp-Model-Overview"><a href="#Problem-Definition-amp-Model-Overview" class="headerlink" title="Problem Definition &amp; Model Overview"></a>Problem Definition &amp; Model Overview</h3><p>在本文中，我们考虑的是这样一种情况：我们只有一个特定语言和特定领域的标记集 $D<em>{s,s}$，我们称之为源语言和源领域，而我们想训练一个分类器，在一个不同语言和不同领域的集合 $D</em>{t,t}$上进行测试，我们称之为目标语言和目标领域。我们还假设在训练阶段可以获得一些未标记的原始数据 $D_{s,u}$，包括源语言的目标域，这在实际应用中通常是可行的。我们称这种设置为无监督的跨语言和跨领域（CLCD）适应。</p><p><img src="https://s2.loli.net/2021/12/27/o3tFG5CdeVp19hS.png" alt=""></p><p>如图1所示，建议的方法由三个部分组成：一个预训练的多语言嵌入模块，将输入文档嵌入到语言不变的表示中；一个无监督特征分解（UFD）模块，<strong>从纠缠的语言不变的表示中提取领域不变的特征和特定领域的特征</strong>；<strong>以及一个根据提取的领域不变的特征和特定领域特征训练的特定任务模块。</strong>我们采用XLM1[Conneau and Lample, 2019]作为我们方法中的多语言嵌入模块，它已经被来自各种语言的大规模平行和单语数据预训练过，是目前最先进的跨语言语言模型。我们在下面的小节中描述其他两个模块和训练过程。</p><p>在我们的方法中，我们采用了最近提出的神经估计方法[Belghazi等人，2018]，该方法通过训练一个网络工作来估计两个连续随机变量 $X$ 和 $Y$ 的MI，以区分来自它们的联合分布 $J$ 的样本和它们的边际分布的乘积 $M$ ，这种估计利用了基于KL-divergence的Donsker-Varadhan表示（DV）[Donsker和Varadhan，1983]的MI下限。</p><script type="math/tex; mode=display">I(X;Y) := D_{KL}(J|M) \ge \hat I^{DV}(X;Y)) := E_J[T_w(x,y)] - logE_M[e^{T_w(x,y)}]</script><p>其中，$T<em>ω$是一个辨别函数，由一个具有可学习参数 $ ω$ 的神经网络作为参数。通过最大化 $\hat I^{DV}$， $T</em>ω$ 被鼓励区分从 $J$ 和 $M$ 中抽取的样本，给前者分配大值，给后者分配小值。</p><h3 id="Proposed-Method"><a href="#Proposed-Method" class="headerlink" title="Proposed Method"></a>Proposed Method</h3><p>让 $X∈R^d$ 表示由预训练的多语言嵌入模块生成的语言不变量表示。然后将其作为输入输入到拟议的 UFD模块。</p><p>如图1所示，我们引入了两个特征提取器：领域不变的提取器 $F_s$（即左边的ReLU激活的两层前馈网络），以及领域特定的提取器 $F_p$（即右边的两层网络）。我们把提取的特征分别表示为 $F_s(X)$ 和 $F_p(X)$。请注意，对于 $F_s$，我们增加了剩余连接，以更好地保持 $X$ 的领域不变属性。</p><p>具体来说，$F_s$ 旨在以无监督的方式从语言不变量的表述中提取领域不变量的特征。<strong>由于多语言嵌入模块是在超过一百种语言的开放领域数据集上进行预训练的，因此可以推测，生成的语言不变量表示应该包含某些可以跨领域泛化的属性。</strong></p><p>当 $F_s$ 在多个领域接受训练，每个领域的输入和输出之间的 $MI$ 共同最大化时，鼓励它从语言不变的表征中保留这些领域之间的共享特征。通过这种方式，$F_s$ 被迫将领域不变的信息从 $X$ 传递给 $F_s(X)$。</p><p>我们利用方程（1）中提出的基于神经网络的估计器来计算MI。在我们的案例中，由于 $F_s(X)$依赖于 $X$ ，我们可以将基于DV-based 的MI估计器简化为Jensen-Shannon MI估计器，正如[Hjelm等人，2019]中建议的那样:</p><script type="math/tex; mode=display">\hat I^{JSD} (X; F_s(X)) := E_p[-sp(-T_w(x, F_s(x)))] - E_{p\times p}[sp(T_w(x',F_s(x)))]</script><p>其中 x 是一个具有经验概率分布 P 的输入嵌入。由于 $F_s(x)$ 是直接从 $x$ 计算出来的，$(x, F_s(x))$ 可以被视为从 $x$ 和 $F_s(x)$ 的联合分布中抽取的样本。$x’$ 对应于来自 $\hat P=P$的输入嵌入，即 $x$ 是从同一输入分布中抽取的随机样本计算出来的，这样 $(x’,F_s(x))$ 就是从边际分布的乘积中抽取的。$sp(z) = log(1+e^z)$ 是 softplus 激活函数。$F_s$ 的训练目标是使 $X$ 和 $F_s (X )$上的MI最大化，损失表述如下:</p><script type="math/tex; mode=display">L_s(w_s,\phi_s) = -\hat I^{JSD}(X,F_s(X))</script><p>其中 $ω_s$ 表示估计器中的辨别网络工作的参数，$ψ_s$表示 $F_s$ 的参数。为了便于学习领域不变的特征，我们还提出对 $F_s(X)$和相应的中间表示(第一层输出) $F’_s(X )$ 的MI最大化，训练损失如下:</p><script type="math/tex; mode=display">L_r(w_r, \phi_s) = -\hat I^{JSD}(F'_s(X), F_s(X))</script><p>其中 $ω_r$ 表示估计器中判别器网络的参数。回顾一下，$F_p$ 的目标是提取特定领域的特征，这应该是排他性的，并且独立于领域的不变量特征。我们建议最小化由 $F_s$ 和 $F_p$ 提取的特征之间的 $MI$，训练损失表述如下:</p><script type="math/tex; mode=display">L_p (w_p, \phi_s, \phi_p) = \hat I^{JSD} (F_s(X), F_p(X))</script><p>其中 $ψ_p$ 表示 $F_p$ 的参数。 $ω_p$ 表示MI估计器中歧视网络的参数。</p><p>因此，拟议的UFD组件的训练目标是使整体损失最小化，具体如下:</p><script type="math/tex; mode=display">L_{UFD} = \alpha L_s +\beta L_r + \gamma L_p</script><p>其中，α、β和γ是用于平衡次损失影响的超参数。</p><h3 id="Task-Specific-Module"><a href="#Task-Specific-Module" class="headerlink" title="Task-Specific Module"></a>Task-Specific Module</h3><p>在特定任务模块中，我们首先采用一个线性层，将 $R^{2d}$ 中的领域不变特征和领域特定特征的串联映射为 $R^d$中的矢量表示。然后，在这个映射的向量表示上采用一个简单的前馈层，用softmax激活来输出任务标签。我们在 $D_{s,s}$上训练这个模块，交叉熵损失表示为 $L_t$，作为训练目标。</p><h3 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h3><p>请注意，多语言嵌入模块的参数是经过预训练的，并且在整个训练过程中被设定为冻结。我们首先优化UFD的参数，即{ωs,ωr,ωp,ψs,ψp}，通过最小化无标签集Ds,u上的LUFD。一旦UFD模块训练完成，我们就固定其参数，并通过在有标签的集合Ds,s上最小化Lt来训练特定任务的模块。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Unsupervised-Domain-Adaptation-of-a-Pretrained-Cross-Lingual-Language-Model&quot;&gt;&lt;a href=&quot;#Unsupervised-Domain-Adaptation-of-a-Pretraine</summary>
      
    
    
    
    
    <category term="context detection" scheme="http://example.com/tags/context-detection/"/>
    
  </entry>
  
  <entry>
    <title>Contrastive Representation Distillation</title>
    <link href="http://example.com/2021/12/22/Contrastive-Representation-Distillation/"/>
    <id>http://example.com/2021/12/22/Contrastive-Representation-Distillation/</id>
    <published>2021-12-22T15:50:39.000Z</published>
    <updated>2021-12-22T15:59:23.978Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Contrastive-Representation-Distillation"><a href="#Contrastive-Representation-Distillation" class="headerlink" title="Contrastive Representation Distillation"></a>Contrastive Representation Distillation</h1><p>我们经常希望将表征性知识从一个神经网络转移到另一个神经网络。这方面的例子包括将一个大型网络提炼成一个较小的网络，将知识从一种感觉模式转移到另一种感觉模式，或者将一系列模型集合成一个单一的估计器。知识提炼是解决这些问题的标准方法，它使教师和学生网络的概率输出之间的KL散度最小。我们证明这个目标忽略了教师网络的重要结构知识。</p><p>这促使我们提出了另一个目标，即训练学生在教师的数据表述中捕捉到更多的信息。我们把这个目标表述为对比学习。</p><p>实验证明，我们所产生的新目标在各种知识迁移任务上优于知识蒸馏和其他尖端的蒸馏器，包括单一模型压缩、集合蒸馏和跨modal转移。我们的方法在许多迁移任务中创造了新的最先进的技术，当与知识蒸馏相结合时，有时甚至超过了教师网络。</p><h2 id="INTRODUCTION"><a href="#INTRODUCTION" class="headerlink" title="INTRODUCTION"></a>INTRODUCTION</h2><p>知识蒸馏（KD）将知识从一个深度学习模型（教师）转移到另一个（学生）。最初由Hinton等人（2015）提出的目标是最小化教师和学生输出之间的KL散度。当输出是一个分布时，这种表述具有直观的意义，例如，在类上的概率质量函数。然而，我们经常希望迁移关于一个表示的知识。例如，在 “跨模型蒸馏 “的问题中，我们可能希望将图像处理网络的表示迁移到声音（Aytar等人，2016）或深度（Gupta等人，2016）处理网络，这样，图像的深度特征和相关的声音或深度特征是高度相关的。在这种情况下，KL散度是不确定的。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Contrastive-Representation-Distillation&quot;&gt;&lt;a href=&quot;#Contrastive-Representation-Distillation&quot; class=&quot;headerlink&quot; title=&quot;Contrastive Re</summary>
      
    
    
    
    
    <category term="context detection" scheme="http://example.com/tags/context-detection/"/>
    
  </entry>
  
  <entry>
    <title>Achieving Forgetting Prevention and Knowledge Transfer in Continual Learning</title>
    <link href="http://example.com/2021/12/22/Achieving-Forgetting-Prevention-and-Knowledge-Transfer-in-Continual-Learning/"/>
    <id>http://example.com/2021/12/22/Achieving-Forgetting-Prevention-and-Knowledge-Transfer-in-Continual-Learning/</id>
    <published>2021-12-22T06:09:05.000Z</published>
    <updated>2021-12-27T09:06:46.628Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Achieving-Forgetting-Prevention-and-Knowledge-Transfer-in-Continual-Learning"><a href="#Achieving-Forgetting-Prevention-and-Knowledge-Transfer-in-Continual-Learning" class="headerlink" title="Achieving Forgetting Prevention and Knowledge Transfer in Continual Learning"></a>Achieving Forgetting Prevention and Knowledge Transfer in Continual Learning</h1><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>持续学习（CL）是指逐步学习一连串的任务，目的是实现两个主要目标：克服灾难性遗忘（CF）和鼓励跨任务的知识转移（KT）。然而，大多数现有的技术只注重克服CF，没有鼓励KT的机制，因此在KT中表现不佳。尽管有几篇论文试图同时处理CF和KT，但我们的实验表明，当任务没有太多的共享知识时，它们受到严重的CF影响。</p><p>另一个观察结果是，目前大多数CL方法没有使用预训练的模型，但事实证明，这种模型可以大大改善最终的任务表现。例如，在自然语言处理中，对类似BERT的预训练语言模型进行微调是最有效的方法之一。</p><p> 然而，对于CL来说，这种方法受到了严重的CF的影响。一个有趣的问题是如何将预训练的模型最好地用于CL。本文提出了一个名为CTR的新模型来解决这些问题。我们的实验结果证明了CTR的有效性。</p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>本文研究了在任务持续学习（Task-CL）环境下的自然语言处理（NLP）任务序列的持续学习（CL）。它的目的是 </p><ul><li>(i) 防止灾难性遗忘(CF)</li><li>(ii)跨任务的知识转移</li></ul><p>(ii)特别重要，因为NLP中的许多任务共享类似的知识，可以利用这些知识来实现更好的准确性。CF意味着在学习一个新的任务时，为以前的任务所学的现有网络参数可能会被修改，从而降低以前任务的性能[40]。</p><p> 在任务-持续学习设置中，在测试中为每个测试案例提供任务ID，这样就可以应用网络中任务的特定模型来对测试案例进行分类。另一个流行的CL设置是类持续学习，它在测试中不提供任务ID，但它是为了解决不同类型的问题。</p><p>现有的CL论文大多集中在处理CF[21, 5]。也有一些论文是进行知识转移的。要实现这两个目标是非常具有挑战性的。为了克服任务-CL设置中的CF，我们不希望新任务的训练更新为以前的任务学习的模型参数，以实现模型分离。</p><p> 但是，为了实现跨任务的知识转移，我们希望新任务能够利用从以前的任务中学到的知识来学习更好的模型（前向转移），也希望新任务能够提高以前类似任务的性能（后向转移）。</p><p>这意味着有必要更新以前的模型参数。这是个两难的问题。虽然有几篇论文试图处理这两方面的问题[22, 37]，但它们只使用具有强大共享知识的情感分析任务进行测试。当用没有太多共享知识的任务进行测试时，它们会受到严重的CF影响（见5.4节）。那些专注于处理CF的现有论文在知识转移方面做得不好，因为它们没有明确的机制来促进转移。</p><p>关于目前CL研究的另一个观察结果是，大多数技术没有使用预训练的模型。但这种预训练的模型或特征提取器可以显著提高CL的性能[18, 24]。一个重要的问题是如何在CL中最好地利用预训练的模型。本文也使用NLP任务来研究这个问题，但我们相信所开发的思想也适用于计算机视觉任务，因为大多数预训练的模型都是基于变换器架构的[60]。我们将看到，在预训练模型上直接添加CL模块的天真或传统方式并不是最佳选择（见第5.4节）。</p><p>在NLP中，微调一个类似于BERT[8]的预训练语言模型已被视为应用中最有效的技术之一[65, 57]。然而，微调对持续学习的效果很差。这是因为一个任务的微调BERT捕获了高度特定的任务信息[41]，这很难被其他任务所使用。当为一个新的任务进行微调时，它必须更新以前的任务已经微调的参数，这将导致严重的CF（见第5.4节）。</p><p>本文提出了一种新型的神经结构，以实现CF的预防和知识转移，同时也处理了具有BERT微调的CF问题。提出的系统被称为CTR（持续学习的胶囊和转移路由）。CTR在BERT的两个位置插入了一个持续学习插件（CL-plugin）模块。在BERT中加入这对CL-插件模块后，我们不再需要为每个任务对BERT进行微调，因为这将导致BERT中的CF，但我们却可以实现BERT微调的功能。CTR与Adapter-BERT[16]有一些相似之处，后者在BERT中增加了适配器，用于参数的有效转移学习，这样，不同的终端任务可以有其独立的适配器（其尺寸非常小）来为各个终端任务调整BERT，并将BERT的知识转移到终端任务中。那么，就不需要为每个任务采用单独的BERT并对其进行微调，如果需要学习许多任务，那么参数效率是非常低的。适配器是一个简单的2层全连接网络，用于将BERT适应于特定的终端任务</p><p>CL-插件与适配器有很大不同。我们不使用一对CL-插件模块来为每个任务调整BERT。相反，CTR只使用插入到BERT中的一对CL-插件模块来学习所有的任务。CL-插件是一个完整的CL网络，可以利用预训练的模型，处理CF和知识转移。具体来说，它使用一个胶囊[15]来代表每个任务，并使用一个拟议的转移路由算法来识别和转移跨任务的知识，以达到提高准确性的目的。它进一步学习和使用任务掩码来保护特定任务的知识，以避免遗忘。经验评估表明，CTR的性能优于强大的基线。还进行了消融实验，以研究在何处插入BERT中的CL-插件模块，以实现最佳性能（见第5.4节）。</p><h2 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h2><h3 id="Catastrophic-Forgetting"><a href="#Catastrophic-Forgetting" class="headerlink" title="Catastrophic Forgetting"></a>Catastrophic Forgetting</h3><p>CL的现有工作主要集中在使用以下方法来克服CF。(1) 基于正则化的方法，如[27, 30, 51, 69]，在损失中加入正则化，以便在学习新任务时巩固以前任务的权重。(2）基于重放的方法，如[45, 36, 4, 63]中的方法，保留一些旧任务的训练数据，并在学习新任务时使用它们。54, 20, 47, 14]中的方法学习数据生成器并生成旧任务数据用于学习新任务。(3) 基于参数隔离的方法，如[52, 21, 39, 10]中的方法，分配专用于不同任务的模型参数，并在学习新任务时将其屏蔽。(4) 基于梯度投影的方法[68]确保梯度更新只发生在旧任务输入的正交方向上，因此不会影响旧任务。最近的一些论文使用了预训练的模型[18, 23, 24]和每个任务学习一个类[18]。应对CF只处理模型恶化的问题。这些方法的表现比单独学习每个任务要差。在[44]中对CF的原因和任务相似性对CF的影响进行了实证研究。</p><p>一些NLP的应用也涉及到CF。例如，CL模型已被提出用于情感分析[23, 24, 37, 43]、对话槽填充[53]、语言建模[58, 7]、语言学习[31]、句子嵌入[33]、机器翻译[25]、跨语言建模[35]，以及问题回答[12]。在[38]中也报告了一个对话CL数据集。</p><h3 id="Knowledge-Transfer"><a href="#Knowledge-Transfer" class="headerlink" title="Knowledge Transfer"></a>Knowledge Transfer</h3><p>理想情况下，从任务序列中学习也应该允许多个任务通过知识转移相互支持。CAT[21]（一个任务-CL系统）在相似和不相似的任务的混合序列上工作，可以在自动检测到的相似任务之间转移知识。渐进式网络[48]做了前向转移，但它是针对类持续学习（Class-CL）。</p><p>本文中的知识转移与终身学习（LL）密切相关，其目的是在不处理CF的情况下提高新的/最后的任务学习[56, 49, 5]。在NLP领域，NELL[3]进行了LL信息提取，还有几篇论文致力于终身的文档情感分类（DSC）和方面情感分类（ASC）。[6]和[61]提出了两种Naive Bayesian方法来帮助提高新任务的学习。[64]提出了一种基于投票的LL方法。[55]将LL用于方面提取。[43]和[62]分别将神经网络用于DSC和ASC。有几篇论文也研究了终身主题建模[5, 13]。然而，所有这些工作都没有涉及到CF。</p><p>SRK[37]和KAN[22]试图在持续情感分类中同时处理CF和知识转移问题。然而，它们有两个关键的弱点。(i) 它们的RNN架构不能使用插件或适配器模块来调整BERT，这大大限制了它们的能力。(ii) 由于它们主要是为知识转移而设计的，因此它们受到了严重的CF（见第5.4节）。B-CL[24]使用适配器的想法[16]来调整BERT的情感分析任务，这两者之间是相似的。然而，由于其知识转移的动态路由机制非常弱，其知识转移能力明显比CTR差（见第5.4节）。CLASSIC[23]是另一个关于知识转移的持续学习的最新工作，但其CL设置是领域持续学习。它的知识转移方法是基于对比学习。</p><p>AdapterFusion[42]使用了[16]中提出的适配器。它提出了一个两阶段的方法来学习一组任务。在第一阶段，它使用任务的训练数据为每个任务独立学习一个适配器。在第二阶段，它再次使用训练数据来学习第一阶段学到的适配器的良好组合，以产生所有任务的最终模型。AdapterFusion基本上试图改善多任务学习。它不是为了持续学习，因此没有CF。正如第1节所解释的，CTR中的CL-插件概念与为每个任务适应BERT的适配器不同。CL-插件是利用预先训练的模型的持续学习系统。</p><h2 id="CTR-Architecture"><a href="#CTR-Architecture" class="headerlink" title="CTR Architecture"></a>CTR Architecture</h2><p><img src="https://s2.loli.net/2021/12/22/5RCDskL4aQvEJeN.png" alt=""></p><p>本节介绍了 CTR 的总体架构。关于其关键组件 CL-plugin 的细节将在下一节介绍。由于其良好的性能，BERT[8]及其变压器[60]结构在我们的模型CTR中被用作基础。由于BERT微调容易出现CF（第1节），我们提出了CL-plugin的想法，其灵感来自Adapter-BERT[16]。CL-插件是一个完整的持续学习模块，旨在与预先训练的模型（在我们的例子中是BERT）进行交互。</p><h3 id="Inserting-CL-plugins-in-BERT"><a href="#Inserting-CL-plugins-in-BERT" class="headerlink" title="Inserting CL-plugins in BERT"></a>Inserting CL-plugins in BERT</h3><p>一个常用的利用预训练模型的方法是在预训练模型的基础上增加终端任务模块。然而，正如第1节所解释的，对预训练模型进行微调会给CL带来严重的CF。使用这种方法的CL系统PCL[18]，将预训练的模型冻结起来，以避免遗忘。但正如我们将在第5.4节中看到的，这不是最好的选择。CTR在BERT的两个位置插入了提议的CL插件，即在BERT的每个变压器层中。我们还将在第5.4节中看到，在一个位置只插入一个CL插件是次优的。图1给出了CTR架构，我们可以看到两个CL-插件被添加到BERT中。在学习中，只有这两个CL插件和分类头被训练。原始预训练的BERT的组件是固定的。</p><h3 id="Continual-learning-plug-in-CL-plugin"><a href="#Continual-learning-plug-in-CL-plugin" class="headerlink" title="Continual learning plug-in (CL-plugin)"></a>Continual learning plug-in (CL-plugin)</h3><p>CL-plugin采用了类似胶囊网络（CapsNet）[15, 50]的架构。在经典的神经网络中，一个神经元输出一个标量、实值的激活作为特征检测器。CapsNets用一个矢量输出的胶囊代替，以保留额外的信息。一个简单的CapsNet由两个胶囊层组成。第一层存储低级别的特征图，第二层生成分类概率，每个胶囊对应一个类别。CapsNet使用动态路由算法，使每个低层的胶囊将其输出发送到类似的（或 “同意的”，由点积计算的）高层胶囊。这一特性已经可以用来对类似的任务及其可共享的特征进行分组，以产生一个CL系统（见5.4节中的消融研究）。CL-插件的关键思想之一（见图2(A)）是一个转移胶囊层，它有一个新的转移路由算法，可以明确地识别从以前的任务转移到新任务的可转移特征/知识。</p><h2 id="Continual-Learning-Plug-in-CL-plugin"><a href="#Continual-Learning-Plug-in-CL-plugin" class="headerlink" title="Continual Learning Plug-in (CL-plugin)"></a>Continual Learning Plug-in (CL-plugin)</h2><p>我们的持续学习插件（CL-plugin）的结构如图2（A）所示。CL-plugin需要两个输入。(1) 来自变压器层内前馈层的隐藏状态h(t)和 (2) 任务ID t，这是任务持续学习（Task-CL）的要求。输出是具有适合第t个任务分类的特征的隐藏状态。在CL-plugin内部，有两个模块。(1）知识共享模块（KSM），用于识别和转移以前类似任务的可共享知识到新任务t，以及（2）任务特定模块（TSM），用于学习任务特定的神经元及其掩码（可以保护神经元不被未来任务更新，以处理CF）。由于TSM是可分的，整个系统CTR可以进行端到端的训练。</p><h3 id="Knowledge-Sharing-Module-KSM"><a href="#Knowledge-Sharing-Module-KSM" class="headerlink" title="Knowledge Sharing Module (KSM)"></a>Knowledge Sharing Module (KSM)</h3><p>KSM通过任务封装层(TK-Layer)、传输胶囊层(TR-Layer)和传输路由机制实现相似任务之间的知识传输。</p><h4 id="Task-Capsule-Layer-TK-Layer"><a href="#Task-Capsule-Layer-TK-Layer" class="headerlink" title="Task Capsule Layer (TK-Layer)"></a>Task Capsule Layer (TK-Layer)</h4><p>TK层中的每个胶囊代表一个任务，它准备了从每个任务中得到的低层次特征（图2（A））。因此，每个新任务都有一个胶囊被添加到TK层中。这种递增式的增长是有效和容易的，因为这些胶囊是离散的，不共享参数。另外，每个胶囊只是一个具有少量参数的2层全连接网络。让 $h(t)∈R^{d_t×d_e}$ 是CL-plugin的输入，其中dt是tokens的数量，de是维数，t是当前任务。在TK层中，我们为每个任务准备了一个胶囊。假设到目前为止我们已经学会了t个任务。第i个（i≤t）任务的胶囊是:</p><script type="math/tex; mode=display">p_i^{(t)} = f_i(h^{(t)})</script><p>其中$f_i(·)=MLP_i(·)$表示2层全连通网络。</p><h4 id="Transfer-Routing-and-Transfer-Capsule-Layer"><a href="#Transfer-Routing-and-Transfer-Capsule-Layer" class="headerlink" title="Transfer Routing and Transfer Capsule Layer"></a>Transfer Routing and Transfer Capsule Layer</h4><p>转移胶囊层（TR层）中的每个胶囊代表从TK层中提取的可转移表示。如图2（A）所示，TK层的低级胶囊和TR层的高级胶囊之间的转移路由有三个组成部分：预路由向量发生器（PVG）、相似性估计器（SE）和任务路由器（TR）。鉴于TK层中的任务胶囊，我们首先通过一个可训练的权重矩阵来转换特征。我们把这种转换的输出称为预路由向量。每个SE使用预路由向量估计以前的任务和当前的任务之间的相似性，从而为每个高层的胶囊得出相似性分数。此外，每个SE都有一个TR模块，一个作为门的可区分的任务路由器。这个路由器估计一个二进制信号，决定是否连接或断开两个连续的胶囊层（即CL-插件中的TK层和TR层）之间的当前路线。由TR估计的二进制信号可以被看作是一个可区分的二进制注意。从概念上讲，每个SE和TR对一起以随机和可区分的方式学习胶囊之间的连接性，这可以被看作是一个基于任务相似性的连接性搜索机制。这种转移路由确定了来自多个任务胶囊的共享特征/知识，并帮助知识在类似任务之间转移。接下来，我们讨论预路由向量发生器、相似性估计器和任务路由器。</p><h1 id="CLASSIC-Continual-and-Contrastive-Learning-of-Aspect-Sentiment-Classification-Tasks"><a href="#CLASSIC-Continual-and-Contrastive-Learning-of-Aspect-Sentiment-Classification-Tasks" class="headerlink" title="CLASSIC: Continual and Contrastive Learning of Aspect Sentiment Classification Tasks"></a>CLASSIC: Continual and Contrastive Learning of Aspect Sentiment Classification Tasks</h1><p>本文研究了在一个特殊的持续学习（CL）环境下的一系列方面情感分类（ASC）任务，称为领域递增学习（DIL）。每个任务都来自不同的领域或产品。DIL设置特别适用于ASC，因为在测试中，系统不需要知道测试数据所属的任务/领域。据我们所知，这种设置以前还没有为ASC研究过。本文提出了一个叫做CLASSIC的新模型。关键的创新点是一种对比性的持续学习方法，它既能实现跨任务的知识转移，又能将知识从旧任务提炼到新任务，这就消除了测试中对任务ID的需求。实验结果表明，CLASSIC的有效性很高。</p><h2 id="Introduction-1"><a href="#Introduction-1" class="headerlink" title="Introduction"></a>Introduction</h2><p>持续学习（CL）以递增的方式学习一连串的任务。在学习完一个任务后，其训练数据通常被丢弃（Chen和Liu，2018）。当数据隐私是一个问题时，CL设置是有用的，即数据所有者不希望他们的数据被其他人使用（Ke等人，2020b；秦等人，2020；Ke等人，2021）。在这种情况下，如果我们想利用过去学到的知识来改善新的任务学习，CL是合适的，因为它只分享学到的模型，而不是数据。在我们的案例中，一个任务是一个产品或领域（例如，相机或手机）的一个单独的方面情感分类（ASC）问题（刘，2012）。ASC表述如下。给出一个方面的术语（例如，手机评论中的声音质量）和一个包含该方面的句子（例如，”声音质量很差”），ASC对该句子是否表达了对该方面的积极、消极或中立的意见进行分类。</p><p>有三种CL设置（van de Ven and Tolias, 2019）。类增量学习（CIL），任务增量学习（TIL），和域增量学习（DIL）。在CIL中，任务包含不重叠的类。对于目前看到的所有类别，只建立一个模型。在测试中，不提供任务信息。这种设置不适合ASC，因为ASC任务有相同的三个类。TIL为共享网络中的每个任务建立一个模型。在测试中，系统需要每个测试实例（例如，”音质很好”）所属的任务（例如，电话领域），并且只使用任务的模型来对实例进行分类。重新要求任务信息（如电话领域）是一个限制。理想情况下，用户不应该为一个测试句子提供这些信息。这就是DIL设置，即所有任务共享相同的固定类别（例如，积极、消极和中立）。在测试中，不需要任何任务信息。</p><p>这项工作使用DIL设置来学习神经网络中的一系列ASC任务。关键的目标是在不同的任务之间转移知识，以改善分类，而不是单独学习每个任务。任何CL的一个重要目标是克服灾难性遗忘（CF）（McCloskey和Cohen，1989），这意味着在学习一个新的任务时，系统可能会改变为以前的任务学习的参数，导致其性能下降。我们也要解决CF的问题，否则我们就不能达到提高准确性的目的。然而，DIL中的所有任务共享分类头，使得跨任务干扰/更新不可避免。没有测试中提供的任务信息，使DIL更具挑战性。</p><p>以前的研究表明，ASC最有效的方法之一（Xu等人，2019；Sun等人，2019）是使用训练数据对BERT进行微调（Devlin等人，2019）。然而，我们的实验表明，这对DIL来说效果很差，因为一个任务上的微调BERT捕获了高度的任务特定特征，而这些特征很难被其他任务使用。</p><p>在本文中，我们在DIL设置中提出了一个名为CLASSIC（Continual and contrastive Learning for ASpect SentIment Classification）的新型模型。CLASSIC没有为每个任务微调BERT，这将导致严重的CF，而是使用（Houlsby等人，2019）中的Adapter-BERT的想法来避免改变BERT参数，但却能获得与BERT微调同样好的结果。提出了一种新颖的对比性持续学习方法（1）将可共享的知识转移到不同的任务中，以提高所有任务的准确性；（2）将以前的任务中的知识（包括可共享的和不可共享的）提炼到新任务的模型中，使新的/最后一个任务模型能够执行所有的任务，这样就不需要在测试中提供任务信息（如任务ID）。现有的对比学习（Chen等人，2020）无法做到这些。</p><p>任务 mask 也被学习并用于保护特定任务的知识以避免遗忘（CF）。已经进行了大量的实验来证明CLASSIC的有效性。<br>综上所述，本文有以下贡献。(1) 它提出了ASC的领域持续学习问题，这在以前是不可能的。(2) 它提出了一个名为CLASSIC的新模型，该模型使用适配器将预先训练好的BERT纳入ASC的持续学习中，使用一种新颖的对比性持续学习方法进行知识转移和提炼，并使用任务掩码隔离特定任务的知识以避免CF。</p><h2 id="Proposed-CLASSIC-Method"><a href="#Proposed-CLASSIC-Method" class="headerlink" title="Proposed CLASSIC Method"></a>Proposed CLASSIC Method</h2><p><img src="https://s2.loli.net/2021/12/22/Gpm9vTXgPAfsqyt.png" alt=""></p><h3 id="3-1-Overview-of-CLASSIC"><a href="#3-1-Overview-of-CLASSIC" class="headerlink" title="3.1 Overview of CLASSIC"></a>3.1 Overview of CLASSIC</h3><p>图1中给出了CLASSIC的结构，它在ASC的DIL设置中工作。它使用Adapter-BERT来避免对BERT进行微调。CLASSIC在训练中需要两个输入。(1) 来自BERT变压器层的前馈层的隐藏状态 $h(t)$ 和  (2) 任务 id $t$（测试时不需要任务 id，见第3.2.3节）。输出是带有任务 $t$ 特征的隐藏状态，以建立一个分类器。</p><p>CLASSIC使用三个子系统来实现其目标（见第1节）。</p><ul><li>(1) 对比性集合提炼(CED)，通过将以前的任务知识提炼到当前的任务模型中来减轻CF；</li><li>(2) 对比性知识共享(CKS)，鼓励知识转移；</li><li>(3) 当前任务模型的对比性监督学习(CSC)，提高当前任务模型的准确性。我们把这个框架称为对比性持续学习，其灵感来自于对比性学习。</li></ul><p>对比学习使用现有数据的多个视图进行表征学习，将相似的数据组合在一起，并将不相似的数据推得很远，这使得学习更准确的分类器更加容易。它使用现有数据的各种转换来创建有用的视图。给定一个由 $N$ 个训练实例组成的小型批次，如果我们为每个实例创建另一个视图，该批次将有 $2N$ 个样本。</p><p>我们假设 $i$ 和 $j$ 是训练实例的两个视图。如果我们用 $i$ 作为锚点。$(i, j)$ 被称为正对。所有其他 $k\ne i$ 的对$(i,k)$都是负对。这个正数对的对比损失是（Chen等人，2020）,</p><script type="math/tex; mode=display">L_{i,j} = - log\frac{exp((h_i\cdot h_j)/ \tau)}{\sum_{k=1}^{2N} 1_{k\ne j} exp((h_i\cdot h_k)/ \tau)}</script><p>其中点积 $h_i \cdot h_j$ 被视为隐藏空间中的相似性函数，$τ$ 是温度。该批次的最终损失是在所有的正数对中计算的。上式是用于无监督的对比学习。它也可以用于监督对比学习，来自同一类别的任何两个实例/视图形成一个正例对，而一个类别的任何实例和其他类别的任何实例形成一个负例对。</p><h3 id="3-2-Overcoming-Forgetting-via-Contrastive-Ensemable-Distillation-CED"><a href="#3-2-Overcoming-Forgetting-via-Contrastive-Ensemable-Distillation-CED" class="headerlink" title="3.2 Overcoming Forgetting via Contrastive Ensemable Distillation (CED)"></a>3.2 Overcoming Forgetting via Contrastive Ensemable Distillation (CED)</h3><p>CED的目标是处理CF。我们首先介绍了CED所依赖的任务掩码，以保留以前的任务知识/模型，将其提炼到新的任务模型中，以避免CF。</p><h4 id="3-2-1-Task-Masks-TMs"><a href="#3-2-1-Task-Masks-TMs" class="headerlink" title="3.2.1 Task Masks (TMs)"></a>3.2.1 Task Masks (TMs)</h4><p>给定来自转换层前馈层的输入隐藏状态 $h^{(t)} $，adapter 通过全连接网络将其映射为输入$k^{(t)}_l$，其中 $l$ 是适配器的第 $l$ 层。</p><p>在训练任务 $t$ 的分类器时，在 adapter 的每一层 $l$ 为每个任务 $t$ 训练一个 TM（一个 “软 “二进制掩码）$m^{(t)}_l$，表明该层中对任务重要的神经元。在这里，我们借鉴了（Serrà等人，2018）中的 hard attention 思想，并利用任务 id 嵌入来训练TM。</p><p>对于一个任务id t，它的嵌入$e^{(t)}_l$ 由可微调的参数组成，可以和网络的其他部分一起学习，它是为 adapter 中的每一层训练的。为了从 $e^{(t)}_l $ 中生成TM $m^{(t)}_l$，Sigmoid被用作伪门，并应用一个正的缩放超参数 $s$ 来帮助训练。$m^{(t)}_l $的计算方法如下:</p><script type="math/tex; mode=display">m_l^{(t)} = \sigma (se_l^{(t)})</script><p>请注意，$ m^{(t)}_l $ 中的神经元可能与以前任务中的其他 $m^{(iprev)}_l$ 的神经元重叠，显示出一些共享的知识。给出适配器中每一层的输出，$k^{(t)}_l $，我们将其进行元素乘法计算 $k^{(t)}_l ⊗ m^{(t)}_l$。</p><p>最后一层的屏蔽输出 $k^{(t)}_l \otimes m_l^{(t)} $ 被送入BERT的下一层，有一个跳过的连接（见图2）在学习任务 $t$ 之后，最终的 $m^{(t)}_l $ 被保存并添加到集合 ${m^{(t)}_l}$中。</p><p><img src="https://s2.loli.net/2021/12/22/UNWkgiRwKYlq4en.png" alt=""></p><h4 id="3-2-2-Training-Task-Masks-TMs"><a href="#3-2-2-Training-Task-Masks-TMs" class="headerlink" title="3.2.2 Training Task Masks (TMs)"></a>3.2.2 Training Task Masks (TMs)</h4><p>对于每个先前的任务 $i<em>{prev} \in T</em>{prev}$，其TM $m^{(iprev)}_l$表明哪些神经元被该任务使用并需要保护。在学习任务 $t$ 中，$m^{(iprev)}_l $ 用来设置 $l$ 层所有使用的神经元上的梯度 $g(t)$ 层的所有神经元的梯度为 0。在修改梯度之前，我们首先积累所有以前的任务TMs 所使用的神经元。由于 $m^{(iprev)}_l$ 是二进制的，我们用最大池化来实现累积：</p><script type="math/tex; mode=display">m_l^{(t_{ac})} = MaxPool(\{m_l^{(i_{prev})}\})</script><p>term $m^{(T_{ac})}_l$用于梯度：</p><script type="math/tex; mode=display">g_l^{'(t)} = g^{(t)}_l \otimes (1-m_l^{(t_{ac})})</script><p>那些对应于 $m^{(t<em>{ac})}_l$ 中1项的梯度被设置为0，而其他梯度则保持不变。通过这种方式，旧任务中的神经元被保护起来。请注意，我们扩展（复制）矢量 $m^{(t</em>{ac})}_l $ 以匹配 $g^{(t)}_l$ 的尺寸。</p><p>虽然这个想法很直观，但 $e^{(t)}<em>l $ 并不容易训练。为了使 $e^{(t)}_l $ 的学习更容易、更稳定，采用了退火策略。也就是说，s在训练期间被退火，诱发梯度 flow，在测试期间设置 $s=s</em>{max}$。公式2将一个单位 step 函数近似为mask，当 $s→∞$ 时，$m^{(t)}_l→{0,1}$。一个训练周期开始时，所有的神经元都是同样活跃的，在周期内逐渐极化。具体来说，$s$ 的退火情况如下:</p><script type="math/tex; mode=display">s = \frac{1}{s_{max}} + (s_{max} - \frac{1}{s_{max}}) \frac{b-1}{B-1}</script><p>其中 $b$ 是批次索引，$B$ 是一个 epoch中的总批次数。</p><p><strong>Illustration</strong> :在图2中，在学习了任务1之后，我们得到了其有用的神经元，用橙色标记，每个神经元中都有一个 “1”，在学习未来的任务时，它可以作为一个屏蔽。在学习任务2时，那些对任务1有用的神经元被掩盖了（左边那些橙色的神经元上有 “0”）。这个过程还学习了任务2的有用神经元，用绿色的 “1 “标记。当任务3到来时，任务1和任务2的所有神经元都被屏蔽了，也就是说，它的TM条目被设置为0（训练前为橙色和绿色）。训练完任务3后，我们看到任务3和任务2有一个共享神经元，对两者都很重要。该共享神经元被标记为红色和绿色。</p><h4 id="3-2-3-Contrastive-Ensemble-Distillation-CED"><a href="#3-2-3-Contrastive-Ensemble-Distillation-CED" class="headerlink" title="3.2.3 Contrastive Ensemble Distillation (CED)"></a>3.2.3 Contrastive Ensemble Distillation (CED)</h4><p>TMs机制为不同的任务隔离了不同的参数。这对于克服遗忘似乎是完美的，因为以前的任务参数是固定的，不能被未来的任务所更新。</p><p>然而，由于DIL设置在测试中没有任务 id，我们不能直接利用TM的优势。为了解决这个问题，我们提出了CED目标，以帮助提炼所有先前的知识到当前的任务模型，这样我们就可以简单地使用最后的模型作为最终模型，而不需要在测试中使用任务 id。</p><p><strong>Representation of Previous Tasks</strong>。回顾一下，我们通过阅读 ${m^{(i)}_l}$ 知道哪些神经元/单元是用于哪个任务的。对于当前任务 $t$ 的每个以前的任务 $i$ 我们可以通过将 $m^{(i)}_l $ 应用于Adapter-BERT(分类头之前的那一层)来计算它的 mask 输出。</p><p><strong>Ensemble Distillation Loss</strong> 我们将以前的任务集合的知识提炼成 单一的当前任务模型。由于我们在DIL中的所有任务都有一个共享的分类头，它被暴露在遗忘中，所以提炼应该基于分类头的输出。具体来说，给定前一个任务的Adapter-BERT输出 $h^{(i)}_m $，我们用 $h^{(i)}_m$ 计算分类头的输出，这就得到了logit（未归一化的预测）值 $z^{(i)}_m$。然后，我们利用 $z^{(i)}_m $和当前任务分类头的输出 $z^{(t)}$ 来提炼知识，其灵感来自于（Tian等人，2020a）的对比损失</p><script type="math/tex; mode=display">L_{CED}^{(i)} = \sum_{n=1}^{2N} - log \frac{exp((z_{m:2n-1}^{(i)} \cdot z^{(t)}_{m:2n}) /\tau)}{ \sum_{j=1}^{2N} 1_{n\neq j} exp((z_{m:n}^{(i)} \cdot z_{m:j}^{(t)})/ \tau)}</script><p>其中，$N$ 是批次大小，$τ&gt;0$ 是一个可调节的温度参数，控制类的分离。索引 $n$ 是锚点，符号 $z^{(i)}_{m:n} $ 指的是 $z^{(i)}_m $ 中的第 $n$ 个样本。</p><p>$z^{(i)}<em>{m:2n-1}$ 和 $z</em>{m:2n}^{(t)}$  是先前和当前任务模型对同一输入样本的对数，是对比学习中的一对正例。所有其他可能的配对都是负例的配对。请注意，对于每个锚点 $i$ ，都有1对正数和 $2N-2$ 对负数。</p><p>分母总共有 $2N - 1$个项（包括正项和负项）。请注意，以前的任务模型是固定的，因此可以作为教师网络。由于我们有$i≥1$ 个以前的任务，因此 $i≥1$个教师网络，但只有一个当前任务的学生网络。我们采用对比性框架，在 $z^{(i)}_m $ 和  $z^{(t)}_m $ 之间定义多个配对的损失。这些损失相加，得出最终的CED损失,</p><script type="math/tex; mode=display">L_{CED} = \sum_{i=1}^{t-1} L_{CED}^{(i)}</script><h3 id="3-3-Transferring-Knowledge-via-Contrastive-Knowledge-Sharing-CKS"><a href="#3-3-Transferring-Knowledge-via-Contrastive-Knowledge-Sharing-CKS" class="headerlink" title="3.3 Transferring Knowledge via Contrastive Knowledge Sharing (CKS)"></a>3.3 Transferring Knowledge via Contrastive Knowledge Sharing (CKS)</h3><p>CKS旨在捕捉任务间的共享知识，帮助新任务学习更好的表示和更好的分类器。CKS的直觉是这样的。对比学习有能力捕捉不同观点之间的共享知识（Tian等人，2020b；van den Oord等人，2018）。这是通过寻求不变的跨类似观点的表示来实现的。</p><p><strong>如果我们能从以前的任务中产生一个与当前任务相似的视图，那么对比性损失就能捕捉到共享的知识</strong>，<strong>并为知识转移到新的任务学习中学习一个表示</strong>。下面，我们首先介绍如何构建这样的视图并在CKS目标中使用它。</p><h4 id="3-3-1-Task-based-Self-Attention"><a href="#3-3-1-Task-based-Self-Attention" class="headerlink" title="3.3.1 Task-based Self-Attention"></a>3.3.1 Task-based Self-Attention</h4><p>直观地说，这两项任务越是相似，它们的共享知识就越多。它们拥有的共享知识就越多。为了实现我们的目标，我们应该将所有类似的任务合并为 共享知识视图。为了专注于 类似的任务，我们建议使用Task-based Self-Attention来关注它们。</p><p>在(Zhang等人，2018年)的启发下，给定Adapter-Bert针对所有先前和当前任务的输出的级联，$h<em>{m}^{(\le t)} = cat({h_m^{(i)}}</em>{i=1}^t)$, 并且 task $i\le t$， 我们首先转换它到两个特征空间，通过 $f(h_m^{(i)}) = W_fh_m^{(i)},  g(h_m^{(i)})=W_gh_m^{(i)}$  （见图1 CKS）</p><p>为了比较任务 $i≤t$ 和 $j≤t$ 之间的相似度，我们通过以下方式计算相似度 $s_{ij}$ :</p><script type="math/tex; mode=display">s_{ij} = f(h_m^{(i)})^T g(h_m^{(j)})</script><p>然后，我们计算注意力分数 $α_{j,i} $，以表明根据当前任务数据，哪些类似的任务（与当前任务 $t$ 类似）应该被关注:</p><script type="math/tex; mode=display">\alpha_{i,j} = \frac{exp(s_{ij})}{\sum_{i=1}^t exp(s_{ij})}</script><p>注意力得分被应用于 $h_m^{(\le t)}$ 中的每个任务，以获得加权和的注意力输出 $o_j$ :</p><script type="math/tex; mode=display">o_j = v(\sum_{i=1}^t \alpha_{j,i} q(h_m^{(i)}))</script><p>其中 $v(-)$ 和 $q(-)$ 是两个用于转换特征空间的函数：$v(h^{(i)}_m) = W_vh^{(i)}_m $和  $q(h^{(i)}_m) = W_vh^{(i)}_m$。</p><p>最后，我们将注意力层的输出乘以一个比例参数，再加回输入特征 $h^{(≤t)}<em>{cks}$。$h^{(≤t)}</em>{CKS}$的最终输出是所有考虑的任务之和,</p><script type="math/tex; mode=display">h_{CKS}^{(\le t)} = \sum_{i=1}^t (\gamma o_i+h_m^{(i)})</script><p>其中 $\gamma$ 是可学习的标量，并且被初始化为0，这允许模型首先在当前任务上进行学习，然后逐渐学习为其他任务分配更多的权重。</p><h4 id="3-3-2-Knowledge-Sharing-Loss"><a href="#3-3-2-Knowledge-Sharing-Loss" class="headerlink" title="3.3.2 Knowledge Sharing Loss"></a>3.3.2 Knowledge Sharing Loss</h4><p>基于任务的自我关注的输出为我们提供了 知识共享视图 $h^{(≤t)}<em>{CKS}$。 伴随着Adapter-BERT对当前任务 $h^{(t)}</em>{m}$ 的输出，我们可以很容易地在这两种观点之间进行对比性学习。</p><p>请注意，$h^{(≤t)}_{CKS} $ 是计算出来的基于当前的任务数据和它们相应的类标签，所以我们给两个视图有相同的标签，因此我们可以在我们的CKS损失中整合标签信息 :</p><script type="math/tex; mode=display">L_{CKS} = \sum_{n=1}^N - \frac{1}{N_{y_n} -  1} \sum_{j=1}^N 1_{n\le j}\  1_{y_n=y_j} log\frac{exp((h^{(\le t)}_{CKS:n} \cdot h_{m:j}^{(t)}) / \gamma)}{ \sum_{k=1}^N 1_{n\ne k} exp((h^{(\le t)}_{CKS:n}) \cdot  h_{m:k}^{(t)})/ \gamma}</script><p>其中，$N$ 是批次大小，$N<em>{yn} $是批次中具有标签 $y_n$的例子的数量。 $h</em>{CKS}^{(\le t)}$ 是第一个视图， 同时 $h_m^{(t)}$ 是第二个视图。</p><p>他们之间的共享知识代表了以前和当前任务之间的共享知识。 与CED损失不同，CKS损失利用了类别信息，因此可以通过两个样本是否共享相同的类别标签来决定多个正例对。</p><h3 id="3-4-Contrastive-Supervised-Learning-of-the-Current-Task-CSC"><a href="#3-4-Contrastive-Supervised-Learning-of-the-Current-Task-CSC" class="headerlink" title="3.4 Contrastive Supervised Learning of the Current Task (CSC)"></a>3.4 Contrastive Supervised Learning of the Current Task (CSC)</h3><p>我们通过采用监督对比损失法进一步提高了当前任务的性能。通过在当前任务 $h(t)$ 上采用有监督的对比性损失 (Khosla et al., 2020)对当前任务 $h^{(t)}_m$：</p><script type="math/tex; mode=display">L_{CSC} = \sum_{n=1}^{N} - \frac{1}{N_{y_n} -1} \sum_{j=1}^N 1_{n\le j} 1_{y_n = y_j} log \frac{exp((h_{m:n}^{(t)}\cdot h_{m:j}^{(t)})/ \tau)}{ \sum_{k=1}^N 1_{n\ne k} exp((h_{m:n}^{(t)} \cdot h_{m:k}^{(t)})/ \tau)}</script><h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><h3 id="Compared-Baselines"><a href="#Compared-Baselines" class="headerlink" title="Compared Baselines"></a>Compared Baselines</h3><p>我们采用了46个基线，其中包括非持续学习和持续学习方法。由于在DIL方面所做的工作很少，我们通过合并分类头来使最近的TIL系统适应DIL，形成DIL系统。</p><p><strong>Non-Continual Learning Baselines</strong> 这些基线中的每一个都为每个任务独立建立一个单独的模型，我们称之为一个变体。因此，它没有知识转移或CF。有8个ONE变体。四个是使用（1）带有微调的BERT，（2）没有微调的BERT（冷冻）（3）Adapter-BERT（Houlsby等人，2019）和（4）W2V（使用FastText（Grave等人，2018）中的亚马逊评论数据训练的word2vec嵌入）。添加CSC（Contrastive Supervised learning of the Current task）会产生另外4种变体。 我们采用（Xue和Li，2018）中的ASC网络工作，将方面术语和评论句子作为BERT变体的输入。对于W2V变体，我们使用它们的连接。</p><p><strong>Continual Learning (CL) Baselines.</strong>CL设置有5个类别的38个基线。</p><ul><li>第一类是使用 自然的CL（NCL）方法。它只是用一个网络来学习所有的任务，没有处理CF或知识迁移的机制。像ONE一样，我们有8个NCL的变体。</li><li>第二类有11条使用最近的CL方法KAN（Ke等人，2020b）、SRK（Lv等人，2019）、HAT（Serrà等人，2018）、UCL（Ahn等人，2019）、EWC（Kirkpatrick等人，2016）、OWM（Zeng等人，2019）和DER++（Buzzega等人，2020）创建的基线。</li></ul><p>KAN 和 SRK是用于文档情感分类。我们使用方面和句子的串联作为输入。HAT、UCL、EWC、OWM和DER++最初是为图像分类设计的。我们用CNN取代它们原来的图像分类网络，用于文本分类（Kim，2014）。HAT是最好的TIL方法之一，几乎没有遗忘。UCL是一种最新的TIL方法。EWC是一种流行的CIL方法，在（Serrà等人，2018）中被调整为TIL。它们通过合并分类头被转换为DIL版本。</p><p>OWM（Zeng等人，2019）是一种CIL方法，我们也将其改编为EWC这样的DIL方法。DER++和SRK可以在DIL环境下工作。HAT和KAN在测试中需要任务ID作为输入，不能在DIL设置中发挥作用。我们创建了HAT（和KAN）的两个变体：在测试中使用最后一个模型，就像CLASSIC所做的那样，或者使用熵法检测任务ID，在这个类别中使用BERT（冻结）作为基础。第三类有7个基线使用Adapter-BERT。KAN和SRK不能被调整为使用适配器。第四类使用W2V，这又有11条基线。最后一类有一个基线LAMOL（Sun等人，2020），它使用GPT-2模型。</p><p>Evaluation Protocol: 我们遵循（Lange等人，2019）中的标准CL评估方法。我们首先向CLASSIC提出一连串的ASC任务供其学习。一旦一个任务被学会，它的训练数据就被丢弃。在所有任务都学会后，我们使用所有任务的测试数据进行测试，而不给任务的ID。</p><h1 id="Continual-Learning-of-a-Mixed-Sequence-of-Similar-and-Dissimilar-Tasks"><a href="#Continual-Learning-of-a-Mixed-Sequence-of-Similar-and-Dissimilar-Tasks" class="headerlink" title="Continual Learning of a Mixed Sequence of Similar and Dissimilar Tasks"></a>Continual Learning of a Mixed Sequence of Similar and Dissimilar Tasks</h1><p>现有的关于一连串任务的持续学习的研究集中在处理灾难性的遗忘上，在这种情况下，任务被认为是不相似的，并且几乎没有共享的知识。也有一些工作是在任务相似且有共享知识的情况下，将以前学到的知识转移到新的任务中。据我们所知，还没有人提出学习混合的相似和不相似的任务序列的技术，该技术可以处理遗忘问题，也可以向前和向后转移知识。本文提出了这样一种技术来学习同一网络中的两种类型的任务。对于不相似的任务，该算法侧重于处理遗忘问题，而对于相似的任务，该算法侧重于有选择地转移从以前一些相似的任务中学到的知识，以提高新任务的学习。此外，该算法还自动检测一个新任务是否与以前的任何任务相似。使用混合任务序列的实证评估表明了所提出的模型的有效性。</p><h1 id="Continual-Learning-with-Knowledge-Transfer-for-Sentiment-Classification"><a href="#Continual-Learning-with-Knowledge-Transfer-for-Sentiment-Classification" class="headerlink" title="Continual Learning with Knowledge Transfer for Sentiment Classification"></a>Continual Learning with Knowledge Transfer for Sentiment Classification</h1><p>本文研究了情感分类（SC）的持续学习（CL）。在这种情况下，持续学习系统在一个神经网络中逐步学习一连串的情感分类任务，每个任务建立一个分类器，对特定产品类别或领域的评论进行分类。两个自然的问题是。系统能否将过去从以前的任务中学到的知识转移到新的任务中，以帮助它为新的任务学习一个更好的模型？而且，在这个过程中，以前的任务的旧模型是否也能得到改善？本文提出了一种叫做KAN的新技术来实现这些目标。KAN可以通过前向和后向的知识转移，明显地提高新任务和旧任务的SC准确性。通过大量的实验证明了KAN的有效性。</p><p>类持续学习（CCL）。在CCL中，每个任务包括一个或多个要学习的类。到目前为止，只为所有的类建立一个模型。在测试中，一个来自任何类别的测试实例可能会被提交给模型，让它进行分类，而不给它任何训练中使用的任务信息。</p><p>任务持续学习（TCL）。在TCL中，每个任务都是一个单独的分类问题（例如，一个是对不同品种的狗进行分类，另一个是对不同类型的鸟进行分类）。TCL在一个神经网络中建立了一组分类模型（每个任务一个）。在测试中，系统知道每个测试实例属于哪个任务，只使用该任务的模型对测试实例进行分类。</p><p>在本文中，我们在TCL环境中工作，不断地学习一连串的情感分析（SA）任务。通常情况下，一个情感分析公司必须为许多客户工作，每个客户都想研究公众对其产品/服务的一个或多个类别以及其竞争对手的意见。对每一类产品/服务进行情感分析是一项任务。为了保密，客户往往不允许SA公司与其他客户分享数据或将其数据用于其他客户。持续的学习是一个自然的过程。在这种情况下，我们也希望在不违反保密性的情况下，随着时间的推移提高SA的准确性。这就提出了两个关键的挑战。(1)如何将从以前的任务中学到的知识转移到新的任务中，以帮助它在不使用以前任务的数据的情况下更好地学习，(2)如何在没有CF的情况下在这个过程中改进以前任务的旧模型？在[15]中，作者表明CL可以帮助提高文档级情感分类（SC）的准确性，这是SA[13]的一个子问题。在本文中，我们提出了一个明显更好的模型，称为KAN（知识可及性网络）。请注意，这里的每个任务都是一个两类SC问题，即对一个产品的评论是正面还是负面进行分类。</p><p>在遗忘方面已经做了相当多的工作。然而，现有的技术主要集中在处理灾难性遗忘（CF）方面[4,18]。在学习一个新的任务时，他们通常试图使权重朝着对以前的任务伤害较小的方向更新，或者防止以前的任务的重要权重被显著改变。我们将在下一节详细介绍这些和其他相关的工作。只处理CF对SC来说是远远不够的。在大多数现有的关于CL的研究中，任务是相当不同的，而且几乎没有共享的知识。因此，专注于处理CF是有意义的。然而，对于SC来说，任务是相似的，因为用于表达不同产品/任务的情感的词和短语是相似的。正如我们在第4.4节中所看到的，由于任务间的共享知识，CF在SC的CL中不是一个主要问题。因此，我们的主要目标是利用任务间的共享知识，使其表现明显优于单独学习单个任务。</p><p>为了实现利用任务间的共享知识来提高SC的准确性的目标，KAN使用了两个子网络，主要的持续学习（MCL）网络和可及性（AC）网络。MCL的核心是一个知识库（KB），它存储了从所有训练过的任务中学到的知识。在学习每个新任务时，AC网络决定过去的知识中哪一部分对新任务有用，并可以共享。这就实现了向前的知识转移。同样重要的是，在新任务训练期间，共享的知识利用其数据得到加强，这导致了后向知识转移。因此，KAN不仅提高了新任务的模型精度，而且还提高了以前任务的精度，而无需任何额外的操作。大量的实验表明，KAN明显优于最先进的基线。</p><h2 id="Proposed-Model-KAN"><a href="#Proposed-Model-KAN" class="headerlink" title="Proposed Model KAN"></a>Proposed Model KAN</h2><p><img src="https://s2.loli.net/2021/12/23/uVSoghHPCYUfrqa.png" alt=""></p><p>为了提高分类的准确性，同时也为了避免遗忘，我们需要确定一些过去的知识，这些知识在学习新的任务时是可以共享和更新的，这样就不会发生遗忘过去知识的情况，新的任务和过去的任务都可以得到改善。<br>我们通过从我们人类似乎做的事情中获取灵感来解决这个问题。例如，我们可能会 “忘记 “10年前的电话号码，但如果同样的号码或类似的号码再次出现，我们的大脑可能会迅速检索出旧的电话号码，并使新旧号码都得到更牢固的记忆。生物学研究[10]表明，我们的大脑会对知识的可及性进行追踪。如果我们以前知识的某些部分对新任务有用（即新任务和以前一些任务之间的共享知识），我们的大脑就会将这些部分设置为可访问，以实现知识的前向转移。这也使后向知识转移成为可能，因为它们现在可以被访问，我们有机会根据新的任务数据来加强它们。对于那些以前的知识中没有用的部分，它们被设置为不可访问，这样可以保护它们不被改变。受到这个想法的启发，我们设计了一个记忆和可访问性机制。<br>我们需要解决两个关键问题。(1）如何检测内存（我们称之为知识库（KB））中的知识的可访问性，即识别以前的知识中对新任务有用的部分；（2）如何利用识别的有用/共享的知识来帮助新任务的学习，同时也保护其他部分。为了应对这些挑战，我们提出了图1所示的知识和可及性网络（KAN）。</p><p>KAN有两个组件（见图1），紫色框中的主要持续学习（MCL）组件和黄色框中的可及性（AC）组件。MCL执行主要的持续学习和测试（AC在测试中不使用，除了从任务id t生成的掩码）。我们看到每个任务的情感分类头（正/负）在顶部。下面是密集层，再往下是绿色虚线框内的知识库（KB）（记忆）。知识库使用RNN（我们在系统中使用GRU）建模，被称为KB-RNN，包含特定任务和跨任务的共享知识。AC通过设置一个基于任务的二进制掩码来决定KB中的哪部分知识（或单元）可以被当前任务t访问。每个任务由AC-EMB从任务ID（t）中产生的任务嵌入来表示。AC-EMB是一个随机初始化的嵌入层。KAN的输入是任务id t和文档d。它们通过掩码a和{hKB}用于训练两个组件。(KB-RNN中的隐藏状态)链接来训练两个组件。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Achieving-Forgetting-Prevention-and-Knowledge-Transfer-in-Continual-Learning&quot;&gt;&lt;a href=&quot;#Achieving-Forgetting-Prevention-and-Knowledg</summary>
      
    
    
    
    
    <category term="context detection" scheme="http://example.com/tags/context-detection/"/>
    
  </entry>
  
  <entry>
    <title>On Transferability of Prompt Tuning for Natural Language Understanding</title>
    <link href="http://example.com/2021/12/21/On-Transferability-of-Prompt-Tuning-for-Natural-Language-Understanding/"/>
    <id>http://example.com/2021/12/21/On-Transferability-of-Prompt-Tuning-for-Natural-Language-Understanding/</id>
    <published>2021-12-21T07:44:25.000Z</published>
    <updated>2021-12-30T15:17:52.830Z</updated>
    
    <content type="html"><![CDATA[<h1 id="On-Transferability-of-Prompt-Tuning-for-Natural-Language-Understanding"><a href="#On-Transferability-of-Prompt-Tuning-for-Natural-Language-Understanding" class="headerlink" title="On Transferability of Prompt Tuning for Natural Language Understanding"></a>On Transferability of Prompt Tuning for Natural Language Understanding</h1><p>Prompt tuning（PT）是一种很有前途的参数高效方法，可以利用极其庞大的预训练语言模型（PLM），只需 tuning 几个软提示，就可以达到与全参数微调相当的性能。</p><p>然而，与微调相比，经验上PT需要更多的训练步骤。为了探索是否可以通过重复使用训练好的 soft prompts 和分享学到的知识来提高 PT 的效率，我们从经验上研究了 soft prompts 在不同任务和模型中的可迁移性。</p><ul><li>在跨任务迁移中，发现经过训练的  soft prompts  可以很好地迁移到类似的任务中，并为它们初始化PT，以加速训练和提高性能。此外，为了探索哪些因素会影响 prompts 的跨任务转移性，我们研究了如何测量 prompt 的相似性，发现<strong>激活的神经元的重叠率与迁移性高度</strong>相关。</li><li>在跨模型迁移中，我们探索了如何将一个PLM的 prompt 投射到另一个PLM上，并成功地训练了一种 projector，该projector 可以在类似的任务上实现非微不足道的迁移性能。然而，用投影的 prompt 初始化PT的效果并不好，这可能是由<strong>优化偏好</strong>和<strong>PLM的高冗余</strong>度造成的。</li></ul><p>我们的研究结果表明，用知识转移来改善PT是可能的，也是有希望的，而提示的跨任务迁移性一般比跨模型转移性好。</p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>预训练的语言模型（PLM），如BERT（Devlin等人，2019）和GPT（Radford等人，2018）在各种自然语言处理任务上取得了很好的性能（Han等人，2021）。最近，在GPT-3（Brown等人，2020）取得成功后，人们发现极大型的PLM可以取得显著的自然语言理解（NLU）性能，各种大型PLM不断被开发出来（Raffel等人，2020；Zhang等人，2021；Zeng等人，2021；Wei等人，2021；Sun等人，2021），它们包含的参数多达数千亿。</p><p>考虑到这些最先进的PLMs的极大规模，传统的全参数微调方法使PLMs适应下游任务，在计算上变得难以承受。因此，各种参数高效的调谐方法（Houlsby等人，2019；Ben Zaken等人，2021；Lester等人，2021；Li和Liang，2021；Liu等人，2021）得到了探索，其中prompt-tuning（PT）引起了广泛的研究关注。</p><p>PT将一些 soft-prompt（本质上是可学习的虚拟 token）预置到输入序列中，并通过反向传播训练它们，同时保持所有PLM参数的固定。训练的目的是输出表示相应标签的 token，即标签 token。PT仅用数千个可调整的参数就可以实现卓越的NLU性能。</p><p>此外，Lester等人（2021）表明，当PLM的规模增长时，PT变得更加有效，当PLM有数十亿个参数时，最终可以达到与全参数微调相当的性能。</p><p>尽管PT是利用极其庞大的PLM的有效方法，但它需要比微调多得多的训练步骤来达到收敛（参考3.1节），<strong>因此值得探讨如何提高PT的效率。直观地说，由于 soft prompt 是PT中唯一可学习的参数，代表了以PLM为条件解决任务的特定知识</strong>，一个任务的训练提示可能对其他需要类似知识的任务有帮助。此外，由于不同的PLM都从预训练中学习了一般的语言理解能力，以不同的PLM为条件的训练过的 prompts 可能在PLM之间迁移。</p><p><img src="https://s2.loli.net/2021/12/21/QYkwWa7o4FR1CI3.png" alt=""></p><p>因此，通过训练有素的 soft prompts 将学到的知识迁移到其他任务和PLM上可能是一种有希望的方式，以加速新任务和PLM的PT。为了了解基本特征并帮助开发PT的迁移学习方法，我们在本文中实证分析了PT在不同任务和模型中的可迁移性，如图1所示。</p><p>在跨任务迁移中，我们研究在同一PLM上训练的 soft-prompt 是否能在不同的NLU任务中转移。</p><ul><li>(1) 我们研究了 soft prompt 在13个NLU任务上的 zero-shot 迁移性能，这些任务根据所需的语言理解能力被分为四种类型。我们发现，经过训练的 soft prompt 可以直接迁移到同一类型的类似任务中，并取得非同寻常的表现，但迁移到需要不同的NLU能力的不同类型的任务中却很差。</li><li>(2) 基于这些结果，我们提出了跨任务的可转移prompt tuning（$TPT<em>{TASK}$），即用类似任务的训练好的 soft prompt作为初始化来启动PT。实验表明，与普通的PT相比，$TPT</em>{TASK}$可以大大加快训练速度，而且还能实现一定的性能提升。</li><li>(3) 我们进一步探讨为什么 prompts 可以跨任务转移，是什么控制了它们的迁移性。为此，我们研究了各种 prompt 相似性指标与prompt 可迁移性的相关性，发现其在PLM前馈层中激活的神经元的重叠率可以更好地反映 prompts 可转移性。</li></ul><p>这表明提示<strong>实质上是在刺激PLM的内在能力在参数（神经元）之间分配，以完成特定的NLU任务，prompts 之间的可迁移性取决于它们在模型刺激方面的相似性，而不是嵌入的相似性</strong>，这可能启发未来PT转移方法的设计。</p><p>在跨模型转移中，我们在两种情况下研究软提示在不同PLM中的可转移性。</p><ul><li>(1) 在相同规模的异质PLM之间转移（例如BERTBASE到RoBERTaBASE）</li><li>(2) 从较小的PLM迁移到较大的同质模型（例如RoBERTaBASE到RoBERTaLARGE）。</li></ul><p>我们发现，直接在目标PLM上重复使用 prompts 是无益的，这一点在实验中得到了证明，或者是不可行的，这是因为不同尺寸的PLM的嵌入尺寸不一致。</p><ul><li>(1）因此，我们开发了各种 prompt projectors，将在一个PLM上训练的 soft prompt 投射到其他PLM的语义空间中，并发现通过在一些任务上用PT训练 projectors，训练后的 projectors 可以成功地投射出类似任务的软提示，并取得非同寻常的性能。</li><li>(2) 与 $TPT<em>{TASK}$ 类似，我们提出了跨模型的可迁移 prompt tuning（$TPT</em>{MODEL}$），即用目标PLM上同一任务的预测 prompt 开始PT。然而，实验表明，$TPT<em>{MODEL}$的效果并不如 $TPT</em>{TASK}$那么好。</li><li>(3) 我们观察到，投射过的 prompts 的激活神经元与最初在目标PLM上训练的 prompt 不相似。考虑到PLM的高冗余度（Aghajanyan等人，2021），这可能表明预测的 prompt 是在目标PLM上完成任务调节的不同解决方案，而PT并不喜欢这些解决方案，并且很难用它们来持续优化。</li></ul><p>总的来说，我们的发现和分析表明，通过知识迁移提高PT的效率是可能的，也是有希望的，在不同的PLM之间迁移提示比在同一PLM的不同任务之间转移更具挑战性。我们希望这些发现能够促进对可迁移和高效的PT的进一步研究。</p><h2 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h2><h3 id="Prompt-Tuning"><a href="#Prompt-Tuning" class="headerlink" title="Prompt Tuning"></a>Prompt Tuning</h3><p>在海量数据上预训练PLM（Radford等人，2018；Devlin等人，2018；Yang等人，2019；Liu等人，2019b；Raffel等人，2020），然后将其调整为下游任务，这已经成为NLP的典型范式。传统上，适应是通过面向任务的微调完成的，它通过特定任务的监督优化PLM的所有参数。</p><p>然而，随着PLM参数的持续增长，全参数微调对于典型的范式和模型存储都变得难以承受。为了弥补这一缺陷，人们提出了许多参数高效的调谐方法（Ben Zaken等人，2021；Houlsby等人，2019；Li和Liang，2021；Qin和Eisner，2021；Lester等人，2021），这些方法只调整几个参数，而保持大部分PLM参数的冻结。</p><p>在这些具有参数效率的微调变体中，prompt tuning 得到了广泛的关注，这是由GPT-3激发的。 它通过在输入文本之前给每个任务预留一个文本提示，并让PLM直接生成答案，从而展示了显著的 few-shot 性能。</p><p>最近，出现了许多基于 prompt 的工作，即人工设计的（Schick和Schütze，2021a，b；Mishra等人，2021）或自动搜索的（Jiang等人，2020；Shin等人，2020；Gao等人，2021）硬提示，它们是离散的 token，但不一定是人类可读的。此外，软提示（Li and Liang, 2021; Hambardzumyan et al., 2021; Zhong et al., 2021; Liu et al., 2021）出现了，它们是可调整的嵌入而不是词汇表中的 token，可以直接用特定任务的监督来训练。</p><p>而Lester等人（2021）证明，当PLM尺寸极大时，这种 PT 方法可以与全参数微调的性能相匹配。这表明 PT 在利用极大的PLM方面很有前景。然而，达到收敛所需的更多训练步骤（第3.1节）使PT效率低下。在这项工作中，我们表明 prompt迁移可以弥补这一点，也在一定程度上提高了知识转移的有效性，并实证分析了PT在不同任务和模型中的转移性。</p><h3 id="Transferring-for-PLM"><a href="#Transferring-for-PLM" class="headerlink" title="Transferring for PLM"></a>Transferring for PLM</h3><p>跨任务转移，或一般的多任务学习（Ruder，2017）一直是提高NLP系统的有效性和效率的一种长期方式。在PLM时代，一些作品提出在中间任务上调整PLM（Phang等人，2019；Pruksachatkun等人，2020；Gururangan等人，2020；Wang等人，2019a；Vu等人，2020；Poth等人，2021），然后再对具体的目标任务进行微调，并取得一定成效。特别是，Vu等人（2020）在这种情况下实证分析了跨任务的可迁移性。然而，这些探索都是针对微调的。Prompt Tuning（PT）是利用大型PLM的一种有前途的方式，我们认为PT的可转移性和转移方法值得探索。</p><p>作为先前的尝试，Lester等人（2021）证明了PT对同一任务的跨域迁移能力强于微调。与我们的工作类似，同时进行的工作（Vu等人，2021）证明了PT的跨任务转移能力，也提出了用提示初始化来进行跨任务迁移。不同的是，我们通过模型刺激的视角进一步分析了 prompt，并通过跨任务迁移提高了PT的效率。此外，我们还尝试了 prompt 的跨模型迁移，这受到了以往跨模型知识迁移工作的启发，如Net2Net（Chen等人，2016）、知识蒸馏（Hinton等人，2015）和知识继承（Qin等人，2021a）。</p><h2 id="Preliminary"><a href="#Preliminary" class="headerlink" title="Preliminary"></a>Preliminary</h2><p>在这一节中，我们介绍了关于 prompt tuning（PT）的基本知识（§3.1）以及实验中调查的下游任务（§3.2）和模型（§3.3）。</p><h3 id="Prompt-Tuning-1"><a href="#Prompt-Tuning-1" class="headerlink" title="Prompt Tuning"></a>Prompt Tuning</h3><p>在这项工作中，我们研究了能够调整大型PLM的PT方法（Li and Liang, 2021; Lester et al, 2021; Liu et al, 2021），同时冻结PLM参数。考虑到我们专注于NLU的能力，我们没有探索在生成任务上工作的前缀调谐（Li and Liang, 2021）。</p><p>PT直接在PLM的输入中预置一些虚拟 token，即 soft prompt，以提供关于下游任务的知识。soft prompt本质上是可调整的嵌入向量，其训练的目的是强制 PLM 解码表示输入的相应标签的 token，而PLM的模型参数则保持冻结。对应于标签的 token  被称为标签 token。</p><p>从形式上讲，给定一个输入序列 $X={x_1,x_2,…,x_n}$，其中 $x_i$ 是 token，我们首先在它们前面预置 $l$ 个随机初始化的软提示 $P={P_1,P_2,…,P_l}$，其中 $P_i\in R_d$是一个嵌入向量，$d$ 是PLM的输入维度。在它们之前，我们先加一个[MASK] token，用来预测标签token $y$。训练目标是使解码 $y$ 的可能性最大化。</p><script type="math/tex; mode=display">L = p(y|[MASK], P, x_1,...,x_n)</script><p>而只有P是可学习的。因此，PT中的调整参数比全参数微调要少得多，这对调谐大型PLM很友好。</p><p>当使用的PLM非常大时，PT可以达到与微调相当的性能，但当PLM不那么大时，明显的性能差距仍然存在，而且PT也比微调需要更多的内存。</p><p>此外，我们根据经验发现，PT的收敛速度明显慢于微调，如图2所示。因此，我们认为PT的效率需要进一步提高，而知识迁移的直观性可能有所帮助。</p><h3 id="Investigated-NLU-Tasks"><a href="#Investigated-NLU-Tasks" class="headerlink" title="Investigated NLU Tasks"></a>Investigated NLU Tasks</h3><p>为了全面研究 soft-prompt 在各种NLU任务中的可迁移性，我们涉及了13个不同的任务，这些任务可以分为4种类型。</p><p>(1）情绪分析（SA），包括IMDB（Maas等人，2011）、SST-2（Socher等人，2013）、笔记本电脑（Pontiki等人，2014）、餐厅（Pontiki等人，2014）、电影理由（Movie）（Zaidan等人，2008）和TweetEval（Tweet）（Bar- bieri等人，2020）；（2）自然语言推理（NLI），包括MNLI（Williams等人，2018 )、QNLI（Wang等人，2019b）和SNLI（Bow- man等人，2015）；（3）伦理判断（EJ），包括deontology（Hendrycks等人，2021）和justice（Hendrycks等人，2021）；（4）转述识别（PI），包括QQP（Sharma等人，2019）和MRPC（Dolan and Brockett，2005）。任务的细节、使用的标签令牌和实施方法分别留在附录A.1、附录A.3和附录A.2中。</p><h3 id="Investigated-Models"><a href="#Investigated-Models" class="headerlink" title="Investigated Models"></a>Investigated Models</h3><p>为了研究跨模型的可转移性，我们调查了两种PLM。BERT（Devlin等人，2019）和RoBERTa（Liu等人，2019b），它们被广泛用于NLU任务。具体来说，我们在实验中使用RoBERTaBASE、RoBERTaLARGE和BERTBASE检查点。RoBERTaBASE和BERTBASE模型由12个Transformer（Vaswani等人，2017）编码器层组成，它们的嵌入尺寸都是768，而RoBERTaLARGE是24个Transformer层和1024个嵌入尺寸。</p><h2 id="Cross-Task-Transfer"><a href="#Cross-Task-Transfer" class="headerlink" title="Cross-Task Transfer"></a>Cross-Task Transfer</h2><p>在这一节中，我们实证研究了 soft-prompt 的跨任务迁移性（第4.1节），并试图通过利用迁移性来提高 prompt tuning的有效性和效率（第4.2节），然后我们通过分析各种 prompts 的相似性指标来探索为什么 prompts可以迁移，是什么控制了prompts之间的转移性（第4.3节）。本节的所有实验都是在RoBERTaBASE上进行的。</p><p><img src="https://s2.loli.net/2021/12/21/UoFWAp8aQ9bnKPd.png" alt=""></p><h3 id="Zero-shot-Transferability"><a href="#Zero-shot-Transferability" class="headerlink" title="Zero-shot Transferability"></a>Zero-shot Transferability</h3><p> 结果如图3所示，从图中我们可以看出。</p><ul><li>(1) 对于同一类型的任务，在它们之间迁移soft prompt一般可以表现良好，甚至可能在target数据集上超过vanilla PT，特别是当源任务的数据集比目标任务大的时候（从IMDB转到Movie的例子），这表明用类似任务的知识转移来提高PT的效果和效率是有希望的。</li><li>(2）对于不同类型的任务，soft prompt 在它们之间的可迁移性普遍较差，迁移的 soft prompt 在很多情况下只能达到与给定的随机初始化 prompt 相似的性能。可转移性差的原因可能是不同类型的任务通常使用不同的标签，例如，entailment和convadict是用于NLI任务，而positive和negative是用于SA任务。为了排除这个因素，我们将不同任务的标签标记统一为同一组数字$(1，2，…)$，结果如图3（b）所示，从中我们可以看出，不同类型任务之间的可转移性一般不会通过这种方式得到改善。这表明，不同类型的任务肯定需要不同的能力，这就禁止在它们之间重复使用prompts。</li><li>(3) 一些任务之间的可迁移性是直观的，例如IMDB表现最好的源任务是Movie。然而，有些则是反直觉的，比如laptop的最佳来源任务是Tweet。为了理解这一点，值得探讨是什么控制了prompts之间的迁移性，我们将在第4.3节做一些初步研究。</li></ul><h3 id="Transfer-with-Initialization"><a href="#Transfer-with-Initialization" class="headerlink" title="Transfer with Initialization"></a>Transfer with Initialization</h3><p>为了研究如何通过跨任务迁移来提高PT的有效性和效率，我们在本节中探讨了跨任务迁移的 prompt tuning（$TPT<em>{TASK}$）。$TPT</em>{TASK}$在开始 prompt tuning 之前，用训练有素的类似任务的 soft prompt 来初始化 soft prompt，并观察它是否能加速训练和提高最终的表现。</p><p>对于13个被调查的任务，我们用训练好的其他任务的 soft prompt 来启动 $TPT<em>{TASK}$，可以达到图3（a）中的最佳性能。性能和训练时间的比较见表1。从结果中，我们可以看到 $TPT</em>{TASK}$在大多数情况下可以达到比 vanilla PT更好或相当的性能，从随机初始化开始，它需要较少的训练步骤来达到相当的性能和收敛性。关于训练曲线的详细比较，请参考附录B。</p><p><img src="https://s2.loli.net/2021/12/21/k29VadtAsJclmvN.png" alt=""></p><h3 id="Exploring-Transferability-Indicator"><a href="#Exploring-Transferability-Indicator" class="headerlink" title="Exploring Transferability Indicator"></a>Exploring Transferability Indicator</h3><p>此外，我们还探讨了为什么 soft prompt 可以跨任务迁移，是什么控制了它们之间的可迁移性，这可能有助于揭示PT成功背后的机制，有助于设计可迁移的PT方法。为此，我们探索了各种 prompts 的相似性指标，并考察了它们与 zero-shot 迁移性能的吻合程度。</p><p>如果所设计的相似性度量标准能够很好地表明可迁移性，我们可以说在设计这个度量标准时考虑的因素大多控制了 prompts 之间的可迁移性。此外，提示的相似性指标可以用训练好的 soft prompt 作为任务嵌入来限定任务的相似性，并可能有助于设计跨任务的迁移方法。作为一个直接的例子，如果我们建立了一个包含不同任务的训练 prompt 的 prompt仓库，我们可以为一个新的任务检索具有一定相似性度量的相似任务的 prompt，并通过 $TPT_{TASK}$在新任务上更好地改进PT。在这项工作中，我们探讨了以下两种度量。</p><h4 id="Embedding-Similarity"><a href="#Embedding-Similarity" class="headerlink" title="Embedding Similarity"></a>Embedding Similarity</h4><p>在第一类被调查的相似性度量中，我们把训练好的 soft prompt 看作是向量空间中的嵌入，用两个常规度量来计算它们的相似性。欧氏相似度和余弦相似度。</p><p>给出两组包含 $l$ 个虚拟 token 的训练有素的 prompts: $P^{t_1} = {P_1^{t_1},…, P_l^{t_1}}$ 和 $P^{t_2} = {P_1^{t_2},.., P_l^{t_2}}$ 对应的任务为 $t_1,t_2$。 首先，我们串联 $l$ prompt token嵌入并得到 $l×d$ 维嵌入 $\hat P^{t_1}$， $ \hat P^{t_2}$，然后我们为它们计算欧氏相似度和余弦相似度:</p><script type="math/tex; mode=display">E_{concat} (P^{t_1}, P^{t_2}) = \frac{1}{ 1+ ||\hat P^{t_1} - \hat P^{t_2}||}</script><script type="math/tex; mode=display">C_{concat} (P^{t_1}, P^{t_2}) = \frac{\hat P^{t_1}\cdot \hat P^{t_2}}{||\hat P^{t_1}||||\hat P^{t_2}||}</script><p>考虑到由于我们在 PT 期间没有将Transformer（Vaswani等人，2017）中的位置嵌入添加到 prompt 中，所以提示是位置不变的，我们进一步介绍了一种简单的方法，使度量标准对 token 位置不变。</p><p>直截了当地，我们为两组中的每个 prompt 对计算欧氏距离和余弦相似度，并使用平均结果作为两个 soft prompt 的最终相似度指标。</p><script type="math/tex; mode=display">E_{average}(P^{t_1}, P^{t_2}) = \frac{1}{ 1+ \frac{1}{l^2}\sum_{i=1}^l \sum_{j=1}^l ||P^{t_1}_i - P^{t_2}_j||}</script><script type="math/tex; mode=display">C_{average} (P^{t_1},P^{t_2}) = \sum_{i=1}^l\sum_{j=1}^l \frac{P^{t_1}_i \cdot P^{t_2}_j}{||P_i^{t_1}||||P_j^{t_2}||}</script><h4 id="Model-Stimulation-Similarity"><a href="#Model-Stimulation-Similarity" class="headerlink" title="Model Stimulation Similarity"></a>Model Stimulation Similarity</h4><p>在第二种方式中，我们不只将 soft prompt 视为嵌入向量，而是根据它们如何刺激 PLM 来描述它们的相似性，也就是说，我们研究PLM对两个训练过的 soft prompt 的反应的相似性。受Mor等人（2021）和Dai等人（2021）的启发，他们都发现Transformer模型的前馈层中间的神经元的激活与特定的模型行为相对应，我们建议使用激活的神经元的重叠率作为软提示的相似性指标。</p><p>具体来说，Transformer（Vaswani等人，2017）层中的前馈网络FFN（-）如下：</p><script type="math/tex; mode=display">FFN(x) = max(0, xW_1^T + b_1) W_2 + b_2</script><p>其中 $x \in R^d$ 是输入embedding， $W_1,W_2\in R^{d_m\times d }$是可训练的矩阵，并且 $b_1,b_2$ 是bias 向量。 $max(xW_1^T +b_1,0)$ 可以被视为 $d_m$ 隐含神经元的非负激活值。然后我们把 $max(xW_1^T + b_1, 0)$的所有正元素改为1，得到 one-hot 激活状态向量$s$ 。</p><p>我们输入一个输入序列 ${[MASK], p_1,…,P_l, <s>}$ 到PLM，其中$<s>$ 是特殊token表示句子的开头。这种格式本质上是PT输入的格式，但没有具体的输入语句。对于PLM的每个Transformer层，我们使用[MASK]位置的激活状态 $s$，因为 $[MASK]$ 是用来预测标签 token 的，因此更具有任务针对性。然后，我们将PLM中所有层的激活状态连接起来，得到整个PLM激活状态：</p><script type="math/tex; mode=display">AS(P) = [s_1;s_2;...,;s_L]</script><p>在相似性计算中，我们也只能检索到一部分层的激活状态。我们用余弦相似度来计算任务 $t_1$ 和 $t_2$ 的训练软提示之间的激活神经元 $ON(P^{t_1} , P^{t_2})$的重叠率：</p><script type="math/tex; mode=display">ON(P^{t_1},P^{t_2}) = \frac{AS(P^{t_1}) \cdot AS(P^{t_2})}{||AS(P^{t_1})|| ||AS(P^{t_2})||}</script><h3 id="Experimental-Results"><a href="#Experimental-Results" class="headerlink" title="Experimental Results"></a>Experimental Results</h3><p>为了评估上述 soft prompt 的相似性指标的有效性，</p><ul><li><p>（1）测试相似性指标是否能区分相同任务和不同任务的训练prompt </p></li><li><p>（2）检查这些指标是否与 soft prompt 的 zero-shot 迁移性能一致。</p></li></ul><p>我们在表2中比较了同一任务内（用不同的随机种子训练的）和不同任务之间两个训练好的 prompt 的相似度值。从结果中，我们可以观察到。</p><p><img src="https://s2.loli.net/2021/12/21/TBX3ghk7ExawsYK.png" alt=""></p><ul><li>(1) 所有的指标都能很好地区分同一任务和不同任务的 prompt 。从嵌入相似性的角度来看，这表明不同任务的训练有素的 soft prompt 形成了可以区分的集群。从模型刺激相似性的角度来看，这表明不同的任务确实需要 soft prompt 来刺激PLM中的不同能力。</li><li>(2)对于激活的神经元的过度覆盖率，任务的差异往往在顶层更大。这与探测结果（Liu et al., 2019a）一致，显示顶层往往更具有任务特异性。激活神经元的重叠率的细节留在附录C中。</li></ul><p>此外，我们还评估了 prompt 的相似性指标是否与图3中的 zero-shot 转移性能一致。具体来说，(a)，我们计算每个目标任务的各种源任务 prompt 的相似性和 zero-shot 迁移性能之间的Spearman’s rank correlation（Spearman, 1987）。结果见表3，从中我们观察到</p><p><img src="https://s2.loli.net/2021/12/21/V6pNjQorDw9LKCe.png" alt=""></p><p> (1) 激活神经元的重叠率(ON)指标一般比所有的嵌入相似性效果好，这表明模型刺激在 prompt 迁移性方面比嵌入距离占据了更重要的位置。我们鼓励未来的工作探索如何更好地模拟提示的刺激。</p><p>(2) 在所有的嵌入相似性度量中，基于欧氏距离的两个度量效果不佳，甚至在某些任务上有负相关。基于余弦相似度的度量工作得更好，$C<em>{average}$度量可以达到与使用底层的ON度量相当的性能。然而，$C</em>{average}$区分不同任务的能力（表2）显然更差。这些结果表明，提示嵌入空间的属性是很棘手的，很难在此基础上设计可迁移的PT方法。</p><p> (3)使用较高模型层的ON的结果一般比使用较低层的好，这再次证实了最高层的模型更具有任务针对性。然而，也有一些反例，如 justice 和QQP，这可能来自于这些任务中需要一些特定的语言能力，需要仔细研究。</p><h2 id="Cross-Model-Transfer"><a href="#Cross-Model-Transfer" class="headerlink" title="Cross-Model Transfer"></a>Cross-Model Transfer</h2><p>在本节中，我们研究了软提示的跨模型转移能力。在实验中，我们研究了两种实际情况：从一个PLM转移到一个异质的同尺寸PLM（BERTBASE到RoBERTaBASE）和从一个较小的PLM转移到一个同质的较大的PLM（RoBERTaBASE到RoBERTaLARGE）。在不同大小的模型之间直接重用训练好的软提示是不可行的，因为嵌入维度不一致，在异质同大小的PLM之间重用的性能很差（见表4的直接重用行），这很直观，因为嵌入空间是不同的。因此，我们研究如何将在一个模型上训练的软提示投射到其他模型的空间（§5.1），并看到转移的性能（§5.2）。此外，与第4.2节类似，我们研究是否可以通过跨模型转移初始化来进一步提高效果和效率（第5.3节）。</p><h3 id="Projecting-Prompts-to-Different-Models"><a href="#Projecting-Prompts-to-Different-Models" class="headerlink" title="Projecting Prompts to Different Models"></a>Projecting Prompts to Different Models</h3><p>在本节中，我们探讨了如何将一个模型的训练好的 soft prompt 投射到另一个模型的语义空间。为此，我们用各种监督方式训练 projectpr，并检验不同 projector 训练方法的有效性。</p><p>训练跨模型 projector 的好方法可能需要一些特定的任务监督，例如两个模型的平行 soft prompt 或某些任务的监督数据，但训练后的 projector 应能泛化到不同的任务，从而提高目标模型上PT新任务的学习效率。</p><p>从形式上讲，projector $Proj(-)$ 是将源模型中训练好的 soft prompt $P^s \in R^{l×d_s} $ 投影到目标模型语义空间中的相应 prompts $\hat P^s \in R^{l×d_t}$，其中 $d_s$ 和 $d_t$ 分别是源模型和目标模型的输入嵌入维度。在这项工作中，projector 的参数化是用两层感知器，具体如下:</p><script type="math/tex; mode=display">\hat P^s = Proj(P^s) = LayerNorm(W_2(tanh(W_1P^s + b_1)) + b_2)</script><p>其中W1、W2是可训练的矩阵，b1、b2是可训练的偏置项，tanh是非线性激活函数，LayerNorm是层归一化。</p><p>我们研究了三种类型的学习目标来训练交叉模型投影仪:</p><ul><li><p>Prompt Mapping : 我们首先尝试通过学习在不同PLM上训练的同一任务的平行 soft prompt 之间的映射来学习跨模型预测。给出同一任务的两组提示 $P^s、P^t$，它们分别在源模型和目标模型上训练。投影仪将投影 $P^s$，训练目标是最小化L2准则:</p><script type="math/tex; mode=display">L_p = ||Proj(P^s) - P^t||_2</script></li><li><p>Token Mapping : 由于提示是预置在输入 token 上的虚拟 token，我们探讨两个不同PLM的输入 token 嵌入之间的映射是否也能适用于提示嵌入。给定一个 token x和它相应的token 嵌入 $x^s$ , $x^t$，它们分别属于源PLM和目标PLM。我们训练投影仪以最小化L2准则:</p><script type="math/tex; mode=display">L_t = ||Proj(x^s) - x^t||_2</script><p>并将词汇表中的所有输入 token 作为训练样本。</p></li><li><p>Task Tuning : 考虑到第4.3节中的发现，即 soft prompt 的可迁移性更多地与它们如何刺激PLM有关，而不是它们的嵌入距离，我们尝试用相应的任务直接调整目标PLM上的投影 prompt，并以这种方式训练投影仪，它应从任务调整中学习如何刺激目标PLM。然后，我们看看经过训练的投影仪是否可以推广到其他未见过的任务。</p></li></ul><p>Prompt Mapping 和 Task Tuning  方法依靠一些任务（平行训练的 soft prompts  或训练数据）来训练投影仪。在实验中，我们分别选择了两个有代表性的SA任务（IMDB和笔记本电脑）和一个NLI任务（MNLI），供投影仪学习。Token Mapping需要源PLM和目标PLM的词汇表是一致的，因此我们只在RoBERTaBASE到RoBERTaLARGE的设置中尝试。</p><h3 id="Transfer-Performance"><a href="#Transfer-Performance" class="headerlink" title="Transfer Performance"></a>Transfer Performance</h3><p><img src="https://s2.loli.net/2021/12/21/khYgN9EDZpWB2lF.png" alt=""></p><p>在从BERTBASE到RoBERTaBASE和从RoBERTaBASE到RoBERTaLARGE的设置上，各种投影仪-学习方法的转移性能分别见表4和表5。我们可以观察到。</p><ul><li>(1）虽然BERTBASE和RoBERTaBASE的输入嵌入维度一致，但它们之间直接重用训练好的 soft prompt 的性能与使用随机生成的 prompt 相似，这证实了不同模型的 prompt 语义空间差距巨大。</li><li>(2) Token Mapping方法的性能也接近于随机基线，这表明虽然 soft prompt 与输入的 token 一起被送入PLM，但它们并不在同一个embedding空间。</li><li>(3) Prompt Mapping在 迁移 投影仪训练中涉及的提示时效果很好，但在未见过的任务上又回到了随机性能，这是不现实的。这与我们在第4.3节中的发现一致，即嵌入的相似性/差异不能很好地反映任务之间的可迁移性。</li><li>(4) Task Tuning 的效果最好，并且成功地将训练任务推广到同类型的未见过的任务中（例如，用MNLI训练的投影仪的NLI任务），这表明为PT设计实用的跨模型迁移方法的可行性。与Prompt Mapping的失败相比，这证实了从模型刺激的角度来分析和操作提示语是更有效的。然而，用任务调谐法训练的投影仪仍然不能用于不同类型的任务，这就要求采用更先进的转移方法。</li></ul><h3 id="Transfer-with-Initialization-1"><a href="#Transfer-with-Initialization-1" class="headerlink" title="Transfer with Initialization"></a>Transfer with Initialization</h3><p>与第4.2节类似，我们进一步研究投射的 soft-prompt 是否能在目标模型上初始化PT，并加速训练以及提高性能。基于第5.2节的结果，我们提出了跨模型迁移 prompt tuning，即 $TPT_{MODEL}$，它采用 Task tuning投射器，将在源PLM上训练的soft prompt 投射到目标PLM上，并用投射的 prompt 初始化PT。</p><p>在从BERTBASE转移到RoBERTaBASE的设置中，性能和训练时间的比较见表6</p><p><img src="https://s2.loli.net/2021/12/21/bJfqPcs5GiVjh8g.png" alt=""></p><p>我们可以注意到。(1)对于同一类型的投影仪训练任务，TPTMODEL大多能以较少的训练步骤获得相当或稍好的性能，这表明实用的跨模型提示转移环是可能的，尽管先前的方法在这里不能取得明显的优势。(2）对于不同类型的投影仪训练任务，$TPT<em>{MODEL}$通常不能在性能和训练时间上带来优势，这表明 $TPT</em>{MODEL}$ 仍然严重受限于提示投影仪的质量。</p><p>一般来说，$TPT<em>{MODEL}$带来的优势是中等的，明显低于 $TPT</em>{TASK}$。为了分析是什么影响了跨模型的可转移性，我们观察了在目标PLM上训练的原始提示和用4.3节中的提示相似度指标预测的提示之间的相似性。结果显示在表7中。我们可以看到，对于用所有指标衡量的所有任务，预测的提示语与最初在目标PLM上训练的提示语高度不相似，而投影仪训练任务的预测提示语可以达到与最初训练的提示语相当的性能。我们猜测这表明由于PLM的高冗余度（Aghajanyan等人，2021），不同的提示激活不同的神经元也能刺激PLM做类似的工作，但由优化器和超参数决定的优化动态更倾向于找到类似的解决方案（表2）。</p><p><img src="https://s2.loli.net/2021/12/21/5hMpG8EmgjD1XK6.png" alt=""></p><h2 id="Discussion"><a href="#Discussion" class="headerlink" title="Discussion"></a>Discussion</h2><h3 id="Using-multiple-source-prompts"><a href="#Using-multiple-source-prompts" class="headerlink" title="Using multiple source prompts."></a>Using multiple source prompts.</h3><p>在 $TPT<em>{TASK}$  和 $TPT</em>{MODEL} $中，我们只使用一个源提示进行初始化，也就是事先尝试。直观地说，将多个源提示混合起来可能会实现进一步的性能和效率提升。实际上，同时进行的工作（Vu等人，2021）在跨任务转移中已经证实了这一点。<strong>未来的工作可以探索先进的混合/组合方法</strong>，以实现更好的初始化，本文探索的提示相似度指标可能有助于实现这一目的。</p><h3 id="Finding-better-prompt-similarity-metric"><a href="#Finding-better-prompt-similarity-metric" class="headerlink" title="Finding better prompt similarity metric"></a>Finding better prompt similarity metric</h3><p>在第5.3节中，我们发现，尽管从另一个PLM投射的提示可以达到与最初在目标PLM上训练的提示相当的性能，但用本文所有的提示相似度指标（包括激活神经元的重叠率）来衡量，这两种提示是高度不相似的。这表明，考虑到PLMs的高度冗余，我们仍然需要一个更好的提示相似性指标，并测量提示的基本因素，这需要对PLMs的机制有更深入的了解。以前的工作（Aghajanyan等人，2021；Qin等人，2021b）表明，各种NLP任务可以被重新参数化为类似的低维子空间，以PLMs为条件，这可能有助于实现这一目的。</p><h3 id="Designing-better-cross-model-prompt-projection"><a href="#Designing-better-cross-model-prompt-projection" class="headerlink" title="Designing better cross-model prompt projection."></a>Designing better cross-model prompt projection.</h3><p>与 $TPT<em>{TASK}$相比，本文中 $TPT</em>{MODEL} $ 的结果要弱得多，这是因为源PLM和目标PLM之间的特征不同，而且投影方法有限。在第5.3节中，我们发现我们的跨模型投影倾向于投影到性能相当的解决方案，但不是那些优化过程中的首选方案；因此 $TPT<em>{MODEL}$ 的效果不如 $TPT</em>{TASK}$好。而且我们发现，当我们去掉任务调优中公式7的LayerNorm(-)后，这种现象更加明显，即使用 $TPT_{MODEL}$时，学习损失并没有减少。详细情况请参考附录D。这表明我们应该设计更好的跨模型投影方法来克服不同PLM的异质性和不同的优化偏好。</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>在本文中，我们实证研究了提示调谐在不同任务和模型中的可转移性。在跨任务的设置中，我们发现软提示可以在不训练的情况下转移到类似的任务中，并且使用训练过的软提示作为初始化可以加速训练并提高效果。我们还探索了各种提示的相似性指标，并表明提示如何刺激PLM比它们的嵌入距离在转移性方面更重要。在跨模型的设置中，我们探索了各种将软提示投射到其他模型空间的方法，发现使用投射提示的转移初始化只能取得适度的改善，这可能是由于PLM的冗余性。我们希望这项工作中的实证分析和尝试的转移方法能够促进PT转移的进一步研究。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;On-Transferability-of-Prompt-Tuning-for-Natural-Language-Understanding&quot;&gt;&lt;a href=&quot;#On-Transferability-of-Prompt-Tuning-for-Natural-La</summary>
      
    
    
    
    
    <category term="context detection" scheme="http://example.com/tags/context-detection/"/>
    
  </entry>
  
  <entry>
    <title>TransPrompt Towards an Automatic Transferable Prompting Framework for Few-shot Text Classification</title>
    <link href="http://example.com/2021/12/19/TransPrompt-Towards-an-Automatic-Transferable-Prompting-Framework-for-Few-shot-Text-Classification/"/>
    <id>http://example.com/2021/12/19/TransPrompt-Towards-an-Automatic-Transferable-Prompting-Framework-for-Few-shot-Text-Classification/</id>
    <published>2021-12-19T13:59:11.000Z</published>
    <updated>2022-01-22T06:30:18.654Z</updated>
    
    <content type="html"><![CDATA[<h1 id="TransPrompt-Towards-an-Automatic-Transferable-Prompting-Framework-for-Few-shot-Text-Classification"><a href="#TransPrompt-Towards-an-Automatic-Transferable-Prompting-Framework-for-Few-shot-Text-Classification" class="headerlink" title="TransPrompt: Towards an Automatic Transferable Prompting Framework for Few-shot Text Classification"></a>TransPrompt: Towards an Automatic Transferable Prompting Framework for Few-shot Text Classification</h1><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>最近的研究表明，prompts 可以提高大型预训练语言模型在 few-shot 文本分类中的表现。然而，目前还不清楚如何在类似的NLP任务中迁移 prompts 知识以达到相互强化的目的。基于连续的 prompts 嵌入，我们提出了TransPrompt，一个可迁移的 prompt 框架，用于在类似的任务中进行 few-shot 的学习。</p><p> 在TransPrompt中，我们采用了一个多任务元知识获取程序来训练一个元学习者，以捕获跨任务的可迁移知识。我们进一步设计了两种去偏技术，使其对任何任务都更具有任务无关性和无偏性。</p><p>之后，元学习器可以以高精确度适应目标任务。大量的实验表明，TransPrompt在多个NLP任务和数据集上的表现优于单任务和跨任务的强基线。我们进一步表明，元学习器可以有效地提高以前未见过的任务的性能。当用完整的训练集学习时，TransPrompt也优于强大的微调基线。</p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>微调预训练语言模型（PLM）已经成为大多数NLP任务训练模型的标准做法（Devlin等人，2019；Liu等人，2019b；Qiu等人，2020）。为了确保高精确度，有必要为下游任务获得足够数量的训练数据，这往往是低资源场景下的瓶颈。</p><p>超大型PLM的应用，如GPT-3（Brown等人，2020），证明了这种PLM可以通过很少的训练样本来学习解决一个任务。受这些工作的启发，Gao等人（2020）提出了一种基于 prompt 的方法，以在少量的学习环境中对BERT-风格的PLM进行微调，它使PLM适应于产生对应于每个类别的特定标记，而不是学习预测头。Schick和Schütze（2020）；Scao和Rush（2021）；Schick和Schütze（2021）等人也表明了 prompt 的有效性。然而，设计高绩效的提示语是具有挑战性的，需要非常大的验证集。为了缓解这个问题，Liu等人（2021）提出了具有完全可分参数的连续 prompt 嵌入，避免了繁琐的手工提示工程过程。</p><p>尽管取得了显著的成功，我们注意到目前基于提示的方法可能有一些限制。对于 few-shot 的学习，下游任务的性能仍然受到训练实例数量的限制。如果模型能够在适应 few-shot 样本的特定任务之前，从类似的NLP任务中获得可迁移的知识，那将是非常理想的。然而，目前还不清楚提示编码器和具有提示技术的PLM中的知识是如何跨任务转移的。一个自然的问题出现了：我们如何为BERT风格的模型设计一个提示框架，以捕捉类似NLP任务中的可转移知识，从而提高少数样本学习的性能？</p><p>上述问题的一个直接解决方案是在这些类似的NLP任务中采用多任务微调。当训练数据稀缺时，微调后的PLM很容易对特定实例过度拟合（Nakamura and Harada, 2019）。在机器学习中，元学习范式被广泛研究，它产生的模型能够以很少的学习步骤迅速适应一组类似的任务（Wang等人，2020c；Huisman等人，2020）。对于PLM，Wang等人（2020a）发现，训练PLM的元学习者能够有效地捕捉不同领域的可转移知识。然而，这种方法并不是为提示性的少量学习而设计的，而且缺乏为所有任务学习无偏见的表征的机制。</p><p>在本文中，我们提出了TransPrompt这个提示框架，它允许PLMs为少量文本分类捕获跨任务的可转移知识，其高级架构如图1所示。TransPrompt首先采用多任务元知识获取（MMA）程序，在类似的NLP任务中共同学习提示编码器和PLM的可转移表示。为了减少过度拟合，使底层PLM更具有任务无关性，并减少对任何特定任务的偏倚，我们提出了两种去偏倚技术，即基于原型的去偏倚和基于熵的去偏倚。学习到的模型可以被看作是一组类似NLP任务的元学习器。</p><p><img src="https://s2.loli.net/2021/12/22/qsxCBdtK18mHhgM.png" alt=""></p><p>在MMA之后，TransPrompt采取了任务意识模型规范（TMS）的步骤，这可以进一步分为两种情况。 i）当模型在MMA期间适应现有任务时，可以应用P-tuning（Liu等人，2021）的变体来进行有效适应。 ii）当需要适应以前未见过的任务时，采用模型泛化策略，具体考虑模型中的通用提示知识。这通常是指由于数据隐私或计算效率问题，对所有任务的元精简器进行重新训练是不可行的情况。</p><p>为了进行评估，我们在三组少有的NLP任务（共包括七个公共数据集）上测试了TransPrompt框架：i）情感分析；ii）自然语言推理（NLI）；以及iii）转述。实验结果表明，TransPrompt在单任务和跨任务的强大基线上都有稳定的表现。我们进一步证明：i）由TransPrompt训练的元学习器可以有效地推广到未见过的任务；ii）在用完整的训练集学习时，TransPrompt也优于流行的微调算法。综上所述，我们在这项工作中做出了以下主要贡献。</p><ul><li>我们介绍了新的TransPrompt框架，以学习跨任务的可转移知识，用于少数文本分类。</li><li>我们提出了一个基于提示的元学习者训练算法和两种去偏技术，以获取可转移的知识。</li><li>在多种类型的NLP任务上的实验表明，TransPrompt在少量学习和标准微调方面的表现一直优于强大的基线。</li></ul><h2 id="The-TransPrompt-Framework"><a href="#The-TransPrompt-Framework" class="headerlink" title="The TransPrompt Framework"></a>The <em>TransPrompt</em> Framework</h2><h3 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h3><p>$T_1, …, T_M$ 是 $M$ 个类似的 few-shot 的文本分类任务。第 $m$ 项任务可以表示为：$T_m:x \to y$， 其中 $x$ 和$y\in Y$ 表示输入文本和分类标签。</p><p>$Y$ 是预先定义的标签集，$|Y| = N$, 其中 $N$ 是预定义的常数。假设在每个任务 $T_m$ 中，有 $K$ 个训练样本与每个类 $y\in Y$相关。因此，我们对每个任务 $T_m$ 有一个训练集 $D_m$，每个训练集包含 $N×K$ 个样本。$M$ 个任务的训练实例的总数是$ N×K×M$ 。</p><p>在 TransPrompt 中，根据 $M$ 个few-shot的训练集 $D<em>1,…,D_M$ 来训练一个元学习器 $F</em>{meta}$，其参数从任何PLM中初始化。之后，$F_{meta}$ 根据每个任务的训练集 $D_m$ 来适应每个任务 $T_m$。特定任务的模型被表示为 $F_m$。</p><p>由于 $F<em>{meta}$ 的设计是为了消化跨任务的可转移知识，而不是简单的多任务学习，$F</em>{meta}$ 也可以适应以前没有见过的任务。</p><p>由于数据隐私或计算效率问题，当在 $F<em>{meta}$ 的训练过程中无法获得相似任务 $\hat T$ 的少量训练集 $\hat D$ 时，我们探索如何利用TransPrompt 来生成基于 $F</em>{meta}$ 和 $\hat D$ 的精确模型 $\hat F$。在这种情况下，$F_{meta}$ 在MMA期间接受训练时，对新任务 $\hat T$ 没有任何了解。</p><p>在下文中，将介绍TransPrompt框架的详细技术，它由两个主要阶段组成，即多任务元知识获取（MMA）和任务意识模型规范（TMS）。最后，我们讨论了如何将 TransPrompt 应用于标准的微调场景，其中我们有相对较大的训练集，而不是解决 $N$ 路 K-shot 问题。</p><h3 id="Multi-task-Meta-knowledge-Acquisition"><a href="#Multi-task-Meta-knowledge-Acquisition" class="headerlink" title="Multi-task Meta-knowledge Acquisition"></a>Multi-task Meta-knowledge Acquisition</h3><p><img src="https://s2.loli.net/2021/12/19/B5Zh3pWesnRJGai.png" alt=""></p><h4 id="Prompt-Encoding"><a href="#Prompt-Encoding" class="headerlink" title="Prompt Encoding"></a>Prompt Encoding</h4><p>由于 TransPrompt 框架被置于多任务设置中，对于每个任务 $T_m$，我们有一个特定任务的提示模板 $t^{(m)} (x)$，如下所示:</p><script type="math/tex; mode=display">P_1^{(m)},...,P_i^{(m)}, x, P_{i+1}^{(m)} ,..., P_I^{(m)} , MASK</script><p>其中 $P_i^{(m)}$ 是 prompt 伪 token，$I$ 是伪token的总数，MASK是特殊 token 是一个特殊标记，用作模型输出的占位符。 我们还为所有任务定义了一个通用提示模板 $t^{(∗)}(x)$ :</p><script type="math/tex; mode=display">P_1^{(*)},...,P_i^{(*)}, x, P_{i+1}^{(*)} ,..., P_I^{(*)} , MASK</script><p>对于一个实例$(x,y)\in D_m$，提示嵌入 $PE^{(m)}(x)$可以计算如下:</p><script type="math/tex; mode=display">PE^{(m)}(x) = AvgPool(MLP(BiLSTM(t^{(m)}(x))) , MLP(BiLSTM(t^{(*)}(x))))</script><p>其中我们使用双向LSTM网络与多层感知器作为提示编码器（Liu等人，2021）。特定任务和通用提示编码器的平均集合结果被视为提示嵌入。提示嵌入 $PE^{(m)}(x)$ 是一个序列，作为PLM的输入:</p><script type="math/tex; mode=display">h_1,...,h_i, h_{[x]}, h_{i+1} ,..., h_I, h_{[MASK]}</script><p>其中 $h<em>{[x]}$ 是输入 $x$ 的序列嵌入，$h</em>{[MASK]}$ 是被MASK的输出 token 嵌入。由于提示参数是完全可微的，在反向传播过程中，它们有效地捕捉了特定任务和一般知识。</p><h4 id="Training-the-Meta-learner"><a href="#Training-the-Meta-learner" class="headerlink" title="Training the Meta-learner"></a>Training the Meta-learner</h4><p>获得元学习者的一个天真的方法是在 $M+1$ 个 prompt 编码器的 $M$ 个任务中应用P-tuning过程（Staudemeyer和Morris，2019）。然而，在实践中，它不能保证满意的结果。由于大型PLMs在 few-shot 学习过程中很容易出现过度拟合（Gao等人，2020），在跨任务的情况下，元学习者会不幸地记住非目标任务中的不可转移的知识。为了缓解这个问题，我们提出了两种去偏技术，以获得一个用可转移知识编码的更无偏见的元学习者，</p><p>即i）基于原型的去偏 和 ii）基于熵的去偏。</p><ul><li><p>Prototype-based De-biasing：这种技术旨在在元学习者的训练过程中对跨任务的原型实例给予更多的重视。在这里，我们扩展了Snell等人（2017）构建的轻量级多任务原型网络G。在网络G中，每个任务 $T_m$ 的类中心点嵌入$c_m(y)(y∈Y)$被计算并存储为:</p><script type="math/tex; mode=display">c_m(y) = \frac{1}{|D_{m,y}|}\sum_{(x,y)\in D_{m,y}} \Epsilon(x)</script><p>其中 $D<em>{m,y}$ 是 $D_m$ 的子集，使得 $D</em>{m,y}$中的每个实例都有标签 $y$ ，而 $E(x)$ 是由前面描述的元学习器生成的 $x$ 的表示。对于每个实例 $(x,y)\in D_m$，我们将文本 $x$ 通过网络来生成跨任务原型得分，表示为 $s(x)$:</p><script type="math/tex; mode=display">s(x) = \tau \cdot \frac{sim(E(x), c_m(y))}{\sum_{\hat y\in Y} sim(E(x), c_m(\hat y))}+ \frac{1-\tau} {M-1} \sum_{\hat m=1 (m\neq\hat m)} \frac{sim(E(x), c_m(y))}{\sum_{\hat y\in Y} sim(E(x), c_m(\hat y))}</script><p>其中 $0&lt;\tau &lt;1$ 是预定义的平衡因素，$sim(\cdot, of K nowcdot)$ 是两个嵌入的相似函数，我们可以看到，如果一个实例与任务 $T<em>m$ 本身和其他任务的中心点都有语义上的联系，那么它就会得到更高的分数，因此更容易跨任务迁移。通过将 $s(x)$ 视为优化权重，$F</em>{meta}$ 的整体损失函数 $L(Θ)$可以通过以下方式给出:</p><script type="math/tex; mode=display">L(\theta) = \sum_{m=1}^M \sum_{(x,y)\in D_m} s(x) l(x,y;\theta) + \lambda_1||\theta||</script><p>其中Θ是所有模型参数的集合，$l(x, y; Θ)$是样本间交叉熵损失，$λ_1$是正则化超参数。</p></li><li><p>Entropy-based De-biasing：仅仅应用基于原型的去偏移技术的一个潜在风险是获得一个非任务无关性的元学习者。考虑三个任务T1、T2和T3。如果T1和T2高度相似，而T3则更不相似。在D1和D2中，自然会得到较高的原型分数，使得元学习者偏向于T1和T2，而对T3很少关注。因此，当元学习者需要拟合T3时，它的参数初始化设置可能很差。为了使其更具任务无关性，受Jamal和Qi（2019）的启发，我们考虑了 $D_m$ 上的模型预测熵 $H(D_m)$：</p><script type="math/tex; mode=display">H(D_m) = -\frac{1}{|D_m|} \sum_{(x,y)\in D_m} \sum_{\hat y \in Y} \hat y(x) \log \hat y(x)</script><p>其中 $\hat y(x)$是 $x$ 被分配到 $\hat y∈Y$类的预测概率。当 $H(D_m)$ 被用作模型正则器的一部分时，元学习器在任何特定任务上的过度训练将减少。</p><p>将 $H(D_m)$ 项插入损失函数 $L(Θ)$，我们就有了新的损失函数 $L’(Θ)$:</p><script type="math/tex; mode=display">L'(\theta) = \sum_{m=1}^M\sum_{(x,y)\in D_m} (s(x) l(x,y;\theta) - \frac{\lambda_2}{|D_m|}\sum_{\hat y \in Y} \hat y(x)\log\hat y(x)) + \lambda_1||\theta||</script><p>其中 $\lambda_2$ 是正则化超参数</p></li><li><p>Optimization Procedure：尽管它的公式很简单，但最小化 $L’(Θ)$是一个非简单的问题。 这是因为当我们计算 $s(x)$时，我们必须事先获得PLM的模型参数，而这在训练过程之前是无法获得的。另一方面，$L (Θ)$的优化重新要求所有训练样本的 $s(x)$ 值，这就造成了 “鸡生蛋，蛋生鸡 “问题。</p><p>我们采用双重优化过程来解决 $L’(Θ)$的问题。在初始阶段，所有的 $s(x)$s都被均匀地初始化。接下来，我们将 $s(x)$s固定为常数，使 $L′(Θ)$ 中的 $l(x, y; Θ)$ 最小化。一个关于PLM的推理过程可以被应用来获得所有的 $s(x)$s。这个过程迭代了一定数量的epoch。读者也可以参考算法1来了解算法的概况。</p><p><img src="https://s2.loli.net/2021/12/22/LdFBUD4zs3OrJcq.png" alt=""></p></li></ul><h3 id="Task-aware-Model-Specification"><a href="#Task-aware-Model-Specification" class="headerlink" title="Task-aware Model Specification"></a>Task-aware Model Specification</h3><p>在MMA之后，元学习者可以很容易地适应特定的任务。对于一个已经被元学习器 “看到 “的任务 $T_m$，我们通过最小化损失函数 $L^{(m)}(Θ)$来微调相应的 prompt 编码器和PLM:</p><script type="math/tex; mode=display">L^{(m)}(\theta) = \sum_{(x,y)\in D_m} l(x,y;\theta) + \lambda_1||\theta||</script><p>这是P-tuning的一个变种（Liu等人，2021），具有更好的参数初始化。</p><p>对于一个先前未见过的任务 $\hat  T$，采用模型泛化策略。这里，我们使用通用 prompt 编码器来初始化其 prompt编码器。整个模型在数据集 $\hat D $上进行训练，损失函数 $\hat L(\theta)$如下:</p><script type="math/tex; mode=display">\hat L(\theta) = \sum_{(x,y)\in \hat D} l(x,y;\theta) + \lambda_1||\theta||</script><p>由于元学习器是高度泛化的，它可以为少数几次的学习任务 $\hat T$提供良好的初始化。</p><h3 id="Learning-with-Full-Training-Sets"><a href="#Learning-with-Full-Training-Sets" class="headerlink" title="Learning with Full Training Sets"></a>Learning with Full Training Sets</h3><p>当我们有相对较大的训练集时，TransPrompt也可以应用于标准的微调，并进行少量修改。在MMA过程中，我们注意到，当它不是一个N-way K-shot问题时，$D_1,…,D_M$ 的大小会有很大的不同。直接在这些数据集上优化 $L’(Θ)$ 会使元学习者偏向于大数据集。为了解决这个问题，当我们从 $D_1, …, D_M$ 中抽出一批样本时，我们采用分层抽样的方式，以与数据集分布 $Pr(D_m)$ 成比例的概率选择训练实例:</p><script type="math/tex; mode=display">Pr(D_m) = \frac{log|D_m| +\gamma}{ \sum_{\hat m=1}^M log|D_{\hat m}| + \gamma}</script><p>其中 $γ&gt;0$ 是一个平滑系数。这导致了对小数据集的过度采样和对大数据集的不足采样。</p><h2 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h2><p>本文旨在解决few-shot的分类问题。这个问题的定义从根本上不同于 与传统的分类法根本不同，传统的分类法的目标不是对其目的不是对未见过的样本进行分类，而是要快速地将元知识适应于新的任务。具体来说，提供一个有足够训练样本的标记数据集。提供了一个有足够训练样本的基础类 $C^{base}$，其目标是用非常有限的数据来学习概念。一组新类 $C^{novel}$，其中 $C^{base} ∩C^{novel} = ∅$。解决 few-shot 问题的一个有效方法是使用情节采样策略episodic sampling strategy.。</p><p>在这个框架中，元训练和元测试中的样本不是样本，而是情节 ${T}$，每个情节包含 $N$ 个类别（方式）和每个类别的 $K$ 个镜头。</p><p>特别地，对于N-way K-shot 任务，采样支持集 $S = {(x<em>i, y_i)}</em>{i=1}^{N\times K}$ 和查询集 $Q = {(x<em>i,y_i)}</em>{i=N\times K +1}^{N\times K +T}$ </p><p>这里，$x_i$ 和 $y_i \in {C_1,…,C_N}$是第 $i$ 个输入数据，并且是来自 $C^{base}$。在元测试中，测试任务也是从未见过的类别$C^{novel}$ 中抽出同样大小的情节。其目的是将查询集中的 $T$ 个未标记的样本正确地分类到 $N$ 个类别中。</p><h3 id="Overview-of-Framework"><a href="#Overview-of-Framework" class="headerlink" title="Overview of Framework"></a>Overview of Framework</h3><p><img src="https://s2.loli.net/2021/12/20/O1FaqzQe4CcDdfl.png" alt=""></p><p>图1说明了所提方法的框架。它主要由三个部分组成，即用于鉴别性特征提取的编码器，用于表达性元知识存储的记忆模块，用于综合推理的图增强模块。一般来说，我们的方法可以概括为三个阶段（即预训练、元训练、元测试）。</p><ul><li>Phase-I Pre-Train. 我们遵循一个简单的基线[Chen <em>et al.</em>, 2020]：在元训练集C的基础上学习一个有监督的表示，然后在这个表示之上学习一个线性分类器。事实证明，这个预训练阶段对下游的 few-shot 任务是有益的[Tian <em>et al.</em>, 2020]，然后将训练好的特征提取器（<em>如ResNet-12[He </em>et al.*, 2016]）和分类器分别作为我们编码器和记忆库的初始化。</li><li>Phase-II Meta-Train. 我们首先提取支持和查询样本的特征作为任务相关的嵌入$V^t$。然后为了促进快速适应，我们的方法拥有一个记忆库来存储支持集的表达式。这个记忆库通过一个新的更新方案进行优化，以逐步净化鉴别性信息（在第2.2节中介绍）。此外，净化后的内存与图的增强模块相结合，用于稳健预测（在第2.3节中介绍）。在这个模块中，我们挖掘相关的原型 $V^m$ ，在本文中被称为元知识，通过图神经网络传播 $V^t$ 和 $V^m$ 之间的相似性。因此，我们的模型能够以可忽略不计的内存成本方便地泛化到新的任务。</li><li>Phase-III Meta-Test. Meta-Test的程序与Meta-Train相似，也是采用情节性抽样策略。但与第二阶段不同的是，记忆库和其他模块在整个过程中不会被更新。换句话说，开关将被关闭，如图1所示。</li></ul><h3 id="Refined-Memory-Updating"><a href="#Refined-Memory-Updating" class="headerlink" title="Refined Memory Updating"></a>Refined Memory Updating</h3><p>元知识在从未见过的样本中学习新概念方面起着重要作用，最近 FSL 的进展[Ramalho和Garnelo, 2019]经常利用内存机制来存储这种元知识。在其典型的设置中，存储器试图保留尽可能多的信息（例如，存储整个特征）。然而，我们认为这种策略是无效的和低效的。在FSL的背景下，偶发抽样使得特征提取器以很少的样本迅速学习新的概念，这就造成了一个问题：当特征提取器处于一个非常不同的任务背景下时，记忆中的特征会被更新。从这个角度来看，从不同的任务中学习到的表征需要一个净化的过程才能成为一个稳定的概念。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;TransPrompt-Towards-an-Automatic-Transferable-Prompting-Framework-for-Few-shot-Text-Classification&quot;&gt;&lt;a href=&quot;#TransPrompt-Towards-an</summary>
      
    
    
    
    
    <category term="GNN" scheme="http://example.com/tags/GNN/"/>
    
  </entry>
  
  <entry>
    <title>Iterative Network Pruning with Uncertainty Regularization for Lifelong Sentiment Classification</title>
    <link href="http://example.com/2021/12/07/Iterative-Network-Pruning-with-Uncertainty-Regularization-for-Lifelong-Sentiment-Classification/"/>
    <id>http://example.com/2021/12/07/Iterative-Network-Pruning-with-Uncertainty-Regularization-for-Lifelong-Sentiment-Classification/</id>
    <published>2021-12-07T13:20:14.000Z</published>
    <updated>2022-01-19T10:41:14.240Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Iterative-Network-Pruning-with-Uncertainty-Regularization-for-Lifelong-Sentiment-Classification"><a href="#Iterative-Network-Pruning-with-Uncertainty-Regularization-for-Lifelong-Sentiment-Classification" class="headerlink" title="Iterative Network Pruning with Uncertainty Regularization for Lifelong Sentiment Classification"></a>Iterative Network Pruning with Uncertainty Regularization for Lifelong Sentiment Classification</h1><p>提出了一种新的具有不确定性正则化的迭代网络修剪方法，用于终身情感分类（IPRLS），它利用了网络修剪和权重正则化的原则。通过以迭代的方式进行网络修剪和不确定性正则化，IPRLS可以使一个单一的BERT模型适应来自多个领域的连续到达的数据，同时避免灾难性的遗忘和相互影响。</p><p>具体来说，利用迭代修剪方法来去除大型深度网络中的冗余参数，这样释放出来的空间就可以用来学习新的任务，解决灾难性遗忘的问题。</p><p>在学习新任务时，我们也使用基于贝叶斯在线学习框架的不确定性正则化来约束BERT中旧任务权重的更新，这使得正向转移成为可能，即学习新任务可以提高过去任务的表现，同时保护旧知识不被丢失。</p><p>此外，我们提出了一个与BERT各层并行的特定任务的低维残差函数，这使得IPRLS在学习新任务时不容易丢失保存在基础BERT网络中的知识。</p><h2 id="INTRODUCTION"><a href="#INTRODUCTION" class="headerlink" title="INTRODUCTION"></a>INTRODUCTION</h2><p>随着网络上大量富含观点的文档的增加，人们对情感分类给予了极大的关注，其目的是自动预测给定文本的情感极性。近年来，深度学习取得了巨大的成功，在情感分类领域几乎占主导地位[35, 36, 38]。强大的深度神经网络必须依赖于大量的注释训练资源。然而，标注大型数据集通常是费时费力的，在将训练好的情感分类器应用于新领域时，会产生很大的障碍。此外，无论收集多少数据并用于训练情感分类器，都很难覆盖网络上所有可能的意见数据领域。因此，当在实践中部署时，训练有素的情感分类器的表现往往不尽如人意。</p><h2 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h2><h3 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h3><p>在本文中，我们使用BERT作为基础模型来构建情感分类器。BERT是快速发展的预训练模型的一个重要代表，它在各种NLP任务中显示出卓越的性能。一般来说，当任务依次到达时，BERT在学习新任务时，会对旧任务产生 “灾难性的遗忘”。为了缓解 “灾难性遗忘 “的问题，我们利用基于架构和基于正则化的持续学习方法来提高BERT在终身情感分类中的性能。具体来说，我们探索了两种机制，以促进BERT模型在学习新任务时保留对先前任务重要的知识。首先，我们探索了一种具有不确定性正则化的迭代修剪，以将来自多个任务的重要知识整合到一个单一的BERT模型中，同时确保准确性的最小下降。其次，我们在每个BERT层中 “并行 “添加一个特定任务的并行残差函数，以进一步保留最重要的新知识，同时适应新任务。接下来，我们将详细说明BERT、具有不确定性正则化的迭代修剪和特定任务的平行残差函数。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Iterative-Network-Pruning-with-Uncertainty-Regularization-for-Lifelong-Sentiment-Classification&quot;&gt;&lt;a href=&quot;#Iterative-Network-Pruning</summary>
      
    
    
    
    
    <category term="context detection" scheme="http://example.com/tags/context-detection/"/>
    
  </entry>
  
  <entry>
    <title>Continual Learning with Hypernetworks</title>
    <link href="http://example.com/2021/12/03/Continual-Learning-with-Hypernetworks/"/>
    <id>http://example.com/2021/12/03/Continual-Learning-with-Hypernetworks/</id>
    <published>2021-12-03T12:18:00.000Z</published>
    <updated>2022-01-22T05:33:10.043Z</updated>
    
    <content type="html"><![CDATA[<p>[TOC]</p><h1 id="Continual-Learning-with-Hypernetworks"><a href="#Continual-Learning-with-Hypernetworks" class="headerlink" title="Continual Learning with Hypernetworks"></a>Continual Learning with Hypernetworks</h1><p>当人工神经网络在多个任务上进行顺序训练时，它们会遭受灾难性的遗忘。 为了克服这个问题，我们提出了一种基于任务条件超网络的新方法，即基于任务身份生成目标模型权重的网络。</p><p>由于一个简单的关键特征，此类模型的持续学习 (CL) 难度较小：任务条件超网络不需要回忆所有先前看到的数据的输入-输出关系，只需要排练特定于任务的权重实现，这可以 使用简单的正则化器在内存中维护。</p><p>除了在标准的CL基准上取得最先进的性能外，对长任务序列的额外实验显示，任务条件下的超网络显示出非常大的能力来保留以前的记忆。</p><p>值得注意的是，当可训练的超网络权重数量与目标网络大小相当或小于目标网络大小时，如此长的记忆寿命是在一个压缩制度下实现的。我们对低维任务嵌入空间（超网络的输入空间）的结构进行了深入研究，并表明任务条件下的超网络展示了迁移学习。最后，基于CIFAR-10/100图像数据集的挑战性CL基准的经验结果进一步支持了前向信息迁移。</p><h2 id="INTRODUCTION"><a href="#INTRODUCTION" class="headerlink" title="INTRODUCTION"></a>INTRODUCTION</h2><p>我们假设一个具有可训练权重 $Θ$ 的神经网络 $f(x,Θ)$ 被赋予来自一组任务的数据 ${(X^{(1)}Y^{(1)})}$， 输入样本 $X^{(t)} = {x^{(t,i)}}<em>{i=1}^{n_i}$，输出样本 $Y^{(t)} = {y^{(t,i)}}</em>{i=1}^{n_t}$ , 其中 $n_t = |X^{(t)}|$ 。</p><p>一个标准的训练方法是使用所有任务的数据来学习模型 一次性从所有任务中学习模型。然而，这在现实世界的问题中并不总是可能的，在在线学习环境中也不可取。持续学习（CL）指的是一种在线学习设置，其中任务是按顺序呈现的（关于持续学习的最新评论，见van de Ven &amp; Tolias, 2019）。</p><p> 在CL中，当学习一个新的任务 $t$ 时，从权重 $Θ^{(t-1)}$ 开始，只观察$(X^{(t)},Y^{(t)})$ ，目标是找到一组新的参数 $Θ^{(t)}$，与 $Θ^{( t-1)}$相比，（1）保留（无灾难性遗忘）或（2）提高（正向转移）以前任务的性能，（3）解决新任务 $t$ 可能利用以前获得的知识（正向转移）。实现这些目标是不容易的，也是神经网络研究中的一个长期问题。</p><p>在这里，我们提议在 meta level 上解决灾难性遗忘问题：我们不直接尝试为以前的任务保留 $f( x,Θ)$，而是固定一个元模型 $f_h(e,Θ_h)$ 的输出，该模型被称为任务条件超网络，将任务嵌入 $e$ 映射到权重 $Θ$ 。现在，每个任务必须记住single point。</p><p>为了激励这种方法，我们做了一个思想实验：我们假设允许我们存储所有的输入 ${X^{(1)},…, X^{(T)} }$，并使用这些数据来计算对应于 $Θ^{(T-1)}$的模型输出。</p><p>在这个理想化的设置中，我们可以通过简单地将当前任务的数据与过去的数据混合来避免遗忘，${(X^{(1)}, Y^{(1)}), . . . , (X^{(T -1)}, Y^{(T -1)}), (X^{(T )}, Y^{(T )})}$，其中 $Y^{(t)}$ 是指使用模型本身 $f(-,Θ^{(t-1)})$ 生成的一组合成目标。因此，通过训练保留以前获得的输入-输出映射，我们可以得到一个原则上与多任务学习一样强大的顺序算法。多任务学习，即所有的任务都是同时学习的，可以被看作是CL的上限。上面描述的策略被称为排练（Robins, 1995）。然而，存储以前的任务数据违反了我们的CL要求。</p><p>因此，我们引入了一个视角的变化，<strong>从维护单个输入输出数据点的挑战转向维护参数集 ${Θ^{(t)}} $ 的问题</strong>，而不明确存储它们。<br>为了实现这一点，我们<strong>训练元模型参数 $Θ_h$，类似于上面概述的学习方案，现在的合成目标对应于适合以前任务的权重配置。</strong>这样就可以用一个低维任务描述符来交换整个数据集的存储，除了最简单的任务外，还能节省大量内存。尽管依赖于正则化，但我们的方法在概念上与之前基于权重正则化的算法（如Kirkpatrick等人，2017；Zenke等人，2017）或激活空间（如He &amp; Jaeger，2018）有所不同。</p><p>我们的实验结果表明，在一组标准的CL基准上，任务条件的超网络并没有遭受灾难性的遗忘。值得注意的是，在面对非常长的任务序列时，它们能够保留记忆，而且性能几乎没有下降。由于神经网络的表达能力，任务条件超网络<strong>利用了任务与任务之间的相似性，并将信息及时迁移到未来的任务中</strong>。最后，我们提出的任务条件元模型观点是通用的，因为它不依赖于目标网络架构的具体细节。我们利用这一关键原则，并表明同样的元模型框架延伸到并可以改善一类重要的CL方法，即生成性重放方法，这些方法在许多实际问题中是目前最先进的表现（Shin等人，2017；Wu等人，2018；van de Ven &amp; Tolias，2018）。</p><h2 id="MODEL"><a href="#MODEL" class="headerlink" title="MODEL"></a>MODEL</h2><h3 id="TASK-CONDITIONED-HYPERNETWORKS"><a href="#TASK-CONDITIONED-HYPERNETWORKS" class="headerlink" title="TASK-CONDITIONED HYPERNETWORKS"></a>TASK-CONDITIONED HYPERNETWORKS</h3><p><strong>Hypernetworks parameterize target models. </strong> 我们持续学习方法的核心是超网络，图1a。<strong>我们不是直接学习一个特定函数 $f<em>{trgt} $ 的参数 $Θ</em>{trgt}$（目标模型），而是学习一个元模型的参数 $Θ<em>h$。这种元模型的输出，即超网络，是 $Θ</em>{trgt}$。因此，超网络可以被认为是权重生成器，它最初是为了以压缩的形式动态地对模型进行参数化</strong>（Ha等人，2017；Schmidhuber，1992；Bertinetto等人，2016；Jia等人，2016）。</p><p><img src="https://i.loli.net/2021/12/03/8AEnX2IeSbGjmhT.png" alt=""></p><p>(a) <strong>通常，神经网络的参数是根据数据直接调整的，以解决一个任务。在这里，一个被称为超网络的权重生成器被学习</strong>。<strong>超网络将嵌入向量映射为权重，从而为目标神经网络提供参数。</strong>在持续学习的情况下，<strong>一组特定任务的嵌入是通过反向传播学习的。嵌入向量提供与任务相关的背景，并使超网络偏向于特定的解决方案。</strong></p><p>(b) 一个较小的、分块的超网络可以被反复使用，一次产生一大块目标网络权重（例如，一次一个层）。分块超网络可以实现模型压缩：可训练参数的有效数量可以小于目标网络权重的数量。</p><p><strong>Continual learning with hypernetwork output regularization.</strong> <strong>避免灾难性遗忘的一种方法是存储以前任务的数据和相应的模型输出，然后固定这种输出。这可以通过以下形式的输出正则器来实现，其中过去的输出起到了伪目标的作</strong>用（Robins, 1995; Li &amp; Hoiem, 2018; Benjamin等人, 2018）</p><script type="math/tex; mode=display">L_{output} = \sum_{t=1}^{T-1} \sum_{i=1}^{|X^{(t)}|} ||f(x^{(t,i)}, \theta^*) - f(x^{(t,i)}, \theta)||^2</script><p>在上面的方程式中，$Θ^∗$是尝试学习任务 $T$ 之前的参数集，$f$ 是学习者。<strong>然而，这种方法需要存储和迭代以前的数据，这个过程被称为排练。这在内存方面可能很昂贵，而且不是严格意义上的在线学习。一个可能的变通方法是通过对随机模式（Robins, 1995）或当前任务数据集（Li &amp; Hoiem, 2018）评估 $f$ 来生成伪目标。</strong>然而，这不一定能固定函数 $f$ 在感兴趣区域的行为。</p><p><strong>超网络自然避开了这个问题。在目标网络权重空间中，每个任务必须固定一个点（即一组权重）。</strong>这可以通过任务条件超网络有效地实现，即把超网络的输出固定在适当的任务嵌入上。</p><p>与Benjamin等人（2018）类似，我们使用两步优化程序来引入内存保护的超网络输出约束。首先，我们计算出一个候选变化 $ΔΘ<em>h$，该变化使当前任务损失 $L(T)=L</em>{task}(Θ_h,e^{(T)},X^{(T)},Y^{(T)})$ 相对于 $Θ$ 最小。候选任务 $∆Θ_h$ 是通过选择的优化器得到的（我们自始至终使用Adam；Kingma &amp; Ba, 2015）。然后通过最小化以下总损失来计算实际的参数变化: </p><script type="math/tex; mode=display">\begin{equation}\begin{split} L_{total} &= L_{task}(\theta_h, e^{(T)}, X^{(T)}, Y^{(T)}) + L_{output} (\theta_{h}^*, \theta_h, \Delta \theta_{h}, \{e^{t}\})\\&=  L_{task}(\theta_h, e^{(T)}, X^{(T)}, Y^{(T)}) + \frac{\beta_{output}}{T-1} \sum_{t=1}^{T-1}||f_h(e^{(t)}, \theta^*_h) - f_h(e^{(t)}, \theta_h + \Delta\theta_h)||^2\end{split}\end{equation}</script><p>其中 $Θ^∗<em>h$ 是尝试学习任务 $T$ 之前的超网络参数集，$ΔΘ_h$ 被认为是固定的，$β</em>{output}$是一个控制正则器强度的超参数。在附录D中，我们对 $β_{output}$进行了敏感性分析，并实验了一个更有效的随机正则器，其中平均化是在过去任务的一个随机子集上进行的。</p><p>可以采用更多的计算密集型算法，包括完整的内环细化，或者通过 $∆Θ<em>h$的反向传播使用二阶梯度信息。然而，我们根据经验发现，我们的单步校正效果很好。探索性的超参数扫描显示，在加入前瞻 $∆Θ_h$带来了性能上的小幅提升，即使是用廉价的一步程序计算时。请注意，与公式1不同的是，保存记忆的项 $L</em>{output}$并不依赖于过去的数据。以前任务的记忆只通过以下集合进入任务嵌入 ${e^{(t)}}^{T-1}_{t-1}$。</p><p><strong>Learned task embeddings.</strong> <strong>任务嵌入是可以学习的可区分的确定性参数</strong>，就像 $Θ<em>h$ 一样。**在我们算法的每个学习步骤中，我们也会更新当前的任务嵌入 $e^{(T )}$，以最小化任务损失 $L^{(T)}</em>{task}$。<strong>学</strong>习任务后，最终的嵌入被保存下来 并添加到集合${e^{(t)}}$中。**</p><h3 id="MODEL-COMPRESSION-WITH-CHUNKED-HYPERNETWORKS"><a href="#MODEL-COMPRESSION-WITH-CHUNKED-HYPERNETWORKS" class="headerlink" title="MODEL COMPRESSION WITH CHUNKED HYPERNETWORKS"></a>MODEL COMPRESSION WITH CHUNKED HYPERNETWORKS</h3><p><strong>Chunking.</strong> 在一个直接的实现中，超网络产生目标神经网络的整个权重集。对于现代深度神经网络，这是一个非常高维的输出。然而，超网络可以被迭代调用，在每一步只填入目标模型的一部分，分块进行（Ha等人，2017；Pawlowski等人，2017）。这种策略允许应用可重复使用的较小的超网络。有趣的是，通过分块超网络，有可能在压缩制度下解决任务，其中学习的参数（超网络的参数）的数量实际上小于目标网络参数的数量。</p><p><strong>Chunk embeddings and network partitioning.</strong> 多次重新应用相同的超网络会在目标网络的各个分区中引入权重共享，这通常是不可取的。为了允许目标网络的灵活参数化，我们引入了一组 $C={c<em>i}^{N_c}</em>{i=1}$ 的块嵌入，它们被用作超网络的额外输入，图1b。因此，整套目标网络参数 $Θ<em>{trgt}=[f_h(e,c_1),…,f_h(e,c</em>{N_C})]$ 是通过对 C 的迭代产生的，保持任务嵌入e不变。这样，超网络可以为每个块产生不同的权重。此外，块嵌入，就像任务嵌入一样，是普通的确定性参数，我们通过反向传播学习。为了简单起见，我们对所有任务使用一组共享的块嵌入，我们不探索特殊的目标网络分区策略。</p><p>我们的方法有多灵活？分块神经网络原则上可以任意地接近任何目标权重配置。为了完整起见，我们在附录E中正式说明这一点。</p><h3 id="CONTEXT-FREE-INFERENCE-UNKNOWN-TASK-IDENTITY"><a href="#CONTEXT-FREE-INFERENCE-UNKNOWN-TASK-IDENTITY" class="headerlink" title="CONTEXT-FREE INFERENCE: UNKNOWN TASK IDENTITY"></a>CONTEXT-FREE INFERENCE: UNKNOWN TASK IDENTITY</h3><p><strong>Determining which task to solve from input data. </strong> 我们的<strong>超网络需要一个任务嵌入输入来生成目标模型权重</strong>。在<strong>某些CL应用中，可以立即选择一个合适的嵌入，因为任务身份是明确的，或者可以很容易地从上下文线索中推断出来。</strong>在其他情况下，手头的任务知识在推理过程中并不明确可用。在下文中，我们展示了我们的元模型框架对这种情况的概括。特别是，我们考虑从一个给定的输入模式中推断出要解决的任务的问题，这是一个著名的基准挑战（Farquhar &amp; Gal, 2018; van de Ven &amp; Tolias, 2019）。下面，我们探讨了在这种CL设置中利用任务条件超网络的两种不同策略。</p><p><strong>Task-dependent predictive uncertainty.</strong> 神经网络模型在指示新奇性和适当处理分布外数据方面越来越可靠。对于分类目标分布，网络最好对未见过的数据产生平坦的、高熵的输出，反之，对分布中的数据产生峰值、低熵的响应（Hendrycks &amp; Gimpel, 2016; Liang et al., 2017）。这表明了第一种简单的任务推理方法（HNET+ENT）。给定一个任务身份未知的输入模式，我们选择产生最低预测不确定性的任务嵌入，这是由输出分布熵量化的。虽然这种方法依赖于精确的新奇性检测，而这本身就是一个远未解决的研究问题，但它在其他方面的实现是很简单的，不需要额外的学习或模型来推断任务身份。</p><p><strong>Hypernetwork-protected synthetic replay.</strong> 当生成模型可用时，灾难性遗忘可以通过将当前任务数据与重放的过去合成数据混合来规避（最近的工作见Shin等人，2017；Wu等人，2018）。除了保护生成模型本身，合成数据还可以保护另一个感兴趣的模型，例如另一个区分性模型。这种概念上简单的策略在实践中往往是最先进的CL解决方案（van de Ven &amp; Tolias, 2019）。受这些成功的启发，我们探索用重放网络来增强我们的系统，这里是一个标准的变异自动编码器（VAE；Kingma &amp; Welling，2014）（但见附录F中的生成对抗网络实验，Goodfellow等人，2014）。</p><p>合成重放是一个强大的，但并不完美的CL机制，因为生成模型会出现漂移，而错误往往会随着时间的推移而积累和放大。在此，我们基于以下关键观察：就像目标网络一样，重放模型的生成器可以由超网络指定。这允许用输出正则器（公式2）来保护它，而不是像相关工作中那样，用模型自身的重放数据来保护它。因此，在这个组合方法中，合成重放和任务条件元模型都是串联起来的，以减少遗忘。</p><p>我们在两个不同的设置中探索超网络保护的重放。首先，我们考虑一个最小的架构（HNET+R），其中只有重放模型，而不是目标分类器，是由超网络提供参数。在这里，目标网络中的遗忘是通过混合当前数据和合成数据来避免的。以前任务的合成目标输出值是用软目标方法产生的，即在合成输入数据上学习新任务之前简单地评估目标函数。其次（HNET+TIR），我们引入了一个辅助的任务推理分类器，使用合成重放数据进行保护，并训练它从输入模式预测任务身份。这种结构需要额外的建模，但当任务有强烈的不相似性时，它可能会很好地工作。此外，任务推理子系统可以很容易地应用于处理更普遍形式的上下文信息，超越了当前的输入模式。我们在附录B和附录C中提供了更多的细节，包括网络结构和被优化的损失函数。</p><h2 id="RESULTS"><a href="#RESULTS" class="headerlink" title="RESULTS"></a>RESULTS</h2><p>我们在MNIST、CIFAR-10和CIFAR-100公共数据集的一组标准图像分类基准上评估我们的方法1。我们的主要目的是：（1）研究任务条件超网络在三种持续学习环境中的记忆保持能力，以及（2）研究在连续学习的任务中的信息转移。</p><h3 id="Continual-learning-scenarios"><a href="#Continual-learning-scenarios" class="headerlink" title="Continual learning scenarios."></a>Continual learning scenarios.</h3><p>在我们的实验中，我们考虑了三种不同的CL场景。在CL1中，任务身份被赋予了系统。这可以说是标准的顺序学习情景，除非另有说明，否则我们考虑的就是这种情景。在CL2中，任务身份对系统来说是未知的，但它不需要明确地确定。需要一个有固定头部的目标网络来解决多个任务。在CL3中，任务身份必须被明确推断出来。有人认为，这种情况是最自然的，也是对神经网络来说比较困难的。</p><h3 id="Experimental-details"><a href="#Experimental-details" class="headerlink" title="Experimental details"></a>Experimental details</h3><p>为了实现可比性，在MNIST数据集的实验中，我们将目标网络建模为全连接网络，并按照van de Ven &amp; Tolias（2019）的方法设置所有超参数，他们最近审查并比较了一大批CL算法。对于我们的CIFAR实验，我们选择了ResNet-32目标神经网络（He等人，2016）来评估我们方法的可扩展性。附录C提供了对架构和特定超参数选择的简要描述，以及其他实验细节。我们强调，在我们所有的实验中，<strong>超网络参数的数量总是小于或等于我们与之比较的模型的参数数量。</strong></p><p><img src="https://s2.loli.net/2022/01/03/u6adf9U41GR5IZL.png" alt=""></p><p>图2：一维非线性回归。(a) 具有输出正则化的任务条件超网络可以很容易地对一连串度数增加的多项式建模，同时以持续的方式学习。(b) 直接对所有任务同时进行训练的目标网络找到的解决方案是相似的。(c) 微调，即按顺序学习，导致对过去任务的遗忘。虚线描述的是基础事实，标记显示的是模型预测。</p><h3 id="Nonlinear-regression-toy-problem"><a href="#Nonlinear-regression-toy-problem" class="headerlink" title="Nonlinear regression toy problem."></a>Nonlinear regression toy problem.</h3><p>为了说明我们的方法，我们首先考虑一个简单的非线性回归问题，其中要近似的函数是标量值的，图2。在这里，必须从嘈杂的数据中推断出一串度数增加的多项式函数。这激发了持续学习的问题：当通过修改 $Θ_h$并关闭保存记忆的正则器（βoutput = 0，见公式2）来连续学习每个任务时，网络学习了最后的任务，但忘记了以前的任务，图2c。正则器保护了旧的解决方案，图2a，并且性能与离线非连续学习器相当，图2b。</p><h3 id="Permuted-MNIST-benchmark"><a href="#Permuted-MNIST-benchmark" class="headerlink" title="Permuted MNIST benchmark."></a>Permuted MNIST benchmark.</h3><p>接下来，我们研究了permuted MNIST基准。这个问题的设置如下。首先，向学习者提供完整的MNIST数据集。随后，通过对输入的图像像素进行随机置换，获得新的任务。这个过程可以重复进行，以产生一个长的任务序列，其典型长度为T=10个任务。考虑到生成的任务的低相似性，混杂的MNIST很适合研究持续学习者的记忆能力。对于T=10，我们发现，任务条件超网络在CL1上是最先进的，表1。有趣的是，通过预测分布熵（HNET+ENT）推断出的任务在permuted MNIST基准上效果很好。尽管方法简单，但突触智能（SI；Zenke等人，2017）和在线弹性重量巩固（EWC；Schwarz等人，2018）在CL3上的表现都要高出很多。当辅以生成性重放 方法时，任务条件超网络（HNET+TIR和HNET+R）在所有三种CL场景中表现最好。</p><p><img src="https://s2.loli.net/2022/01/03/ApV5gDtvwZ3YM2i.png" alt=""></p><p>图3：在置换的MNIST基准上进行的实验。(a) 在学习了一百个排列组合（PermutedMNIST-100）之后，第 $t$ 个任务的最终测试集分类准确率。任务条件下的超网络（hnet，红色）在permuted MNIST基准上实现了非常大的记忆寿命。突触智能（SI，蓝色；Zenke等人，2017）、在线EWC（橙色；Schwarz等人，2018）和深度生成重放（DGR+distill，绿色；Shin等人，2017）方法被显示出来进行比较。SI和DGR+distill的记忆保持率优雅地下降，而EWC则受到僵化的影响，永远无法达到非常高的准确性，即使记忆持续了整个实验时间。(B)压缩比 $\frac{|\theta<em>h \cup {e^{(t)}}|}{\theta</em>{trgt}}$对于PermutedMNIST-10基准，在学习所有任务(标记为“最终”，红色)之后和紧接着学习任务(标记为“期间”，紫色)之后的任务平均测试集准确性。超网络允许模型压缩，即使目标模型参数的数量超过其自身，也有良好的表现。性能的衰减是非线性的：在压缩比低于1的大范围内，精度保持大致不变。对压缩比≈1的超参数进行一次调整，然后用于所有压缩比。阴影部分表示5个随机种子的STD（a）和SEM（b）。</p><p>在长序列的限制下，性能差异变得更大，图3a。对于较长的任务序列（T=100），SI和DGR+distill（Shin等人，2017；van de Ven &amp; Tolias，2018）优雅地退化，而在线EWC的正则化强度使该方法无法实现高精确度（见图A6，关于相关工作的超参数搜索）。值得注意的是，任务条件的超网络显示出最小的内存衰减，并找到高性能的解决方案。由于超网络在压缩制度下运行（见图3b和图A7对压缩率的探索），我们的结果并不天真地依赖于参数数量的增加。相反，它们表明以前的方法还没有能力在CL环境下充分利用目标模型的能力。我们在附录D中报告了一组关于该基准的扩展结果，包括对CL2/3（T=100）的研究，其中HNET+TIR强烈地超过了相关工作。</p><h3 id="Split-MNIST-benchmark"><a href="#Split-MNIST-benchmark" class="headerlink" title="Split MNIST benchmark."></a>Split MNIST benchmark.</h3><p>拆分MNIST是另一个流行的CL基准，旨在引入任务重叠。在这个问题中，各种数字被依次配对，并用于形成五个二进制分类任务。在这里，我们发现任务条件下的超网络是整体表现最好的。特别是，HNET+R在CL2和CL3上都改进了以前最先进的方法DGR+distill，几乎饱和了重放模型的CL2上限（附录D）。由于HNET+R本质上是超网络保护的DGR，这些结果证明了任务条件超网络作为有效内存保护器的普遍性。为了进一步支持这一点，我们在附录F中表明，我们的重放模型（我们用VAE和GAN做实验）可以以类增量的方式学习完整的MNIST数据集。最后，HNET+ENT再次胜过EWC和SI，没有任何生成模型。</p><p>在分裂的MNIST问题上，任务是重叠的，因此持续学习者可以跨任务转移信息。为了分析这种影响，我们研究了具有二维任务嵌入空间的任务条件超网络，它可以很容易地被可视化。尽管学习是持续进行的，但我们 我们发现，在适当的任务嵌入下，算法会收敛到一个超网络配置，该配置可以产生同时解决新旧任务的目标模型参数，图4。</p><p><img src="https://s2.loli.net/2022/01/03/1yGoNSQ2X7KdfAW.png" alt=""></p><p>图4：分裂的MNIST基准的二维任务嵌入空间。在学习了五种拆分后的彩色编码的测试集分类准确率，随着嵌入向量成分的变化而显示。标记表示最终任务嵌入的位置。(a) 即使e-空间是低维的，也能实现高分类性能，几乎没有遗忘。该模型显示了嵌入空间中的信息转移：第一个任务在一个包括后续学习任务的嵌入的大体积中得到解决。(b) 嵌入空间的竞争：最后一个任务占据了一个有限的高性能区域，在远离嵌入矢量的地方出现了优雅的退化。以前学到的任务嵌入仍然导致适度的、高于机会的性能。</p><h3 id="Split-CIFAR-10-100-benchmark"><a href="#Split-CIFAR-10-100-benchmark" class="headerlink" title="Split CIFAR-10/100 benchmark"></a>Split CIFAR-10/100 benchmark</h3><p>最后，我们研究了一个更具挑战性的基准，学习者首先被要求解决完整的CIFAR-10分类任务，然后从CIFAR-100数据集中拿出10个类别的集合。我们用一个高性能的ResNet-32目标网络结构（图5）和一个较浅的模型（图A3）进行了实验，我们完全复制了以前的工作。值得注意的是，在ResNet-32模型上，我们发现有任务条件的超网络基本上可以完全消除遗忘。此外，还发生了前向信息转移；与从初始条件单独学习每个任务时相比，来自先前任务的知识使网络能够找到更好的解决方案。有趣的是，在浅层模型实验中，前向转移更强（图A3），否则我们发现我们的方法与SI的表现相当。</p><h2 id="DISCUSSION"><a href="#DISCUSSION" class="headerlink" title="DISCUSSION"></a>DISCUSSION</h2><h3 id="Bayesian-accounts-of-continual-learning"><a href="#Bayesian-accounts-of-continual-learning" class="headerlink" title="Bayesian accounts of continual learning."></a>Bayesian accounts of continual learning.</h3><p>根据标准的贝叶斯CL观点，后验参数分布是使用贝叶斯规则递归更新的，因为任务到达了. 虽然这种方法在理论上是合理的<strong>，但在实践中，通常首选的近似推理方法会导致僵硬的模型，因为必须在第一个任务确定的模式内找到适合所有任务的折中方案。</strong> 这种限制并不适用于超网络，它原则上可以为复杂的多模态分布建模。因此，丰富的、超网络建模的先验是贝叶斯CL方法的一个改进途径。有趣的是，任务条件提供了另一种可能性：<strong>与其把每个任务合并到一个单一的分布上，不如利用一个共享的任务条件超网络来模拟一组参数后验分布。这种条件元模型自然地将我们的框架扩展到贝叶斯学习环境中。与传统的递归贝叶斯更新相比，这种方法可能会受益于额外的灵活性。</strong></p><h3 id="Related-approaches-that-rely-on-task-conditioning"><a href="#Related-approaches-that-rely-on-task-conditioning" class="headerlink" title="Related approaches that rely on task-conditioning."></a>Related approaches that rely on task-conditioning.</h3><p>我们的模型符合，并在某些方面概括了以前的CL方法，该方法将网络计算置于任务描述符上。任务条件通常在模块（Rusu等人，2016；Fernando等人，2017）、神经元（Serra等人，2018；Masse等人，2018）或权重（Mallya和Lazebnik，2018）层面上使用乘法掩码来实现。这类方法在大型网络中效果最好，而且有很大的存储开销，通常随着任务数量的增加而增加。我们的方法与之不同，它使用元模型，即超网络，明确地对全部参数空间进行建模。由于这个元模型，参数和任务空间的泛化是可能的，任务与任务之间的依赖关系可以被利用来有效地表示解决方案，并将目前的知识转移到未来的问题中。有趣的是，与我们同时进行的工作中也得出了类似的论点（Lampinen &amp; McClelland, 2019），在那里，任务嵌入空间在几率学习的背景下被进一步探索。同样，和这里开发的方法一样，最近在CL中的工作将最后一层网络参数作为管道的一部分来生成，以避免灾难性遗忘（Hu等人，2019），或者将参数提炼到一个收缩的自动编码模型上（Camp等人，2018）。</p><h3 id="Positive-backwards-transfer"><a href="#Positive-backwards-transfer" class="headerlink" title="Positive backwards transfer."></a>Positive backwards transfer.</h3><p>在其目前的形式下，<strong>超网络输出正则器保护以前学到的解决方案不发生变化，这样就只能发生弱的信息反向转移</strong>。鉴于选择性遗忘和完善过去的记忆在实现智能行为方面的作用（Brea等人，2014年；Richards和Frankland，2017年），调查和改进反向转移是未来研究的一个重要方向。</p><h3 id="Relevance-to-systems-neuroscience"><a href="#Relevance-to-systems-neuroscience" class="headerlink" title="Relevance to systems neuroscience."></a>Relevance to systems neuroscience.</h3><p>揭示支持大脑和人工神经网络持续学习的机制是一个长期存在的问题（McCloskey &amp; Cohen, 1989; French, 1999; Parisi et al., 2019）。最后，我们对我们的工作进行了推测性的系统解释（Kumaran等人，2016；Hassabis等人，2017），作为大脑皮层中自上而下的调制信号的模型。<strong>任务嵌入可以被看作是低维语境开关，它决定了一个调节系统的行为，在我们的案例中是超网络。</strong>根据我们的模型，超网络将反过来调节目标皮质网络的活动。</p><p>就目前而言，实现超网络需要动态地改变目标网络或皮层区域的整个连接。这样的过程在大脑中似乎很难想象。然而，这种严格的字面解释是可以放松的。例如，超网络可以输出低维的调节信号（Marder，2012），而不是一整套的权重。 这种解释与越来越多的工作是一致的，这些工作表明调节性输入参与实施上下文或任务相关的网络模式切换（Mante等人，2013；Jaeger，2014；Stroud等人，2018；Masse等人，2018）。</p><h2 id="CONCLUSION"><a href="#CONCLUSION" class="headerlink" title="CONCLUSION"></a>CONCLUSION</h2><p>我们引入了一种新的神经网络模型—任务条件超网络，它非常适合于CL问题。任务条件超网络是一个元模型，它可以学习目标函数的参数化，这些目标函数是用任务嵌入向量以压缩的形式指定和识别的。过去的任务使用超网络输出正则器保存在内存中，该正则器对以前发现的目标权重配置的变化进行惩罚。这种方法是可扩展的和通用的，可作为独立的CL方法或与生成性重放结合使用。我们的结果在标准基准上是最先进的，并表明任务条件下的超网络可以实现较长的记忆寿命，以及将信息转移到未来的任务中，这是持续学习者的两个基本属性。</p><h2 id="TASK-CONDITIONED-HYPERNETWORKS-MODEL-SUMMARY"><a href="#TASK-CONDITIONED-HYPERNETWORKS-MODEL-SUMMARY" class="headerlink" title="TASK-CONDITIONED HYPERNETWORKS: MODEL SUMMARY"></a>TASK-CONDITIONED HYPERNETWORKS: MODEL SUMMARY</h2><p>在我们的模型中，一个有任务条件的超网络产生一个目标神经网络的参数 $Θ<em>{trgt} = f</em>{trgt} (e, Θ<em>{trgt} )$。给定一个这样的参数化，目标模型然后根据输入数据计算预测值 $\hat y=f</em>{trgt}(x,Θ<em>{trgt})$。学习相当于调整超网络的参数 $Θ_h$。超网络的参数，包括一组任务嵌入 ${e^{(t)}}^T</em>{t=1}$，以及一组分块嵌入 ${c<em>i}^{N_C}</em>{i=1}$，以便在寻求压缩或整个超网络太大而无法直接处理的情况下。<strong>为了避免灾难性的遗忘，我们引入了一个输出正则器，它通过惩罚目标模型参数的变化来固定超网络的行为，这些变化是针对以前学习的任务而产生的。</strong></p><h3 id="Variables-that-need-to-be-stored-while-learning-new-tasks"><a href="#Variables-that-need-to-be-stored-while-learning-new-tasks" class="headerlink" title="Variables that need to be stored while learning new tasks."></a>Variables that need to be stored while learning new tasks.</h3><p>在持续学习时，我们的模型的存储要求是什么？</p><ul><li>内存保留依赖于每个任务保存一个嵌入。因此，这个集合 ${e^{(t)}}^T_{t=1}$随T线性增长。这种线性扩展在渐进上是不可取的，但它在实践中基本上可以忽略不计，因为每个嵌入是一个单一的低维向量（例如，见图4中的2D嵌入运行）。</li><li>在学习一个新任务之前，需要保留超网络参数 $Θ^∗_h$的冻结快照，以评估公式2中的输出正则器。</li></ul><h2 id="ADDITIONAL-DETAILS-ON-HYPERNETWORK-PROTECTED-REPLAY-MODELS"><a href="#ADDITIONAL-DETAILS-ON-HYPERNETWORK-PROTECTED-REPLAY-MODELS" class="headerlink" title="ADDITIONAL DETAILS ON HYPERNETWORK-PROTECTED REPLAY MODELS"></a>ADDITIONAL DETAILS ON HYPERNETWORK-PROTECTED REPLAY MODELS</h2><h3 id="Variational-autoencoders"><a href="#Variational-autoencoders" class="headerlink" title="Variational autoencoders."></a>Variational autoencoders.</h3><p>对于正文中报告的所有HNET+TIR和HNET+R实验，我们使用VAE作为我们的重放模型（图A1a，Kingma &amp; Welling，2014）。简而言之，VAE由一对编码器-解码器网络组成，其中编码器网络处理一些输入模式 $x$，其输出 $f<em>{enc}(x) = (μ, σ^2)$ 包括一个对角多变量高斯 $p_Z (z; μ, σ^2)$的参数 $μ$ 和 $σ^2$（在对数域中编码，以强制执行非负性），它支配着潜在样本 $z$ 的分布。在电路的另一端，解码器网络处理一个潜伏样本 $z$ 和一个one-hot编码的任务身份向量，并返回一个输入模式重建，$f</em>{dec}（z，1_t）=\hat x$。</p><p>VAEs可以使用一种叫做生成性重放的技术来保存记忆：当训练任务$T$时，通过改变 $1_t$ 和抽取潜伏空间样本 $z$，从当前重放网络中生成旧任务 $t&lt;T$ 的输入样本。生成的数据可以与当前数据集混合，产生一个增强的数据集 $\gat X$，用于重新学习模型参数。当保护一个判别性模型时，可以通过在 $\hat X$上评估网络来生成合成的 “软 “目标。我们使用这种策略来保护HNET+TIR中的辅助任务推理分类器，并保护HNET+R中的主要目标模型。</p><h3 id="Hypernetwork-protected-replay"><a href="#Hypernetwork-protected-replay" class="headerlink" title="Hypernetwork-protected replay."></a>Hypernetwork-protected replay.</h3><p>在我们的HNET+TIR和HNET+R实验中，我们通过任务条件超网络 $f<em>{h,dec}(e,Θ</em>{h,dec})$ 对解码器网络进行参数化。与我们的输出正则器相结合，这使我们能够利用超网络的记忆保留能力，现在是在生成模型上。</p><p>重放模型（编码器、解码器和解码器超网络）是一个独立的子系统，独立于目标网络进行优化。它的参数 $Θ<em>{enc}$和$Θ</em>{h,dec}$是通过最小化我们的正则化损失函数（公式2）来学习的，这里的任务特定项被设置为标准的VAE目标函数：</p><script type="math/tex; mode=display">L_{VAE}(X,\theta_{enc},\theta_{h,dec}) = L_{rec}(X,\theta_{enc},\theta_{dec}) + L_{prior}(X,\theta_{enc},\theta_{dec})</script><p>$Θ<em>{dec} = f</em>{h,dec}(e, Θ<em>{h,dec})$引入对 $Θ</em>{h,dec}$的依赖。$L<em>{VAE}$平衡了一个重建 $L</em>{rec}$和一个先验匹配 $L_{prior}$的惩罚。对于我们的MNIST实验，我们选择二进制交叉熵（在像素空间）作为重建损失，我们在下面写出一个单一的例子 x</p><script type="math/tex; mode=display">L_{rec} (x,\theta_{enc},\theta_{dec}) = L_{xent}(x,f_{dec}(z, 1_{t(x)}, \theta_{dec}))</script><p>其中$L<em>{xent}(t,y) = - \sum</em>{k}t_klogy_k$是交叉熵，对于一个对于对角线高斯 $p_Z$，先验匹配项可以用分析法评估:</p><script type="math/tex; mode=display">L_{prior} = -\frac{1}{2}\sum_{i=1}^{|z|}(1+log\sigma^2_i-\sigma_i^2-\mu_i^2)</script><p>以上，$z$ 是通过重新参数化技巧获得的 $p<em>Z（z;μ(\hat x),σ^2(\hat x))$的样本（Kingma &amp; Welling，2014；Rezende等人，2014）。这就引入了 $L</em>{rec}$对 $Θ_{enc}$的依赖性。</p><h3 id="Task-inference-network-HNET-TIR"><a href="#Task-inference-network-HNET-TIR" class="headerlink" title="Task inference network (HNET+TIR)."></a>Task inference network (HNET+TIR).</h3><p>在HNET+TIR设置中，我们将我们的系统扩展到包括一个任务推理神经网络分类器 $α(x)$，参数为 $Θ_{TI}$，其中任务被编码为一个T-维softmax输出层。在CL2和CL3场景中，我们对 $α$ 使用了一个不断增长的单头设置，并随着任务的到来增加softmax层的维度。</p><p>当任务不断被学习时，这个网络很容易出现灾难性的遗忘。为了防止这种情况的发生，我们借助于上述由超网络保护的VAE产生的重放数据。更具体地说，我们引入了一个任务推理损失。</p><script type="math/tex; mode=display">L_{TI} (\hat x,\theta_{TI}) = L_{xent} (1_{t(\hat x)}, \alpha(\hat x,\theta_{enc}))</script><p>其中 $t(\hat x)$表示从增强的数据集 $\hat X= {\hat X^{(1)},…,\hat X^{(T-1)},\hat X^{(t)}}$,  其中 $\hat X^{(t)}$  是 $t=1…T-1$ 的合成数据$f<em>dec(z,1_t,Θ</em>{dec})$，而 $\hat X^{(T)}= X^{(T )}$是当前任务数据。重要的是，合成数据对于获得任务推理的定义明确的目标函数至关重要；交叉熵损失$L_{TI}$至少需要两个groundtruth类来进行优化。请注意，重放的数据可以通过从先验中抽取样本 $z$ 来在线生成。</p><p><img src="https://s2.loli.net/2022/01/04/SqdsY5u42WpNBUr.png" alt=""></p><p>图A1：超网络保护的重放模型设置。(a) 一个超网络保护的VAE，我们用于HNET+R和HNET+TIR正文实验。(b) 一个超网络保护的GAN，我们用于类增量学习附录F的实验。(c) 一个用合成重放数据保护的任务推理分类器，用于HNET+TIR的实验。</p><h3 id="Hypernetwork-protected-GANs"><a href="#Hypernetwork-protected-GANs" class="headerlink" title="Hypernetwork-protected GANs"></a>Hypernetwork-protected GANs</h3><p>生成对抗网络（Goodfellow等人，2014年）已经成为生成建模的既定方法，与VAE相比，往往能产生更高质量的图像，即使是在ImageNet这样复杂的数据集规模下（Brock等人，2019年；Lucˇić等人，2019年；Donahue &amp; Simonyan，2019年）。这使得GAN成为强大重放模型的完美候选者。Wu等人（2018）研究的条件GAN（Mirza &amp; Osindero，2014）是CL的一个合适的GAN实例。GAN文献的最新发展已经暗示了使用类似超网络结构的潜力，例如，在注入潜伏噪声时（Karras等人，2019年）或使用类条件批量规范化时，如（Brock等人，2019年）。我们建议更进一步，使用一个超网络，将条件映射到生成器参数的完整集合 $Θ^∗_{gen}$。我们的框架允许一次训练一个条件性的GAN。这可能具有普遍意义，并超出了重放模型的范围，因为像Brock等人（2019）那样以多任务方式训练的条件GAN需要非常大的计算资源。</p><p>对于我们关于类增量MNIST学习的展示实验，图A8，我们的目的不是与相关工作进行比较，因此没有调整超网络中的权重比目标网络中的权重少（对于VAE实验，我们使用与正文中相同的压缩设置，见附录C）。GAN超网络是一个全连接的分块超网络，有2个大小为25和25的隐藏层，然后是75000的输出大小。我们对鉴别器和生成器超网络的学习率都是0.0001，鉴别器的辍学率也是0.4，系统对每个任务进行了10000次迭代训练。我们在实验中使用Mao等人（2017）的Pearson Chi2 Least-Squares GAN损失。</p><h2 id="ADDITIONAL-EXPERIMENTAL-DETAILS"><a href="#ADDITIONAL-EXPERIMENTAL-DETAILS" class="headerlink" title="ADDITIONAL EXPERIMENTAL DETAILS"></a>ADDITIONAL EXPERIMENTAL DETAILS</h2><p>所有的实验都是使用16个NVIDIA GeForce RTX 2080 TI显卡进行的。</p><p>为了简单起见，我们决定始终保持以前的任务嵌入 $e^{(t)}$ , $t = 1, . . . , T - 1$，固定不变，只学习当前的任务嵌入 $e^{(T)}$。一般来说，如果公式2中的正则器有一份学习当前任务之前的任务嵌入 $e^{(t,∗)}$的单独副本，这样 $e^{(t)}$就可以被适应，性能就应该得到提高。因此，目标成为 $f_h(e^{(t,∗)},Θ^∗_h)$ 并保持不变。同时学习任务T。这将使超网络具有调整嵌入的灵活性，即目标的预像，因此代表了任何包括其图像中所有期望目标的函数。</p><p>HNET+TIR的VAE的细节。对于这个变异自动编码器，我们使用两个全连接的神经网络，编码器的层数为1000，1000，解码器为1000，潜伏空间为100。这个设置也是从我们比较的工作中复制过来的。</p><p>HNET+R的VAE的细节。对于这个变异自动编码器，我们使用两个全连接的神经网络，编码器的层数为400，400，解码器的层数为400，400（在相关工作中都是1000，1000），潜空间的维度为100。这里，我们与相关工作不同，为自动编码器选择了一个较小的架构。请注意，我们仍然使用一个超网络，其可训练的参数比相关工作中使用的目标网络（在这种情况下是解码器）少。</p><p>PermutedMNIST-10中目标分类器的超网络细节（HNET+TIR &amp; HNET+ENT）。我们使用与上述VAE相同的超网络设置，但由于目标网络较小，我们将超网络的输出减少到78,000。我们还将参数βoutput调整为0.01，与我们的PermutedMNIST-100实验一致。因此，这个超网络的权重数量是2,029,931个参数（2,029,691个网络权重+240个任务嵌入权重）。相应的目标网络（来自相关工作）将有2,126,100个权重用于CL1和CL3，2,036,010用于CL2（只有一个输出头）。</p><p>PermutedMNIST-100的目标分类器的超网络细节。在这些实验中，我们选择了一个在PermutedMNIST-10基准上运行良好的架构，没有再进行新架构的搜索。对于PermutedMNIST-100，报告的结果是通过使用一个分块超网络获得的，该网络有3个隐藏层，大小为200、250和350（CL2为300），输出大小为7500（CL2为6000）（这样，我们大约与CL1/CL2/CL3的相应目标网络大小一致）。有趣的是，图A2b显示，即使我们不根据目标网络权重的增加来调整超网络权重的数量，我们方法的优越性也是显而易见的。除此之外，图3中的图是用PermutedMNIST-10 HNET+TIR设置生成的（注意，这包括相关工作为PermutedMNIST-10设定的条件，如目标网络大小、训练迭代次数、学习率等）。</p><p>PermutedMNIST-100中用于CL2/CL3的VAE和超网络的细节。我们对VAE和它在HNET+TIR中用于PermutedMNIST-10的超网络使用了非常类似的设置，如上所述。我们只做了以下改动。全连接超网络有一个大小为100的隐藏层；块嵌入大小被设置为12；任务嵌入大小被设置为两个128，VAE的隐藏层大小为400，600。同时，我们增加了VAE其生成器超网络的正则化强度βoutput=0.1。</p><p>HNET+TIR和HNET+ENT的目标分类器的细节。对于这个分类器，我们使用与我们比较的研究（van de Ven &amp; Tolias, 2019）相同的设置，即一个全连接的网络，层的大小为1000，1000。请注意，如果该分类器被用作任务推理模型，它是在重放数据和相应的硬目标，即软目标的argmax上训练的。</p><h1 id="Continual-Model-Based-Reinforcement-Learning-with-Hypernetworks"><a href="#Continual-Model-Based-Reinforcement-Learning-with-Hypernetworks" class="headerlink" title="Continual Model-Based Reinforcement Learning with Hypernetworks"></a>Continual Model-Based Reinforcement Learning with Hypernetworks</h1><p>使用超网络的任务意识持续学习是一种有效和实用的方法，可以适应新的任务和不断变化的动态，用于基于模型的强化学习，而不需要保留旧任务的状态转换，也不需要向动态模型增加容量。</p><h2 id="Hypernetworks-for-Continual-Learning"><a href="#Hypernetworks-for-Continual-Learning" class="headerlink" title="Hypernetworks for Continual Learning."></a>Hypernetworks for Continual Learning.</h2><p>超网络[35], [36]是一个生成另一个神经网络的权重的网络。具有权重 $Θ$ 的超网络 $H<em>Θ(e)=θ$ 可以以嵌入向量 $e$ 为条件，通过改变嵌入向量 $e$ 来输出主（目标）网络的权重 $θ$ ，$f</em>θ(x) = f(x; θ) = f(x; H_Θ(e))$。</p><p>与主网络相比，超网络的可训练参数数量通常更大，因为超网络中输出层的大小等于目标网络中权重的数量。</p><p>超网络已被证明在持续学习环境下[1]对分类和生成模型很有用。这已被证明可以缓解一些灾难性遗忘的问题。它们也被用来实现基于梯度的超参数优化[37]。</p><p>我们考虑MBRL的求解设置，它有一个学习的动力学模型，<strong>其参数是通过一个任务条件超网络推断出来的</strong>。考虑到学习到的任务嵌入 $e<em>t$ 和超网络 $H(-)$ 的参数 $Θ_t$，我们推断出动态神经网络 $f</em>{θ_t}(-)$的参数 $θ_t$。利用这个动力学模型，我们进行CEM优化，生成动作序列，并在环境中用MPC执行K个时间步长。我们将观察到的过渡存储在重放数据集中，并更新超网络的参数 $Θ_t$ 和任务嵌入等（非政策性优化）。我们对每个任务的 $M$ 个插曲，以及每 $T$ 个任务的顺序重复这一过程。</p><p>动态学习。学习的动力学模型是一个前馈神经网络，其参数在不同的任务中是不同的。在不同的任务中学习动力学网络$f<em>θ(-)$的一种方法是随着训练的进行按顺序更新它。然而，由于我们的问题设置是不允许代理人在重放缓冲器中保留以前任务的状态转换数据，因此在不同任务中按顺序调整单个网络的权重可能会导致灾难性的遗忘[1]。为了减轻灾难性遗忘的问题，**同时试图适应网络的权重，我们学习一个超网络，将任务嵌入作为输入，并输出每个任务对应的动态网络的参数，为每个任务t学习不同的动态网络 $f</em>{θ_t}（-）$。**</p><p>我们假设代理人有有限的内存，并且不能访问跨任务的状态转换数据。因此，在每个任务 $t$ 开始时，特定任务的重放缓冲器 $D<em>t$ 被重置。对于当前的情节，代理人使用 $θ_t=H</em>{Θ<em>t}（e_t）$生成一个动力学网络 $f</em>{θ<em>t}$。然后，对于 $k=1…K$个时间段和规划期限 $h$，代理人使用CEM优化行动序列 $a</em>{k：k+h}$，并执行第一个行动 $a<em>k$（MPC）。$D_t$被一个元组（$s_k$,$a_k$, $s</em>{k+1}$）所增强，其中 $s<em>k$ 是当前状态，$a_k$是已执行的行动，$s</em>{k+1}$是任务t下的下一个观察状态。</p><p>超网络的参数 $Θ<em>t$ 和任务嵌入 $e_t$ 通过反向传播梯度更新，涉及动态损失 $L</em>{dyn}$和正则化项之和。</p><p>我们定义了动态损失 $L<em>{dyn}(\theta_t, e_t) = \sum</em>{D<em>t}||\hat s</em>{k+1} - s<em>{k+1}||_2$ , 预测的下一状态在哪里 $\hat s</em>{k+1} = f<em>{\theta_t}(s_k, a_k)$ 和 $\theta_t = H</em>{\theta_t}(e_t)$</p><p>$\hat s<em>{k+1}=f</em>{\theta<em>t}(s_k,a_k)$ 和 $\theta_t = H</em>{\theta_t}(e_t)$</p><p>超网络的规范化:</p><p>为了减轻灾难性的遗忘，我们对超网络的输出进行正则化，即所有以前的任务嵌入 $e<em>{1:t-1}$。在对任务 $t-1$进行训练后，超网络权重的快照被保存为 $Θ</em>{t-1}$。</p><p>对于每个过去的任务 $i = 1…t - 1$，我们使用正则化损失来保持快照 $H<em>{Θ_t} (e_i)$的输出接近当前输出 $H</em>{Θ<em>t} (e_i)$。这种方法避开了存储所有过去任务数据的需要，保留了动态网络 $f</em>{θ<em>t}$的预测性能，并且只需要存储权重空间中的一个点（超网络的副本）。任务嵌入是与超网络的参数一起学习的可微分向量。更新 $Θ_t$和 $e_t$ 的总体损失函数由动态损失 $L</em>{dyn}(-)$和正则化项$L_{reg}(-)$组成，动态损失是根据任务 $t$ 收集的数据评估的:</p><script type="math/tex; mode=display">L_t(\theta_t, e_t) = L_{dyn}(\theta_t, e_t) + L_{reg}(\theta_{t-1}, \theta_t, e_{1:t-1})</script><script type="math/tex; mode=display">L_{reg}(\cdot) = \frac{\beta_{reg}}{t-1}\sum_{i=1}^{t-1}||H_{\theta_{t-1}}(e_i) - H_{\theta_t}(e_i)||_2^2</script><p>CEM优化行动序列的计划目标是由在学习到的任务动力学模型 $f<em>{θ_t}(-)$下执行行动序列 $a</em>{k:k+h}$得到的奖励之和给出的。奖励函数 $r(s,a)$ 被假定为已知的，但在我们目前的框架下，没有什么可以排除从数据中学习它。</p><h1 id="Hypernetworks-for-Continual-Semi-Supervised-Learning"><a href="#Hypernetworks-for-Continual-Semi-Supervised-Learning" class="headerlink" title="Hypernetworks for Continual Semi-Supervised Learning"></a>Hypernetworks for Continual Semi-Supervised Learning</h1><p>从顺序到达的数据中学习，可能在非 i.i.d. 方式，随着时间的推移不断变化的任务分配被称为持续学习。 迄今为止，持续学习的大部分工作都集中在监督学习上，而最近的一些工作则集中在无监督学习上。</p><p>在许多领域，每个任务都包含标记（通常很少）和未标记（通常很多）的训练示例，这需要半监督学习方法。 为了在持续学习环境中解决这个问题，我们提出了一个半监督持续学习的框架，称为持续半监督学习的元合并 (MCSSL)。</p><p>我们的框架有一个超网络，它学习生成作为基础网络的半监督辅助分类器生成对抗网络（Semi-ACGAN）的权重的元分布。 <strong>我们在超网络中巩固序列任务的知识</strong>，基础网络学习半监督学习任务。 此外，我们提出了 Semi-Split CIFAR-10，这是一个用于持续半监督学习的新基准，通过修改 Split CIFAR-10 数据集获得，其中带有标记和未标记数据的任务按顺序到达。 我们提出的模型在持续的半监督学习环境中产生了显着的改进。 我们比较了几种现有的持续学习方法在 Semi-Split CIFAR-10 数据集提出的持续半监督学习基准上的性能。</p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>人类拥有非凡的持续学习能力，即使在顺序设置中也是如此。 在机器学习中，从可能以非 i.i.d. 连续到达的数据中学习。 使任务随时间变化的方式称为持续学习、终身学习或增量学习。 人类学习的另一个突出方面是人类并不总是需要对对象的概念进行监督，他们可以通过对相似的事物进行分组来学习。 相比之下，神经网络在以顺序方式学习新任务时表现出忘记先前获得的知识的趋势 [Kirkpatrick et al., 2017]，这通常被称为灾难性遗忘。</p><p>随着数据的日益多样化，缺乏标记数据是监督机器学习模型面临的一个普遍问题。 然而，未标记的数据很丰富，并且很容易用于训练机器学习模型。 在标准（非连续）环境中，存在几种无监督学习方法，它们可以在没有监督的情况下基于某种相似性概念进行学习。 然而，半监督学习模型可以利用标记和未标记的数据，从而实现两全其美。</p><p>大多数现有的持续学习方法都集中在监督分类设置上。 最近的一些工作探索了持续的无监督学习设置 [Lee et al., 2019; Rao et al., 2019] 专注于图像生成任务的生成模型。</p><p>然而，这些方法中的大多数都没有研究半监督的持续学习设置。 [Smith et al., 2021] 最近的一项工作探索了连续半监督设置，但他们的设置使用了 CIFAR 数据集的超类结构，因此，顺序到达的任务与我们的设置不同 . 此外，他们的方法使用判别分类器，而我们的方法使用生成模型，因为模型学习输入的分布。</p><p>因此，我们研究了一种用于连续半监督学习的新设置，其中连续学习器遇到带有标记和未标记数据的顺序到达任务。 与标准的半监督学习设置类似，未标记数据和标记数据在每个学习任务中具有内在相关性，使学习者能够利用标记数据和未标记数据。</p><p>大多数持续学习方法通过在权重（或参数）空间或数据空间中巩固知识来对抗灾难性遗忘。 根据对人脑的研究，语义知识或解决任务的能力表示在高级语义概念的元空间中。</p><p>此外，<strong>记忆会定期巩固，帮助人类持续学习 受此启发，[Joseph and Balasubramanian, 2020] 最近的工作提出了一个框架，即持续学习的元巩固 (MERLIN)，它巩固了持续任务的知识 在元空间中，即权重生成网络的参数空间</strong>。 这个权重生成网络称为超网络，它生成基础网络的参数。 这样一个基础网络负责解决特定的不断到达的下游任务。 <strong>我们在 [Joseph and Balasubramanian, 2020] 中使用具有特定任务先验的变分自动编码器 (VAE) 模型对超网络进行建模。</strong> 然而，他们只关注监督学习设置。 因此，基础网络是判别神经网络，例如前馈神经网络或改进的残差网络 (ResNet-18)。</p><p>在本文中，我们提出了 MCSSL: Meta-Consolidation for Continual Semi-Supervised Learning，这是一个源自 MERLIN [Joseph and Balasubramanian, 2020] 的框架，其中持续学习发生在权重生成过程的潜在空间中，即 ，在超网络的参数空间中。 然而，[Joseph and Balasubramanian, 2020] 使用判别分类器 (ResNets) 作为基础网络，因此他们只关注持续监督设置。与 [Joseph and Balasubramanian, 2020] 相比，我们的模型使用改进形式的辅助分类器生成对抗网络 (ACGAN) [Odena et al., 2017] 作为基础网络来执行持续的半监督学习。 GAN 中的辅助分类器提供了使用标记数据学习分类的能力。 受 [Salimans et al., 2016] 的启发，我们修改了 ACGAN 中的判别器来处理未标记的数据，我们称之为 Semi-ACGAN。 这导致在 Semi-ACGAN 训练目标中具有监督和非监督组件。 因此，类 VAE 的超网络学习生成 Semi-ACGAN 基础网络的参数，该基础网络执行半监督分类的下游任务。</p><h2 id="MCSSL-Meta-Consolidation-for-Continual-Semi-Supervised-Learning"><a href="#MCSSL-Meta-Consolidation-for-Continual-Semi-Supervised-Learning" class="headerlink" title="MCSSL: Meta-Consolidation for Continual Semi-Supervised Learning"></a>MCSSL: Meta-Consolidation for Continual Semi-Supervised Learning</h2><p>本节从持续半监督学习的问题设置开始。 在此之后，我们介绍了我们提出的框架的概述。 然后，我们将 Semi-ACGAN 描述为基本模型和 Semi-ACGAN 的训练机制。 此外，我们提供了学习特定任务参数分布的超网络 VAE 的详细信息。 此外，我们描述了超网络元整合的细节，然后是推理机制。</p><h3 id="Problem-Set-up-and-Notation"><a href="#Problem-Set-up-and-Notation" class="headerlink" title="Problem Set-up and Notation"></a>Problem Set-up and Notation</h3><p>持续半监督学习的问题涉及从顺序到达的半监督任务中学习，因为任务的数据仅在前一个任务完成后到达。 令 $T_1、T_2、···、T_K$ 为半监督任务序列，使得 $T_k$ 为时间实例 k 处的任务。</p><p>此外，对于 $j ∈{1,····,K}$，每个任务 $T$ 由 $T^{tr}_j$、$T^{val}_j$ 和 $T^{test}_j$ 组成，分别对应于任务 $j$ 的训练集、验证集和测试集。此外，我们定义</p><script type="math/tex; mode=display">T^{tr} = [\{x_m,y_m\}^{M^j_{tr}}_{m=1}, \{u_n\}^{N_{tr}^j}_{n=1}]</script><h3 id="Model-Overview"><a href="#Model-Overview" class="headerlink" title="Model Overview"></a>Model Overview</h3><p>在我们提出的框架中，<strong>超网络是一个类似于 VAE 的模型，具有特定于任务的条件先验，它对基础网络的参数分布进行建模。</strong> 对于每个任务，基础网络的多个实例使用标记和未标记的训练数据来学习下游半监督任务。 <strong>我们使用这些训练过的基础模型的权重作为训练超网络的输入。</strong> <strong>因此，超网络学习为基础网络生成任务特定的权重，最终执行连续的半监督任务。 此外，元整合使超网络能够整合来自先前任务的知识。</strong> 此外，在训练之后，在预测或推理期间对基础网络的权重进行采样和集成。</p><h3 id="Base-Model-Semi-ACGAN"><a href="#Base-Model-Semi-ACGAN" class="headerlink" title="Base Model: Semi-ACGAN"></a>Base Model: Semi-ACGAN</h3><p><img src="https://s4.ax1x.com/2022/01/21/7RzXy4.png" alt=""></p><p>基础网络是一个改进的辅助分类器 GAN (Semi-ACGAN)，因此由一个生成器 G、一个带有辅助分类器的鉴别器 D 组成。 我们使用 $Θ_k$ 表示任务 k 的基础网络的权重。</p><p>在 Semi-ACGAN 中，G 以类标签 y 和噪声 $z<em>b$ 为条件。 因此，生成的样本 $x</em>{fake} = G(z_b,y)$ 对应于一个类标签。让 s 表示样本 x 的来源是真实的还是虚假的。 对于样本 x，判别器给出源 $p(s|x)$ 上的概率分布以及类 $p(y|x)$ 上的概率分布，即 $[p(s|x), p(y| x)] = D(x)$。</p><p>让我们用 $x_{real}$ 表示真实样本，用 $\hat y$ 表示样本的实际类别。 训练目标包括以下内容：</p><ul><li><p>对于标记数据：</p></li><li><ul><li><p>a.记录正确来源的可能性，</p></li><li><script type="math/tex; mode=display">L_s^{L} = E[\log p(s=real|x_{real})] +E[\log p(s=fake|x_{fake})]</script></li><li><p>b.记录正确类别的可能性，</p></li><li><script type="math/tex; mode=display">L_c^L=E[\log p(y=\hat y|x_{real})] + E[\log p(y=\hat y|x_{fake})]</script></li></ul></li><li><p>对于无标注数据：</p></li><li><ul><li><p>a. 记录真实图像正确来源的可能性，</p></li><li><script type="math/tex; mode=display">L_s^{U} = E[\log p(s=real|x_{real})]</script></li></ul></li></ul><p>鉴别器 D 通过最大化 $L^L_c + L^L_s + L^U_s$ 来学习，而生成器 G 通过最大化 $L^L_c - L^L_s$ 来学习。</p><p>请注意，由于缺少未标记数据的类别信息，因此我们不考虑未标记数据情况下正确类别的对数似然。</p><p>生成器 G 是一个接受类标签和噪声的神经网络。 类标签嵌入是使用可训练的类嵌入层从类 id 获得的。 因此，G 学习生成特定类别的样本。</p><p>D 的共享层可以从标记数据和未标记数据中学习。 随着训练的进行，G 学习生成具有已知类标签的真实样本，使 D 能够进行更好的分类。</p><p>图 1 显示了基础网络 Semi-ACGAN 的模块。 由于真实样本可以由标记数据和未标记数据组成，图中分别使用绿色和蓝色箭头显示。 另一方面，红色箭头描绘了生成的样本。 此外，输出以类似的颜色编码。</p><h3 id="Task-specific-Parameter-Distribution-Hypernetwork"><a href="#Task-specific-Parameter-Distribution-Hypernetwork" class="headerlink" title="Task-specific Parameter Distribution: Hypernetwork"></a>Task-specific Parameter Distribution: Hypernetwork</h3><p>由于训练过的基础网络的 B 个实例被用作训练超网络的输入，我们使用 ${Θ^l<em>k}^B</em>{l=1}$ 来表示任务 k 的这个集合。 由于使用具有特定任务条件先验的 VAE 类模型作为超网络，我们将超网络的参数定义为 $[θ, φ]$，使得 $θ$ 和 $φ$ 分别是超网络的编码器和解码器参数 .</p><p>超网络 VAE 对特定于任务的参数分布 $p(Θ|t)$ 进行建模。 因此，学习超网络可以整合元空间中先前任务的知识。 第 k 个任务的向量表示 $t_j$ 可以是任何固定长度的向量表示，包括 Word2Vec [Mikolov et al., 2013]、GloVe [Pennington et al., 2014] 或只是任务标识的 one-hot 编码。 为简洁起见，我们在本小节中使用 $t$ 来表示 $t_j$。</p><p>受 MERLIN [Joseph and Balasubramanian, 2020] 的启发，超网络通过优化类似 VAE 的目标 [Kingma and Welling, 2013] 进行训练。</p><p>参数分布 $p<em>θ (Θ|t) = \int p</em>θ (Θ|z, t)p<em>θ (z|t)dz$ 的边际似然的计算是难以处理的，因为其真实后验 $p</em>{\theta}(z|Θ,t)=\frac{p<em>{\theta}(Θ|z,t) p</em>{\theta}(z|t)}{p_{\theta}(Θ|t)}$ 的计算难以处理。</p><p>因此，我们引入了一个近似变分后验 $q_\phi(z|Θ,t)$ 来解决难以处理的问题。 对数边际似然可以写成：</p><script type="math/tex; mode=display">p_{\theta}(Θ|t) = KL(q_{\phi}(z|Θ,t) || p_{\theta}(z|Θ,t) + L(\theta,\phi|Θ,t)</script><p>其中 $L(\theta,\phi|\theta,t) = \int<em>z q</em>{\phi}(z|Θ,t)\log \frac{p<em>{\theta(z,Θ|t)}}{q</em>{\phi}(z|Θ,t)}$ 是证据下限 (ELBO)。 为了最大化对数似然，可以最大化这个下限。</p><p>此外，$L(θ, φ|Θ, t)$ 可以表示为（完整推导参见[Joseph and Balasubramanian, 2020]）：</p><script type="math/tex; mode=display">L(θ, φ|Θ, t) = -KL(q_{\phi}(z|Θ,t) || p_{\theta}(z|t) + E_{q_{\phi(z|Θ,t)}}[\log p_{\theta}(Θ|z,t)])</script><p>最大化上面方程，最小化 KL 散度项，导致近似后验权重变得接近于特定任务的先验 $p_θ(z|t)$。 第二项是预期的负重构误差，它需要抽样来估计。</p><p>超网络参数 φ 和 θ，也称为编码器和解码器参数，使用反向传播和随机梯度下降进行训练。 我们假设 $p<em>θ (.)$ 和 $q</em>φ (.)$ 是高斯分布。此外，重新参数化技巧 [Kingma and Welling, 2013] 用于通过随机参数进行反向传播。 以 ${Θ^l<em>k}^B</em>{l=1}$ 作为输入，我们通过最大化 上式 来训练超网络。 </p><p>与标准 VAE 不同，特定于任务的先验不是各向同性的多元高斯。 它由以下给出：</p><script type="math/tex; mode=display">p_{\theta}(z|t) = N(z|\mu_t,\Epsilon_t)</script><p>其中 $\mu<em>t = W^T</em>{\mu} t$ 和 $\Epsilon<em>t = W^T</em>{\Epsilon}t$ 这样 $W<em>μ$ 和 $W</em>Σ$ 是可训练的参数，并与超网络参数一起学习。</p><h3 id="Meta-Consolidation"><a href="#Meta-Consolidation" class="headerlink" title="Meta-Consolidation"></a>Meta-Consolidation</h3><p>直接在 ${Θ^l<em>k}^B</em>{l=1}$ 上训练 VAE 会导致分布偏移，即偏向当前任务 $k$。 因此，超网络 VAE 需要巩固来自先前任务的知识。我们称之为元整合。 我们存储所有学习到的特定于任务的先验的均值和协方差，这增加了可以忽略不计的存储复杂性。 元整合机制描述如下：</p><p>1.对于直到当前任务 $k (j=1,…,k) $的每个任务 $z_{t_j}$，</p><ul><li><p>(a) 来自特定任务的先验样本 $z_{t_j }$：</p><script type="math/tex; mode=display">z_{t_j} \sim N(z|\mu_{t_j}, \Epsilon_{t_j})</script></li><li><p>(b) 从解码器中采样 P 个半监督基础伪模型：</p><script type="math/tex; mode=display">Θ_j^i \sim p_{\theta}(Θ|z_{t_j}, t_j); \ where \ \ i\in\{1,2,...,P\}</script></li><li><p>(c)使用公式5计算损失：</p><script type="math/tex; mode=display">Loss = \sum_{i=1}^P L(Θ,\phi|Θ^i_j,t_j)</script></li><li><p>(d)优化 Loss 以更新参数φ，θ</p></li></ul><h3 id="Inference"><a href="#Inference" class="headerlink" title="Inference"></a>Inference</h3><p>学习特定于任务的参数分布 $p_θ(Θ|z,t)$ 可以在推理过程中对多个 $Θ$ 进行采样。 这种能力提供了多个模型的集成效果，而无需先验地存储模型。 与大多数其他持续学习方法一样，我们在推理过程中使用一个小的示例内存缓冲区 $\epsilon$ 进行微调。</p><p>我们的方法可以在推理过程中使用或不使用特定于任务的信息。 然而，我们专注于与任务无关的设置，因为它更加现实和具有挑战性。 任务无关推理的推理过程如下所述：</p><h1 id="HYPERMODELS-FOR-EXPLORATION"><a href="#HYPERMODELS-FOR-EXPLORATION" class="headerlink" title="HYPERMODELS FOR EXPLORATION"></a>HYPERMODELS FOR EXPLORATION</h1><p>我们考虑由参数空间 $θ$ 的元素 $θ$ 参数化的基本模型。 给定 $θ$ ∈ $Θ$ 和输入 $X<em>t ∈ R^{N_x}$ ，基本模型假设输出 $Y</em>{t+1} ∈ R$ 的条件期望由 $E[Y<em>{t+1}|X_t,θ] = f</em>θ(X_t)$ 给出，对于某些函数 f 由 θ 索引。 图 1a 描述了这类参数化基础模型。</p><p>超模型由参数 ν 参数化，参数 ν 标识函数 $g_ν : Z 􏰝→ Θ$。我们将每个 z ∈ Z 称为索引，因为它标识了基本模型的特定实例。 特别是，给定超模型参数 ν，可以通过选择 z ∈ Z 并设置 θ = gν (z) 来生成基本模型参数 θ。</p><p>这种超模型的概念如图 1b 所示。 与超模型一起，为了表示基础模型上的分布，我们必须指定一个参考分布 $p_z$，它可用于对 Z 的元素进行采样。超模型和参考分布通过提供一种机制共同表示基础模型上的分布 通过对索引进行采样并通过映射对其进行采样。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;[TOC]&lt;/p&gt;
&lt;h1 id=&quot;Continual-Learning-with-Hypernetworks&quot;&gt;&lt;a href=&quot;#Continual-Learning-with-Hypernetworks&quot; class=&quot;headerlink&quot; title=&quot;Conti</summary>
      
    
    
    
    
    <category term="context detection" scheme="http://example.com/tags/context-detection/"/>
    
  </entry>
  
  <entry>
    <title>PromptBERT: Improving BERT Sentence Embeddings with Prompts</title>
    <link href="http://example.com/2021/12/02/PromptBERT-Improving-BERT-Sentence-Embeddings-with-Prompts/"/>
    <id>http://example.com/2021/12/02/PromptBERT-Improving-BERT-Sentence-Embeddings-with-Prompts/</id>
    <published>2021-12-02T12:31:29.000Z</published>
    <updated>2021-12-21T07:07:19.885Z</updated>
    
    <content type="html"><![CDATA[<h1 id="PromptBERT-Improving-BERT-Sentence-Embeddings-with-Prompts"><a href="#PromptBERT-Improving-BERT-Sentence-Embeddings-with-Prompts" class="headerlink" title="PromptBERT: Improving BERT Sentence Embeddings with Prompts"></a>PromptBERT: Improving BERT Sentence Embeddings with Prompts</h1><p>在以前的工作中，原始的BERT在句子语义相似性方面的表现不佳，已经被广泛讨论。我们发现，不尽如人意的表现主要是由于静态 token 嵌入的偏差和无效的 BERT 层，而不是因为句子嵌入的高余弦相似度。</p><p>为此，我们提出了一种 prompt based 的句子嵌入方法，它可以减少 token 嵌入的偏差，使原来的BERT层更加有效。通过将句子嵌入任务重新表述为填空问题，我们的方法显著提高了原始BERT的性能。我们讨论了 prompt based 的句子嵌入的两种 prompt 表示方法和三种 prompt 搜索方法</p><p>此外，我们通过模板去噪技术提出了一个新的无监督训练目标，这大大缩短了有监督和无监督设置之间的性能差距。</p><p>在实验中，我们对我们的方法在非微调和微调的设置上进行评估。即使是一个非微调的方法，也可以在STS任务上超过微调的方法，如无监督的ConSERT。我们的微调方法在无监督和有监督的情况下都优于最先进的方法SimCSE。与SimCSE相比，在无监督设置下，我们在BERT和RoBERTa上分别取得了2.29和2.58分的改进。</p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>以前的研究将各向异性与解释原始BERT的不良性能联系起来（Li等人，2020；Yan等人，2021；Gao等人，2021）。各向异性使得 token 嵌入占据一个狭窄的锥体，导致任何句子对之间的高相似度 </p><p>Li 等人（2020）提出了一种归一化 flows 方法，将句子嵌入分布转化为平滑和各向同性的高斯分布，Yan等人（2021）提出了一个对比性框架来迁移句子表示。这些方法的目标是消除句子嵌入中的各向异性。然而，我们发现，各向异性并不是导致语义相似性差的主要原因。例如，在语义文本相似性任务中，对原始BERT的最后一层进行平均，甚至比对其静态token 嵌入进行平均更差，但最后一层的句子嵌入比静态 token 嵌入的各向异性要小。</p><p>根据这一结果，我们发现原始的 BERT层 实际上损害了句子嵌入的质量。然而，如果我们将静态 token 嵌入视为单词嵌入，与GloVe相比，它产生的结果仍然不能令人满意。受（Li等人，2020）的启发，他们发现 token 频率偏向其分布，我们发现分布不仅偏向频率，还偏向WordPiece（Wu等人，2016）中的大小写和子词。 </p><p>我们设计了一个简单的实验来测试我们的猜想，只需去除这些有偏的token（如高频子词和标点符号），并使用剩余token嵌入的平均值作为句子表示。它可以超越Glove，甚至取得与后处理方法BERT-flow（Li等人，2020）和BERT-whitening（Su等人，2021）相当的结果。</p><p>在这些发现的激励下，避免嵌入偏差可以提高句子表述的性能。然而，手动消除嵌入偏差是很费力的，而且如果句子太短，可能会导致一些有意义的词被遗漏。</p><p>受(Brown et al., 2020)的启发，将不同的NLP任务通过不同的 prompt 重新表述为填空问题，我们提出了一种基于 prompt 的方法，使用模板来获得BERT中的句子表述。</p><p>Prompt based 的方法可以避免嵌入偏差并利用原始BERT层。我们发现原始的BERT在句子嵌入的模板帮助下可以达到合理的性能，它甚至超过了一些基于BERT的方法，这些方法在下游任务中对BERT进行了微调。</p><p>我们的方法同样适用于微调的设置。目前的方法利用对比学习来帮助BERT学习更好的句子嵌入（Gao等人，2021；Yan等人，2021）。然而，无监督的方法仍然存在泄漏适当积极对的问题。Yan等人（2021）讨论了四种数据增强方法，但其性能似乎比直接使用BERT中的 dropout 作为噪声要差（Gao等人，2021）。</p><p>我们发现 prompt 可以提供一个更好的方法，通过不同模板的不同观点来生成正数对。为此，我们提出了一种基于prompt的对比学习方法，该方法带有模板去噪功能，可以在无监督的情况下利用BERT的力量，这大大缩短了有监督和无监督性能之间的差距。我们的方法在无监督和有监督的情况下都取得了最先进的结果。</p><h2 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h2><p>学习句子嵌入作为一个基本的NLP问题已经被大量研究。目前，如何在句子嵌入中利用BERT的力量已经成为一个新的趋势。许多工作（Li等人，2020年；Gao等人，2021年）在有监督和无监督的情况下都用BERT取得了强大的性能。在这些工作中，基于对比学习的方法取得了最先进的成果。这些工作（Gao等人，2021；Yan等人，2021）注意构建积极的句子对。Gao等人（2021）提出了一个新颖的对比性训练目标，直接使用内部 dropout 作为噪声来构建正向句对。Yan等人（2021）讨论了四种构建积极句对的方法。</p><p>虽然BERT在句子嵌入方面取得了巨大的成功，但原始BERT的表现并不令人满意。原始BERT的上下文令牌嵌入甚至比GloVe等词嵌入的表现还差。一种解释是原始BERT中的各向异性，这导致句子对具有高相似性。根据这一解释，BERT-flow（Li等人，2020）和 BERT-whitening（Su等人，2021）已被提出，通过对原始BERT的句子嵌入进行后处理来减少各向异性。</p><h2 id="Rethinking-the-Sentence-Embeddings-of-Original-BERT"><a href="#Rethinking-the-Sentence-Embeddings-of-Original-BERT" class="headerlink" title="Rethinking the Sentence Embeddings of Original BERT"></a>Rethinking the Sentence Embeddings of Original BERT</h2><p>以前的工作（Yan等人，2021年；Gao等人，2021年）解释了原始BERT的不良性能是由学习的各向异性的 token 嵌入空间限制的，其中 token 嵌入占据一个狭窄的锥体。然而，我们通过研究各向异性和性能之间的关系发现，各向异性并不是诱发不良语义相似性的关键因素。我们认为主要原因是无效的BERT层和静态 token 嵌入偏差。</p><h3 id="Observation-1-Original-BERT-layers-fail-to-improve-the-performance"><a href="#Observation-1-Original-BERT-layers-fail-to-improve-the-performance" class="headerlink" title="Observation 1: Original BERT layers fail to improve the performance"></a>Observation 1: Original BERT layers fail to improve the performance</h3><p>在本节中，我们通过比较两种句子嵌入方法来分析 BERT 层的影响：平均静态 token 嵌入（BERT层的输入）和平均最后层（BERT层的输出）。我们报告了句子嵌入的性能和它的句子水平各向异性。</p><p>为了测量各向异性，我们遵循（Ethayarajh，2019）的工作，测量句子嵌入中的句子水平各向异性。让 $s_i$ 是出现在语料库${s_1, …, s_n }$ 中的一个句子。该各向异性可按以下方式测量:</p><script type="math/tex; mode=display">\frac{1}{n^2-n} |\sum_i\sum_{j\neq i} cos(M(s_i), M(s_j))|</script><p>其中 M 定义为表示语句嵌入方法，它将原始句子映射到其嵌入，cos是余弦相似度。换句话说，M的各向异性是通过一组句子的平均余弦相似度来衡量的。</p><p>如果句子嵌入是各向同性的（即方向均匀），那么均匀随机抽样的句子之间的平均余弦相似度将是0（Arora等人，2016）。它越接近于1，句子的各向异性就越大。我们从维基百科语料库中随机抽取100,000个句子来计算各向异性。</p><p>我们比较了不同的预训练模型（Bert-base-uncased、Bert-base-cased和Roberta-base）和不同的句子嵌入方法（最后一层平均法、最后一个隐藏层token作为句子嵌入和静态token嵌入的平均法、直接对静态token嵌入的平均法）。我们在表1中显示了这些方法的spearman相关性和句子水平各向异性。</p><p><img src="https://s2.loli.net/2021/12/20/mHGx3YdhwRoKCfM.png" alt=""></p><p>如表1所示，我们发现bert-base-uncased和roberta-base中的BERT层明显损害了句子嵌入性能。即使在bert-base-cased中，BERT层的增益也是微不足道的，只有0.28的改善。我们还展示了每种方法的句子层面的各向异性。BERT层的性能下降似乎与句子水平各向异性无关。例如，最后一层的平均值比bert-base-uncased中的静态标记嵌入平均值更加各向同性。然而，静态标记嵌入平均数实现了更好的句子嵌入性能。</p><h3 id="Observation-2-Embedding-biases-harms-the-sentence-embeddings-performance"><a href="#Observation-2-Embedding-biases-harms-the-sentence-embeddings-performance" class="headerlink" title="Observation 2: Embedding biases harms the sentence embeddings performance."></a>Observation 2: Embedding biases harms the sentence embeddings performance.</h3><p>Li等人（2020）发现，token嵌入会对 token 频率产生偏差。Yan等人（2021）也研究了类似的问题。BERT静态令牌嵌入的各向异性对令牌频率很敏感。因此，我们研究了嵌入偏差是否会产生不理想的句子嵌入性能。我们观察到，token嵌入不仅对token频率有偏见，而且对WordPiece（Wu等人，2016）中的子词和大小写敏感。</p><p>如图1所示，我们在bert-base-uncased、bert-base-cased 和 roberta-base 的token embeddings 中直观地看到这些偏差。三种预训练模型的 token 嵌入受到 token 频率、子词和大小写的高度偏向。根据子词和大小写的偏差，token 嵌入可以大致分为三个区域：1）小写的词首token，2）大写的词首token和3）子词token。对于无大小写的预训练模型bert-base-uncased，token嵌入也可以大致分为两个区域。1）词首token，2）子词token。</p><p>对于频率偏差，我们可以观察到，在所有的模型中，高频率的token是聚集的，而低频率的 token 是稀疏地分散的（Yan等人，2021）。在BERT中，词首 token 比子词token 更容易受到频率的影响。然而，在RoBERTa中，子词 token 更容易受到影响。</p><p>以前的工作（Yan等人，2021；Li等人，2020）经常将 “token嵌入偏见 “的概念与token嵌入各向异性作为偏见的原因。然而，我们认为各向异性与偏见无关。偏差意味着嵌入的分布被一些不相关的信息，如token频率所干扰，这可以根据PCA直接可视化。对于各向异性，它意味着整个嵌入在高维向量空间中占据了一个狭窄的锥体，这不能被直接可视化。</p><p><img src="https://s2.loli.net/2021/12/21/M2gTN4HvDZxEkdf.png" alt=""></p><p>表2显示了图1中三个预训练模型的静态token embeddings各向异性，根据任意两个token embeddings之间的平均余弦相似度计算。与之前的结论相反（Yan等人，2021；Li等人，2020），我们发现只有Bert-base-uncased的静态令牌嵌入是高度各向异性的。像roberta-base的静态 token 嵌入是各向同性的，平均余弦相似度为0.0235。对于偏差，这些模型受到静态标记嵌入中的偏差的影响，这与各向异性无关。</p><p><img src="https://s2.loli.net/2021/12/21/GlATLnuCBDia6ye.png" alt=""></p><p>为了证明偏见的负面影响，我们用平均的静态 token 嵌入作为句子嵌入（没有BERT层）来展示偏见对句子嵌入的影响。在表3中的三个预训练模型上，消除嵌入偏差的结果相当可观。仅仅去除一组token，结果就可以分别提高9.22、7.08和11.76。roberta-base的最终结果可以超过后处理方法，如BERT-flow（Li等人，2020）和BERT-whitening（Su等人，2021），只使用静态 token 嵌入。</p><p><img src="https://s2.loli.net/2021/12/21/9cTUVYF72pzC8XO.png" alt=""></p><p>手动消除嵌入偏差是提高句子嵌入性能的一个简单方法。但是，如果句子太短，这不是一个适当的解决方案，可能会导致一些有意义的词被遗漏。</p><h2 id="Prompt-Based-Sentence-Embeddings"><a href="#Prompt-Based-Sentence-Embeddings" class="headerlink" title="Prompt Based Sentence Embeddings"></a>Prompt Based Sentence Embeddings</h2><p>受（Brown等人，2020）的启发，我们提出了一种 基于提示的句子方法来获得句子嵌入。通过将句子嵌入任务重新表述为掩码语言任务，我们可以通过利用大规模的知识有效地使用原始BERT层。我们还通过从[MASK] token 表示句子来避免嵌入偏差。</p><p>然而，与文本分类或问题回答任务不同，句子嵌入中的输出不是MLM分类头预测的标签 token，而是表示句子的向量。我们按照这两个问题来讨论基于提示的句子嵌入的实现。1）如何用提示表示句子，以及2）如何为句子嵌入找到一个合适的提示。基于这些，我们提出了一种基于提示的对比学习方法来微调句子嵌入的BERT。</p><h3 id="Represent-Sentence-with-the-Prompt"><a href="#Represent-Sentence-with-the-Prompt" class="headerlink" title="Represent Sentence with the Prompt"></a>Represent Sentence with the Prompt</h3><p>在本节中，我们将讨论两种用提示语表示一个句子的方法。例如，我们有一个模板”[X]意味着[MASK]”，其中[X]是一个放置句子的占位符，[MASK]代表[MASK]token。给定一个句子 $x<em>{in}$，我们用模板将 $x</em>{in}$ 映射到 $x<em>{prompt}$。然后，我们将$x</em>{prompt}$送入一个预先训练好的模型，以生成句子表示 $h$。</p><p>一种方法是使用 $[MASK]$ token 的隐藏向量作为句子表示:</p><script type="math/tex; mode=display">h = h_{[MASK]}</script><p>对于第二种方法，就像其他基于提示的任务一样，我们根据 $h_{[MASK]}$ 和MLM分类头得到top-k tokens，然后根据概率分布找到这些tokens的加权平均值。$h$ 可以被表述为:</p><script type="math/tex; mode=display">h = \frac{\sum_{v\in V_{top-k}}W_v P([MASK] = v|h_{[MASK]})}{\sum_{v\in V_{top-k}} P ([MASK]=v|h_{[MASK]})}</script><p>其中，v 是 top-k token 集 $V<em>{top-k}$ 中的BERT标记，$W_v$ 是 $v$ 的静态 token 嵌入，$P([MASK] = v|h</em>{[MASK]})$表示token $v$被MLM头预测为 $h_{[MASK]}$ 的概率。</p><p>第二种方法是将句子映射到 token 上，比第一种方法更常规。但它的缺点也很明显：1）如前所述，由于句子嵌入来自静态 token 嵌入的平均化，它仍然存在偏差。2）权重平均化使BERT在下游任务中很难进行微调。由于这些原因，我们用第一种方法来表示带有提示的句子。</p><h3 id="Prompt-Search"><a href="#Prompt-Search" class="headerlink" title="Prompt Search"></a>Prompt Search</h3><p>第二种方法是将句子映射到 token 上，比第一种方法更常规。但它的缺点也很明显：1）如前所述，由于句子嵌入来自静态 token 嵌入的平均化，它仍然存在偏差。2）权重平均化使BERT在下游任务中很难进行微调。由于这些原因，我们用第一种方法来表示带有提示的句子。</p><p>对于人工搜索，我们需要手工制作模板，鼓励将整个句子用 $h_{[MASK]} $ 表示。为了搜索模板，我们将模板分为两部分：关系token，表示 $[X]$ 和 $[MASK]$ 之间的关系；前缀token，包裹 $[X]$ 。然后，我们贪婪地搜索遵循关系 token 和前缀 token的模板。</p><p><img src="https://s2.loli.net/2021/12/21/7uzvhb3feKsIoEt.png" alt=""></p><p>表4中显示了一些贪婪搜索的结果。当涉及到句子嵌入时，不同的模板产生了极其不同的结果。与简单地连接 $[X]$ 和$[MASK]$ 相比，复杂的模板如这句话：” $[X]$ “意味着 $[MASK]$，可以提高34.10的spearman相关度。</p><p>对于基于T5的模板生成，Gao等人（2020）提出了一种新颖的方法，通过使用T5根据句子和相应的标签来自动生成模板。在GLUE基准测试中，生成的模板可以胜过人工搜索的模板（Wang等人，2018）。</p><p>然而，实现它的主要问题是缺乏 token 标签。Tsukagoshi等人（2021年）通过根据字典将定义句子分类到其单词，成功地将句子嵌入任务转化为文本分类任务。受此启发，我们使用单词和相应的定义来生成500个模板（例如，橙子：一种大而圆的多汁柑橘类水果，有坚韧的鲜红黄色的外皮）。然后，我们在STS-B开发集中对这些模板进行评估，与模板 “也叫[MASK]”的最佳spearman相关度为64.75。[X]”. 也许这就是句子嵌入和单词定义之间的差距。与人工搜索相比，这种方法不能产生更好的模板。</p><p>OptiPrompt（Zhong等人，2021）用连续模板取代了离散模板。为了优化连续模板，我们按照(Gao et al., 2021)的设置，使用无监督的对比学习作为训练目标，冻结整个BERT参数，连续模板由手工模板的静态 token 嵌入初始化。与输入的人工模板相比，连续模板可以将STS-B开发集的spearman相关度从73.44提高到80.90。</p><h3 id="Prompt-Based-Contrastive-Learning-with-Template-Denoising"><a href="#Prompt-Based-Contrastive-Learning-with-Template-Denoising" class="headerlink" title="Prompt Based Contrastive Learning with Template Denoising"></a>Prompt Based Contrastive Learning with Template Denoising</h3><p>最近，对比性学习成功地利用了句子嵌入中的BERT的力量。句子嵌入对比学习中的一个挑战是如何构建适当的正向实例。Gao等人（2021）直接将BERT中的dropout作为正例。Yan等人（2021）讨论了四种数据增强策略，如对抗性攻击、token shuffling、cutoff 和输入 token 嵌入中的dropout来构建正面实例。在基于提示的句子嵌入的激励下，我们提出了一种新的方法来合理地生成基于提示的正面实例。</p><p>这个想法是用不同的模板来表示同一个句子的不同观点，这有助于模型产生更合理的正向对。为了减少模板本身对句子表述的影响，我们提出了一种新的方法来去掉模板信息。给定句子 $x_i$，我们首先用模板计算出相应的句子嵌入$h_i$。然后，我们通过直接给BERT输入模板和相同的模板位置 id 来计算模板偏差 $\hat h_i$。例如，如果 $x_i$ 有5个 token，那么 [X] 后面的模板标记的位置id将被加上 5，以确保模板的位置id是相同的。最后，我们可以直接使用 $h_i - \hat h_i$ 作为去噪后的句子表示。关于模板去噪，更多细节可以在讨论中找到。</p><p>形式上，让 $h_i’$ 和 $h_i$ 表示不同模板的 $x_i$ 的句子嵌入，$\hat h_i’$和 $\hat h_i$ 分别表示 $x_i$ 的两个模板偏差，最终训练目标如下:</p><script type="math/tex; mode=display">l_i = -log \frac{e^{cos(h_i-\hat h_i, h'_i-\hat h'_i)/ \tau}}{\sum_{j=1}^N e^{cos(h_i-\hat h_i, h'_j-\hat h'_j)/ \tau}}</script><p>其中，$τ$ 是对比学习中的一个温度超参数，N 是小批量的大小。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;PromptBERT-Improving-BERT-Sentence-Embeddings-with-Prompts&quot;&gt;&lt;a href=&quot;#PromptBERT-Improving-BERT-Sentence-Embeddings-with-Prompts&quot; cl</summary>
      
    
    
    
    
    <category term="context detection" scheme="http://example.com/tags/context-detection/"/>
    
  </entry>
  
  <entry>
    <title>Parameter-Efficient Tuning by Manipulating Hidden States of Pretrained Language Models For Classification Tasks</title>
    <link href="http://example.com/2021/11/30/Parameter-Efficient-Tuning-by-Manipulating-Hidden-States-of-Pretrained-Language-Models-For-Classification-Tasks/"/>
    <id>http://example.com/2021/11/30/Parameter-Efficient-Tuning-by-Manipulating-Hidden-States-of-Pretrained-Language-Models-For-Classification-Tasks/</id>
    <published>2021-11-30T11:46:34.000Z</published>
    <updated>2021-11-30T15:46:44.472Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Parameter-Efficient-Tuning-by-Manipulating-Hidden-States-of-Pretrained-Language-Models-For-Classification-Tasks"><a href="#Parameter-Efficient-Tuning-by-Manipulating-Hidden-States-of-Pretrained-Language-Models-For-Classification-Tasks" class="headerlink" title="Parameter-Efficient Tuning by Manipulating Hidden States of Pretrained Language Models For Classification Tasks"></a>Parameter-Efficient Tuning by Manipulating Hidden States of Pretrained Language Models For Classification Tasks</h1><p>Parameter-Efficient tuning旨在通过优化一些引入的参数的同时，冻结 PLMs 来提取下游任务的知识。</p><p>连续的 prompt tuning 在输入的嵌入中预先加入一些可训练向量。是其中的一种方法，由于其有效性和效率而受到广泛关注。这个系列的方法可以被理解为对PLM内部的隐藏状态进行了非线性转换。</p><p>然而，一个自然的问题被忽略了：隐藏状态能否直接用于分类而不改变它们？在本文中，我们旨在通过提出一种简单的 tuning 方法来回答这个问题，这种方法只引入了三个可训练的向量。</p><p>首先，我们使用引入的向量整合不同层的隐藏状态。然后，我们将整合后的隐藏状态输入到一个特定任务的线性分类器中，以预测类别。</p><p>这个方案类似于ELMo利用隐藏状态的方式，只是他们将隐藏状态反馈给基于LSTM的模型。 虽然我们提出的tuning 方案很简单，但它取得了与 P-tuning 和 P-tuning v2等 prompt tuning 方法相当的性能，验证了原始隐藏状态确实包含分类任务的有用信息。此外，我们的方法在时间和参数数量上比  prompt tuning  有优势。</p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>为了将 PLM 重用于不同的任务，已经提出了越来越多的 parameter-efficient tuning 方法。 他们旨在通过仅优化少量额外参数，从冻结的 PLM 中挖掘特定于任务的信息。  </p><ul><li><p>Adapter tuning 建议将两个可训练的 Adapter 插入到每个 transformer 中，这些适配器由一些简单的变换组成。 虽然适配器达到了近乎 state-of-the-art 的性能，但它引入的额外参数数量仍然非常多，并且原始 transformer 的架构也需要修改。</p></li><li><p>《Few- shotqa: A simple framework for few-shot learning of question answering tasks using pre-trained text- to-text models》 试图规避预训练和 tuning 过程之间的错位，因其在 few-shot 情况下的优越性而受到广泛关注。</p></li><li><p>《Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing》包括离散prompt tuning 和连续prompt tuning，是最流行的方法。离散prompt tuning通常在输入句子中插入一些标记（出现在模型的词汇中），将任务重新表述为填空问题。然而，离散prompt tuning的调整涉及到巨大的人工努力，在高资源数据集上的表现更差，限制了其使用。连续 prompt tuning 不是插入离散的标记，而是在输入句子的嵌入中增加特定任务的可训练向量。在训练期间，只有这些特定任务的向量被优化。他们的实验表明，通过这些额外的向量，有可能从冻结的PLMs中获取知识。</p></li><li><p>《The power of scale for parameter-efficient prompt tuning》试图利用提示向量的意义，发现它们的词邻往往是相似的词，说明连续 prompt tuning 与离散 prompt tuning 完全不同。另外，如图1所示，与P-tuning将可训练向量预置到词嵌入中不同，我们尝试将这些向量预置到特定的 transformer 中。图2描述了四个任务的准确性。我们可以看到，将向量预置到任何一层，甚至最后一层，都可以取得类似的结果。我们从这个现象中得到两个启发。(i) 当可训练的向量被插入到最后一个 transformer 时，P-tuning甚至也能发挥作用。这是否意味着这些原始的隐藏状态已经包含了大部分甚至所有用于分类的信息？(ii) 当向量被预置到第0层时，可能无法获得最好的准确性。这与ELMo类似，表现为不同层对下游任务有不同的权重</p><p><img src="https://i.loli.net/2021/11/30/ZBlXyOH7vKtF48A.png" alt=""></p></li></ul><p>在本文中，通过提出一种只引入三个可训练向量的简单方法，表明分类信息可以很容易地提炼出来。</p><p>这个方法首先获得了输入的所有隐藏状态，并学习了一个softmax归一化的权重向量来堆叠跨层的隐藏状态。其次，一个软掩码向量被用来选择隐藏状态中对下游任务有用的维度子集。最后，进行仅由一个可训练向量组成的自我注意操作，以输出用于分类的状态。</p><p>我们发现，分类信息在表面，这意味着没有必要使用复杂的分类头，如LSTM，CNN。我们的分类头只包含一个线性转换，然后是一个softmax函数。</p><p>我们在各种任务上进行了实验，结果表明，我们的方法可以达到与P-tuning和P-tuning v2所取得的性能相当。这证实了原始的隐藏状态确实包含了分类所需的信息，而且这种信息可以通过简单的线性转换来提取。我们希望这一发现能够帮助推进对连续 prompt tuning  方案的理解。</p><h2 id="Preliminaries"><a href="#Preliminaries" class="headerlink" title="Preliminaries"></a>Preliminaries</h2><p>在这一节中，我们首先介绍了一些 tuning 方案的背景，介绍了ELMo和 transformer 家族语言模型如何应用于下游分类任务。</p><h3 id="ELMo"><a href="#ELMo" class="headerlink" title="ELMo"></a>ELMo</h3><p>ELMo 的骨干是 L 层双向LSTM。经过预训练，当有一个下游任务时，ELMo学习了一个特定任务的跨层隐藏状态的线性组合，并将这些隐藏状态输入到基于 LSTM 的模型，以输出一个输入的目标：</p><script type="math/tex; mode=display">e_{k} = \gamma\sum_{i=0}^{L} s_jh_{k,j}</script><script type="math/tex; mode=display">\hat y = Model ([e_1,e_2,...,e_n])</script><p>其中 $h<em>{k,j}$  是第 $j$ 层中第 $k$ 个token的隐藏状态。$h</em>{k,0}$是第 $k$ 个token词嵌入层表示。$(s_0,s_1,…,s_L)$ 是任务特定的softmax归一化权重的表示，它们在训练下游任务时被优化。这些权重允许模型根据下游任务的属性，利用不同层次的表征（例如，语法、语义）。$\gamma$ 是可训练标量，其用于辅助优化过程。$e_k$ 是第 $k$个词的最终加权嵌入。最后，$[e_1, e_2, …, e_n]$被输入到量身定做的模型（通常是一个复杂的网络，如LSTM），以预测标签或生成特定任务的目标句。</p><h3 id="The-Transformer-Family"><a href="#The-Transformer-Family" class="headerlink" title="The Transformer Family"></a>The Transformer Family</h3><p>在根据下游任务调整PLM时，最常用的方法叫做微调，把PLM和特定任务的分类器 $C$ 一起优化:</p><script type="math/tex; mode=display">min_{\theta,\beta} \sum_{x\in D} L(C_{\beta}(E_{\theta}(x)), y)</script><p>其中 $C、E$分别代表特定任务的分类头和编码器（一个PLM）。$β，θ$ 分别是 $C$ 和 $E$ 的参数。Fine tuning LM通常可以获得令人满意的性能。然而，在新数据按顺序出现的情况下，这种调整方案不再起作用。 因为当一个新的数据集出现时，我们要么重新训练所有的数据，要么为新的数据训练一个单独的模型。由于耗费大量时间和存储，这两种方法都是不可接受的。因此，研究人员试图通过引入一些可训练的参数，从冻结的PLM中提炼出知识。</p><p>Adapter tuning 和连续  prompt tuning 是两种普遍的方法。这里，我们只介绍第二种。有许多关于连续 prompt tuning 的工作，我们对其中的两个进行了详细介绍</p><ul><li><p>P-tuning 对于一个输入句子 $x=(x_1,x_2,…,x_n)$，P-tuning在 $x$ 的词嵌入矩阵中加入K个向量，用 $P（x）=[w_0,p_1,p_2,…,p_K,w_1,…,w_n]$表示。$w_0$ 是[CLS] token 的嵌入。$P(x)$ 被输入到PLM的其余各层以预测 $x$ 的标签，优化目标是:</p><script type="math/tex; mode=display">min_{\beta, p_{1,...K}} \sum_{x\in D} L(C_{\beta}(E(P(x))) ,y)</script><p>我们可以看到，在训练期间，只有预置的向量和分类器被优化。虽然P-tuning的想法受到离散 prompt tuning 的启发，但这两者并没有显示出任何共同的特征。例如，在将 $p_i,…, p_K$ 映射到词汇中最接近的词后，这些词往往是类似的词（如technology，technologies），这并没有显示出连续 prompt tuning 背后的机制是像离散 prompt tuning 那样利用PLM的语言建模特性。最近的一项工作（He et al., 2021）揭示了P-tuning和适配器之间的联系，他们发现P-tuning相当于原始隐藏状态和由预置向量产生的新隐藏状态的加权平均值。应该注意的一点是，这些向量是由数据集中的所有样本共享的。同样的新隐藏状态可以应用于所有不同的样本，这有点不可思议。一个可能的解释是，原始的隐藏向量已经包含了用于分类的信息，而这正是我们论文的重点。</p></li><li><p>P-tuning v2  是一种变种的P-tuning，可以扩展到困难的任务，与P-tuning相比，取得了更好的性能。与P-tuning不同的是，P-tuning将向量插入到单词嵌入矩阵中，而这些向量在后面几层的隐藏状态是根据前一层的表示来计算的，P-tuning v2利用多层提示，将一组可训练的向量插入到PLM的每层。换句话说，第 $l$ 层的原始隐藏状态会受到第 $l - 1$ 层的提示向量的影响。由于引入了更多的可训练向量，这种修改使得每个任务的容量更大。</p></li></ul><h2 id="Proposed-Approach"><a href="#Proposed-Approach" class="headerlink" title="Proposed Approach"></a>Proposed Approach</h2><p><img src="https://i.loli.net/2021/11/30/ZCm7KItPuDd8bpQ.png" alt=""></p><p>该方法直接操纵不同层的隐藏状态。与通过改变隐藏状态来提炼有用信息的 adapters 和 prompt tuning 方法不同，我们对原始隐藏状态进行操作。由于有许多方法可以整合这些隐藏状态，我们只介绍最简单的方法，由三部分组成。</p><h3 id="Layer-Level-Weighted-Addition"><a href="#Layer-Level-Weighted-Addition" class="headerlink" title="Layer-Level Weighted Addition"></a>Layer-Level Weighted Addition</h3><p>这一步与公式1类似，只是我们不使用标量 $\gamma $。形式上，给定输入x，我们首先获得隐藏状态:</p><script type="math/tex; mode=display">\{H_i\}_{i=0}^L = \{h_{i,0},..., h_{i,N}\}_{i=0}^L = E(x)</script><p>其中 $L$ 为tansformer 层数， 第 $0$ 层是词嵌入层，$N$ 是 $x$ 的长度。每个 $h_{i,j}$ 是一个 $d$ 维向量，每个 $H_i$ 是一个 $d×（N+1）$维矩阵。然后，我们给每个层分配一个权重，因为以前的工作表明，低层、中层、顶层捕捉的信息粒度不同，不同的下游任务可能对这些层有不同的关注。</p><p>我们通过引入第一个可训练向量 $v_1\in R^{L+1}$来实现这一目标:</p><script type="math/tex; mode=display">H = \{h_0, h_1,..., h_N\} = \sum_{i=0}^L s_i H_i , \ \ \ s = softmax(v_1)</script><h3 id="Subspace-Mining"><a href="#Subspace-Mining" class="headerlink" title="Subspace Mining"></a>Subspace Mining</h3><p>我们认为，对于一个d 维的隐藏状态，存在一个维度为 $d_1$ 的子空间，它包含下游任务的区分信息。用二进制掩码向量选择这样的子空间是一种选择，但它在优化方面有困难《 Masking as an efficient alternative to finetuning for pretrained language models》。在此，我们通过引入第二个可训练向量 $v_2\in R^d$ 来采用软屏蔽策略:</p><script type="math/tex; mode=display">H = m \otimes H , \ \ \ m = sigmoid(v_2)</script><p>如果下游的任务是一个序列标记 任务，如命名实体识别，H可以直接用于分类。然而，对于情感分类、自然语言推理等任务，应该进行进一步的处理步骤。</p><h3 id="Self-Attention"><a href="#Self-Attention" class="headerlink" title="Self-Attention"></a>Self-Attention</h3><p>使用 Self-Attention 来聚合矩阵 $H$ 。但是这种 Self-Attention  需要很多参数, 引入第三个可训练向量 $v_3\in R^d$ :</p><script type="math/tex; mode=display">h = H \cdot w , \ \ \ w=softmax(v_3\cdot H)</script><h3 id="Task-Specific-Classification"><a href="#Task-Specific-Classification" class="headerlink" title="Task-Specific Classification"></a>Task-Specific Classification</h3><p>有了 $h$ 和 $H$ ，我们可以把它们输入到特定任务的分类头。为了说明原始隐藏状态包含了大部分（如果不是全部）分类信息，而且这些信息都在表面，我们只进行了线性变换和softmax操作来输出标签，对于序列标签任务:</p><script type="math/tex; mode=display">y = argmax(softmax(WH))</script><p>对于情感分类 ：</p><script type="math/tex; mode=display">y = argmax(softmax(Wh))</script><p>在训练过程中，只有v1、v2、v3和w是被操作的。因此，与P-tuning和P-tuning v2相比，我们的方法在内存和时间方面更加有效，因为额外的参数不参与PLM内部的计算，而且输入长度也没有增加。在第4.2节，我们将提供一个详细的分析。</p><h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><p><img src="https://i.loli.net/2021/11/30/DsPSl6HW8bNpLAE.png" alt=""></p><p><img src="https://i.loli.net/2021/11/30/EDne5dYPKgl8vN4.png" alt=""></p><p>为了考察这些调谐方法在额外参数数量上的表现，我们把P-tuning中的提示向量数量减少到3个，把P-tuning v2中的提示向量数量减少到1个，结果见图4。我们可以发现Ours在整体上优于P-tuning，与P-tuning v2相当。我们还尝试增加Ours的参数数量，即引入多个V3来形成多头自关注，但发现性能没有改善。这可能是我们方法的一个缺点。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Parameter-Efficient-Tuning-by-Manipulating-Hidden-States-of-Pretrained-Language-Models-For-Classification-Tasks&quot;&gt;&lt;a href=&quot;#Parameter</summary>
      
    
    
    
    
    <category term="context detection" scheme="http://example.com/tags/context-detection/"/>
    
  </entry>
  
  <entry>
    <title>P-Tuning v2，Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks</title>
    <link href="http://example.com/2021/11/25/P-Tuning-v2-Prompt-Tuning-Can-BeComparable-to-Fine-tuning-Universally-Across-Scales-and-Tasks/"/>
    <id>http://example.com/2021/11/25/P-Tuning-v2-Prompt-Tuning-Can-BeComparable-to-Fine-tuning-Universally-Across-Scales-and-Tasks/</id>
    <published>2021-11-25T09:29:41.000Z</published>
    <updated>2021-12-12T15:01:56.511Z</updated>
    
    <content type="html"><![CDATA[<h1 id="P-Tuning-v2-Prompt-Tuning-Can-Be-Comparable-to-Fine-tuning-Universally-Across-Scales-and-Tasks"><a href="#P-Tuning-v2-Prompt-Tuning-Can-Be-Comparable-to-Fine-tuning-Universally-Across-Scales-and-Tasks" class="headerlink" title="P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks"></a>P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks</h1><p>Prompt tuning 只用冻结的语言模型来调整连续的prompts，大大减少了训练时每个任务的存储和内存使用。但</p><ul><li><p>prompt tuning 对于正常大小的预训练模型来说表现并不理想。</p></li><li><p>现有的 prompt tuning 方法不能处理困难的序列标记任务，缺乏普适性。</p></li></ul><p>P-Tuning-v2 与微调的性能相匹配，并且只有0.1%-3%的调整参数。</p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>微调，为目标任务更新整个模型参数集。虽然微调能获得良好的性能，但在训练过程中却很耗费内存，因为必须存储所有参数的梯度和优化器状态。</p><p>此外，微调需要在推理过程中为每个任务保留一份模型参数，这很不方便，因为预训练的模型通常很大。</p><p><strong>Prompting</strong> 另一方面，冻结PLMs的所有参数并使用自然语言 prompts 来查询语言模型。例如，对于情感分析，我们可以将一个样本与一个 prompts 串联起来 “这部电影是[MASK]”，并要求预训练的语言模型预测被mask的 token。然后，我们可以使用 “好 “和 “坏 “是被 MASK 的标记的预测概率来预测样本的标签。Prompting 完全不需要训练，只需存储一份模型参数。然而，与微调相比，提示 在许多情况下会导致次优的性能（Liu等人，2021b；Lester等人，2021）。</p><p><strong>Prompt tuning</strong> 是一种只调谐连续 prompts 的想法。具体来说，Liu等人（2021b）；Lester等人（2021）提出在输入词嵌入的原始序列中加入可训练的连续嵌入。这些连续嵌入（也称为连续 prompts ）类似于 prompting 中离散的手动签名 prompts。在训练过程中，只有连续的 prompts 被更新。虽然 prompt tuning 在许多任务上比 prompting 有提高 （Liu等人，2021b；Lester等人，2021），但当模型规模较小，特别是小于100亿个参数时，它仍然不如 fine-tuning（Lester等人，2021）。</p><p>从技术上讲，P-tuning v2可以被看作是 prefix-tuning  的优化版本，适用于NLU。最显著的改进来自于使用深度 prompt tuning，即对预训练模型的每一层应用连续的 prompt。深度 prompt tuning 增加了连续 prompt 的能力，并缩小了在各种设置中进行微调的差距，特别是对于小模型和困难任务。此外，还提出了一些优化和实施的细节，以进一步提高结果。</p><h2 id="Preliminaries"><a href="#Preliminaries" class="headerlink" title="Preliminaries"></a>Preliminaries</h2><h3 id="NLU-Tasks"><a href="#NLU-Tasks" class="headerlink" title="NLU Tasks"></a>NLU Tasks</h3><p>在这项工作中，将NLU的挑战分为两个系列：</p><ul><li>Simple NLU tasks ：涉及单一标签的分类。GLUE（Wang等人，2018）和Super- GLUE（Wang等人，2019）的大多数数据集，包括文本分类（如SST-2）、自然语言推理（NLI，如MNLI-m，RTE）、多选题回答（如BoolQ）等，都属于这一类。</li><li>Hard sequence NLU tasks ：涉及对一连串标签的分类。它们大多是与信息提取有关的问题，如开放式信息提取、命名实体识别、提取式问题回答和语义角色标签。</li></ul><h3 id="Prompt-Tuning"><a href="#Prompt-Tuning" class="headerlink" title="Prompt Tuning"></a>Prompt Tuning</h3><p>Prompt tuning（Lester等人，2021），或P-tuning（Liu等人，2021b），引入了可训练的连续prompts，作为骨干语言模型的参数被冻结时对NLU的自然语言 prompts 的替代。例如，让 $V$ 指的是语言模型 $M$ 的词汇表，$e$ 作为 $M$ 的嵌入函数。</p><p>要把一篇电影评论 x=”Amazing movie!” 分类为正面或负面，很自然地就会想到在评论中加入一个 prompts  “It is [MASK]”，并生成MASK token被预测为 “好 “或 “坏 “的条件概率作为分类。在这种情况下，prompt tokens  {“It”、”is”、”[MASK]”} 都属于模型的词汇表 $V$，而输入嵌入序列将是：</p><script type="math/tex; mode=display">[e(x), e("It"), e("is"), e("[MASK]")]</script><p>然而，由于模型 $M$ 在本质上是连续的，从优化的角度来看，人们永远不可能用离散的自然 prompts 来达到最佳效果。相反，P-tuning建议用可训练的连续 embeddings $[h_0, …, h_i]$ 代替 prompt tokens ，并将输入序列变成:</p><script type="math/tex; mode=display">[e(x), h_0,...,h_i, e("[MASK]")]</script><p>并因此可以进行不同的优化（参考图2（a））。在骨干预训练模型的参数被冻结的严格约束下，在简单的NLU任务和知识探测中，prompt tuning 已被证明具有与100亿参数模型的 fine-tuning 相当的性能。</p><h2 id="P-Tuning-v2"><a href="#P-Tuning-v2" class="headerlink" title="P-Tuning v2"></a>P-Tuning v2</h2><p><img src="https://i.loli.net/2021/11/25/hAoQrbPSGTtIsnz.png" alt=""></p><h3 id="Lack-of-Universality"><a href="#Lack-of-Universality" class="headerlink" title="Lack of Universality"></a>Lack of Universality</h3><p>在许多NLP应用中，Prompt tuning 和  P-tuning 已经被证明是相当有效的。然而，考虑到缺乏普遍性， P-tuning 还不是微调的全面替代方法。</p><h3 id="Lack-of-universality-across-scales"><a href="#Lack-of-universality-across-scales" class="headerlink" title="Lack of universality across scales"></a>Lack of universality across scales</h3><p> Lester等人（2021）表明，当模型规模超过100亿个参数时，prompt tuning 可以与微调相媲美。但是对于那些较小的模型（从100M到1B），prompt tuning和微调的表现有很大差异，这大大限制了prompt tuning的适用性。</p><h3 id="Lack-of-universality-across-tasks"><a href="#Lack-of-universality-across-tasks" class="headerlink" title="Lack of universality across tasks."></a>Lack of universality across tasks.</h3><p>尽管Lester等人（2021年）和 P-tuning 在GLUE和SuperGLUE等NLU基准上显示出优越性，但它们在另一大类序列NLU任务（即序列标签）上的有效性却没有得到验证。</p><p>首先，序列标签需要预测一连串的标签，而不是单一的标签。其次，序列标签通常预测的是无实际意义的标签，这对变成有效的言语者来说可能是个挑战。</p><h3 id="Deep-Prompt-Tuning"><a href="#Deep-Prompt-Tuning" class="headerlink" title="Deep Prompt Tuning"></a>Deep Prompt Tuning</h3><p><img src="https://i.loli.net/2021/11/25/42eZyjHrnuWAmNv.png" alt=""></p><p>Prefix-tuning（Li and Liang, 2021）最初是为自然语言生成（NLG）任务提出的，但我们发现它对NLU也非常有效。我们描述了一个适合NLU的 Prefix-tuning 版本。</p><p>在(Lester et al., 2021)和P-tuning中，连续 prompts 只被插入到输入嵌入序列中（参考图2(a)），用于 transformer’s 第一层。在接下来的  transformer 中，插入连续 prompts 的位置的嵌入是由之前的transformer 层计算出来的，这可能导致两个可能的优化挑战。</p><ul><li>可调整的参数数量有限。大多数语言模型目前只能支持512的最大序列长度（由于注意力的二次计算复杂性的成本）。如果我们另外扣除我们的上下文的长度（例如，要分类的句子），那么我们用连续提示来填充的长度是有限的。</li><li>在用非常深的 transformers 进行调整时，稳定性有限。随着 transformers 的不断深入，由于许多中间层的计算（具有非线性激活函数），来自第一个transformers 层的提示的影响可能是意想不到的，这使得我们的优化不是一个非常平稳的优化。</li></ul><p>鉴于这些挑战，P-tuning v2利用多层 prompts（即深度prompt tuning）作为 prefix-tuning（Li and Liang, 2021）中的提示（参见图2（b）），作为对P-tuning和Lester等人（2021）的重大改进。不同层的 prompt 作为前缀 tokens 添加到输入序列中，并独立于其他层（而不是由之前的 transformers 层计算）。一方面，通过这种方式，P-tuning v2 有更多的可调整的特定任务参数（从0.01%到0.1%-3%），以允许更多的每个任务容量，而它仍然比完整的预训练语言模型小得多；另一方面，添加到更深层的 prompt（例如图2中的LayerN Prompts）可以对输出预测产生更直接和显著的影响，而中间的transformers层更少。</p><h3 id="Optimization-and-Implementation"><a href="#Optimization-and-Implementation" class="headerlink" title="Optimization and Implementation"></a>Optimization and Implementation</h3><p><strong>Optimization：Reparameterization</strong>。以前的方法利用重新参数化功能来提高训练速度、鲁棒性和性能（例如，MLP的 prefix-tuning 和 LSTM的P调整）。然而，对于NLU任务，我们发现这种技术的好处取决于任务和数据集。对于一些数据集（如RTE和CoNLL04），MLP的重新参数化带来了比嵌入更稳定的改进；对于其他的数据集，重新参数化可能没有任何效果（如BoolQ），有时甚至更糟（如CoNLL12）。</p><p><img src="https://i.loli.net/2021/11/25/T1axhfKtEoXPZOR.png" alt=""></p><p><strong>Optimization: Prompt length</strong> Prompt length在 prompt tuning 方法的超参数搜索中起着核心作用。在我们的实验中，我们发现不同的理解任务通常以不同的 Prompt length 达到最佳性能，这与 prefix- tuning 的发现一致，不同的文本生成任务可能有不同的最佳 Prompt length。</p><p>从图3中，我们观察到，对于简单的NLU任务，通常，较短的prompts 就能获得最佳性能；对于困难的序列任务，通常，比100长的 prompts 语会有帮助。<br>我们还发现，重新参数化与 Prompt length 长度有着密切的联系。例如，在RTE、CoNLL04和BoolQ中，MLP的重新参数化比嵌入更早达到最佳结果。这一结论可能有助于对P-tuning的优化特性进行一些思考。</p><p><strong>Optimization: Multi-task learning.</strong> 多任务学习对我们的方法来说是可选的，但可能是相当有帮助的。一方面，连续prompts 的随机惯性给优化带来了困难，这可以通过更多的训练数据或与任务相关的无监督预训练来缓解（Gu等人，2021）；另一方面，连续 prompts 是跨任务和数据集的特定任务知识的完美载体。 我们的实验表明，在一些困难的序列任务中，多任务学习可以作为P-tuning v2的有益补充，表示为MPT-2。</p><p><strong>Implementation: [CLS] and token classification, rather than verbalizers.</strong>  Verbalizer 一直是 Prompt tuning 的核心组成部分，它将一类的labels变成有意义的词，以利用预训练语言模型head 。尽管它在少数情况下有潜在的必要性，但在全数据监督的情况下，verbalizer 不是必须的。它阻碍了 Prompt tuning 在我们需要无实际意义的标签和语义嵌入的场景中的应用。因此，P-tuning v2回到了传统的[CLS]标签分类（参照图2）范式，采用随机初始化的线性头。见第4.4节中的比较。</p><h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><p>在这项工作中，”prompt tuning”、”P-tuning”、”P-tuning v2 “和 “多任务P-tuning v2 “的所有结果都是通过冻结transformer的参数，只调整连续prompts。特定任务参数的比率（例如0.1%）是通过比较连续prompts 的参数和transformer的参数得出的。只有 “微调 “的结果是通过调整transformer的参数（不使用连续提示）得到的。</p><p>另外需要注意的是，我们的实验都是在全数据监督下的学习环境下进行的，而不是在少量的学习环境下进行的，这一点很重要，因为我们利用的一些特性（例如，使用具有线性head 的类标签而不是具有LM头的言语者）只可能在监督下进行。</p><p><img src="https://i.loli.net/2021/11/25/q12FUMtevPgoI3V.png" alt=""></p><h3 id="P-tuning-v2-Across-Scales"><a href="#P-tuning-v2-Across-Scales" class="headerlink" title="P-tuning v2: Across Scales"></a>P-tuning v2: Across Scales</h3><p>表1展示了P-tuning v2在不同模型规模下的表现。对于简单的NLU任务，如SST-2（单句分类），Lester等人（2021）和P-tuning在较小的规模下没有显示出明显的劣势。但是，当涉及到复杂的挑战，如自然语言推理（RTE）和多选题回答（BoolQ）时，它们的性能会非常差。相反，P-tuning v2在所有任务中以较小的规模与微调性能相匹配。令我们惊讶的是，P-tuning v2在RTE中的表现明显优于微调，特别是在BERT中。</p><p>就较大尺度（2B到10B）的GLM（Du等人，2021）而言，P-调谐&amp;Lester等人（2021）与精细调谐之间的差距逐渐缩小了。在10B尺度上，我们有一个类似于（Lester等人，2021）报告的观察结果，即及时调谐变得与精细调谐竞争。然而，P-tuning v2在所有尺度上都与微调相当，但与微调相比，只需要0.1%的任务特定参数。<br>此外，我们观察到，在一些数据集中，RoBERTa-large的性能比BERT-large差。部分原因是，我们根据经验发现及时调谐对超参数相当敏感，有时调谐会被困住。P-tuning v2在调谐过程中可以更加稳定和稳健。关于超参数的更多细节，请参考我们的代码库。</p><h3 id="P-tuning-v2-Across-Tasks"><a href="#P-tuning-v2-Across-Tasks" class="headerlink" title="P-tuning v2: Across Tasks"></a>P-tuning v2: Across Tasks</h3><p>在第4.2节中，我们讨论了P-tuning v2的一贯性，无论何种尺度，其性能都与微调相当。然而，GLUE和SuperGLUE的大多数任务都是相对简单的NLU问题。另一个重要的硬NLU挑战系列是序列标签，它与一些更高级的NLP应用有关，包括开放信息提取、阅读理解等。</p><p>为了评估P-tuning v2在这些硬NLU挑战上的能力，我们选择了三个典型的序列标签任务。名称实体识别、外部问题回答（QA）和语义角色标签（SRL），共八个数据集。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;P-Tuning-v2-Prompt-Tuning-Can-Be-Comparable-to-Fine-tuning-Universally-Across-Scales-and-Tasks&quot;&gt;&lt;a href=&quot;#P-Tuning-v2-Prompt-Tuning-</summary>
      
    
    
    
    
    <category term="context detection" scheme="http://example.com/tags/context-detection/"/>
    
  </entry>
  
  <entry>
    <title>PADA: A Prompt-based Autoregressive Approach for Adaptation to Unseen Domains </title>
    <link href="http://example.com/2021/11/23/PADA-A-Prompt-based-Autoregressive-Approach-for-Adaptation-to-Unseen-Domains/"/>
    <id>http://example.com/2021/11/23/PADA-A-Prompt-based-Autoregressive-Approach-for-Adaptation-to-Unseen-Domains/</id>
    <published>2021-11-23T01:49:35.000Z</published>
    <updated>2021-12-26T07:59:10.009Z</updated>
    
    <content type="html"><![CDATA[<h1 id="PADA-A-Prompt-based-Autoregressive-Approach-for-Adaptation-to-Unseen-Domains"><a href="#PADA-A-Prompt-based-Autoregressive-Approach-for-Adaptation-to-Unseen-Domains" class="headerlink" title="PADA: A Prompt-based Autoregressive Approach for Adaptation to Unseen Domains"></a>PADA: A Prompt-based Autoregressive Approach for Adaptation to Unseen Domains</h1><p>PADA: A Prompt-based Autoregressive Domain Adaptation algorithm, based on the T5 model</p><p>作者提出解决的是这个领域适应问题，即一个算法在几个源域上进行训练，然后应用于在训练时未知的未见过的领域的样本（更准确的说这其实是领域泛化问题）。</p><p>在训练时，没有任何样本，不管是有标签的还是无标签的，或者关于目标领域的任何其他知识。</p><p>给定一个测试样本，PADA首先生成一个独特的 prompt，然后以这个 prompt 为条件，在NLP任务方面给这个样本贴上标签。</p><p>prompt 是一个长度不受限制的序列，由预先定义的领域相关特征（DRFs）组成，这些特征是每个源域的特征。直观地说，prompt 是一个独特的签名，它将测试实例映射到源域所跨越的语义空间。</p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>NLP算法往往依赖于一个开创性的假设，即训练集和测试集来自相同的基础分布。不幸的是，这个假设往往不成立，因为文本可能来自许多不同的来源，每个来源都有独特的分布属性。由于超出训练分布的泛化仍然是一个基本的挑战，NLP算法在应用于非分布的应用时，会出现明显的退化。</p><p>领域适应（DA）明确地解决了上述挑战，努力改善NLP算法的 out-of-distribution 。DA算法在源领域的标注数据上进行训练，以有效地应用于各种目标领域。</p><p>多年来，人们为DA挑战付出了相当大的努力，专注于目标领域在训练时是已知的（例如，通过标记或未标记的数据），但仍未得到充分体现的各种情况（Roark和Bacchiani，2003；Daumé III和Marcu，2006；Reichart和Rappoport，2007；McClosky等人，2010；Rush等人，2012；Schnabel和Schütze，2014）。然而，对训练时未知的任何可能的目标领域的适应性挑战还没有得到充分的探索。</p><p>PADA具有独特的建模优势，因为目标感知算法通常需要为每个目标域训练一个单独的模型，导致整体解决方案效率低下。</p><p><strong>直观地说，通过整合来自几个源域的知识，可以实现对未见过的事物更好的泛化。</strong>PADA：基于 Prompt 的自回归领域适应算法，它利用自回归语言模型（T5），并包括一个适应于多个源领域的新型 Prompt 机制。给定一个来自任何未知领域的新样本，该模型首先生成属于熟悉的（源）领域并与给定样本相关的属性。然后，在模型执行下游任务时，生成的属性被用作 prompts。</p><p>为了产生有效的 prompts ，我们从以前关于 pivot features 的工作中得到启发（Blitzer等人，2006；Ziser和Reichart，2018a；Ben-David等人，2020），<strong>定义了领域相关特征（DRFs）的集合。DRFs是与源域之一密切相关的特征，编码了特定领域的语义。</strong>我们<strong>利用各个源域的DRFs，以跨越它们的共享语义空间</strong>。这些<strong>DRFs共同反映了源域之间的相似性和差异性，以及特定领域的知识</strong>。</p><h2 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h2><p>在DA研究中，有两种突出的设置：有监督的和无监督的。有监督的算法利用来自目标领域的稀缺标记的例子（Daumé III, 2007），而无监督的方法只假设源标记的数据和未标记的源和目标数据在手（Blitzer等人，2006）。</p><p>我们首先描述无监督DA的研究，重点是基于pivot-based的方法。然后，我们继续研究多源的DA方法，重点是专家混合模型。最后，我们描述了自回归语言模型和我们采用T5进行DA的独特方式。</p><h3 id="Unsupervised-Domain-Adaptation-UDA"><a href="#Unsupervised-Domain-Adaptation-UDA" class="headerlink" title="Unsupervised Domain Adaptation (UDA)"></a>Unsupervised Domain Adaptation (UDA)</h3><p>随着深度神经网络（DNN）建模的突破，DA社区的注意力已经被引向了表征学习方法。其中一项工作是采用基于DNN的自编码器来学习潜在的表征。这些模型在无标签的源数据和目标数据上进行训练，并有输入重建损失（Glorot等人，2011；Chen等人，2012；Yang和Eisenstein，2014；Ganin等人，2016）。</p><p>另一个分支采用 pivot 特征来弥补源域和目标域之间的差距（Blitzer等人，2006，2007；Pan等人，2010）。支点特征对感兴趣的任务很突出，在源域和目标域都很丰富。最近，Ziser和Reichart（2017，2018b）将这两种方法结合起来。后来，Han和Eisenstein（2019）提出了一种预训练方法，随后Ben-David等人（2020）提出了一种基于 pivot-based 的变体，用于预训练语境词嵌入。</p><p>最重要的是，UDA模型假定在训练过程中可以获得来自目标领域的无标签数据。我们认为这是对超越训练分布的泛化目标的一个轻微的放松。此外，这个定义在工程上有缺点，因为每个目标域都需要一个新的模型。为此，我们追求任何领域的适应性设置，即在训练时无法获得未标记的目标数据。</p><p>我们从 pivot-based 的模型中得到启发。pivot 的定义依赖于标记的 源域数据 和 未标记的源域 和 目标域数据。特别是，好的 pivot 是与任务标签相关的。相反，我们定义了任务变量DRF，这些特征与领域的身份高度相关。由于领域与单词高度相关，我们的DRFs在本质上是词汇性的。</p><p>虽然我们的方法可以在单一的源域中运行，但我们利用多个源域来促进对未知目标域的推广。我们接下来讨论多源DA。</p><h3 id="Multi-Source-Domain-Adaptation"><a href="#Multi-Source-Domain-Adaptation" class="headerlink" title="Multi-Source Domain Adaptation"></a>Multi-Source Domain Adaptation</h3><p>大多数现有的多源DA方法遵循无监督DA的设置定义，同时考虑一个以上的源域。一个突出的方法是融合几个来源的模型。早期的工作是为每个领域训练一个分类器，并假设所有的源领域对测试样本都是同等重要的（Li和Zong，2008；Luo等人，2008）。最近，基于对抗的方法使用未标记的数据，将源域与目标域对齐（Zhao等人，2018；Chen和Cardie，2018）。同时，Kim等人（2017年）和Guo等人（2018年）根据目标实例和每个源域之间的关系，明确地对专家混合模型（MoE）模型进行加权。然而，Wright和Augenstein（2020）在这项工作之后，在基于Transfomers的MoE上测试了各种加权方法，发现加权方法非常有效。</p><p>我们认识到所提出的MoE解决方案的两个局限性。首先，它是不可扩展的，因为它要求每个源域都有一个专家，导致模型参数随着源域数量的增加而增加（通常是线性的）。第二，领域专家是针对特定领域的知识进行调整的。然而，测试实例可能来自未知的领域，并可能反映出来源的复杂组合。为了解决这个问题，MoE使用启发式方法将专家的预测集合起来，例如简单的平均数或基于领域分类器预测的加权平均数。我们的结果表明，这种方法是次优的。</p><p>在这项工作中，我们训练一个模型，该模型在所有领域中共享其参数。此外，我们对适应任何目标领域感兴趣，这样在训练时就不需要知道关于潜在目标领域的信息。上述一些工作（Wright和Augenstein，2020年）事实上避免了利用目标数据，因此它们适合任何领域的设置，并形成了我们的两个基线。然而，与这些作品相比，我们认为这个定义是本研究的核心部分。</p><h3 id="Autoregressive-Language-Modeling"><a href="#Autoregressive-Language-Modeling" class="headerlink" title="Autoregressive Language Modeling"></a>Autoregressive Language Modeling</h3><p>以前的工作在训练基于Transformer（Vaswani等人，2017）的语言模型时主要考虑两种方法。第一种实现了经典的马尔科夫语言建模方法，通过训练Transformer解码器模型，根据其之前的上下文自动生成下一个词（Radford和Narasimhan，2018；Radford等人，2019）。第二种是将自回归语言建模方法作为一个掩盖的标记预测任务，通过训练Transformer的编码器来得出上下文的单词嵌入（Devlin等人，2019；Liu等人，2019；Sanh等人，2019）。当为一个新的任务微调模型时，一个自定义的解码器被实现，并与模型的预训练编码器联合训练。</p><p>最近提出了第三种方法，试图将以前的方法中的优点结合起来。它提出训练一个完整的Transformer（编码器-解码器）语言模型，从输入序列中自动渐进地生成屏蔽的、缺失的或扰乱的标记跨度，作为一个序列到序列的任务（Raffel等人，2020；Lewis等人，2020b）。最近，Raffel等人（2020）提出了T5，一个基于转化器的模型，提出了文本到文本的迁移学习方法。T5基本上将所有的任务视为生成性的，同时利用一个提示短语来表示正在执行的具体任务。结合其文本到文本的方法，T5在许多鉴别性和生成性任务中显示出其优越性，同时消除了对特定任务网络结构的需求。</p><p>T5的一个特别有趣和有用的特点是其 prompting 机制。prompt 短语通常用于指示模型要执行的任务，被作为前缀添加到所有与任务相关的输入实例中。最近的工作也探索了这种 prompt 机制，以使语言模型适应不同的目的（Brown等人，2020年），激发情感或话题相关的信息（Jiang等人，2020年；Sun和Lai，2020年；Shin等人，2020年），或作为一种有效的微调方法（Li和Liang，2021年）。在这项工作中，我们利用T5的提示机制，作为激发模型编码与每个测试例子相关的特定领域特征的方式。</p><h2 id="Any-Domain-Adaptation"><a href="#Any-Domain-Adaptation" class="headerlink" title="Any-Domain Adaptation"></a>Any-Domain Adaptation</h2><h3 id="DA-and-Transfer-Learning"><a href="#DA-and-Transfer-Learning" class="headerlink" title="DA and Transfer Learning"></a>DA and Transfer Learning</h3><p>一个预测任务被定义为 $T = {Y}$，其中 $Y$ 是任务的标签空间。定义 $X$ 为特征空间，$P(X)$ 是 $X$ 上的边缘分布，$P(Y)$ 对 $Y$ 的先验分布。domain 被定义为 $D^T={X, P(X), P(Y),P(Y|X)}$</p><p>DA是迁移学习的一个特殊案例，即过渡性转移学习，其中 $T_S$ 和 $T_T$，即源任务和目标任务，是相同的。</p><p>$D<em>S^T, D^{T}</em>{T}$ 是源域和目标域，至少有一个基础概率分布不同，即$P(X),P(Y) \ or \ P(Y|X)$。</p><p>DA 的目标是从一组源域 ${ D<em>{S_i}}^K</em>{i=1}$ 中学习一个函数 $f$ ，这个函数可以很好地泛化到一组目标域$ { D<em>{T_i} }^M</em>{i=1}$ </p><h3 id="The-Any-Domain-Setting"><a href="#The-Any-Domain-Setting" class="headerlink" title="The Any-Domain Setting"></a>The Any-Domain Setting</h3><p>我们专注于为一个给定的任务建立一个能够适应任何领域的算法。为此，我们假设在训练时对目标领域 $D_T$ 的了解为零。因此，我们稍微修改了无监督多源领域适应的经典设置，假设我们不知道或无法获得目标领域的标记或未标记数据。</p><p>我们只假设可以从K个源域中获得标记的训练数据  $ {D<em>{s_i}}$，其中 $D</em>{S_i} = {(x_t^{S_i}, y_t^{S_i})}$。目标是学习一个仅使用源域数据的模型，该模型可以很好地概括到一个未知的目标域。</p><h3 id="Any-Domain-Adaptation-and-Zero-Shot-Learning"><a href="#Any-Domain-Adaptation-and-Zero-Shot-Learning" class="headerlink" title="Any-Domain Adaptation and Zero-Shot Learning"></a>Any-Domain Adaptation and Zero-Shot Learning</h3><p>我们避免将我们的设置命名为 “Zero-Shot DA”，因为我们认为Zero-Shot学习是一个过载的术语，而且它的用法在不同的作品中是不同的。一方面，GPT-3的作者（Brown等人，2020）用这个术语来表示向未知目标任务 $T^T$和未知领域 $D^T$的转变。</p><p>另一方面，Kodirov等人（2015）假设任务/标签空间漂移，而目标域在训练期间是已知的，Blitzer等人（2009）假设可以访问来自包括目标域在内的各种领域的无标签数据，而Peng等人（2018）使用来自目标域的不同任务数据。我们的问题设置与上述作品不同，但在某种程度上都可以被描述为 “Zero-shot”。在我们看来，这些差异应该被澄清，因此我们为我们的设置提出了一个指定的术语。</p><h2 id="Prompt-based-Autoregressive-DA"><a href="#Prompt-based-Autoregressive-DA" class="headerlink" title="Prompt-based Autoregressive DA"></a>Prompt-based Autoregressive DA</h2><p>正如前面第2节所讨论的，我们认识到基于MoE的方法所提出的解决方案有两个主要限制。(1) 它是不可扩展的。训练的参数总数，对于单个模型来说已经很大了，随着源域数量的增加而线性增长，因为需要为每个域分别训练一个专家模型。自然，这也增加了整体的训练时间；（2）在这种方法中，每个领域都要训练一个单独的模型。直观地说，针对特定领域的专家被调整为针对特定领域的知识，有时会牺牲跨领域的知识，因为跨领域的知识强调不同领域之间的关系。此外，由于领域的划分往往是任意的（例如考虑dvd和电影领域之间的差异），我们不希望将我们的模型严格限制在一个特定的分区，而是鼓励对领域边界采取更宽松的方法。</p><p>因此，我们提出一个单一的模型来编码来自多个领域的信息。我们的模型是这样设计的：<strong>来自新的未知领域的测试样本可以触发模型中最相关的参数</strong>。这样，<strong>我们允许我们的模型在各领域之间共享信息</strong>，<strong>并在测试时使用最相关的信息</strong>。我们的模型受到最近关于自回归语言模型 prompt 机制的研究启发。最近的工作显示了prompt 机制在激发这些模式方面的有效性（§2），尽管不是在DA的背景下。</p><p>我们首先（第4.1节）描述了我们模型的一般结构，然后（第4.2节）介绍了形成我们prompt的领域相关特征。</p><h3 id="The-Model"><a href="#The-Model" class="headerlink" title="The Model"></a>The Model</h3><p>一个多任务模型，<strong>有一个为DRF生成训练的生成头和一个为谣言检测训练的鉴别头</strong>。标记的文字表示DRF，标记的文字表示域名。黑色箭头（→）表示第一个推理步骤，红色箭头（→）表示第二个推理步骤。提出的模型是在4个不同的源域上训练的。Ferguson, Germanwings-crash, Ottawa-shooting, and Sidney-siege，而测试实例来自Charlie-Hebdo域。这些模型识别出例子的来源是悉尼围城，并将其与<strong>3个DRF相关联：人质、咖啡馆和枪手</strong>。</p><p><img src="https://i.loli.net/2021/11/23/mtD8MgoxRXGOSJz.png" alt=""></p><p>我们提出了基于提示的领域适应自回归算法（PADA，图2a）。PADA采用了一个预先训练好的T5语言模型，并<strong>学习生成特定样本的领域相关特征（DRFs），以促进准确的任务预测。</strong>这是通过<strong>一个两步多任务机制实现</strong>的，<strong>首先生成一个DRF集以形成一个prompt，然后预测任务标签。</strong></p><p>形式上，假设一个输入样本  $ (x_i, yi) \sim S_i $ ，这样 $x_i$ 是输入文本，$y_i$ 是任务label，$S_i$是这个例子的领域。</p><p> <strong>对于输入的 $x_i$，PADA被训练成首先生成 $N_i$，即域名</strong>，然后是 $R_i$，即 $x_i$ 的DRF签名，<strong>并根据这个 prompt 来预测标签$y_i$。</strong>在测试时，<strong>当模型遇到一个来自未知领域的例子时，它会产生一个 prompt，该 prompt 可能由一个或多个域名以及一个或多个源域的DRF集的特征组成，并基于该 prompt 预测任务标签。</strong></p><p><img src="https://i.loli.net/2021/11/23/ot5qEnNY1HCzx4K.png" alt=""></p><p>考虑到图1中的例子，它描述了一个情感分类模型，在餐馆、家庭家具、电子设备和电影等源域上进行训练。该模型观察到一个来自航空公司领域的测试例子，这是一个以前没有见过的领域，模型不知道其名称。该模型首先生成最适合这个例子的训练域的名称，在这个例子中是餐馆。然后，它继续生成 “食物 “和 “椅子”，这两个词分别与餐馆和家庭家具领域有关。最后，鉴于这一 prompt，该模型预测了该例子的（负面）情绪。</p><p><strong>为了将 prompt 生成任务与判别分类任务分开，我们在一个多任务框架内训练我们的模型</strong>。<strong>根据样本的prompt，PADA被训练成执行两个任务。一个是生成 prompt，由例子领域的DRF集的特征组成，另一个是预测样本的标签。</strong></p><p>对<strong>于第一个生成任务，模型接收带有特殊prompt “域：”的例子，这为模型生成 $N_i$ 和 $R_i$ 提供了条件。</strong>请注意，$R_i$是一组从 $S_i$ 的DRF集衍生出来的特征，如第4.2节所述，训练的样本被自动注释了它们的 $R_i$。对于第二个判别性任务，模型收到一个 prompt ，由 $N_i$ 和 $R_i$ 组成，其任务是预测 $y_i$。</p><p>按照T5的多任务训练协议，我们对每个任务的样本进行混合。为此，我们定义了一个任务比例混合参数 $α$。 训练集中的每个例子都以 $α$ 的概率形成生成性任务的样本，以 $1-α$ 的概率形成鉴别性任务的样本。$α$ 的值越大，模型对生成性任务的训练就越多。</p><p>PADA以生成的 prompt 为条件进行分类。为了评估这一条件的效果，我们还考虑了一个更简单的PADA变体，它联合执行分类和生成任务，但不使用生成任务的输出作为分类任务的 prompt 。我们把这个变体命名为PADA-NC，以强调判别任务不以生成部分的输出为条件。PADA和PADA-NC之间的区别在图2中得到了强调。</p><p>我们方法的核心是<strong>巧妙地选择每个领域的DRF集</strong>。我们接下来讨论这些特征和它们的选择过程。</p><h3 id="Domain-Related-Features"><a href="#Domain-Related-Features" class="headerlink" title="Domain Related Features"></a>Domain Related Features</h3><p><strong>对于每个领域，我们定义DRF集，使这些特征为该领域提供一个语义签名</strong>。重要的是，<strong>如果两个领域有共同的语义，例如餐馆和烹饪领域，我们希望它们的DRFs在语义上是重叠的</strong>。<strong>由于每个训练样本的 prompt 由其领域的DRF集的特征子集组成，我们也应该决定一个 prompt 生成规则，可以用其相关的特征来注释这些训练样本。</strong></p><p>为了反映该领域的语义，DRF应该经常出现在该领域。<strong>此外，相对于所有其他领域，它们在该特定领域中应该是非常普遍的。尽管DRF在一个特定的领域中很突出，但它也可以与其他领域相关。例如，考虑图2中的例子。人质 “这个词与 “Charlie-Hebdo “领域高度相关，而且确实是其DRFs之一。然而，这个词也与 “Sydney-Siege “域相关</strong>，这是Rumour Detection数据集的另一个域（Zubiaga等人，2016）。此外，<strong>由于这两个领域都与类似的事件有关，前者的DRF集包含恐怖分子的特征，后者的DRF集包含枪手的特征</strong>，这并不令人惊讶。<strong>这些特征的相似性促进了我们模型中的参数共享。</strong></p><p>我们<strong>对每个源域的DRF集定义如下。让第 $j$ 个源域（$S_j$）的样本（文本）被标记为1，所有其他域（ $S\setminus S_j$ ）的例子被标记为 0。</strong>我们首先<strong>计算所有 tokens 和这个二元变量之间的相互信息（MI）</strong>，<strong>并选择 MI 得分最高的 $l$ 个token。</strong>注意，<strong>MI标准可能会促进与（ $S\setminus S_j$ ）高度相关的标记</strong>，<strong>而不是与 $S_j$ 。</strong>因此，<strong>我们根据以下条件来过滤 $l$ 个token:</strong></p><script type="math/tex; mode=display">\frac{C_{S\setminus S_j}(n)}{C_{S_j}(n)} \le \rho , C_{S_j}(n) \gt 0</script><p>其中 $C<em>{S_j}(n)$ 是 $S_j$ 中n-gram $n$ 的计数， $C</em>{S\setminus S_j}(n)$ 是在所有源域中除了 $ S_j$ 的 n-gram 计数，$ρ$ 是 n-gram 频率比参数。</p><p>直观地说，<strong>$ρ$ 越小，我们就越确定这个n-gram与 $S_j$ 特别相关，与其他领域相比。由于 $S_j$ 中的样本数量远远小于  $S\setminus S_j$  中的样本数量，</strong>我们选择 $ρ≥1$ ，但不允许它过大。因此，这个标准允许与 $S_j$ 相关但也与其他源域相关的特征成为 $S_j$ 的DRF集的一部分。我们用 $R_j$ 来表示第 $j$ 个域的DRF集。</p><p>给定一个来自领域 $j$ 的训练样本 $i$ ，我们<strong>从 $R_j$ 中选择与该样本最相关的 $m$ 个特征来形成其 prompt</strong>。为此，我们计算DRF特征的T5嵌入 和 每个样本的T5嵌入 之间的欧几里得距离。然后，我们根据分数对这个列表进行排序，并选择最重要的 $m$ 个特征。（在这个计算中，我们考虑了T5在其预训练期间学到的非语境嵌入。在我们的实验中，我们只考虑单字（单词）作为DRFs。）</p><p>总而言之，我们<strong>针对特定领域的 DRF 集提取和训练样本的 prompt 注释的方法，展示了三个有吸引力的特性</strong>。首先，<strong>每个样本都有它自己独特的prompt</strong> 。其次，<strong>我们的 prompt 将每个训练样本映射到其领域的语义空间。</strong>最后，<strong>特定领域的DRF集可能会在其语义上重叠，要么包括相同的token，要么包括具有类似含义的token。</strong>这样，<strong>与单独的域名相比，它们提供了一个更细微的领域签名。</strong>在<strong>推理阶段，模型可以生成一个特定的样本prompt，该提示由不同源域的DRF集的特征组成</strong>，这一点后来被使用。</p><h2 id="Experimental-Setup"><a href="#Experimental-Setup" class="headerlink" title="Experimental Setup"></a>Experimental Setup</h2><p>我们的主要模型是PADA：这个<strong>多任务模型首先生成域名和领域相关的特征，形成一个prompt，然后用这个prompt来预测任务标签</strong>。我们将其与两种类型的模型进行比较。(a) 基于T5的基线，对应于多源DA工作中提出的想法，以及其他最近的最先进的模型；以及(b) 使用PADA特定部分的消融模型，以强调其组成部分的重要性。</p><h3 id="Baseline-Models"><a href="#Baseline-Models" class="headerlink" title="Baseline Models"></a>Baseline Models</h3><ul><li><em>Content-CRF</em> ： 一个为谣言检测而训练的CRF模型。每个预测都以相关的推文以及之前的推文为条件，同时结合了基于内容和社会特征。</li><li><em>Transformer-based Mixture of Experts</em>： 对于每个源域，在该域的训练集上训练一个单独的基于变压器的DistilBERT专家模型（Sanh等人，2019），并在所有源域的数据上训练另一个模型。在测试时，计算这些模型的类别概率的平均值，并选择最高概率的类别。这个模型被Wright和Augenstein（2020）命名为MoE-avg，并证明了在谣言检测方面取得了最先进的性能（该论文将CCRF的重新结果报告为其之前的最先进性能）。</li><li><em>T5-MoE</em> ：一个基于T5的MoE集合模型。对于每个源域，一个单独的预训练的T5模型在该域的训练集上进行微调（即一个领域专家模型）。在推理过程中，模型的最终预测是用Tr-MoE中相同的平均程序决定的。</li><li><em>T5-No-Domain-Adaptation (T5-NoDA)</em> ：一个预先训练好的T5模型，它向PADA（见下文）中使用的同一任务分类器提供信息，以预测任务标签。 在每个DA设置中，该模型是在所有源域的训练数据上训练的。</li><li><em>T5-Domain-Adversarial-Network (T5-DAN)</em> ：一个将T5-NoDA与对抗性领域分类器整合的模型，以学习领域不变的表征（Ganin和Lempitsky，2015）。</li><li><em>T5-Invariant-Risk-Minimization (T5-IRM)</em> ：一个基于T5的模型，它对每个领域有不同的最佳线性分类器的特征分布进行惩罚。IRM（Arjovsky等人，2019）是一个成熟的机器学习基线，用于超越多源分布的泛化（Koh等人，2020）。该模型是在所有源域的训练数据上训练的。</li><li><em>T5-UpperBound (T5-UB)</em> ：一个与T5-NoDA结构相同的域内模型。它在所有领域的训练数据上进行训练，在每个领域的开发数据上进行测试。我们将其性能视为所有DA设置中平均目标性能的上限，对于我们设置中的任何基于T5的模型。</li></ul><h3 id="Ablation-Models"><a href="#Ablation-Models" class="headerlink" title="Ablation Models"></a>Ablation Models</h3><ul><li>PADA-DN 我们的PADA模型的一个简化变体，它只给输入文本分配一个域名作为prompt。由于域名在测试时是未知的，我们为每个测试样本创建多个变体，每个变体都有一个训练域名作为prompt。对于模型的最终预测，我们遵循与Tr-MoE和T5-MoE相同的平均化过程。</li><li>PADA-NC 一个类似于PADA的多任务模型，只是它同时生成特定于样本的域名和DRF prompt并预测任务标签。这个模型不以提示为条件进行任务预测。</li></ul><h3 id="Implementation-Details"><a href="#Implementation-Details" class="headerlink" title="Implementation Details"></a>Implementation Details</h3><p>对于所有实现的模型，我们都使用了 “Hugging-Face “ Transformers库。基于T5的文本分类模型没有遵循Raffel等人（2020）最初描述的程序。相反，我们在T5编码器之上添加了一个简单的 1D-CNN分类器 来预测任务标签（图2）。</p><p>该分类器中的过滤器数量为32个，过滤器大小为9。基于T5的模型的生成部分与原始T5的生成部分相同。我们基于T5的特征预测模型将序列标记作为一个序列到序列的任务，采用Raffel等人（2020）的文本到文本方法，为每个输入标记生成一个’B’（开始）、’I’（进入）或’O’（退出）标记。 除了这一变化外，这些模型与基于T5的文本分类模型完全相同。</p><p>我们对所有的文本分类模型进行5个 epochs 的训练，对所有的序列标签模型进行60个 epoch的训练，并根据开发数据的表现制定早期停止的标准。我们对所有模型使用交叉熵损失函数，用ADAM优化器（Kingma和Ba，2015）优化其参数。我们对文本分类采用32个批处理规模，对序列标签采用24个批处理规模，预热比为0.1，学习率为5 e10-5。所有基于T5的模型的最大输入和输出长度被设定为128个符号。我们对较短的序列进行填充，并将较长的序列截断到最大输入长度。</p><p>对于PADA，我们调整α（例子比例—混合物，见§4.1）参数，考虑到{0.1, 0.25, 0.5, 0.75, 0.9}的数值范围。）选择的数值是 αrumour = 0.75，αmnli = 0.1和αabsa = 0.1。对于每个例子，我们选择与之最相关的前m = 5个DRF，对其进行提示。</p><p>对于基于T5的模型的生成部分，我们用Diverse Beam Search算法（Vijayaku- mar等人，2016）进行推理，考虑以下超参数。我们产生了5个候选人，使用10个波束大小，5个波束组，多样性惩罚值为1.5。DRF提取程序（§4.2）的l和ρ参数被调整为1000和1.5，适用于所有领域。</p><h2 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h2><p>Binary-F1测量的是正类的F1得分。它对正类感兴趣的不平衡数据集很有用。在谣言检测数据集中，34%的例子属于正类。</p><p><img src="https://i.loli.net/2021/11/23/z4rZXTJYnOytFRE.png" alt=""></p><p>表2显示了我们的结果。 PADA在10个设置中的6个中优于所有的模型，在Rumour Detection和MNLI中分别比T5-NoDA的平均性能提高了3.5%和1.3%，T5-NoDA是不属于我们PADA框架的最佳模型。此外，在10个设置中的9个中，PADA模型是表现最好的模型之一。有趣的是，不执行任何DA的T5-NoDA的性能超过了所有不属于PADA系列的模型，包括MoE模型（平均和大多数模型之间的比较）。</p><p>虽然不同任务之间的性能提升不同，但它们部分源于每个任务中源域和目标域之间的不同性能差距。回顾一下，我们认为T5-UB在谣言检测（82.8%）和MNLI（80.8%）的开发集上的表现，是任何基于T5的模型在所有DA设置中平均目标表现的上限。当考虑到这个上限和T5-NoDA之间的差距时（Rumour Detection为65.8%，MNLI为78.3%），PADA将Rumour Detection的错误率降低了21%，MNLI为52%。事实上，PADA在这两项任务中获得的改进是巨大的。</p><p>虽然不同任务之间的性能提升不同，但它们部分源于每个任务中源域和目标域之间的不同性能差距。回顾一下，我们认为T5-UB在谣言检测（82.8%）和MNLI（80.8%）的开发集上的表现，是任何基于T5的模型在所有DA设置中平均目标表现的上限。当考虑到这个上限和T5-NoDA之间的差距时（Rumour Detection为65.8%，MNLI为78.3%），PADA将Rumour Detection的错误率降低了21%，MNLI为52%。事实上，PADA在这两项任务中获得的改进是巨大的。<br>与MoE相比，PADA的优势并不局限于改进预测。特别是，对于PADA，我们训练一个单一的模型，而对于MoE，我们为每个源域训练一个独特的模型，因此MoE框架中的参数数量随着源域的数量而线性增加。例如，在我们的设置中，Tr-MoE训练了五个DistilBERT模型（每个源域一个，所有源域一个），导致5 - 66M = 330M参数。相比之下, PADA模型保留了T5的220M参数, 而不考虑源域的数量。</p><p>我们的研究结果显示，在10个环境中的9个中，PADA及其变体PADA-DN和PADA-NC优于所有其他模型。特别是，PADA在10个环境中的7个环境中优于非PADA模型，PADA-NC在6个环境中优于这些模型，而PADA-DN在5个环境中优于这些模型。此外，PADA在所有的谣言检测设置中和5个MNLI设置中的3个中优于PADA-DN变体，而其PADA-NC变体在10个设置中的8个中优于PADA-DN。这些结果突出了我们设计选择的重要性。(a) 在特定例子的提示中包括DRFs，使它们能够表达源域和测试例子之间的关系（PADA vs PADA-DN）；以及(b) 利用自回归组件，其中生成的DRF提示被任务分类组件使用（PADA vs PADA-NC）。</p><h3 id="Performance-Shifts-between-Source-and-Target"><a href="#Performance-Shifts-between-Source-and-Target" class="headerlink" title="Performance Shifts between Source and Target"></a>Performance Shifts between Source and Target</h3><p><img src="https://i.loli.net/2021/11/23/x1Lza6UsSTZbhk4.png" alt=""></p><p>当DA方法提高了模型在目标域的性能时，这可能会导致源域和目标域之间的性能差距增加或减少。如果一个模型在其源训练域和未见过的目标域的表现相似，其源域的表现也可以为其未来在这些未见过的域的表现提供一个重要的指示。因此，在我们的设置中，如果未来的目标域是未知的，我们认为这种性能的稳定性是一个理想的属性。</p><p>图3显示了三个热图，描述了每个模型在源域和目标域之间的性能变化。如第6节所述，我们通过计算所有源域开发样本的F1得分和目标域测试集的表现来衡量每个模型的域内性能。然后，我们计算源域和目标域性能指标之间的差异，并对实验中表现最好的模型进行重新定位。总的趋势是明确的：PADA不仅在目标域表现更好，而且它还大大减少了源-目标性能的差距。虽然不是DA模型的T5-NoDA引发了最大的平均绝对性能转变—Rumour Detection为17%，MNLI为4.3%，Aspect Prediction为34%，但PADA的平均绝对性能转变分别为8.7%、3.5%和26%。</p><h2 id="Discussion"><a href="#Discussion" class="headerlink" title="Discussion"></a>Discussion</h2><p>我们解决了在训练时不知道目标域的情况下的多源域适应问题。这种设置的有效模型可以应用于任何目标域，对目标域没有任何数据再要求，而且模型参数的数量不会随着源或目标域的数量而增加。我们的算法PADA利用了T5自回归语言模型的提示机制，将测试例子映射到源域所跨越的语义空间。<br>我们对三个任务和十四个多源适应性设置的实验结果表明，与强大的替代方案相比，我们的方法是有效的，同时也表明了模型组件和我们的设计选择的重要性。此外，与MoE范式相比，PADA提供了一个统一的模型，即为每个源域训练一个模型。从直觉上讲，这种方法似乎也更符合认知规律—一个单一的模型试图使自己适应新的输入领域，而不是在每个领域采用一个独立的模型。<br>PADA的提示生成机制自然受到它所训练的源域集的限制。这可能会产生次优的DRF，而这些测试例子来自于与任何源域在语义上极不相关的领域。此外，我们没有直接用主要预测任务来优化提示生成过程，这也可能导致次优的DRF生成。在未来的工作中，我们希望改进我们方法的这些方面，并探索在一个单一模型中容纳多个任务和领域的自然扩展。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;PADA-A-Prompt-based-Autoregressive-Approach-for-Adaptation-to-Unseen-Domains&quot;&gt;&lt;a href=&quot;#PADA-A-Prompt-based-Autoregressive-Approach-</summary>
      
    
    
    
    
    <category term="context detection" scheme="http://example.com/tags/context-detection/"/>
    
  </entry>
  
  <entry>
    <title>二叉树刷题1</title>
    <link href="http://example.com/2021/11/19/%E4%BA%8C%E5%8F%89%E6%A0%91%E5%88%B7%E9%A2%981/"/>
    <id>http://example.com/2021/11/19/%E4%BA%8C%E5%8F%89%E6%A0%91%E5%88%B7%E9%A2%981/</id>
    <published>2021-11-19T11:17:33.000Z</published>
    <updated>2021-11-26T01:55:29.841Z</updated>
    
    <content type="html"><![CDATA[<h1 id="二叉树刷题1"><a href="#二叉树刷题1" class="headerlink" title="二叉树刷题1"></a>二叉树刷题1</h1><p>[TOC]</p><h2 id="树的基础"><a href="#树的基础" class="headerlink" title="树的基础"></a>树的基础</h2><h3 id="102-二叉树的层序遍历"><a href="#102-二叉树的层序遍历" class="headerlink" title="102. 二叉树的层序遍历"></a><a href="https://leetcode-cn.com/problems/binary-tree-level-order-traversal/">102. 二叉树的层序遍历</a></h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> List&lt;List&lt;Integer&gt;&gt; levelOrder(TreeNode root) &#123;</span><br><span class="line">        List&lt;List&lt;Integer&gt;&gt; res = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        <span class="keyword">if</span>(root == <span class="keyword">null</span>) <span class="keyword">return</span> res;</span><br><span class="line"></span><br><span class="line">        Queue&lt;TreeNode&gt; queue = <span class="keyword">new</span> LinkedList&lt;&gt;();</span><br><span class="line">        queue.offer(root);</span><br><span class="line">        <span class="keyword">while</span>(!queue.isEmpty())&#123;</span><br><span class="line">            List&lt;Integer&gt; level = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">            <span class="keyword">int</span> currentLevelSize = queue.size();</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">1</span>; i&lt;= currentLevelSize; ++i)&#123;</span><br><span class="line">                TreeNode node = queue.poll();</span><br><span class="line">                level.add(node.val);</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span>(node.left!=<span class="keyword">null</span>)&#123;</span><br><span class="line">                    queue.offer(node.left);</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span>(node.right!=<span class="keyword">null</span>)&#123;</span><br><span class="line">                    queue.offer(node.right);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            res.add(level);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="107-二叉树的层序遍历-II"><a href="#107-二叉树的层序遍历-II" class="headerlink" title="107. 二叉树的层序遍历 II"></a><a href="https://leetcode-cn.com/problems/binary-tree-level-order-traversal-ii/">107. 二叉树的层序遍历 II</a></h3><p>从根节点开始搜索，每次遍历同一层的全部节点，使用一个列表存储该层的节点值。</p><p>如果要求从上到下输出每一层的节点值，做法很直观，在遍历完一层节点之后，将存储该层节点值的列表添加到结果列表的尾部。</p><p>但这道题要求从下到上输出每一层，只要对上述操作稍作修改即可；在遍历完一层节点之后，将存储该节点值的列表添加到结果列表的头部。</p><p>为了降低在结果列表的头部添加一层节点值的列表的时间复杂度，结果列表可以使用链表的结构，在链表头部添加一层节点值的列表的时间复杂度是 O(1)O(1)。在 Java 中，由于我们需要返回的 List 是一个接口，这里可以使用链表实现；而 C++ 或 Python 中，我们需要返回一个 vector 或 list，它不方便在头部插入元素（会增加时间开销），所以我们可以先用尾部插入的方法得到从上到下的层次遍历列表，然后再进行反转。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> List&lt;List&lt;Integer&gt;&gt; levelOrderBottom(TreeNode root) &#123;</span><br><span class="line">        List&lt;List&lt;Integer&gt;&gt; res = <span class="keyword">new</span> LinkedList&lt;&gt;();</span><br><span class="line">        <span class="keyword">if</span>(root == <span class="keyword">null</span>) <span class="keyword">return</span> res;</span><br><span class="line"></span><br><span class="line">        Queue&lt;TreeNode&gt; queue = <span class="keyword">new</span> LinkedList&lt;&gt;();</span><br><span class="line">        queue.offer(root);</span><br><span class="line">        <span class="keyword">while</span>(!queue.isEmpty())&#123;</span><br><span class="line">            List&lt;Integer&gt; level = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">            <span class="keyword">int</span> size = queue.size();</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;size;i++)&#123;</span><br><span class="line">                TreeNode node = queue.poll();</span><br><span class="line">                level.add(node.val);</span><br><span class="line">                TreeNode left = node.left, right =node.right;</span><br><span class="line">                <span class="keyword">if</span>(left!=<span class="keyword">null</span>)&#123;</span><br><span class="line">                    queue.offer(left);</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span>(right!=<span class="keyword">null</span>)&#123;</span><br><span class="line">                    queue.offer(right);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            res.add(<span class="number">0</span>, level);</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="二叉树的遍历"><a href="#二叉树的遍历" class="headerlink" title="二叉树的遍历"></a>二叉树的遍历</h2><h3 id="前中后序"><a href="#前中后序" class="headerlink" title="前中后序"></a>前中后序</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> List&lt;Integer&gt; <span class="title">preorderTraversal</span><span class="params">(TreeNode root)</span> </span>&#123;</span><br><span class="line">        List&lt;Integer&gt; res = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        preorder(root, res);</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">preorder</span><span class="params">(TreeNode root, List&lt;Integer&gt; res)</span></span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(root == <span class="keyword">null</span>) <span class="keyword">return</span>;</span><br><span class="line">        res.add(root.val);</span><br><span class="line">        preorder(root.left, res);</span><br><span class="line">        preorder(root.right, res);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>迭代</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> List&lt;Integer&gt; <span class="title">preorderTraversal</span><span class="params">(TreeNode root)</span> </span>&#123;</span><br><span class="line">        List&lt;Integer&gt; res = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        <span class="keyword">if</span>(root==<span class="keyword">null</span>) <span class="keyword">return</span> res;</span><br><span class="line"></span><br><span class="line">        Deque&lt;TreeNode&gt; stack = <span class="keyword">new</span> LinkedList&lt;&gt;();</span><br><span class="line">        TreeNode node = root;</span><br><span class="line">        <span class="keyword">while</span>(!stack.isEmpty() || node!=<span class="keyword">null</span>)&#123;</span><br><span class="line">            <span class="keyword">while</span>(node!=<span class="keyword">null</span>)&#123;</span><br><span class="line">                res.add(node.val);</span><br><span class="line">                stack.push(node);</span><br><span class="line">                node = node.left;</span><br><span class="line">            &#125;</span><br><span class="line">            node = stack.pop();</span><br><span class="line">            node = node.right;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> List&lt;Integer&gt; <span class="title">inorderTraversal</span><span class="params">(TreeNode root)</span> </span>&#123;</span><br><span class="line">        List&lt;Integer&gt; res = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        <span class="keyword">if</span>(root==<span class="keyword">null</span>) <span class="keyword">return</span> res;</span><br><span class="line">        Deque&lt;TreeNode&gt; stack = <span class="keyword">new</span> LinkedList&lt;&gt;();</span><br><span class="line">        TreeNode node = root;</span><br><span class="line">        <span class="keyword">while</span>(!stack.isEmpty() || node!=<span class="keyword">null</span>)&#123;</span><br><span class="line">            <span class="keyword">while</span>(node!=<span class="keyword">null</span>)&#123;</span><br><span class="line">                stack.push(node);</span><br><span class="line">                node = node.left;</span><br><span class="line">            &#125;</span><br><span class="line">            node = stack.pop();</span><br><span class="line">            res.add(node.val);</span><br><span class="line">            node = node.right;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">  </span><br><span class="line">   <span class="function"><span class="keyword">public</span> List&lt;Integer&gt; <span class="title">postorderTraversal</span><span class="params">(TreeNode root)</span> </span>&#123;</span><br><span class="line">        List&lt;Integer&gt; res = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        <span class="keyword">if</span>(root==<span class="keyword">null</span>) <span class="keyword">return</span> res;</span><br><span class="line"></span><br><span class="line">        Deque&lt;TreeNode&gt; stack = <span class="keyword">new</span> LinkedList&lt;&gt;();</span><br><span class="line">        TreeNode prev = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">while</span>(root!=<span class="keyword">null</span> || !stack.isEmpty())&#123;</span><br><span class="line">            <span class="keyword">while</span>(root!=<span class="keyword">null</span>)&#123;</span><br><span class="line">                stack.push(root);</span><br><span class="line">                root = root.left;</span><br><span class="line">            &#125;</span><br><span class="line">            root = stack.pop();</span><br><span class="line">            <span class="keyword">if</span>(root.right==<span class="keyword">null</span> || root.right==prev)&#123;</span><br><span class="line">                res.add(root.val);</span><br><span class="line">                prev = root;</span><br><span class="line">                root = <span class="keyword">null</span>;</span><br><span class="line">            &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                stack.push(root);</span><br><span class="line">                root = root.right;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><h3 id="112-路径总和"><a href="#112-路径总和" class="headerlink" title="112. 路径总和"></a><a href="https://leetcode-cn.com/problems/path-sum/">112. 路径总和</a></h3><h4 id="DFS"><a href="#DFS" class="headerlink" title="DFS"></a>DFS</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">hasPathSum</span><span class="params">(TreeNode root, <span class="keyword">int</span> sum)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(root==<span class="keyword">null</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(root.left==<span class="keyword">null</span> &amp;&amp; root.right==<span class="keyword">null</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span> root.val == sum;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> hasPathSum(root.left, sum - root.val) || hasPathSum(root.right, sum - root.val);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="BFS"><a href="#BFS" class="headerlink" title="BFS"></a>BFS</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">hasPathSum</span><span class="params">(TreeNode root, <span class="keyword">int</span> sum)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(root == <span class="keyword">null</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        Queue&lt;TreeNode&gt; queNode = <span class="keyword">new</span> LinkedList&lt;TreeNode&gt;();</span><br><span class="line">        Queue&lt;Integer&gt; queVal = <span class="keyword">new</span> LinkedList&lt;Integer&gt;();</span><br><span class="line">        queNode.offer(root);</span><br><span class="line">        queVal.offer(root.val);</span><br><span class="line">        <span class="keyword">while</span>(!queNode.isEmpty())&#123;</span><br><span class="line">            TreeNode now = queNode.poll();</span><br><span class="line">            <span class="keyword">int</span> temp = queVal.poll();</span><br><span class="line">            <span class="keyword">if</span>(now.left == <span class="keyword">null</span> &amp;&amp; now.right==<span class="keyword">null</span>)&#123;</span><br><span class="line">                <span class="keyword">if</span>(temp==sum)&#123;</span><br><span class="line">                    <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span>(now.left != <span class="keyword">null</span>)&#123;</span><br><span class="line">                queNode.offer(now.left);</span><br><span class="line">                queVal.offer(now.left.val + temp);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span>(now.right !=<span class="keyword">null</span>)&#123;</span><br><span class="line">                queNode.offer(now.right);</span><br><span class="line">                queVal.offer(now.right.val + temp);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="113-路径总和-II"><a href="#113-路径总和-II" class="headerlink" title="113. 路径总和 II"></a><a href="https://leetcode-cn.com/problems/path-sum-ii/">113. 路径总和 II</a></h3><p>问完成一件事情的所有解决方案，一般采用回溯算法（<strong>深度优先遍历</strong>）完成。做回溯算法问题一般先画图，好在这就是一个树形问题，题目已经给我们画好了示意图。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> List&lt;List&lt;Integer&gt;&gt; pathSum(TreeNode root, <span class="keyword">int</span> targetSum) &#123;</span><br><span class="line">        List&lt;List&lt;Integer&gt;&gt; res = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        <span class="keyword">if</span>(root == <span class="keyword">null</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span> res;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        Deque&lt;Integer&gt; path = <span class="keyword">new</span> ArrayDeque&lt;&gt;();</span><br><span class="line">        dfs(root, targetSum, path,res);</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">dfs</span><span class="params">(TreeNode node, <span class="keyword">int</span> sum, Deque&lt;Integer&gt; path, List&lt;List&lt;Integer&gt;&gt; res)</span></span>&#123;</span><br><span class="line">        <span class="comment">// 递归终止条件1</span></span><br><span class="line">        <span class="keyword">if</span>(node == <span class="keyword">null</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 递归终止条件2</span></span><br><span class="line">        <span class="keyword">if</span>(node.val == sum &amp;&amp; node.left==<span class="keyword">null</span> &amp;&amp; node.right==<span class="keyword">null</span>)&#123;</span><br><span class="line">            <span class="comment">//当前节点的值还没添加到列表中，所以要先添加，再移除</span></span><br><span class="line">            path.addLast(node.val);</span><br><span class="line">            res.add(<span class="keyword">new</span> ArrayList&lt;&gt;(path));</span><br><span class="line">            path.removeLast();</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        path.addLast(node.val);</span><br><span class="line">        dfs(node.left, sum-node.val, path, res);</span><br><span class="line">        <span class="comment">// 进入左右分支的 path 是一样的，这里不用写下面两行，因为一定会调用到 path.removeLast();</span></span><br><span class="line">        <span class="comment">// path.removeLast();</span></span><br><span class="line">        <span class="comment">// path.addLast(node.val);</span></span><br><span class="line">        dfs(node.right, sum-node.val, path, res);</span><br><span class="line">        path.removeLast();</span><br><span class="line">    &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 由于先减去了当前非空节点的值，递归终止条件写 sum==0</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">dfs</span><span class="params">(TreeNode node, <span class="keyword">int</span> sum, Deque&lt;Integer&gt; path, List&lt;List&lt;Integer&gt;&gt; res)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 递归终止条件 1：遇到空结点不再递归调用</span></span><br><span class="line">        <span class="keyword">if</span> (node == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 沿途结点必须选择，这个时候要做两件事：1、sum 减去这个结点的值；2、添加到 path 里</span></span><br><span class="line">        sum -= node.val;</span><br><span class="line">        path.addLast(node.val);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 递归终止条件 2：遇到叶子结点，sum 恰好为 0，说明从根结点到叶子结点的路径是一个符合要求的解</span></span><br><span class="line">        <span class="keyword">if</span> (sum == <span class="number">0</span> &amp;&amp; node.left == <span class="keyword">null</span> &amp;&amp; node.right == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="comment">// path 全局只有一份，必须做拷贝</span></span><br><span class="line">            res.add(<span class="keyword">new</span> ArrayList&lt;&gt;(path));</span><br><span class="line">            <span class="comment">// 注意：这里 return 之前必须重置</span></span><br><span class="line">            path.removeLast();</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        pathSum(node.left, sum, path, res);</span><br><span class="line">        pathSum(node.right, sum, path, res);</span><br><span class="line">        <span class="comment">// 递归完成以后，必须重置变量</span></span><br><span class="line">        path.removeLast();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="437-路径总和-III"><a href="#437-路径总和-III" class="headerlink" title="437. 路径总和 III"></a><a href="https://leetcode-cn.com/problems/path-sum-iii/">437. 路径总和 III</a></h3><h4 id="法一-深度优先遍历"><a href="#法一-深度优先遍历" class="headerlink" title="法一 深度优先遍历"></a>法一 深度优先遍历</h4><p>穷举所有可能，访问每一个节点node，检测以 node 为起始点且向下延伸的路径有多少种。递归遍历每个节点的所有可能的路径，然后将这些路径数目加起来即为返回结果。</p><ul><li>首先定义 $rootSum(p, val)$ 表示以节点 $p$ 为起点向下且满足路径总和为 $val$ 的路径数目。我们队二叉树上每个节点 $p$ 求出 $rootSum(p,targetSum)$，然后对这些路径数目求和为返回结果</li><li>对节点 $p$ 求 $rootSum(p, targetSum)$时，以当前节点 $p$ 为目标路径的起点递归向下进行搜索。假设当前的节点$p$的值为$val$ ，对左子树和右子树进行递归搜索</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">pathSum</span><span class="params">(TreeNode root, <span class="keyword">int</span> targetSum)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(root == <span class="keyword">null</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">int</span> ret = rootSum(root, targetSum);</span><br><span class="line">        ret += pathSum(root.left, targetSum);</span><br><span class="line">        ret += pathSum(root.right, targetSum);</span><br><span class="line">        <span class="keyword">return</span> ret;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">rootSum</span><span class="params">(TreeNode root, <span class="keyword">int</span> targetSum)</span></span>&#123;</span><br><span class="line">        <span class="keyword">int</span> ret = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">if</span>(root == <span class="keyword">null</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">int</span> val = root.val;</span><br><span class="line">        <span class="keyword">if</span>(val == targetSum)&#123;</span><br><span class="line">            ret++;</span><br><span class="line">        &#125;</span><br><span class="line">        ret += rootSum(root.left, targetSum-val);</span><br><span class="line">        ret += rootSum(root.right, targetSum-val);</span><br><span class="line">        <span class="keyword">return</span> ret;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="方法二-前缀和"><a href="#方法二-前缀和" class="headerlink" title="方法二 前缀和"></a>方法二 前缀和</h4><p>上一解法存在许多重复计算，定义节点的前缀和为：由根节点到当前节点的路径上所有节点的和。</p><p>利用先序遍历二叉树，记录下根节点 $root$ 到当前节点 $p$ 的路径上除当前节点以外所有节点的前缀和，在已保存的路径前缀和中查找是否存在前缀和刚好等于当前节点到根节点的前缀和 $curr - targetSum$</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">pathSum</span><span class="params">(TreeNode root, <span class="keyword">int</span> targetSum)</span> </span>&#123;</span><br><span class="line">      Map&lt;Integer, Integer&gt; prefix = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">      <span class="comment">// 前缀和为0的一条路径</span></span><br><span class="line">      prefix.put(<span class="number">0</span>,<span class="number">1</span>);</span><br><span class="line">      <span class="comment">// 前缀和的递归回溯</span></span><br><span class="line">      <span class="keyword">return</span> recursionPathSum(root, prefix, targetSum, <span class="number">0</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">recursionPathSum</span><span class="params">(TreeNode node, Map&lt;Integer,Integer&gt; prefix, <span class="keyword">int</span> target, <span class="keyword">int</span> currSum)</span></span>&#123;</span><br><span class="line">      <span class="keyword">if</span>(node==<span class="keyword">null</span>)&#123;</span><br><span class="line">          <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">int</span> res = <span class="number">0</span>;</span><br><span class="line">      currSum += node.val;</span><br><span class="line"></span><br><span class="line">      <span class="comment">//---核心代码</span></span><br><span class="line">      <span class="comment">// 看看root到当前节点这条路上是否存在节点前缀和加target为currSum的路径</span></span><br><span class="line">      <span class="comment">// 当前节点-&gt;root节点反推，有且仅有一条路径，如果此前有和为currSum-target,而当前的和又为currSum,两者的差就肯定为target了</span></span><br><span class="line">      <span class="comment">// currSum-target相当于找路径的起点，起点的sum+target=currSum，当前点到起点的距离就是target</span></span><br><span class="line">      res += prefix.getOrDefault(currSum - target, <span class="number">0</span>);</span><br><span class="line">      <span class="comment">// 更新路径上当前节点前缀和的个数</span></span><br><span class="line">      prefix.put(currSum, prefix.getOrDefault(currSum, <span class="number">0</span>)+<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">      <span class="comment">// 进入下一层</span></span><br><span class="line">      res += recursionPathSum(node.left, prefix, target, currSum);</span><br><span class="line">      res += recursionPathSum(node.right, prefix, target, currSum);</span><br><span class="line"></span><br><span class="line">      <span class="comment">// 回到本层，恢复状态，去除当前节点的前缀和数量</span></span><br><span class="line">      prefix.put(currSum, prefix.get(currSum) - <span class="number">1</span>);</span><br><span class="line">      <span class="keyword">return</span> res;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><h3 id="129-求根节点到叶节点数字之和"><a href="#129-求根节点到叶节点数字之和" class="headerlink" title="129. 求根节点到叶节点数字之和"></a><a href="https://leetcode-cn.com/problems/sum-root-to-leaf-numbers/">129. 求根节点到叶节点数字之和</a></h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">sumNumbers</span><span class="params">(TreeNode root)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> dfs(root, <span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">dfs</span><span class="params">(TreeNode root, <span class="keyword">int</span> prevSum)</span></span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(root==<span class="keyword">null</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">int</span> sum = prevSum * <span class="number">10</span> + root.val;</span><br><span class="line">        <span class="keyword">if</span>(root.left == <span class="keyword">null</span> &amp;&amp; root.right==<span class="keyword">null</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span> sum;</span><br><span class="line">        &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">            <span class="keyword">return</span> dfs(root.left, sum) + dfs(root.right, sum);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="100-相同的树"><a href="#100-相同的树" class="headerlink" title="100. 相同的树"></a><a href="https://leetcode-cn.com/problems/same-tree/">100. 相同的树</a></h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isSameTree</span><span class="params">(TreeNode p, TreeNode q)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(p == <span class="keyword">null</span> &amp;&amp; q == <span class="keyword">null</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        &#125;<span class="keyword">else</span> <span class="keyword">if</span>(p==<span class="keyword">null</span> || q==<span class="keyword">null</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125;<span class="keyword">else</span> <span class="keyword">if</span>(p.val != q.val)&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">            <span class="keyword">return</span> isSameTree(p.left, q.left) &amp;&amp; isSameTree(p.right, q.right);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;二叉树刷题1&quot;&gt;&lt;a href=&quot;#二叉树刷题1&quot; class=&quot;headerlink&quot; title=&quot;二叉树刷题1&quot;&gt;&lt;/a&gt;二叉树刷题1&lt;/h1&gt;&lt;p&gt;[TOC]&lt;/p&gt;
&lt;h2 id=&quot;树的基础&quot;&gt;&lt;a href=&quot;#树的基础&quot; class=&quot;headerl</summary>
      
    
    
    
    
    <category term="LeetCode" scheme="http://example.com/tags/LeetCode/"/>
    
  </entry>
  
  <entry>
    <title>Towards a Unified View of Parameter-Efficient Transfer Learning</title>
    <link href="http://example.com/2021/11/17/Towards-a-Unified-View-of-Parameter-Efficient-Transfer-Learning/"/>
    <id>http://example.com/2021/11/17/Towards-a-Unified-View-of-Parameter-Efficient-Transfer-Learning/</id>
    <published>2021-11-17T09:16:12.000Z</published>
    <updated>2021-11-20T07:55:10.006Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Towards-a-Unified-View-of-Parameter-Efficient-Transfer-Learning"><a href="#Towards-a-Unified-View-of-Parameter-Efficient-Transfer-Learning" class="headerlink" title="Towards a Unified View of Parameter-Efficient Transfer Learning"></a>Towards a Unified View of Parameter-Efficient Transfer Learning</h1><p>ICLR2022高分文章</p><p>这篇工作将最近提出的多种Parameter-Efficient的迁移学习方法联系在了一起，提出了一个统一的框架，并探索了这些方法成功的关键因素是什么。</p><p>统一什么？把Adapter、prompt-tuning、LoRA都定义为预训练模型中添加可调整的特定的隐层状态，只是设计的参数维度、修改函数的计算和位置不同。定义成一个统一的框架，顺便还排列组合出几个小变体。</p><h2 id="INTRODUCTION"><a href="#INTRODUCTION" class="headerlink" title="INTRODUCTION"></a>INTRODUCTION</h2><p>使通用PLM适应下游任务的最常见方法是微调所有模型参数。然而，这导致每个任务都有一份单独的微调模型参数，当为执行大量任务的模型提供服务时，其成本过高。</p><p>为了缓解这个问题，已经提出了一些轻量级的替代方案，只更新少量的额外参数，同时保持大多数预训练参数的冻结，如：Adapters、prefix tuning 与 prompt tuning、LoRA 。（下文详细介绍他们）</p><p>这些方法都在不同的任务集上表现出与完全微调相媲美的性能，通常是通过更新不到1%的原始模型参数。除了节省参数外，参数有效的调整使其有可能快速适应新的任务，而不会出现灾难性的遗忘（Pfeiffer等人，2021），并且在 out-of-distribution 上往往表现出卓越的稳健性。</p><p>作者接下来针对上面这几种参数有效的方法提出了几个问题：</p><ul><li>这些方法是如何联系的？</li><li>这些方法是否具有对其有效性至关重要的设计要素，这些要素是什么？</li><li>每种方法的有效成分是否可以转移到其他方法中，以产生更有效的变体？</li></ul><h2 id="PRELIMINARIES"><a href="#PRELIMINARIES" class="headerlink" title="PRELIMINARIES"></a>PRELIMINARIES</h2><p>首先看一下现有这些方法在Transformer里的结构是如何：</p><p><img src="https://i.loli.net/2021/11/20/BNFQM3GX546kyiL.png" alt=""></p><ul><li><p>Adapters：在PLM的每一层插入称为适配器的小型神经模块，在微调时只对适配器进行训练。适配器层一般使用$W<em>{down}\in R^{d×r}$的向下投影，将输入 $h$ 投影到瓶颈维度 $r$ 指定的低维空间，然后使用非线性激活函数 $f(\cdot)$，再使用$W</em>{up}\in R^{r×d}$的向上投影，还有一个残差连接。</p><script type="math/tex; mode=display">\begin{equation}\begin{split}  h \leftarrow h + f(hW_{dnow})W_{up}    \end{split}\end{equation}</script><p>将两个适配器依次放在变压器的一个层内，一个在多头关注之后，一个在FFN子层之后。</p></li><li><p>prefix tuning 与 prompt tuning ：受通prompt方法的启发，在输入层或隐藏层中预置了额外的 $l$ 个可调整的前缀tokens，在下游任务的微调时只训练这些 soft prompt。具体来说，两组prefix 向量 $P_k , P_v\in R^{l×d}$ 与原始键 $K$ 和值$V$相连接，如图中所示。然后对新的 prefixed key 和值进行多头注意力计算：</p><script type="math/tex; mode=display">\begin{equation}\begin{split}  head_i = Attn(x W_{q}^{(i)} , concat(P_k^{(i)}, CW_{k}^{(i)}), concat(P_v^{(i)}, CW_v^{(i)}))    \end{split}\end{equation}</script><p>这其实也于Graphormer等Graph Transformer模型有异曲同工之妙。$P_k$ 和 $P_v$ 分别被分成 $N_h$个头部向量。Prompt-tuning 简化了前缀调整，其只对第一层的输入词嵌入进行预处理；类似工作还包括P-tuning。</p></li><li><p>LoRA ：将可训练的低秩矩阵注入 transformer 层，以近似权重更新。对于一个预训练好的权重矩阵 $W\in R^{d×k}$ LoRA用低秩分解 $W +\Delta W = W +W<em>{down}W</em>{up}$ 表示其更新，其中$W<em>{down}\in R^{d×r},W</em>{up}\in R^{r×k} $ 是可调整的参数。LoRA将这种更新应用于多头注意子层中的 Query 和 Key 投影矩阵，如图1所示。对于多头注意力中的线性投影的特定输入$x$ ，LoRA将投影输出 $h$ 修改为:</p><script type="math/tex; mode=display">\begin{equation}\begin{split}  h \leftarrow  h + s \cdot x W_{down}W_{up}    \end{split}\end{equation}</script><p>其中 $s≥1$ 是可调标量超参数。</p></li></ul><p>其实还有一些参数有效的调整方法像：BitFit 只对预训练模型中的 bias 向量进行微调，以及上一篇文章提到的diff-pruning，它学习一个稀疏的参数更新向量。</p><h2 id="推导-prefix-tuning"><a href="#推导-prefix-tuning" class="headerlink" title="推导 prefix tuning"></a>推导 prefix tuning</h2><p>上文关于 prefix tuning  在注意力 K 和 V上添加可学习的向量来改变注意力模块，这里提出另一种观点：</p><script type="math/tex; mode=display">\begin{equation}\begin{split}  head &=Attn(x W_{q} , concat(P_k, CW_{k}, concat(P_v, CW_v) \\ &= softmax(x W_q concat(P_k, CW_k)^T) \begin{bmatrix} P_v \\ CW_v\\ \end{bmatrix} \\ &= (1-\lambda(x)) softmax(xW_qW_k^TC^T) CW_v + \lambda(x)softmax(xW_qP_k^T) P_v\\& = (1 - \lambda(x)) \underbrace{ \text{Attn}(xW_q, CW_k, CW_v) }_{\text{standard attention}} + \lambda(x) \underbrace{ \text{Attn}(xW_q, P_k, P_v) }_{\text{independent of } C},    \end{split}\end{equation}</script><p>其中 $λ(X)$ 是标量，归一化注意力权重之和：</p><script type="math/tex; mode=display">\begin{equation}\begin{split} \lambda(x) = \frac{\sum_i\exp (xW_qP_k^T)_i}{\sum_i \exp (xW_qP_k^T)_i + \sum_j \exp(xW_qW_k^TC^T)_j}.    \end{split}\end{equation}</script><h2 id="THE-UNIFIED-FRAMEWORK"><a href="#THE-UNIFIED-FRAMEWORK" class="headerlink" title="THE UNIFIED FRAMEWORK"></a>THE UNIFIED FRAMEWORK</h2><p>受 prefix tuning   和  Adapter 之间联系的启发，作者提出了一个总体框架，旨在统一几种最先进的参数有效的调谐方法。</p><p>具体来说，作者把它们看作是学习一个向量 $∆h$，它被应用于各种隐藏表征。形式上，作者把要直接修改的隐藏表征表示为 $h$ ，把计算 $h$ 的PLM子模块的直接输入表示为 $x$。</p><p>为了描述这个修改过程，作者定义了一组设计维度，不同的方法可以通过改变这些维度的值而被实例化。并在表1中说明了Adapters、prefix tuning 和LoRA在这些维度上的情况。</p><p><img src="https://i.loli.net/2021/11/20/45RtsBp9aCEZQlg.png" alt=""></p><ul><li>表中的 Functional Form :是指计算 $∆h$ 的具体函数。所有这些方法的函数形式都类似于proj down → nonlinear → proj up的架构。</li><li>Modified Representation : 指直接修改的隐藏表示形式。</li><li>Insertion Form : 指添加的模块如何插入到网络中。传统上适配器是以 sequential 方式插入某个位置的，其中输入和输出都是 $h$ 。prefix tuning和LoRA 相当于 parallel 插入。</li><li>Composition Function :指修改后的向量 $∆h$ 如何与原始隐藏表征 $h$ 计算，以形成新的隐藏表征。例如，适配器执行简单的加法组合，前缀调整使用门控加法组合，而LoRA通过一个恒定的因子对 $Δh$ 进行缩放，并将其添加到原始隐藏表示中。</li></ul><h2 id="变体组合——通过在不同的方法之间转移设计元素而得到"><a href="#变体组合——通过在不同的方法之间转移设计元素而得到" class="headerlink" title="变体组合——通过在不同的方法之间转移设计元素而得到"></a>变体组合——通过在不同的方法之间转移设计元素而得到</h2><p><img src="https://i.loli.net/2021/11/20/VpIxoeY5yRLZiOF.png" alt=""></p><ul><li>Parallel Adapter 是通过将 prefix tuning 的 parallel 插入转移到 Adapter 的变体。</li><li>Multi-head Parallel Adapter 是使 Adapter 与 prefix tuning 更加相似的进一步措施：应用 Parallel Adapter 来修改头部注意力输出作为 prefix tuning 。这样，变体通过利用多头投影来提高能力</li><li>Scaled Parallel Adapter 是通过将LoRA的组成和插入形式转移到适配器的变体，如图3e所示。</li></ul><h2 id="EXPERIMENTS"><a href="#EXPERIMENTS" class="headerlink" title="EXPERIMENTS"></a>EXPERIMENTS</h2><p>下图说明，在数据较为充沛、比较有挑战的任务中，现有的方法 距离 Full FIne-tuning 还有一定差距</p><p><img src="https://i.loli.net/2021/11/20/4kcyzS9rXLFgbNI.png" alt=""></p><h3 id="SEQUENTIAL-OR-PARALLEL"><a href="#SEQUENTIAL-OR-PARALLEL" class="headerlink" title="SEQUENTIAL OR PARALLEL?"></a>SEQUENTIAL OR PARALLEL?</h3><p>Parallel 和  sequential 哪个方式好些？</p><p><img src="https://i.loli.net/2021/11/20/Kxwtri6pOHbU4SG.png" alt=""></p><p> Parallel Adapter在所有情况下都能够击败 Sequential Adapter</p><h3 id="WHICH-MODIFIED-REPRESENTATION-–-ATTENTION-OR-FFN"><a href="#WHICH-MODIFIED-REPRESENTATION-–-ATTENTION-OR-FFN" class="headerlink" title="WHICH MODIFIED REPRESENTATION – ATTENTION OR FFN?"></a>WHICH MODIFIED REPRESENTATION – ATTENTION OR FFN?</h3><p>适配修改放在Transformer哪里比较好？</p><p><img src="https://i.loli.net/2021/11/20/hlqXwRJOBMDVsWv.png" alt=""></p><p><img src="https://i.loli.net/2021/11/20/j7kGyYfVLsQRADE.png" alt=""></p><h3 id="哪个-COMPOSITION-FUNCTION-比较好"><a href="#哪个-COMPOSITION-FUNCTION-比较好" class="headerlink" title="哪个 COMPOSITION FUNCTION 比较好"></a>哪个 COMPOSITION FUNCTION 比较好</h3><p><img src="https://i.loli.net/2021/11/20/BGhesmZN2tREPAr.png" alt=""></p><p>简单composition（Adapter）、门控composition（ prefix tuning ）和缩放composition（LoRA）。</p><p>缩放的 composition 函数，同时也很容易适用。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>(1) Scaled parallel adapter 是修改FFN的最佳变体</p><p>(2) FFN可以在更大的容量下更好地利用修改</p><p>(3) 像 prefix tuning 这样修改头部注意力可以在只有0.1%的参数下实现强大的性能。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Towards-a-Unified-View-of-Parameter-Efficient-Transfer-Learning&quot;&gt;&lt;a href=&quot;#Towards-a-Unified-View-of-Parameter-Efficient-Transfer-Le</summary>
      
    
    
    
    
    <category term="context detection" scheme="http://example.com/tags/context-detection/"/>
    
  </entry>
  
  <entry>
    <title>Generalizing to Unseen Domains: A Survey on Domain Generalization</title>
    <link href="http://example.com/2021/11/14/Generalizing-to-Unseen-Domains-A-Survey-on-Domain-Generalization/"/>
    <id>http://example.com/2021/11/14/Generalizing-to-Unseen-Domains-A-Survey-on-Domain-Generalization/</id>
    <published>2021-11-14T03:02:01.000Z</published>
    <updated>2021-12-22T03:30:51.438Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Generalizing-to-Unseen-Domains-A-Survey-on-Domain-Generalization"><a href="#Generalizing-to-Unseen-Domains-A-Survey-on-Domain-Generalization" class="headerlink" title="Generalizing to Unseen Domains: A Survey on Domain Generalization"></a>Generalizing to Unseen Domains: A Survey on Domain Generalization</h1><p>机器学习系统通常假定训练和测试分布是相同的。为此，一个关键的要求是开发能够泛化到未见过的分布的模型。近年来，Domain generalization 领域泛化（DG），即 out-of- distribution 泛化，吸引了越来越多的兴趣。</p><p>领域泛化处理的是一个具有挑战性的环境，即给定一个或几个不同但相关的领域，目标是学习一个能够泛化到未见过的测试领域的模型。</p><p>本文首次对该领域的最新进展进行了回顾。</p><ul><li>首先，提供了一个领域泛化的正式定义，并讨论了几个相关的领域。</li><li>然后，彻底回顾了与领域泛化相关的理论，并仔细分析了泛化背后的理论。我们将最近的算法分为三类：数据操作、表征学习和学习策略，并对每一类算法详细介绍了几种流行的算法。</li><li>第三，介绍了常用的数据集和应用。</li><li>最后，我们总结了现有的文献并提出了一些未来的潜在研究课题。</li></ul><h2 id="INTRODUCTION"><a href="#INTRODUCTION" class="headerlink" title="INTRODUCTION"></a>INTRODUCTION</h2><p>传统的ML模型是基于 i.i.d. 假设进行训练的，即训练和测试数据是完全独立分布的。然而，这一假设在现实中并不总是成立。当训练数据和测试数据的概率分布不同时，由于领域分布的差距，ML模型的性能往往会恶化。收集所有可能领域的数据来训练ML模型是昂贵的，甚至是不可能的。因此，提高ML模型的泛化能力在工业和学术领域都很重要。</p><p>有许多与泛化相关的研究课题，如领域适应、元学习、迁移学习、covariate shift等等。近年来，领域泛化（DG）受到广泛关注。</p><p><img src="https://i.loli.net/2021/11/14/CzTe6qKXc9StOPm.png" alt=""></p><p>如图1所示，领域泛化的目标是从一个或几个不同但相关的领域（即不同的训练数据集）中学习一个模型，该模型将在未见过的测试领域中具有良好的泛化能力。</p><blockquote><p>例如，给定一个由素描、卡通图像和绘画组成的训练集，领域泛化要求训练一个好的机器学习模型，该模型在对来自自然图像或照片的分类中具有最小的预测误差，这些图像显然与训练集中的图像具有不同的分布。</p><p>在过去的几年里，领域泛化在计算机视觉和自然语言处理等各个领域都取得了重大进展。尽管取得了这些进展，但在这一领域还没有一份全面介绍和总结其主要思想、学习算法和其他相关问题的调查报告，以提供对未来的研究见解。</p><p>在本文中，我们提出了第一份关于领域泛化的调查报告，介绍了它的最新进展，特别关注它的公式、理论、算法、数据集、应用和未来研究方向。我们希望这个调查能够为感兴趣的研究者提供一个全面的回顾，并激发在这个领域和相关领域的更多研究。</p></blockquote><ul><li><p>提出了关于领域泛化和相关领域适应的理论分析。</p></li><li><p>通过增加新的类别：特征分解的生成模型、不变的风险最小化、基于梯度运算的方法和其他学习策略来全面总结这些泛化方法。</p></li><li><p>对于所有的类别，我们通过包括更多的相关算法、比较和讨论，扩大了对不同类别方法的分析。</p></li><li><p>扩展了数据集和应用的范围，同时我们也探索了领域通用的评价标准。</p></li></ul><p>本文的组织结构如下。在第二节中提出了领域泛化的问题并讨论了它与现有研究领域的关系。第三节介绍了领域泛化的相关理论。在第四节中，我们详细描述了一些有代表性的DG方法。第五节介绍了应用，第六节介绍了DG的基准数据集。我们在第七节中总结了现有工作的启示，并提出了一些可能的未来方向。最后，我们在第八节中对本文进行总结。</p><h2 id="BACKGROUND"><a href="#BACKGROUND" class="headerlink" title="BACKGROUND"></a>BACKGROUND</h2><h3 id="A-Formalization-of-domain-generalization"><a href="#A-Formalization-of-domain-generalization" class="headerlink" title="A. Formalization of domain generalization"></a><em>A. Formalization of domain generalization</em></h3><p>在本节中，我们介绍本文中使用的符号和定义。</p><p><strong>Definition 1 (Domain) :</strong> X 表示一个非空的输入空间，Y 表示一个输出空间。一个域是由从分布中取样的数据组成的。我们把它表示为 $S = {(x<em>i, y_i)}^n</em>{i=1} \sim P<em>{XY}$ , 其中 $x\in X \subset R^d, y\in Y \subset R$ 表示标签，而 $P</em>{XY}$ 表示输入样本和输出标签的联合分布。X、Y表示相应的随机变量。</p><p><strong>Definition 2 (Domain generalization) :</strong></p><p><img src="https://i.loli.net/2021/11/14/QGw1vmbkEZcjSHD.png" alt=""></p><p>在领域泛化中，我们得到了M个训练（源）的领域 $S<em>{train} = {S^i| i = 1,…,M}$ 其中 $S^i={(x^i_j,y^i_j)}</em>{j=1}^{n<em>i}$ 定义为第 $i$ 个域。每对域的联合分布是不同的：$P</em>{XY}^i \neq P<em>{XY}^j, 1\le i \neq j \le M$ 。域泛化的目标是在 $M$ 个训练域中学习一个稳健的、可泛化的预测函数 $h : X → Y$，以实现对未见过的测试域 $S</em>{test}$ 的最小预测误差（即在训练中不能访问 $S<em>{test}$，$P^{test}</em>{XY}\neq P^i_{XY}  i∈{1,…,M}$）:</p><script type="math/tex; mode=display">min_h E_{(x,y)\in S_{test}} [l(h(x),y)]</script><p>其中 $E$ 是期望， $l(\cdot,\cdot)$ 是loss 。我们在表1中列出了常用的记号。</p><p><img src="https://i.loli.net/2021/11/14/FiE4rGMZsNjq6pb.png" alt=""></p><h3 id="B-Related-research-areas"><a href="#B-Related-research-areas" class="headerlink" title="B. Related research areas"></a><em>B. Related research areas</em></h3><p>有几个研究领域与领域泛化密切相关，包括但不限于：迁移学习、领域适应、多任务学习、多领域学习、元学习、终身学习和 zero-shot 学习。我们在表二中总结了它们与领域泛化的区别，并在下文中简要介绍了它们。</p><p><img src="https://i.loli.net/2021/11/14/MPWAwsXG1t7dBH5.png" alt=""></p><ul><li>Multi-task learning ：联合优化了几个相关任务的模型。通过在这些任务之间共享表征，我们可以使模型在原来的任务上有更好的泛化能力。请注意，多任务学习的目的不是为了加强对新的（未见过的）任务的泛化。特别是，多领域学习是一种多任务学习，它在多个相关领域进行训练，为每个原始领域而不是新的测试领域学习好的模型。</li><li>Transfer learning：在一个源任务上训练一个模型，旨在提高该模型在不同但相关的目标领域/任务上的性能。预训练-微调是转移学习的常用策略，在这种情况下，源域和目标域有不同的任务，目标域在训练中被访问。在DG中，目标域不能被访问，训练和测试任务往往是相同的，而它们的分布是不同的。</li><li>Domain adaptation（DA）：在最近几年也很流行。DA的目的是利用现有的训练源域在给定的目标域上实现性能最大化。DA和DG的区别在于，DA可以接触到目标域的数据，而DG在训练过程中无法看到这些数据。这使得DG比DA更具挑战性，但在实际应用中更现实和有利。</li><li>Meta-learning ：旨在通过学习以前的经验或任务来学习学习者本身，即学会学习。虽然元学习中的学习任务是不同的，但在领域泛化中的学习任务是相同的。元学习是一种通用的学习策略，可以用于DG，通过模拟训练领域中的元训练和元测试任务来提高DG的性能。</li><li>终身学习，或持续学习：关注的是多个连续领域/任务之间的学习能力。它要求模型通过容纳新的知识，同时保留以前学到的经验，随着时间的推移不断地学习。这也与DG不同，因为它可以在每个时间步骤中访问目标域，而且它没有明确处理跨域的不同分布。</li><li>Zero-shot learning：旨在从已看到的类别中学习模型，并对在训练中未看到的类别的样本进行分类。与此相反，一般来说，领域概括研究的问题是训练和测试数据来自相同的类别，但分布不同。</li></ul><p>此外，领域泛化还与 tributionally robust optimization（DRO）有关，其目标是在最坏的分布情况下学习一个模型，希望它能够很好地泛化到测试数据。DRO关注的是优化过程，在领域泛化研究中也可以利用。此外，DG也可以通过数据操作或表征学习方法来完成，这与DRO方法不同。</p><h2 id="THEORY"><a href="#THEORY" class="headerlink" title="THEORY"></a>THEORY</h2><p>在本节中，我们将回顾一些与领域泛化相关的理论。由于领域适应与领域泛化密切相关，我们从领域适应的理论开始。</p><h3 id="A-Domain-adaptation"><a href="#A-Domain-adaptation" class="headerlink" title="A. Domain adaptation"></a><em>A. Domain adaptation</em></h3><p>对于一个二元分类问题，我们把源域上的真实标签函数表示为 $h^{∗s} : X → [0,1]$，目标域上的真标签函数为 $h^{∗t}$。让 $h:X →[0,1]$ 是来自假设空间 $H$ 的任何分类器。然后，源域上两个分类器 $h$ 和 $h’$之间的分类误差可以通过以下方式测量 :</p><script type="math/tex; mode=display">\epsilon^s(h,h') = E_{x\sim P^s_X} [h(x) \neq h'(x)] = E_{x\sim P^s_X} [|h(x) - h'(x)|]</script><p>同样地，我们可以定义 $ε^t$，当取 $x∼P^t_X$ 的期望时。定义 $\epsilon^s(h) := \epsilon^s(h,h^{<em>s})$ 并且 $\epsilon^t(h):=\epsilon^t(h,h^{</em>t})$ 作为分类器 $h$ 在源域和目标域上的风险。</p><p>DG/DA 的目标是使目标风险 $ε^t(h)$ 最小。但由于我们没有任何关于 $h^{∗t}$ 的信息，所以不容易达到这个目标。因此，人们试图用可操作的源风险 $ε^s(h)$来约束目标风险 $ε^t(h)$。 Ben-David等人给出两种风险的界限：</p><script type="math/tex; mode=display">\epsilon^t(h) \leq \epsilon^s(h) +2d_1(P_X^s,P_X^t)+min_{P_{X}\in \{P^s_X,P^t_X\}} E_{x\sim P_X}[|h^{*s}(x) - h^{*t}(x)|]</script><p>其中 $d<em>1 (P_X^s , P_X^t ) := sup</em>{A∈X} |P_X^s [A] - P_X^t [A]| $ 是两个分布之间的总变化，$\mathbf{X}$ 表示 $X$ 上的 σ场。r.h.s 上的第二项衡量的是两个领域中分布的差异，第三项代表的是标签函数的差异。</p><p>然而，总变化是一个强距离（即，它倾向于非常大），可能会使约束（1）松动，并且很难使用有限样本来估计。为了解决这个问题，Ben-David等人开发了另一个约束 ：</p><script type="math/tex; mode=display">\epsilon^t(h) \le \epsilon^s(h) + d_{H\Delta H}(P^s_X,P^t_X) + \lambda_H</script><p>其中，H∆H-divergence 定义为 $d<em>{H∆H}(P_X^s , P_X^t ) := sup</em>{h,h’∈H} |ε^s (h, h’ ) - ε^t (h, h’)|$，取代总变异d1来衡量分布差异，理想联合风险 $λ<em>H : = inf</em>{h∈H} [ε^s (h) + ε^t (h)]$ 衡量 $H$ 在两个领域的预测任务中的复杂性。</p><h3 id="B-Domain-generalization"><a href="#B-Domain-generalization" class="headerlink" title="B. Domain generalization"></a><em>B. Domain generalization</em></h3><ul><li>数据操作，指的是通过对数据的增强和变化使训练数据得到增强。这一类包括数据增强和数据生成两大部分。</li><li><strong>表征学习，指的是学习领域不变特征（Domain-invariant representation learning）以使得模型对不同领域都能进行很好地适配。领域不变特征学习方面主要包括四大部分：核方法、显式特征对齐、领域对抗训练、以及不变风险最小化（Invariant Risk Minimiation, IRM）。特征解耦与领域不变特征学习的目标一致、但学习方法不一致，我们将其单独作为一大类进行介绍。</strong></li><li>学习策略，指的是将机器学习中成熟的学习模式引入多领域训练中使得模型泛化性更强。这一部分主要包括基于集成学习和元学习的方法。同时，我们还会介绍其他方法，例如自监督方法在领域泛化中的应用。</li></ul><h2 id="METHODOLOGY"><a href="#METHODOLOGY" class="headerlink" title="METHODOLOGY"></a>METHODOLOGY</h2><p><img src="https://i.loli.net/2021/11/14/o2gSpyE89cRQkd5.png" alt=""></p><h3 id="数据操作"><a href="#数据操作" class="headerlink" title="数据操作"></a>数据操作</h3><p>在机器学习（ML）中，我们总是渴望得到更多的训练数据。一个ML模型的泛化性能往往依赖于训练数据的数量和多样性。考虑到一组有限的训练数据，数据处理是产生样本的最便宜和最简单的方法之一，这样可以提高模型的泛化能力。基于数据处理的DG的主要目标是使用不同的数据处理方法来增加现有训练数据的多样性。同时，数据数量也会增加。</p><p>我们将基于数据操作的DG的总体学习目标制定为：</p><script type="math/tex; mode=display">min_h E_{x,y} [l(h(x), y)] + E_{x',y}[l(h(x'),y)]</script><p>其中 x′=mani(x) 表示使用函数mani(-)操纵的数据。基于这个函数上的差异，我们进一步将现有的工作分为两类：数据增强和数据生成。</p><ol><li><p>基于数据增强的DG：数据增量。扩增是训练机器学习模型的最有用的技术之一。典型的增强操作包括翻转、旋转、缩放、裁剪、添加噪声等等。它们已被广泛用于监督学习中，通过减少过拟合来提高模型的泛化性能[117, 34]。毫无例外，它们也可以被采用于DG，其中mani(-)可以被实例化为这些数据增强函数。</p><p><strong>领域随机化</strong>。除了典型的扩增，领域随机化是一种有效的数据扩增技术。它通常通过生成新的数据来完成，这些数据可以在有限的训练样本基础上模拟复杂的环境。随着数据变得更加复杂和多样化，泛化能力可以得到提高。在这里，mani(-)函数被实现为几个手动变换（常用于图像数据），如：改变物体的位置和纹理，改变物体的数量和形状，修改光照和相机视角，以及在数据中加入不同类型的随机噪声。<br>Tobin等人[29]首先使用这种方法从模拟环境中产生更多的训练数据，以便在真实环境中进行概括。类似的技术也被用于[30, 31, 32, 28]以加强模型的泛化能力。Prakash等人[33]在随机放置物体进行数据生成时进一步考虑了场景的结构，这使得神经网络在检测物体时能够学会利用上下文。</p><p><strong>抗辩式数据增强</strong>。抗辩式数据增强的目的是通过增强数据的多样性，同时保证数据的可靠性，来指导增强工作，优化泛化能力。Shankar等人[35]使用贝叶斯网络来模拟标签、行为和输入实例之间的依赖性，并提出了CrossGrad，这是一种谨慎的数据增强策略，沿最大领域变化的方向对输入进行扰动，同时尽可能少地改变类标签。Volpi等人[36]提出了一个迭代程序，用一个虚构的目标领域的例子来增加源数据集，该领域在当前模型下是 “硬 “的，在每次迭代中都会添加对抗性例子，以实现自适应数据增强。Zhou等人[37]用对抗性训练的转换网络进行数据扩充，而不是直接用梯度上升法更新输入。</p></li></ol><p>2) 基于数据生成的DG：数据生成也是一种流行的技术，可以生成多样化和丰富的数据来提高模型的泛化能力。在这里，函数mani(-)可以使用一些生成模型来实现，如变异自动编码器（VAE）[118]，以及生成对抗网络（GAN）[119]。此外，它也可以使用Mixup[120]策略来实现。<br>Rahman等人[38]使用ComboGAN[121]来生成新的数据，然后应用领域差异度量，如MMD[122]来最小化真实图像和生成图像之间的分布分歧，以帮助学习一般代表。Qiao等人[39]利用对抗性训练来创建 “虚构 “而又 “具有挑战性 “的人群，其中Wasserstein Auto-Encoder（WAE）[123]被用来帮助生成保留语义并具有大领域转移的样本。Zhou等人[42]在语义一致的情况下生成了新的分布，然后将源分布和新分布之间的差异最大化。Somavarapu等人[43]引入了一个基于图像风格化的简单转换，以探索跨源的可变性，从而实现更好的泛化，其中AdaIN[124]被用来实现快速风格化的任意风格。<br>除了上述生成模型外，Mixup[120]也是一种流行的数据生成技术。Mixup通过在任何两个实例之间和它们的标签之间进行线性插值，并从Beta分布中抽取权重来生成新数据，这不需要训练生成式模型。最近，有几种方法将Mixup用于DG，通过在原始空间[47, 48]中执行Mixup来生成新的样本；或者在特征空间[49]中，不明确生成原始训练样本。这些方法在流行的基准上取得了很好的性能，同时在概念上和计算上保持简单。</p><h3 id="表征学习"><a href="#表征学习" class="headerlink" title="表征学习"></a>表征学习</h3><p>几十年来，表征学习一直是机器学习的重点[125]，也是领域泛化成功的关键之一。我们将预测函数h分解为 $h = f ◦ g$，其中g是一个表征学习函数，f是分类器函数。表征学习的目标可以被表述为：</p><script type="math/tex; mode=display">min_{f,g} E_{x,g}l(f(g(x)),y) + \lambda l_{reg}</script><p>其中 $l<em>{reg}$ 表示一些正则化项，λ是权衡参数。许多方法都是为了更好地学习具有相应 $l</em>{reg}$ 的特征提取函数 $g$。在本节中，我们根据不同的学习原理将现有的关于表征学习的文献分为两大类：领域不变的表征学习和特征分解。</p><p>1) 基于领域不变表征的DG：[23]的工作从理论上证明，如果特征表征对不同领域保持不变，那么表征就是通用的，可以转移到不同领域（也可以参考第三节）。基于这一理论，人们提出了大量用于领域适应的算法。同样，对于领域泛化来说，目标是减少特定特征空间中多个源域之间的表征差异，使之成为领域不变的，这样学到的模型就能对未见过的领域具有可泛化的能力。按照这一思路，主要有四种方法：基于核的方法、领域对抗性学习、显式特征对齐和不变风险最小化。</p><pre><code>**基于核的方法**是机器学习中最经典的学习范式之一。基于核的机器学习依靠核函数将原始数据转化为高维特征空间，而不需要计算数据在该空间的坐标，只需要计算特征空间中所有对的样本之间的内积。最具代表性的基于核的方法之一是支持向量机（SVM）[126]。对于领域泛化，有很多基于核方法的算法，其中表征学习函数g被实现为一些特征映射φ(-)，这很容易用核函数k(-, -)来计算，如RBF核和Laplacian核。</code></pre><p>   Blanchard等人[24]首次将核方法用于领域泛化，并在[52]中加以扩展。他们采用正半无限核学习，从训练数据中学习一个领域不变的核。Grubinger等人[53]采用转移成分分析法（TCA）[127]来弥补多领域的距离，使之更接近于DG。与TCA的核心思想类似，域不变分量分析（DICA）[25]是使用核进行DG的经典方法之一。DICA的目标是找到一个特征转换核k(-, -)，使特征空间中所有数据之间的分布差异最小。Gan等人[54]采用了与DICA类似的方法，并进一步增加了属性正则化。与处理边际分布的DICA相比，Li等人[55]学习了一种具有领域不变的类条件分布的特征表示。Ghifary等人[56]采用Fisher判别分析法来最小化来自同一类别和同一领域的表示的差异，最大化来自不同类别和不同领域的表示的差异。他们提出了散点成分分析（SCA），使用基于核的方法学习领域不变的表征，其中SCA核考虑了类间和类内的差异。Erfani等人[57]提出了椭圆总结随机化（ESRand），它包括一个随机内核和椭圆数据总结。ESRand将每个领域投射到一个椭圆中以表示领域信息，然后使用一些相似性指标来计算距离。Hu等人[58]提出了多域判别分析法来对DG进行分类核学习，这种方法的粒度更细。Mahajan等人[74]提出使用因果匹配来学习分解表征，他们提出MatchDG来匹配在结果表征下相似的输入，以建立一个不变的分类器。对于领域泛化，一些基于核的方法的理论分析可以从[24, 26]中找到。</p><p>   <strong>领域对抗性学习</strong>。领域对抗性训练被广泛用于学习领域不变的特征。Ganin和Lempitsky[77]和Ganin等人[78]提出了用于领域适应的领域对抗性神经网络（DANN），它对生成器和鉴别器进行对抗性训练。鉴别器被训练来区分领域，而生成器被训练来愚弄鉴别器以学习领域不变的特征表示。Li等人[64]对DG采用了这种想法。Gong等人[79]通过逐渐减少流形空间中的域差异来使用对抗性训练。Li等人[80]提出了一个条件不变的对抗网络（CIAN），用于学习DG的分类对抗网络。类似的想法也被用在[81, 85, 86]中。Jia等人[87]使用单边对抗学习和非对称三倍损失来确保只有来自不同领域的真实面孔是不可区分的，但对于假的面孔则不是。除了对抗性领域分类，Zhao等人[82]通过最小化不同训练领域的条件分布之间的KL分歧，引入了额外的熵正则化，以推动网络学习领域不变的特征。其他一些基于GAN的方法[45, 84, 27]也被提出，在理论上保证了泛化边界。</p><p>   <strong>明确的特征对齐</strong>。这类工作通过明确的特征分布对齐[64, 128, 129]，或特征归一化[130, 131, 132, 62]，将各源域的特征进行对齐，以学习领域不变的表示。<br>   Motiian等人[60]为表征学习引入了一个跨域对比性损失，其中映射的域在语义上是一致的，但又是最大限度的分离。一些方法通过最小化最大平均差异（MMD）[133, 127, 134, 135]、二阶相关[136, 137, 138]、均值和方差（时刻匹配）[129]、Wasserstein距离[128]等，明确地将特征分布分歧最小化，用于域适应或域概括。Zhou等人[128]通过最小化Wasserstein距离，通过最优传输将不同源域的边际分布对齐，实现域不变的特征空间。</p><p>   此外，也有一些工作使用特征归一化技术来提高领域泛化能力[130, 131]。Pan等人[130]将实例归一化（IN）层引入CNN，以提高模型的泛化能力。IN在图像风格转换领域得到了广泛的研究[139, 140, 124]，图像的风格由IN参数反映，即每个特征通道的平均值和方差。因此，IN层[141]可用于消除特定实例的风格差异，以增强概括性[130]。然而，IN是与任务无关的，可能会消除一些鉴别性的信息。在IBNNet中，IN和批量归一化（BN）被平行利用，以保留一些鉴别性信息[130]。在[132]中，BN层被批量归一化（BIN）层所取代，它通过选择性地使用BN和IN来自适应平衡每个通道的BN和IN。Jin等人[62, 63]提出了一个风格归一化和恢复（SNR）模块，以同时确保网络的高泛化和辨别能力。在通过IN进行风格归一化后，进行还原步骤，从残差（即原始特征和风格归一化特征之间的差异）中提炼出与任务相关的鉴别特征，并将其添加到网络中以确保高鉴别力。恢复的想法被扩展到其他基于对齐的方法，以恢复因对齐而丢失的有用的鉴别性信息[142]。</p><p>   <strong>不变风险最小化（IRM）</strong>。Arjovsky等人[88]从另一个角度考虑了领域泛化的表征的领域不变性。他们并不寻求与所有领域的表征分布相匹配，而是强制要求表征空间之上的最优分类器在所有领域都是一样的。其直觉是，预测的理想表征是y的原因，而因果机制不应受到其他因素/机制的影响，因此是领域不变的。</p><p>   对 f 的约束体现了所有域共享相同的表示级分类器的愿望，而目标函数鼓励 f 和 g 实现低源域风险。然而，这个问题很难解决，因为它的约束条件中涉及到一个内部层次的优化问题。然后，作者开发了一个代用问题来学习特征提取器g，这个问题更加实用。</p><p>   其中，一个假的表示级分类器f = 1被认为是，梯度规范项衡量这个分类器的最优性。这项工作还提出了一个可能是强线性假设下的泛化理论，即对于足够多的源域，可以确定基础真理不变的分类器。</p><p>   由于新的概念和容易实现，IRM最近获得了明显的知名度。有一些关于IRM的成功[143]和失败案例的进一步理论分析[92]，而且IRM已经被扩展到其他任务，包括文本分类[91]和强化学习[144]。追求最优表示级分类器的不变性的想法也得到了扩展。Krueger等人[145]通过最小化源域之间的外推风险来促进这种不变性，这基本上是最小化源域风险的方差。Mitrovic等人[146]的目标是在自我监督的设置中学习这样的表征，其中第二域是通过显示各种语义不相关的变化的数据增量构建的。</p><ol><li><p>基于特征解缠的DG：解缠表征学习的目标是学习一个函数，该函数将样本映射到一个特征向量，该向量包含关于不同变化因素的所有信息，每个维度（或维度的一个子集）只包含关于某些因素的信息。基于Disentanglement的领域泛化方法一般将一个特征表示分解为可理解的组合/子特征，其中一个特征是领域共享/不变的特征，另一个是领域特定的特征。基于解缠的DG的优化目标可以总结为：</p><script type="math/tex; mode=display">min_{g_c,g_s,f} E_{x,y}l(f(g_c(x)), y) + \lambda l_{reg}+\mu l_{recon}([g_c(x),g_s(x)],x)</script><p>其中 $g<em>c$ 和 $g_s$ 分别表示领域共享和领域特定的特征表示。 λ，μ是权衡参数。损失 $l</em>{reg} $是一个正则化项，明确鼓励领域共享特征和特定特征的分离，$l_{recon}$表示一个重建损失，防止信息的损失。注意，$[g_c (x), g_s (x)]$表示两种特征的组合/整合（不限于连接操作）。</p><p>根据网络结构和实现机制的选择，基于解缠的DG方法主要可分为两类：多分量分析和生成模型。</p><p><strong>多组份分析</strong>。在多成分分析中，一般来说，使用领域共享和领域特定的网络参数来提取领域共享和领域特定的特征。UndoBias[94]的方法从SVM模型出发，在所有的训练数据上最大化区间分类，以实现领域泛化。他们将第 $i$ 个领域的参数表示为 $w_i = w_0 + ∆_i$，其中 $w_0$ 表示领域共享参数，$∆_i$表示领域特定参数。其他一些方法从不同方面扩展了UndoBias的思想。Niu等人[95]提出使用多视图学习进行领域泛化。他们提出了多视图DG（MVDG）来学习不同视图下的示范性SVM的组合，以实现稳健的泛化。Ding和Fu[96]为每个领域设计了特定领域的网络，并为所有领域设计了一个共享的领域变量网络，以学习不相干的表征，其中采用低秩重建的方式将两类网络以结构化的低秩方式对齐。Li等人[1]将UndoBias的思想扩展到神经网络背景下，并开发了一个用于端到端训练的低秩参数化CNN模型。Zunino等人[97]通过手动比较不同领域的某些区域的注意力热图来学习分解表征。还有其他一些作品采用多成分分析法进行解构[98, 93, 99, 100]。</p><p><strong>生成式模型</strong>。生成模型可用于从数据生成过程的角度进行拆分。这类方法试图从领域层面、样本层面和标签层面制定样本的生成机制。有些工作进一步将输入分解为与类别无关的特征，这些特征包含与特定实例相关的信息。Domain-invariant variational autoencoder (DIVA) [101]将特征分解为domain信息、类别信息和其他信息，这是在VAE框架下学习的。Peng等人[102]将细粒度的领域信息和类别信息进行了分解，这些信息在VAE中被学习。Qiao等人[39]也将VAE用于拆分，他们提出了一个统一特征拆分网络（UFDN），将感兴趣的数据域和图像属性都作为潜在因素来拆分。Liu等人[103]基于数据生成过程的因果观，提出了领域适应和领域泛化的统一解决方案，并为语义表示和泛化误差边界制定了一个识别保证。</p></li></ol><h3 id="学习策略"><a href="#学习策略" class="headerlink" title="学习策略"></a>学习策略</h3><p>除了数据处理和表征学习，DG也被研究在一般的机器学习范式中，分为四类：基于集合学习的DG、基于元学习的DG、基于梯度运算的DG和其他。</p><p>1) 基于集合学习的通用技术：集合学习通常将多个模型（如分类器或专家）结合起来，以增强模型的力量。对于领域泛化，集合学习通过使用特定的网络架构设计和训练策略，利用多个源领域之间的关系来提高泛化能力。他们认为任何样本都可以被看作是多个源域的综合样本，因此整体预测结果可以看作是多个域网络的叠加。</p><p>   Mancini等人[104]提出使用可学习的权重来汇总来自不同来源特定分类器的预测，其中一个领域预测器被用来预测样本属于每个领域的概率（权重）。Segu`等人[61]为不同的源域维护了与域相关的批判性归一化（BN）统计数据和BN参数，而所有其他参数是共享的。在推理中，最终的预测是依赖于域的模型的线性组合，其组合权重是通过测量测试样本的实例归一化统计数据和每个域的累积群体统计数据之间的距离推断出来的。105]的工作提出了不同源域的特定域层，并学习这些层的线性聚合来代表测试样本。Zhou等人[3]提出了领域自适应集合学习（DAEL），其中DAEL模型是由一个跨领域共享的CNN特征提取器和多个特定领域的分类器头组成。每个分类器对自己的领域来说是专家，对其他领域来说则是非专家。DAEL的目的是协同学习这些专家，通过对非专家的教学，鼓励集合体学习如何处理来自<br>   未见过的领域的数据。</p><p>2) 基于元学习的DG：元学习的关键思想是通过基于优化的方法[147]或基于模型的方法[149]，从多个任务中学习通用模型。是通过基于优化的方法[147]、基于度量的学习[148]或基于模型的方法[149]，从多个任务中学习一个通用模型。元学习的思想已经被利用于领域概括。他们将多源领域的数据划分为元训练集和元测试集，以模拟领域转移。用θ表示要学习的模型参数，元学习可以表述为：</p><script type="math/tex; mode=display">       \begin{equation}\begin{split}     \theta^* &= Learn(S_{mte};\phi^*) \\    &= Learn(S_{mte}; MetaLearn(S_{mtrn}))       \end{split}\end{equation}</script><p>   其中 $φ^*=MetaLearn(S<em>{mtrn})$ 表示从元训练集 $S</em>{mtrn}$ 中元学习的参数，然后用于在元测试集 $S_{mte}$ 上学习模型参数θ∗。这两个函数 Learn(-) 和 MetaLearn(-) 要由不同的元学习算法来设计和实现，这相当于一个双级优化问题。梯度更新可以表述为：</p><script type="math/tex; mode=display">   \theta = \theta - \alpha \frac{\partial(l(S_{mte};\theta) + \beta l(S_{mtrn}; \phi)) }{\partial \theta}</script><p>   其中η,β分别是外循环和内循环的学习率。</p><p>   Finn等人[147]提出了模型不可知元学习（MAML）。受MAML的启发，Li等人[12]提出了MLDG（meta-learning for domain generalization），将元学习策略用于DG。MLDG将源域的数据拆分为元训练和元测试，以模拟域转移的情况来学习一般的表征。Balaji等人[13]提出要为分类器学习元正则器（MetaReg）。[14]提出通过设计元优化器对特征提取器进行特征批评训练。Dou等人[108]使用了类似于MLDG的思想，另外还引入了两个互补的损失来明确规范化特征空间的语义结构。Du等人[15]提出了一个信息瓶颈的扩展版本，名为Meta Variational Information Bottleneck（MetaVIB）。他们对来自不同领域的具有相同类别的样本的潜在编码分布之间的Kullback-Leibler（KL）分歧进行正则化，并通过使用随机神经网络来学习生成权重。最近，一些作品也采用了元学习的方式来进行半监督式DG或判别式DG[109, 110, 111, 44]。</p><ol><li>基于梯度操作的DG：除了元学习和集合学习之外，最近的一些工作考虑使用梯度信息来迫使网络学习一般化的表征。Huang等人[112]提出了一种自我挑战的训练算法，旨在通过操纵梯度来学习一般表征。他们迭代地丢弃了在训练数据上激活的主导特征，并迫使网络激活与标签相关的剩余特征。通过这种方式，网络可以被迫从更多的坏情况中学习，这将提高泛化能力。Shi等人[113]提出了一个梯度匹配方案，他们的假设是两个领域的梯度方向应该是相同的，以增强共同表征学习。为此，他们提出将梯度内积（GIP）最大化，以调整各域的梯度方向。通过这种操作，网络可以找到权重，使输入-输出的对应关系在各领域中尽可能接近。GIP可以被表述为：<script type="math/tex; mode=display">L = L_{cls}(S_{train};\theta) - \lambda\frac{2}{M(M-1)} \sum_{i,j}^{i\neq j}G_i\cdot G_j</script>其中 $G_i, G_j$ 是两个域的梯度，可以被 $G = E \frac{\partial l(x,y;\theta)}{\partial\theta}$ 计算得到</li></ol><h3 id="其他学习策略"><a href="#其他学习策略" class="headerlink" title="其他学习策略"></a>其他学习策略</h3><p>还有一些其他的学习策略用于领域泛化。例如，自我监督学习是最近流行的一种学习范式，它从大规模的无标签数据中建立自我监督任务[150]。受此启发，Carlucci等人[114]引入了一个解决拼图的自我监督任务来学习泛化表征。<br>Li等人[116]交替地学习了特征提取器和分类器。首先，他们固定分类器来学习最坏情况下的特征提取器；然后，他们固定特征提取器来学习最坏情况下的分类器。通过这样的偶发训练，最终特征提取器和分类器可以从这些最坏情况中学习到更好的分布外任务的表现。Ryu等人[115]使用随机森林来提高卷积神经网络（CNN）的泛化能力。他们根据随机森林给出的拆分结果的概率质量函数对三联体进行采样，用于通过三联体损失更新CNN的参数。在未来，将有更多的工作用于使用其他学习策略的DG。</p><h2 id="Future-research-challenges"><a href="#Future-research-challenges" class="headerlink" title="Future research challenges"></a>Future research challenges</h2><p>总结了未来在领域泛化方面的一些研究挑战。</p><p>1）<strong><em>Continuous domain generalization</em> 连续的领域泛化</strong>。在许多实际应用中，系统消耗的是具有非平稳统计数据的流媒体数据。在这种情况下，进行连续的领域泛化是非常重要的，它可以有效地更新DG模型以克服灾难性的遗忘并适应新的数据。虽然有一些专注于连续学习的领域适应方法[166]，但只有很少的关于连续DG的调查[167]，而这在实际场景中是有利的。</p><p>2）<strong>对新类别的领域泛化</strong>。现有的DG算法通常假定不同领域的标签空间是相同的。一个更实际、更普遍的设定是支持对新类别的泛化，也就是领域和任务的泛化。这在概念上类似于元学习和 zero-shot 学习的目标。一些工作[65,168]提出了  zero-shot DG，我们期望在这个领域有更多的工作。</p><p>3）<strong>可解释的领域概括</strong>。基于Disentanglement的DG方法将一个特征分解为领域不变/共享和领域特定的部分，为DG提供一些解释。对于其他类别的方法，目前仍然缺乏对DG模型中学习到的特征的语义或特征的深入理解。因果关系[103]可能是理解领域泛化网络并提供解释的一个有前途的工具。</p><p>4）<strong>大规模预训练/自学和DG</strong>：近年来，我们见证了大规模预训练/自学的快速发展，如BERT[169]、GPT- 3[170]和Wav2vec[171]。在大规模数据集上进行预训练，然后根据下游任务对模型进行微调，可以提高其性能，其中预训练有利于学习一般表征。因此，如何设计有用和高效的DG方法来帮助大规模的预训练/自我学习是值得研究的。</p><p>5）<strong>DG的性能评估</strong>：最近的工作[71]指出，在几个数据集上，一些DG方法的性能几乎与基线方法（即经验风险最小化）相同。我们不认为这就是DG在实际应用中没有用处的全部证据。相反，我们认为这可能是由于现在使用的评估方案不合适，或者是领域的差距没有那么大。在更现实的情况下，比如存在明显领域差距的人际关系[63]，DG的改进是巨大的。因此，我们对DG的价值保持肯定，并希望研究人员也能找到更合适的设置和数据集进行研究。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Generalizing-to-Unseen-Domains-A-Survey-on-Domain-Generalization&quot;&gt;&lt;a href=&quot;#Generalizing-to-Unseen-Domains-A-Survey-on-Domain-Genera</summary>
      
    
    
    
    
    <category term="context detection" scheme="http://example.com/tags/context-detection/"/>
    
  </entry>
  
  <entry>
    <title>EANN: Event Adversarial Neural Networks for Multi-Modal Fake News Detection</title>
    <link href="http://example.com/2021/11/12/EANN-Event-Adversarial-Neural-Networks-for-Multi-Modal-Fake-News-Detection/"/>
    <id>http://example.com/2021/11/12/EANN-Event-Adversarial-Neural-Networks-for-Multi-Modal-Fake-News-Detection/</id>
    <published>2021-11-12T06:39:26.000Z</published>
    <updated>2021-12-28T11:04:48.131Z</updated>
    
    <content type="html"><![CDATA[<h1 id="EANN-Event-Adversarial-Neural-Networks-for-Multi-Modal-Fake-News-Detection"><a href="#EANN-Event-Adversarial-Neural-Networks-for-Multi-Modal-Fake-News-Detection" class="headerlink" title="EANN: Event Adversarial Neural Networks for Multi-Modal Fake News Detection"></a>EANN: Event Adversarial Neural Networks for Multi-Modal Fake News Detection</h1><p>社交媒体上的假新闻检测的独特挑战之一是如何识别新出现的事件的假新闻。</p><p>大多数现有的方法很难应对这一挑战，因为它们倾向于学习特定于事件的特征，这些特征不能迁移到看不见的事件。</p><p>事件对抗神经网络(EANN)，它可以提取事件不变的特征，从而有利于对新到达的事件进行假新闻的检测。包括三个主要部分：</p><ul><li>多模态特征提取器：负责从帖子中提取文本和视觉特征</li><li>假新闻检测器：学习用于检测假新闻的可判别表示</li><li>事件鉴别器：去除事件的特定特征，并保留事件间的共享特征</li></ul><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>最近，社交媒体的激增大大改变了人们获取信息的方式。如今，通过社交媒体消费新闻的人越来越多，社交媒体可以为世界各地发生的事件提供及时、全面的多媒体信息。与传统的文字新闻相比，带有图片和视频的新闻可以提供更好的故事性，吸引更多读者的关注。不幸的是，这也被假新闻所利用，它们通常包含错误的甚至是伪造的图片，以误导读者并获得快速传播。</p><p>假新闻的传播可能造成大规模的负面影响，有时会影响甚至操纵重要的公共事件。例如，在2016年美国总统大选的最后三个月内，为支持两位提名人中的任何一位而产生的假新闻被很多人相信，在Facebook上的分享次数超过3700万次。因此，非常需要一个自动检测器来减轻假新闻造成的严重负面影响。</p><p>到目前为止，各种假新闻检测方法，包括传统学习[6, 15, 29]和基于深度学习的模型[21, 25]，都被利用来识别假新闻。在对不同事件进行充分验证的情况下，现有的深度学习模型由于其卓越的特征提取能力，已经取得了比传统模型更好的性能。<strong>然而，它们仍然无法处理假新闻检测的独特挑战，即检测新出现的和时间关键的事件上的假新闻[27]</strong>。由<strong>于缺乏相应的先验知识，关于这类事件的经过验证的帖子很难及时获得，这导致现有模型的性能不尽人意。</strong>事实上，<strong>现有的模型倾向于捕捉许多事件的特定特征，这些特征在不同的事件中并不共享。</strong>这些<strong>特定的事件特征，虽然能够帮助对已验证的事件进行分类，但会影响对新出现的事件的检测</strong>。出于这个原因，我们<strong>认为学习所有事件中的共享特征将有助于我们从未经核实的帖子中检测出假新闻，而不是捕捉事件的具体特征</strong>。因此，这项工作的目标是设计一个有效的模型，<strong>去除不可转移的特定事件特征，保留所有事件中的共享特征</strong>，以完成识别假新闻的任务。</p><p><strong>要删除事件的具体特征，第一步是要识别它们。对于不同事件的帖子，它们有自己独特的或特定的特征，是不可共享的。这种特征可以通过测量对应于不同事件的帖子之间的差异来检测。</strong>在这里，<strong>帖子可以用学到的特征来表示。因此，识别事件的特定特征等同于测量不同事件的学习特征之间的差异。</strong>然而，这是一个在技术上具有挑战性的问题。首先，由于帖子的学习特征表示是高维的，像平方误差这样的简单指标可能无法估计这种复杂特征表示之间的差异。其次，在训练阶段，特征表示不断变化。这就要求所提出的测量机制能够捕捉到特征表征的变化并持续提供准确的测量。尽管这非常具有挑战性，但<strong>有效估计不同事件上所学特征的差异性是去除事件特定特征的前提。</strong>因此，如何在这种条件下有效地估计异同性是我们必须解决的挑战。</p><p>为了应对上述挑战，提出了一个端到端的框架，称为事件对抗神经网络（EANN），用于基于多模态特征的假新闻检测。受对抗网络的启发，我们在训练阶段加入了<strong>事件判别器来预测事件的辅助标签，而相应的损失可以用来估计不同事件之间特征表示的不相似性。损失越大，不相似性越低。</strong>由于假新闻利用多媒体内容来误导读者并得到传播，我们的模型需要处理多模态的输入。多模态特征表示仍然高度依赖于数据集中的特定事件，不能很好地泛化为识别新来事件的假新闻。</p><p>受到对抗网络的启发。现有的对抗网络通常用于生成能够与观察到的样本相匹配的图像，通过最小化博弈框架。对抗性学习框架已被用于一些任务，如半监督学习的表征[23]、鉴别性的图像特征[20]和领域适应[8, 9]。</p><p><strong>模型还在事件判别器和多模态特征提取器之间建立了一个最小化博弈。特别是，多模态特征提取器被强制要求学习一个事件不变的表征来欺骗判别器。通过这种方式，它消除了对所收集的数据集中特定事件的严格依赖，并对未见过的事件实现了更好的概括能力。</strong></p><h2 id="METHODOLOGY"><a href="#METHODOLOGY" class="headerlink" title="METHODOLOGY"></a>METHODOLOGY</h2><p><img src="https://i.loli.net/2021/11/12/wZ1o2DQRTXMnylm.png" alt=""></p><p>目标是为假新闻检测学习可迁移和可鉴别的特征表示。假新闻检测器和事件判别器都是建立在多模式特征提取器之上的。</p><ul><li>假新闻检测器将学到的特征表示作为输入，预测帖子是假的还是真的。</li><li>事件判别器根据这个潜在的表征来识别每个帖子的事件标签。</li></ul><h3 id="Multi-Modal-Feature-Extractor"><a href="#Multi-Modal-Feature-Extractor" class="headerlink" title="Multi-Modal Feature Extractor"></a>Multi-Modal Feature Extractor</h3><p>文本表征 $R_T$  和 视觉表征 $R_V$， 多模态特征为：$R_F = R_T \oplus R_V \in R^{2p}$</p><h3 id="Fake-News-Detector"><a href="#Fake-News-Detector" class="headerlink" title="Fake News Detector"></a>Fake News Detector</h3><p>它部署了一个带有softmax的全连接层来预测帖子是假的还是真的。假新闻检测器是建立在多模态特征提取器之上的，因此将多模态特征表 $R_F$ 作为输入。我们将假新闻检测器表示为 $G_d(\cdot;θ_d)$，其中 $θ_d$ 代表所有包含的参数。对于第 $i$ 个多媒体帖子，假新闻检测器的输出表示为 $m_i$，是这个帖子是假的概率:</p><script type="math/tex; mode=display">P_{\theta}(m_i) = G_d(G_f(m_i;\theta_f); \theta_d)</script><p>假新闻检测器的目标是识别一个特定的帖子是否是假新闻。我们使用 $Y_d$ 来表示标签集，并采用交叉熵来计算检测损失。</p><script type="math/tex; mode=display">L_d(\theta_f,\theta_d) = -E_{(m,y)\sim(M,Y_d)}[ylog(P_{\theta}(m))+ (1-y)(log(1-P_{\theta}(m)))]</script><p>我们通过寻求最佳参数 $\hat θ_f$和 $\hat θ_d $ 来最小化检测损失函数，这个过程可以表示为：</p><script type="math/tex; mode=display">(\hat\theta_f,\hat\theta_d) = argmin_{\theta_f,\theta_d} L_d(\theta_f,\theta_d)</script><p>如前所述，<strong>假新闻检测的主要挑战之一是训练数据集没有涵盖的事件</strong>。<strong>这就要求我们能够为新出现的事件学习可迁移的特征表示</strong>。<strong>检测损失的直接最小化只有助于检测训练数据集中所包含的事件的假新闻，因为这只捕捉到了特定事件的知识（如关键词）或模式，不能很好地进行推广。</strong></p><p>因此，我们需要使模型能够学习更多的一般特征表示，<strong>以捕捉所有事件中的共同特征</strong>。这样的表征应该是事件不变的，不包括任何事件的特定特征。<strong>为了实现这一目标，我们需要消除每个事件的独特性</strong>。特别是，<strong>我们测量不同事件中特征表征的不相似性，并将其去除，以捕获事件不变的特征表征。</strong></p><h3 id="Event-Discriminator"><a href="#Event-Discriminator" class="headerlink" title="Event Discriminator"></a>Event Discriminator</h3><p>事件判别器是一个神经网络，由两个具有相应激活函数的全连接层组成。它的<strong>目的是根据多模态特征表示，将帖子正确地分类为K个事件之一</strong>。我们将事件判别器表示为 $G_e (R_F; θ_e)$，其中 $θ_e$ 代表其参数。我们用交叉熵来定义事件判别器的损失，并使用 $Y_e$ 来表示事件标签的集合:</p><script type="math/tex; mode=display">L_e(\theta_f, \theta_e) = - E_{(m,y)\sim (M,Y_e)} [\sum_{k=1}^K 1_{[k=y]} log(G_e(G_f(m;\theta_f)); \theta_e)]</script><p>损失最小化的事件判别器的参数 $L_e (-, -)$被写成:</p><script type="math/tex; mode=display">\hat \theta_e = argmin_{\theta_e} L_e(\theta_f,\theta_e)</script><p>上述损失 $L_e (θ_f , \hat θ_e )$<strong>可以用来估计不同事件分布的不相似性</strong>。<strong>大的损失意味着不同事件的分布表征是相似的</strong>，而且学到的特征是事件不变量。因此，为了消除每个事件的唯一性，我们需要通过寻求最佳参数来最大化判别损失。</p><p>上述想法激发了多模态特征提取器和事件判别器之间的最小值博弈。</p><p><strong>一方面，多模态特征提取器试图愚弄事件判别器，使判别损失最大化；另一方面，事件判别器旨在发现包含在特征表示中的事件特定信息，以识别事件。</strong>下一小节将介绍三个部分的整合过程和最终的目标函数。</p><h3 id="Model-Integration"><a href="#Model-Integration" class="headerlink" title="Model Integration"></a>Model Integration</h3><p>在训练阶段，多模态特征提取器 $G_f(-;θ_f)$ 需要与假新闻检测器 $G_d(-;θ_d)$ 合作，使检测损失 $L_d(θ_f , θ_d)$ 最小，从而提高假新闻检测任务的性能。同时，多模态特征提取器 $G_f (-;θ_f)$试图欺骗事件判别器 $G_e (-; θˆe)$，通过最大化事件鉴别损失 $L_e (θ_f, θ_e)$ 来实现事件不变的表示。事件判别器 $G_e (R_F;θ_e)$试图通过最小化事件判别损失来识别基于多模态特征表示的每个事件。我们可以将这个三人游戏的最终损失定义为:</p><script type="math/tex; mode=display">L_{final} (\theta_f,\theta_d,\theta_e) = L_d(\theta_f, \theta_d) - \lambda L_e(\theta_f,\theta_e)</script><p>其中，$λ$ 控制着 【假新闻检测】 和 【事件识别】 的目标函数之间的权衡。在本文中，我们简单地将 $λ$ 设置为1，而不对权衡参数进行调整。对于最小化博弈，我们寻求的参数集是最终目标函数的鞍点:</p><script type="math/tex; mode=display">(\hat \theta_f,\hat \theta_d) = argmin_{\theta_f,\theta_d} L_{final} (\theta_f,\theta_d,\hat \theta_e)</script><script type="math/tex; mode=display">\hat \theta_e = argmax_{\theta_e} L_{final} (\hat \theta_f,\theta_e)</script><p>我们使用随机梯度下降法来解决上述问题。$θ_f$ 根据</p><script type="math/tex; mode=display">\theta_f \leftarrow \theta_f - \eta (\frac{\partial L_d}{\partial \theta_f} - \lambda \frac{\partial L_e}{\partial \theta_f})</script><p>进行更新。这里我们采用[8]中介绍的梯度反转层（GRL）。梯度反转层在前向阶段作为一个识别函数，它将梯度与 $-λ$ 相乘，并在反推阶段将结果传递给前层。GRL可以很容易地加在 多模态特征提取器和事件判别器 之间。</p><p>为了稳定训练过程，我们采用了[8]中的方法来衰减学习率η。</p><script type="math/tex; mode=display">\eta'=\frac{\eta}{(1+\alpha\cdot p)^{\beta}}</script><p>其中 $α=10，β=0.75$，p从0到1线性变化，对应于训练进度。所提出的事件对抗性神经网络（EANN）的详细步骤在算法1中进行了总结。</p><p><img src="https://i.loli.net/2021/11/12/XNKMlT6p2G8ngQE.png" alt=""></p><h2 id="EXPERIMENTS"><a href="#EXPERIMENTS" class="headerlink" title="EXPERIMENTS"></a>EXPERIMENTS</h2><p><img src="https://i.loli.net/2021/11/12/PUrRayJ4wCjKsTQ.png" alt=""></p><p>为了进一步分析事件判别器的有效性，我们将EANN-和EANN在微博测试集上用t-SNE[22]学习的文本特征RT定性为图4所示。每个帖子的标签是真实或虚假的。<br>从图4中，我们可以观察到，对于EANN-的方法，它可以学习到可分辨的特征 ，但学到的特征仍然是扭曲在一起的，特别是对于图4a的左边部分。相比之下，EANN模型学习到的特征表征更具可辨识性，而且在图4b所示的不同标签的样本之间有更大的隔离区域。这是因为在训练阶段，事件判别器试图消除特征表征与特定事件之间的依赖关系。在最小化博弈的帮助下，多模态特征提取器可以针对不同的事件学习不变的特征表征，并获得更强大的转移能力来检测新事件的假新闻。EANN-和EANN的比较证明，所提出的方法在事件判别器的作用下可以学习到更好的特征表征，从而取得更好的性能。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;EANN-Event-Adversarial-Neural-Networks-for-Multi-Modal-Fake-News-Detection&quot;&gt;&lt;a href=&quot;#EANN-Event-Adversarial-Neural-Networks-for-Mul</summary>
      
    
    
    
    
    <category term="context detection" scheme="http://example.com/tags/context-detection/"/>
    
  </entry>
  
  <entry>
    <title>SPoT: Better Frozen Model Adaptation through Soft Prompt Transfer</title>
    <link href="http://example.com/2021/11/09/SPoT-Better-Frozen-Model-Adaptation-through-Soft-Prompt-Transfer/"/>
    <id>http://example.com/2021/11/09/SPoT-Better-Frozen-Model-Adaptation-through-Soft-Prompt-Transfer/</id>
    <published>2021-11-09T07:25:44.000Z</published>
    <updated>2021-11-09T13:14:50.422Z</updated>
    
    <content type="html"><![CDATA[<h1 id="SPoT-Better-Frozen-Model-Adaptation-through-Soft-Prompt-Transfer"><a href="#SPoT-Better-Frozen-Model-Adaptation-through-Soft-Prompt-Transfer" class="headerlink" title="SPoT: Better Frozen Model Adaptation through Soft Prompt Transfer"></a>SPoT: Better Frozen Model Adaptation through Soft Prompt Transfer</h1><p>在 《The Power of Scale for Parameter-Efficient Prompt Tuning》的 PROMPTTUNING 方法（学习特定任务的软 prompt，以调节冻结的语言模型来执行下游任务）的基础上，提出了一种新的基于Prompt 的迁移学习方法，称为SPOT：Soft Prompt Transfer。</p><p>SPOT首先在一个或多个源任务上学习 prompt，然后用它来初始化目标任务的 prompt。</p><p>更重要的是，SPOT 大于等于 model-tuning ，同时参数效率更高（最多可减少27,000倍的特定任务参数）。</p><p>进一步对26个NLP任务和160个源-目标任务的组合进行了大规模的任务迁移性研究，并证明了多任务往往可以通过 Prompt Transfer 而相互受益。</p><p>最后，提出了一种简单有效的检索方法，将任务 prompts 解释为任务 embeddings，以识别任务之间的相似性，并预测最可迁移的源任务用于新目标任务。</p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>越来越大的预先训练的语言模型是获得最佳性能的关键因素。虽然这一趋势不断推动着各种NLP基准的可能性，但这些模型的巨大规模对实际应用提出了重大挑战。对于100B以上的参数模型，为每个下游任务微调和部署一个单独的模型实例将是非常昂贵的。</p><p>为了绕过微调的不可行性，GPT-3 提出了 Prompt design，其中每一个下游任务都被铸成一个语言建模任务，冻结的预训练模型通过对推理时提供的手动文本 prompts 调节来执行不同的任务。</p><p>Brown等人（2020）用一个冻结的GPT-3模型展示了令人印象深刻的 few-shot 性能，尽管其性能高度依赖于 prompt 的选择，并且仍然远远落后于最先进的微调结果。</p><p>最近的工作探索了学习软prompt的方法（</p><ul><li>《Gpt understands, too》</li><li>《Learning how to ask: Querying LMs with mixtures of soft prompts》</li><li>《Prefix-tuning: Optimizing continuous prompts for generation》</li><li>《The power of scale for parameter-efficient prompt tuning》</li></ul><p>），这可以被视为注入语言模型的额外可学习参数。</p><p>PROMPTTUNING 在适应过程中为每个下游任务学习一个小的特定任务 prompt（一个可调整的标记序列，预置在每个样本中），以调节冻结的语言模型来执行该任务。</p><p>引人注目的是，随着模型容量的增加，PROMPTTUNING 与 model-tuning 比较起来，后者在每个下游任务上对整个模型进行微调。然而，在小规模和中等规模的模型（小于11B参数）中，PROMPTTUNING 和 model tuning 之间仍有很大差距。</p><p>例如，对于T5 BASE（220M参数）和T5 XXL（11B参数）模型，在SuperGLUE基准上分别获得了+10.1和+2.4点的平均精度改进。SPOT在所有模型规模上的表现都比model tuning有竞争力或明显更好</p><p><img src="https://i.loli.net/2021/11/09/78b2YLcQWw3xOVg.png" alt=""></p><p>在这些结果的激励下，通过任务 prompts 的视角来研究任务之间的可迁移性。目标是回答以下问题：</p><ul><li><p>(a) 对于一个给定的目标任务，何时将 prompt 初始化为源任务的 prompt 有助于提高性能？</p><p>为了解决(a)，作者使用26个NLP任务和160个源-目标任务的组合对T5模型进行了系统研究。结果表明，任务往往可以通过prompt transfer 而相互受益。</p></li><li><p>(b) 能不能利用任务 prompt，对给定的新目标任务使用哪些源任务做出更有原则的选择？</p><p>为了解决(b)，把学到的任务 prompt 解释为任务嵌入，以构建一个任务的语义空间，并规范任务之间的相似性。设计了一种高效的检索算法，用来测量任务嵌入的相似性，使能够识别那些有可能对给定的新目标任务产生积极迁移性的源任务。</p></li></ul><h2 id="Improving-PROMPTTUNING-with-SPOT"><a href="#Improving-PROMPTTUNING-with-SPOT" class="headerlink" title="Improving PROMPTTUNING with SPOT"></a>Improving PROMPTTUNING with SPOT</h2><p>为了提高PROMPTTUNING的性能，SPOT引入了源 prompt tuning，这是语言模型预训练和目标 prompt tuning 之间的一个中间训练阶段（如图左），在一个或多个源任务上学习prompt（同时仍保持基础模型冻结），然后用来初始化目标任务的prompt。</p><p><img src="https://i.loli.net/2021/11/09/vBU7Mqmlt6JP5Ie.png" alt=""></p><h3 id="Experimental-setup"><a href="#Experimental-setup" class="headerlink" title="Experimental setup"></a>Experimental setup</h3><p>冷冻模型是建立在预先训练好的各种尺寸的T5 checkpoints 之上的。SMALL、BASE、LARGE、XL、XXL，参数分别为60M、220M、770M、3B和11B。在对SPOT的实验中，利用了T5的LM adapted（<a href="https://github.com/google-research/text-to-text-transfer-transformer/blob/main/released_checkpoints.md">prefix LM</a>）版本，发现它更容易为PROMPTTUNING优化。</p><h3 id="Baselines"><a href="#Baselines" class="headerlink" title="Baselines"></a>Baselines</h3><ul><li>PROMPTTUNING : vanilla prompt tuning approach , 其中针对每个目标任务直接训练独立提示。</li><li>MODELTUNING &amp; MULTI-TASKMODEL TUNING: 将 prompt tuning 方法与MODELTUNING—标准的微调方法进行比较，其中所有的预训练参数都在每个目标任务上分别进行微调。为了进行 apples-to-apples 的比较，我们还包括MULTI-TASKMODEL TUNING，这是一个更有竞争力的基线，首先在SPOT使用的相同混合源任务上微调整个模型，然后在每个目标任务上单独微调。</li></ul><h3 id="Evaluation-datasets"><a href="#Evaluation-datasets" class="headerlink" title="Evaluation datasets"></a>Evaluation datasets</h3><p>在GLUE 和SuperGLUE 基准（每个基准都有8个数据集）的不同任务集上研究下游的性能。</p><h3 id="Data-for-source-prompt-tuning"><a href="#Data-for-source-prompt-tuning" class="headerlink" title="Data for source prompt tuning"></a>Data for source prompt tuning</h3><p>与语言模型的预训练一样，训练数据的选择对于成功的 prompt transfer至关重要。为了研究源训练数据对下游性能的影响，我们比较了一系列不同的源任务。</p><ul><li><strong>A single unsupervised learning task :</strong> 首先考虑在C4数据集上使用 “prefix LM” 目标训练一个 prompt。虽然这个任务是用来预先训练冷冻T5模型的，但它仍然可以帮助学习一个通用的提示。</li><li><strong>A single supervised learning task :</strong> 另外，我们可以使用监督任务来训练 prompt。我们使用MNLI或SQuAD作为单源任务。MNLI被证明对许多句子级别的分类任务有帮助，而SQuAD被发现对QA任务有很好的概括性。</li><li><strong>A multi-task mixture :</strong> 到目前为止，我们一直在对单一来源的任务进行训练提示。另一种方法是多任务训练。在T5的统一文本到文本框架内，这只是相当于将不同的数据集混合在一起。我们探索混合来自不同NLP基准或任务系列的数据集，包括GLUE、SuperGLUE、自然语言推理（NLI）、转述/语义相似性、情感分析、MRQA的问题回答、RAINBOW的常识推理。 我们使用Raffel等人（2020）的例子—比例混合策略，从上述每个NLP基准/任务家族中创建了一个源任务的mixture，人工数据集大小限制为K = 219个训练例子。最后，我们包括C4和上述NLP基准/任务族中的所有标记数据集的混合（55个数据集）。</li></ul><p>遵循 PROMPTTUNING 的观点。，我们使用 CLASS-LABEL 方案(其中 prompt tokens用表示输出类的合并的嵌入来初始化)来初始化提示，并退回到SAMPLEDVOCAB方案以填充任何剩余的提示位置)。</p><h3 id="Effect-of-SPOT"><a href="#Effect-of-SPOT" class="headerlink" title="Effect of SPOT"></a>Effect of SPOT</h3><p><img src="https://i.loli.net/2021/11/09/P79bgkXEKDuZArh.png" alt=""></p><p>我们在图1和表1中比较了SPOT和其他方法的结果。下面，我们对每个发现进行详细的总结和分析。</p><ul><li><strong>SPOT significantly improves performance and stability of PROMPTTUNING:</strong>  表1显示了我们在T5-BASE glue 和SuperGlue基准上的结果。总体而言，结果表明，prompt transfer 为 PROMPTTUNING 提供了一种提高性能的有效手段。我们的烧蚀研究表明，Longer tuning 也是实现我们最佳性能的一个重要因素，并且是对 prompt transfer 的补充。此外，当Longer tuning 被省略时，我们观察到SPOT在不同的运行中提高了稳定性。</li><li><strong>Different source mixtures can lead to performance gains:</strong>  在SPOT方法中，我们可以比较不同来源混合的有效性（见表1）。在GLUE和SuperGLUE上的源 prompt tuning 表现最好，分别获得82.8和73.2的平均分数。有趣的是，C4上的无监督源 prompt tuning（与预训练我们的冻结模型的任务相同）仍然产生了相当大的改进，甚至在SuperGLUE任务中超过了SuperGLUE的源 prompt tuning。此外，使用MNLI或SQuAD作为单一源数据集对GLUE和SuperGLUE都特别有帮助。最后，其他来源的混合也能带来明显的收益，一些NLP基准/任务家族（如NNLI和转述/语义相似性）比其他任务更有利。</li><li><strong>SPOT helps close the gap with MODELTUNING across all model sizes:</strong>  最后，SPOT产生了与强大的MULTI-TASKMODEL TUNING基线相竞争的性能，同时在多任务源 tuning 和目标 tuning 方面参数效率更高；在XXL尺寸下，SPOT获得了91.2的最佳平均得分，<strong>比MULTI-TASKMODELTUNING好+1.1分，尽管其特定任务参数少27000倍。</strong></li></ul><h2 id="Investigating-task-transferability"><a href="#Investigating-task-transferability" class="headerlink" title="Investigating task transferability"></a>Investigating task transferability</h2><p>在确定了 prompt transfer 对 prompt tuning 有帮助之后，我们现在将重点转移到通过任务prompts 的视角来研究任务迁移性。</p><p>为了阐明不同任务之间的可迁移性，我们对26个NLP任务（包括一个无监督的任务）和160个源-目标任务的组合进行了大规模的实证研究。我们证明，在各种情况下，任务可以通过 prompt transfer 来互相帮助，而任务的相似性在决定迁移性方面起着重要作用。</p><p>此外，我们表明，通过将任务prompts解释为任务嵌入，我们可以构建一个任务的语义空间，并制定一个更严格的任务相似性概念。最后，我们提出了一种检索算法，该算法测量任务嵌入的相似性，以选择哪些源任务用于给定的新目标任务（图2，右）。</p><p><img src="https://i.loli.net/2021/11/09/lzYAeRdUOH6rfPh.png" alt=""></p><p>我们学习源任务的prompts，并将早期检查点作为任务嵌入，将最佳检查点保存为源prompts。这些构成了我们prompts库的键和值。给定一个新的目标任务。用户：(i) 计算一个任务嵌入，(ii) 检索一个最佳的源prompt，(iii) 训练一个目标prompt，该prompt以源prompt为初始化。</p><h3 id="Experimental-setup-1"><a href="#Experimental-setup-1" class="headerlink" title="Experimental setup"></a>Experimental setup</h3><p>我们研究了16个源数据集和10个目标数据集的不同集合（见表2）。我们考虑了所有160对可能的源和目标数据集，并从每个源任务转移到每个目标任务。</p><p><strong>Source and target tasks</strong></p><p> 源任务包括一个无监督任务（C4）和15个监督任务，涵盖自然语言推理（NLI）、转述/语义相似性、情感分析、问题回答（QA）和常识推理。所有的源任务都是数据丰富的，或者在以前的工作中已经被证明产生了积极的转移。为了模拟一个真实的场景，我们使用低资源任务（少于1万个训练实例）作为目标任务。这些任务涵盖了上述类型的任务，此外还包括语法可接受性、词义消歧和核心推理的解决。</p><p><strong>Training details</strong></p><p>为了限制计算成本，我们在所有的任务迁移性实验中使用T5 BASE。我们在每个源任务上执行262,144个 prompt tuning 步骤。选择具有最高源任务验证性能的 prompt checkpoint 来初始化不同目标任务的 prompt。由于目标数据集较小，我们只对每个目标任务进行100K的 prompt tuning 步骤。</p><p><strong>Constructing a semantic space of tasks</strong></p><p>由于在具体任务的 prompt tuning 过程中只有 prompt 参数被更新，任务prompt很可能编码了特定的任务知识。这表明，它们可以被用来推理任务的性质及其关系。为了测试这个想法，我们将任务 prompt 解释为任务嵌入，并构建一个任务语义空间。请注意，虽然我们使用源任务的最佳 prompt checkpoint 来迁移到目标任务中，但我们使用早期的 prompt checkpoint 作为我们的任务嵌入。这使得新的目标任务的任务嵌入可以快速计算。在我们的实验中，任务嵌入来自一个固定的prompt checkpoint，即在10K步，为每个任务。我们通过测量它们对应的任务嵌入 $e^1$, $e^2$之间的相似性来估计两个任务 $t^1$,  $t^2$ 之间的相似性，使用以下指标:</p><ul><li><p>COSINE SIMILARITY OF AVERAGE TOKENS: 计算 prompt tokens 的平均集合表示之间的余弦相似度。</p><p>$sim(t^1,t^2) = cos(\frac{1}{L} \sum_i e^1_i, \frac{1}{L}\sum_j e_j^2)$ , 其中 $e^1_i,e^2_j$ 定义为各自的 prompt tokens</p></li><li><p>PER-TOKEN AVERAGE COSINE SIMILARITY: 计算每个 prompt token 对之间的平均余弦相似度 $(e_i^1,e^2_j)$:</p><p>$sim(t^1,t^2) = \frac{1}{L^2} \sum_i\sum_j cos(e_i^1,e_j^2)$</p></li></ul><h3 id="Predicting-and-exploiting-transferability"><a href="#Predicting-and-exploiting-transferability" class="headerlink" title="Predicting and exploiting transferability"></a>Predicting and exploiting transferability</h3><p>利用任务嵌入来预测和利用任务迁移性。具体来说，我们探索了预测对给定目标任务最有利的源任务的方法，然后利用其prompt 来提高目标任务的表现。</p><p>为了扩大我们的源 prompts 集，我们使用了每个源任务上所有三个不同的 prompt tuning运行的 prompt，从而产生了48个源 prompts。给定一个具有任务嵌入的目标任务 $t$ ，我们将所有的源prompts $ρ^s$按其对应的任务嵌入$e^s$ 和目标嵌入$e^t$之间的相似度从高到低排序。</p><p>我们将源prompts 的排序列表表示为 $ρ^{s_r}$，其中r表示排序（r=1,2,…,48）。我们用以下方法进行实验:</p><ul><li>BEST OF TOP-k : 选择前 k 个源prompts，并分别使用它们来初始化目标prompt。这个过程需要对目标任务 t 进行 k 次prompt tuning，每个源prompt一次。然后，最好的单个结果被用来评估这个方法的有效性。</li><li>TOP-k WEIGHTED AVERAGE: 用前k个源prompt 的加权平均数初始化目标prompt $\sum<em>{r=1}^k \alpha_r ρ^{s_r}$，这样我们只对目标任务 $t$ 进行一次提示调整。 权重 $\alpha_r = \frac{sim(e^{s_r, e^t})}{\sum</em>{l=1}^k sim(e^{s_l, e^t})}$， $e^{s_r}$表示相应的任务嵌入 $ρ^{s_r}$</li><li>TOP-k MULTI-TASK MIXTURE: 首先确定 prompt 在前k个 prompt 中的源任务，并将其数据集和目标数据集混合在一起，使用Raffel等人（2020）的例子-比例混合策略。然后，我们在这个多任务混合物上进行源prompt tuning，并使用最后的 prompt checkpoint 来为目标 prompt tuning 进行初始化。</li></ul><p><strong>Evaluation</strong></p><p>我们报告了通过使用上述每一种方法在目标任务中取得的平均分数。对于每个目标任务 $t$ ，我们衡量三个不同的 prompt tuning 运行（导致不同的任务嵌入等）的平均和标准偏差。为了进行比较，我们报告了在对每个目标任务从头开始进行prompt tuning（即没有任何 prompt Transfer）时，比基线的绝对和相对改进。此外，我们还包括通过使用暴力搜索来确定每个目标任务的48个源 prompt 中的最佳 prompt 所取得的谕示结果。</p><h3 id="Effect-of-prompt-based-task-embeddings"><a href="#Effect-of-prompt-based-task-embeddings" class="headerlink" title="Effect of prompt-based task embeddings"></a>Effect of prompt-based task embeddings</h3><p>在这一部分中，我们首先分析我们的任务可迁移性结果。然后，我们论证了使用基于 prompt 的任务嵌入来表示任务、预测和开发任务可迁移性的有效性。</p><p><img src="https://i.loli.net/2021/11/09/bBqas3ylQuUZndf.png" alt=""></p><p><strong>Tasks can help each other via prompt transfer in various scenarios:</strong>  实验结果表明，在许多情况下，将 prompt 从源任务转移到目标任务（SOURCE → TARGET）可以在目标任务上提供显著的增益。</p><p><img src="https://i.loli.net/2021/11/09/e1y6ipCjg5OfaLn.png" alt=""></p><p><strong>Task embeddings capture task relationships :</strong> 图3显示了研究的26个NLP任务的任务嵌入之间的余弦相似性的分层聚类热图，使用的是平均托肯斯的余弦相似性指标。具体来说，类似的任务被归为几个集群，包括问题回答（SQuAD、ReCoRD和DROP；MultiRC和BoolQ）、情感分析（Yelp-2、SST-2和CR）、NLI（MNLI和CB；DocNLI和RTE）、语义相似性（STS-B和CxC）、副词（MRPC和QQP）和常识推理（WinoGrande、HellaSWAG和CosmosQA）。我们注意到，QNLI是由SQuAD数据集建立的NLI任务，与SQuAD没有密切联系；这表明我们的任务模型对任务类型比领域相似性更敏感。有趣的是，它们也捕捉到了ReCoRD对WSC的高可转移性这一非直观的情况。此外，来自同一任务的不同提示的任务嵌入具有很高的相似性分数</p><p><img src="https://i.loli.net/2021/11/09/eEAGvyxmXN8nzlh.png" alt=""></p><p><strong>Correlation between task embedding similarity and task transferability:</strong> 图4显示了目标任务上的相对误差减少是如何作为源和目标任务嵌入之间的相似性的函数而变化的。总的来说，我们发现，在我们研究的四个（10个）目标任务上，任务嵌入的相似性和任务可转移性之间存在明显的正相关，包括STS-B（p &lt; 0.001），CB（p &lt; 0.001，未显示），WSC（p &lt; 0.01），和RTE（p &lt; 0.05），而在其他任务上则不太明显。</p><p><img src="https://i.loli.net/2021/11/09/eVcs79ZDtWYK2JM.png" alt=""></p><p><strong>Task embeddings can be used to predict and exploit task transferability:</strong> 我们在表3中比较了不同方法的结果，以确定哪些源提示可能对给定的目标任务有益。我们发现，对于小的k值(≤9)，使用每键平均COSINE SIMILARITY指标比使用AV-ERAGE TOKENS的COSINE SIMILARITY指标产生更好的结果。我们的结果还表明，BEST OF TOP-k提供了一个预测和利用任务转移性的有效手段。简单地选择源提示，其相关的任务嵌入与目标嵌入具有最高的相似性，使用每键平均COSMINE SIMILARITY度量，比基线有很大的改善（从平均得分74.7到76.7，平均相对误差减少12.1%）。为每个目标任务尝试所有前三名（共48个）的源提示，得到的平均分数为77.5分。随着k值的增大，我们可以保留神谕选择源提示的大部分好处（k=9时平均得分的80%，k=15时平均得分的90%），同时仍然可以消除2/3以上的候选源提示。尽管这种方法需要对目标任务进行K次提示调谐，但与模型调谐相比，提示调谐的成本相对低廉。在k=1的情况下，TOP-k加权平均法与BEST OF TOP-k的平均性能相似，但实现的方差较小。因此，在禁止对tar-get任务进行多次调谐的情况下，这可能是对BEST OF TOP-k的一个有吸引力的替代方案。最后，TOP-k MULTI-TASK MIXTURE也提供了一种获得强大性能的方法，其平均得分为77.8，甚至在k≤3的情况下超过了BEST OF TOP-k。</p><h2 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h2><p><strong>Parameter-efficient transfer learning &amp; lan- guage model prompting</strong></p><p>预训练的语言模型已被证明是改善许多NLP基准的最先进结果的有效手段（Devlin等人，2019；Liu等人，2019b；Yang等人，2019；Lan等人，2020；Raffel等人，2020；Brown等人，2020；He等人，2021）。然而，MODELTUNING（又称微调）—目前将这些模型应用于下游任务的主流方法—可能变得不切实际，因为为每项任务微调所有预训练的参数可能过于昂贵，特别是随着模型规模的不断扩大。</p><p>为了解决这个问题，早期的工作使用了compression技术，如知识分散（Sanh等人，2019；Jiao等人，2020；Sun等人，2020）和模型修剪（Fan等人，2020；Sanh等人，2020；Chen等人，2020），以获得轻型预训练模型。其他工作只更新语言模型的小部分（Zaken等人，2021）或训练特定的任务模块，如适配器（Houlsby等人，2019；Karimi Mahabadi等人，2021）和/或低等级结构（Mahabadi等人，2021；Hu等人，2021），同时保持大部分或全部预训练参数固定。值得注意的是，Brown等人（2020年）使用PROMPTDESIGN的单一冻结的GPT-3模型展示了显著的几次学习性能，其中每个任务都是在推理时间向模型提供手动文本提示，要求它产生一些输出文本。</p><p>此后，一些努力集中在开发基于提示的学习方法，包括精心手工制作的提示（Schick和Schütze，2021）、提示挖掘和转述（Jiang等人，2020b）、基于梯度搜索的改进提示（Shin等人，2020）和自动提示生成（Gao等人，2021）。然而，使用硬性提示被发现是次优的和敏感的，即下游表现和提示格式之间没有明显的相关性，提示的微小变化会导致下游表现的显著差异（Liu等人，2021b）。因此，最近的工作已经转向学习软提示（Liu et al., 2021b; Qin and Eisner, 2021; Li and Liang, 2021; Lester et al., 2021），这可以被看作是注入语言模型的一些额外的可学习参数。我们请读者参考Liu等人（2021a）对基于提示的学习研究的最新调查。</p><p>同时进行的工作（Gu等人，2021）也探讨了 prompt 预训练的有效性。他们的方法使用手工制作的预训练任务，为不同类型的下游任务量身定做，这限制了其对新型下游任务的应用。相比之下，我们使用现有的任务作为源任务，并表明即使在源任务和目标任务之间存在不匹配（如任务类型、输入/输出格式）的情况下，prompt transfer也能带来好处。他们的工作也集中在 few-shot 的设置上，而我们是在较大的数据集背景下工作。此外，我们研究了任务的可迁移性，并证明任务往往可以通过 prompt transfer 来互相帮助，而任务 prompt 可以被解释为任务嵌入，以正式确定任务的相似性，从而确定哪些任务可以互相受益。</p><p><strong>Task transferability</strong></p><p>我们还建立在现有的关于NLP的任务迁移性的工作上（Phang等人，2019；Wang等人，2019a；Liu等人，2019a；Talmor和Berant，2019；Pruksachatkun等人，2020；Vu等人，2020；Poth等人，2021）和计算机视觉（Zamir等人，2018；Achille等人，2019；Yan等人，2020）。之前的工作表明，从数据丰富的源任务（Phang等人，2019年）、需要复杂推理和推理的任务（Pruksachatkun等人，2020年）或与目标任务相似的任务（Vu等人，2020年）中有效转移。也有人努力预测任务之间的可转移性（Bingel和Søgaard，2017；Vu等人，2020；Poth等人，2021）。Vu等人（2020）使用来自输入文本或语言模型对角线Fisher信息矩阵的任务嵌入，而Poth等人（2021）探索基于适配器的方法。在这里，我们对T5的使用使我们能够更好地对任务空间进行建模，因为每个任务都被投到一个统一的文本到文本的格式中，并且在不同的任务中使用相同的模型（没有特定的任务成分）。此外，基于提示的任务嵌入相对来说更容易获得。</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>在本文中，我们研究了在提示调谐背景下的转移学习。我们表明，规模对于PROMPTTUNING与MODEL-TUNING的性能相匹配是没有必要的。我们的SPOT方法在不同的模型规模下与MODEL-TUNING的性能相匹配，甚至超过了MODEL-TUNING的性能，同时参数效率更高（最多可减少27,000倍的特定任务参数）。我们对任务转移性的大规模研究表明，在各种情况下，任务可以通过提示转移而相互受益。最后，我们证明，任务提示可以被解释为任务嵌入，以正式确定任务之间的相似性。我们提出了一种简单而有效的检索方法，以衡量任务的相似性，从而确定哪些源任务可以给一个新的目标任务带来好处。从整体上看，我们希望我们的工作能够促进对基于提示的迁移学习的更多研究。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;SPoT-Better-Frozen-Model-Adaptation-through-Soft-Prompt-Transfer&quot;&gt;&lt;a href=&quot;#SPoT-Better-Frozen-Model-Adaptation-through-Soft-Prompt-</summary>
      
    
    
    
    
    <category term="context detection" scheme="http://example.com/tags/context-detection/"/>
    
  </entry>
  
  <entry>
    <title>The Power of Scale for Parameter-Efficient Prompt Tuning</title>
    <link href="http://example.com/2021/11/08/The-Power-of-Scale-for-Parameter-Efficient-Prompt-Tuning/"/>
    <id>http://example.com/2021/11/08/The-Power-of-Scale-for-Parameter-Efficient-Prompt-Tuning/</id>
    <published>2021-11-08T03:04:04.000Z</published>
    <updated>2021-11-08T11:14:12.897Z</updated>
    
    <content type="html"><![CDATA[<h1 id="The-Power-of-Scale-for-Parameter-Efficient-Prompt-Tuning"><a href="#The-Power-of-Scale-for-Parameter-Efficient-Prompt-Tuning" class="headerlink" title="The Power of Scale for Parameter-Efficient Prompt Tuning"></a>The Power of Scale for Parameter-Efficient Prompt Tuning</h1><p><a href="https://zhuanlan.zhihu.com/p/428512183">https://zhuanlan.zhihu.com/p/428512183</a></p><p>在这项工作中，作者探索了 “prompt tuning”，这是一种简单而有效的机制，用于学习 “软提示”，以调节冻结的语言模型来执行特定的下游任务。</p><p>与GPT-3使用的离散文本提示不同，软提示是通过反向传播来学习的，并且可以进行调整以合并来自任何数量的标注样本的信号。</p><p>此端到端学习方法在很大程度上超过了GPT-3的 few-shot learning。更值得注意的是，通过使用T5对模型规模的消减，表明，随着规模的扩大，prompt tuning变得更有竞争力：当模型超过数十亿个参数时，该方法 “缩小了差距”，与model tuning （其中调整了所有模型权重）的强大性能相匹配。</p><p>这一发现尤其重要，因为共享和服务大型模型的成本很高，而将一个冻结模型重用于多个下游任务的能力可以减轻这一负担。</p><p>此方法可以看作是对最近提出的  “prefix tuning”，以软提示为条件的冻结模型对领域转移的鲁棒性有好处，并能实现有效的 “prompt ensembling”。</p><h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1 Introduction"></a>1 Introduction</h2><p>随着预训练的大型语言模型的广泛成功，出现了一系列的技术来适应这些通用模型的下游任务。ELMo提出冻结预训练的模型，并学习其每层表征的特定任务加权。</p><p>然而，自GPT和BERT以来，主流的适应技术是模型调整（或 “微调”），即在适应期间调整所有的模型参数。</p><p>最近，GPT3 表明，prompt design （或 “priming”）在通过文本提示来调节冻结的GPT-3模型的行为方面是惊人的有效。提示通常由一个任务描述和/或几个典型的例子组成。这种回到 “冻结 “预训练模型的做法很有吸引力，尤其是在模型规模不断扩大的情况下。与其说每个下游任务都需要一个单独的模型副本，不如说一个通用模型可以同时为许多不同的任务服务。</p><p>不幸的是，基于提示的适应有几个关键的缺点。任务描述容易出错，需要人的参与，而且提示的有效性受限于模型输入中能容纳多少条件文本。</p><p>因此，下游任务的质量仍然远远落后于 model tuning。例如，GPT-3 175B 在SuperGLUE上的几率性能比微调的T5-XXL低17.5分（71.8比89.3），尽管使用了16倍的参数。</p><p>最近提出了几项自动化 prompt 设计。</p><p>《 AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts》</p><p>虽然这种技术优于人工提示设计，但相对于 model tuning 而言，仍有差距。</p><p>《Prefix-tuning: Optimizing continuous prompts for generation》 提出 “prefix tuning” 并 在生成性任务中表现出很强的效果。这种方法冻结了模型参数，并将调整过程中的误差反向传播到预置在编码器堆栈中每一层的前缀激活，包括输入层。</p><p>《WARP: Word-level Adversarial ReProgramming》 通过将可训练的参数限制在 masked 语言模型的输入和输出子网络上，简化了这个方法，并在分类任务上显示了合理的结果。</p><p>本文提出了 prompt tuning 作为适应语言模型的进一步简化方法。我们冻结了整个预训练的模型，只允许每个下游任务有额外的 $k$ 个可调整的标记被预加到输入文本中。这种 “软提示 “是端到端的训练，可以浓缩来自完整的标记数据集的信号，使我们的方法能够胜过  few-shot prompts，并缩小与模型调整的质量差距。如图1所示，随着规模的扩大，提示调谐变得更具竞争力。</p><p><img src="https://i.loli.net/2021/11/08/Ws5EYPU7JOTMItl.png" alt=""></p><p>同时，由于一个预训练模型被循环用于所有下游任务，因此我们保留了冻结模型的有效服务优势</p><p><img src="https://i.loli.net/2021/11/08/VGpNzwImrZFR7oE.png" alt=""></p><p>与Prefix-tuning 和 AutoPrompt 虽然都使用 “软提示”，但本文是第一个表明单独的 prompt tuning（没有中间层前缀或特定任务的输出层）就足以与 model tuning 相媲美。</p><p>主要贡献：</p><ul><li>提出 prompt tuning，并证明其在大型语言模型体系中与模型调谐的竞争力。</li><li>消融了许多设计选择，并证明质量和稳健性随着规模的扩大而提高。</li><li>表明在领域转移问题上，prompt tuning 优于 model tuning。</li><li>提出 “prompt ensembling”并显示其有效性。</li></ul><h2 id="2-Prompt-Tuning"><a href="#2-Prompt-Tuning" class="headerlink" title="2 Prompt Tuning"></a>2 Prompt Tuning</h2><p>按照T5的 “text-to-text”的方法，将所有的任务作为文本生成。我们现在不是将分类建模为给定某种输入的输出类别的概率$Pr(y|X)$ ，其中 $X$ 是一系列 tokens，$y$ 是一个单一的类别标签，而是将其建模为条件生成，其中 $Y$ 是代表一个类别标签的一系列 tokens。T5将分类建模为 $Pr_θ(Y|X)$，参数由构成其编码器和解码器的 transformer 的权重 $θ$ 决定。</p><p>Prompting 是指在生成 $Y$ 的过程中为模型添加额外的信息作为条件的方法。</p><p>通常情况下，提示是通过在输入的 $X$ 上预置一系列标记 $P$ 来完成的，这样模型就能最大限度地提高正确 $Y$ 的可能性，即$Pr_θ(Y |[P ; X ])$，同时保持模型参数 $θ$ 的固定。在GPT-3中，prompt tokens的表示，$P={p_1, p_2, …, p_n}$，是模型嵌入表的一部分，由冻结的 $θ$ 作为参数。</p><p> 因此，寻找最佳 prompt 需要通过人工搜索或无差别搜索方法来选择提示符。</p><p>Prompt tuning 消除了提示 $P$ 被 $θ$ 参数化的限制；相反，提示有它自己的专用参数 $θ_P$，可以被更新。prompt design 涉及从固定的冻结嵌入词汇中选择提示标记，而 Prompt tuning 可以被认为是使用固定的特殊标记的提示，其中只有这些提示标记的嵌入可以被更新。</p><p>新的条件生成现在是 $Pr_{\theta;\theta_P} (Y| [P;X])$，可以通过反向传播使 $Y$ 的可能性最大化来训练，同时只对 $θ_P$ 应用梯度更新。</p><p>给定一系列的 n个 tokens，${x_1, x_2,…, x_n}$，T5做的第一件事就是嵌入这些tokens，形成一个矩阵 $X_e\in R^{n\times e}$，其中 $e$ 是嵌入空间的维度。</p><p>soft-prompts 被表达为一个参数 $P_e\in R^{p\times e}$ 其中 $p$ 是prompt长度。</p><p>然后，prompt 与嵌入的输入相连接，形成一个单一的矩阵 $[P_e; X_e]\in R^{(p+n)×e}$，然后像平常一样流经编码器-解码器。我们的模型被训练为最大化 $Y$ 的概率，但只有 prompt 参数 $P_e$被更新。</p><h3 id="Design-Decisions"><a href="#Design-Decisions" class="headerlink" title="Design Decisions"></a>Design Decisions</h3><p>有许多可能的方法来初始化 prompt 表征。最简单的是从头开始训练，使用随机初始化。一个更复杂的选择是将每个 prompt token 初始化为一个从模型词汇中提取的嵌入。</p><p>从概念上讲，soft-prompt  以与输入前的文本相同的方式调节冻结网络的行为，因此，类似于单词的表述可能作为一个好的初始化点。对于分类任务，第三个选择是用列举输出类别的嵌入来初始化 prompt，类似于 “verbalizers”。</p><p>由于我们希望模型在输出中产生这些 tokens，用有效的目标 tokens 的嵌入来初始化prompt ，应该使模型将其输出限制在合法的输出类别中。</p><p>另一个设计考虑是 prompt 的长度。我们方法的参数成本是 $EP$ ，其中E是 token 嵌入维度，P是 prompt 长度。prompt越短，必须调整的新参数就越少，所以我们的目标是找到一个表现良好的最小长度。</p><h3 id="Unlearning-Span-Corruption"><a href="#Unlearning-Span-Corruption" class="headerlink" title="Unlearning Span Corruption"></a>Unlearning Span Corruption</h3><p>T5 模型的预训练任务是 Span Corruption，模型被要求去重构被打乱的句子</p><p>与GPT-3等自回归语言模型不同，我们试验的 T5 模型使用编码器-解码器架构，并对 Span Corruption 目标进行预训练。具体来说，T5的任务是 “重建 “输入文本中被屏蔽的span ，这些跨度被 tokens 为独特的哨兵符号。目标输出文本由所有被屏蔽的跨度组成，用哨兵标记分开，再加上最后一个哨兵标记。</p><p>例如。从文本 “Thank you for inviting me to your party last week”中，我们可以构建一个预训练的例子，其中输入是 “Thank you ⟨X⟩ me to your party ⟨Y⟩ week”，目标输出是”⟨X⟩ for inviting ⟨Y⟩ last ⟨Z⟩”。</p><p>虽然Raffel等人（2020年）发现这种架构和预训练目标比传统的语言建模更有效，但我们假设这种设置并不适合产生一个可以通过prompt tuning而随时控制的冻结模型。特别是，一个专门针对 Span Corruption 进行预训练的T5模型，如T5.1.1，从未见过真正自然的输入文本（不含哨兵标记），也从未被要求预测真正自然的目标。</p><p>事实上，由于T5的 Span Corruption 预处理的细节，每个预训练目标都会以哨兵开始。虽然这种输出哨兵的 “非自然 “倾向很容易通过微调来克服，但我们怀疑，由于解码器的先验因素无法调整，仅通过提示就很难推翻它。</p><p>考虑到这些问题，我们在三种情况下试验了T5模型。</p><ul><li>(1) “Span Corruption”。我们使用预先训练好的现成的T5作为我们的冻结模型，并测试其为下游任务输出预期文本的能力。</li><li>(2) “Span Corruption + Sentinel”。我们使用相同的模型，但在所有的下游目标中预置一个哨兵，以便更接近于预训练中看到的目标。</li><li>(3) “LM Adaptation”。我们继续T5的自我监督训练，进行少量的附加步骤，但使用Raffel等人（2020）所讨论的 “LM “目标；给定一个自然文本 prefix 作为输入，该模型必须产生自然文本的延续作为输出。</li></ul><p>最重要的是，这种适应性只发生一次，产生一个单一的冻结模型，我们可以在任何数量的下游任务中重复使用，进行prompt tuning。</p><p>通过LM adaptation，我们希望将T5 “快速 “转变为一个与GPT-3更相似的模型，GPT-3总是输出真实的文本，并且作为一个 “few-shot learner”，对提示有良好的反应。与从头开始的预训练相比，这种后期转变的成功率并不明显，而且据我们所知，以前也没有人研究过这种情况。因此，我们对各种长度的适应进行了实验，最高可达10万步。</p><h2 id="3-Results"><a href="#3-Results" class="headerlink" title="3 Results"></a>3 Results</h2><p>实验设定如下：</p><p><strong>预训练模型：</strong>T5 v1.1 from small to XXL。</p><p><strong>默认设置：</strong>采用经过额外 100k steps 的 LM Adaption 以后的 T5 模型 + 100 tokens 的 prompt。</p><p><strong>评测数据集：</strong>采用 SuperGLUE 基准的全量数据，将数据集重定义为 text-to-text 的形式（但是并不会加上 task name 的前缀），每一个 task 单独训练一个 prompt，训练步数为 30K，最后报告 SuperGLUE 的 dev set 的结果。</p><p><strong>基线模型：</strong>1）Model Tuning：每个 task 分别微调一个 T5 模型；2） Model Tuning（Multi-Task）：多个 task 一起训练，为了区分每个 task，会加上 task name 的前缀。</p><p>实验结果如下：</p><p><img src="https://i.loli.net/2021/11/08/gyFpB84RMnjEA3I.png" alt=""></p><p>随着模型参数的增加，Prompt Tuning 的效果越来越好，当 T5 模型参数达到 XXL 时，Prompt Tuning 的效果追平了 Model Tuning 和 Model Tuning（Multi-Task）。同时，Prompt Tuning 的效果远远超过了与 T5 同参数级别的 GPT-3 in context learning 的效果。</p><p><strong>prompt tokens 对 prompt tuning 的影响：</strong>在一般模型大小情况下，prompt tokens 越多，确实效果越好，但是当 token 超过 20 以后，增益就越来越小，对于超大模型的情况，即使是单个 prompt token，也能达到和 20 个 token 以上的 prompt 相近的效果。</p><p><strong>prompt token 的初始化：</strong>1. 随机初始化；2. 从 T5 词表中 5000 个常见单词中采样；3. 用类标签来初始化，标签是多个 token 时，则取均值，当类标签都用完后，剩下的 prompt token 用方法 2 初始化。类标签初始化在各种尺寸的模型上都表现最好，但是不同初始化策略在各种尺寸模型上表现差异很大，当尺寸变 XXL 后，这种差异就会消失。</p><p><strong>预训练任务对 prompt tuning 的影响：</strong>Span Corruption 任务导致了 prompt tuning 表现很差，即使加了 Sentinel 也没法缓解，而 LM Adaptation 设定下随着模型尺寸增大则 prompt tuning 表现越来越好。当然，当尺寸变为 XXL 后，这种影响也会消失。</p><p><strong>LM Adaptation steps 对 prompt tuning 的影响：</strong>LM Adaptation steps 越多，效果越好，这也说明 T5 需要进一步预训练才行。当然，当尺寸变为 XXL 后，这种影响也会消失。</p><h2 id="4-Comparison-to-Similar-Approaches"><a href="#4-Comparison-to-Similar-Approaches" class="headerlink" title="4 Comparison to Similar Approaches"></a>4 Comparison to Similar Approaches</h2><p>比较的一个重要轴是每种方法所需的特定任务参数的数量，如图4所示。在具有可学习参数的方法中，prompt tuning是参数效率最高的，对于超过10亿个参数的模型，需要不到0.01%的特定任务参数。</p><p><img src="https://i.loli.net/2021/11/08/NHCwWmDvGKdOY9o.png" alt=""></p><p><strong>“prefix tuning”</strong>：学习在每个 transformer 层预置的前缀序列。这类似于学习 transformer 的激活，这些激活在每个网络层都是固定的。与此相反，Prompt Tuning 使用单一的提示表示，被预置到嵌入式输入。除了重新引用较少的参数外，我们的方法允许 transformer 更新中间层的任务表征，就像输入实例的背景一样。他们的工作建立在GPT-2 和 BART 的基础上，而我们的工作则以T5为基础，研究了随着模型大小的增加，设计选择的性能和稳健性的变化。当使用BART时，prefix tuning 包括编码器和解码器网络上的前缀，而 Prompt Tuning 只需要编码器上的提示。</p><p><strong>与 P-tuning 的区别：</strong>P-tuning 的 soft tokens 需要考虑插入位置，同时采取的策略是 LM+Prompt Tuning，而 Prompt Tuning 则是直接插入在 prefix 位置，同时固定了 LM。同时 Prompt Tuning 相比 Model Tuning 的好处在于不会太过拟合在目标任务上，拥有更好的泛化性。</p><p><strong>“adapters”</strong>，即在冻结的预训练网络层之间插入小型瓶颈层。adapters 提供了另一种减少特定任务参数的手段，Houlsby等人（2019年）在冻结BERT-Large并只增加2-4%的额外参数时，实现了接近全模型调谐的GLUE性能。Pfeiffer等人（2020年）在一个多语言文本中使用多个适配器，明确地将语言理解与任务规范分开，与我们的方法类似。</p><p>adapters 和 Prompt Tuning 之间的一个核心区别是这些方法如何改变模型行为。</p><p>adapters 通过允许重写任何给定层的激活来修改作用于输入表征的实际函数，该功能由神经网络参数化。</p><p>Prompt Tuning  通过保留固定的函数和增加新的输入表示来修改行为，这些表示会影响后续输入的处理。</p><h2 id="5-Resilience-to-Domain-Shift"><a href="#5-Resilience-to-Domain-Shift" class="headerlink" title="5 Resilience to Domain Shift"></a>5 Resilience to Domain Shift</h2><p><strong>通过冻结核心语言模型参数，prompt tuning可防止模型修改其对语言的一般理解。相反，prompt表示间接调整输入的表示。</strong></p><p><strong>这减少了模型通过记忆特定的词汇线索和虚假的相关关系来 overfit 数据集的能力。</strong>这一限制表明，prompt tuning可能会提高对domain shifts 的稳健性，在这种情况下，输入的分布在训练和评估之间有所不同。</p><p>我们在两个任务上研究了  zero-shot  的领域转移：问题回答（QA）和转述检测（paraphrase detection）。对于问答，使用MRQA 2019关于泛化的共享任务。这项任务以统一的格式收集提取的QA数据集，并测试在 “域内 “数据集上训练的模型在评估 “域外 “数据集时的表现。在我们的实验中，我们在SQuAD上训练，并在每个域外数据集上进行评估。</p><p><img src="https://i.loli.net/2021/11/08/v2mIghVcnt6FCUk.png" alt=""></p><p>作为对结构域转移稳健性的第二个测试，我们探索了来自GLUE的两个释义检测任务之间的迁移。第一个任务是QQP(Iyer等人，2017年)，它询问来自社区问答网站Quora的两个问题是否是“重复的”。</p><p><img src="https://i.loli.net/2021/11/08/odZXCSlN2ceIExk.png" alt=""></p><h2 id="6-Prompt-Ensembling"><a href="#6-Prompt-Ensembling" class="headerlink" title="6 Prompt Ensembling"></a>6 Prompt Ensembling</h2><p><strong>Prompt 集成：</strong>prompt tuning 的另一个好处在于可以在保存一份 LM 模型拷贝情况下，同时训练多个 prompt，并实现集成。作者在 SuperGLUE 上训练了 5 个 prompt，并用多数投票法进行集成，表现优于单一 prompt。</p><p><strong>总结</strong></p><p>Prompt Tuning 的做法是添加可训练的 prefix，同时固定 LM，只训练 prefix，采用 Prompt Tuning 的方式可以在 T5 超大模型和全量数据的情况下，追平 fine-tuning 的效果。</p><p>实验发现采用 prompt tuning 的方式在小模型的情况容易受到 prompt 长度，初始化策略，预训练任务等影响，并不稳定，也没法超过 fine-tuning 的效果。</p><p>作者没有探索少量数据 + 超大模型情况下和 fine-tuning 的效果比较。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;The-Power-of-Scale-for-Parameter-Efficient-Prompt-Tuning&quot;&gt;&lt;a href=&quot;#The-Power-of-Scale-for-Parameter-Efficient-Prompt-Tuning&quot; class=</summary>
      
    
    
    
    
    <category term="context detection" scheme="http://example.com/tags/context-detection/"/>
    
  </entry>
  
</feed>
