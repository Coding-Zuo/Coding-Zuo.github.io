<!DOCTYPE html><html lang="zh-CN" data-theme="dark"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>第五届达观杯——风险事件标签识别比赛复盘 | Coding-Zuo</title><meta name="keywords" content="DataGame"><meta name="author" content="Coding-Zuo"><meta name="copyright" content="Coding-Zuo"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#0d0d0d"><meta name="description" content="第五届达观杯Rank4——风险事件标签识别比赛复盘成绩：A榜第5，B榜第4，最终分数分别为：0.62411600、0.58140504 比赛链接：https:&#x2F;&#x2F;www.datafountain.cn&#x2F;competitions&#x2F;512 代码：https:&#x2F;&#x2F;github.com&#x2F;Coding-Zuo&#x2F;DaguanFengxian 赛题任务这个比赛的全名是叫：基于大规模预训练模型的风险事件标签识别，">
<meta property="og:type" content="article">
<meta property="og:title" content="第五届达观杯——风险事件标签识别比赛复盘">
<meta property="og:url" content="http://example.com/2021/10/01/%E7%AC%AC%E4%BA%94%E5%B1%8A%E8%BE%BE%E8%A7%82%E6%9D%AF%E2%80%94%E2%80%94%E9%A3%8E%E9%99%A9%E4%BA%8B%E4%BB%B6%E6%A0%87%E7%AD%BE%E8%AF%86%E5%88%AB%E6%AF%94%E8%B5%9B%E5%A4%8D%E7%9B%98/index.html">
<meta property="og:site_name" content="Coding-Zuo">
<meta property="og:description" content="第五届达观杯Rank4——风险事件标签识别比赛复盘成绩：A榜第5，B榜第4，最终分数分别为：0.62411600、0.58140504 比赛链接：https:&#x2F;&#x2F;www.datafountain.cn&#x2F;competitions&#x2F;512 代码：https:&#x2F;&#x2F;github.com&#x2F;Coding-Zuo&#x2F;DaguanFengxian 赛题任务这个比赛的全名是叫：基于大规模预训练模型的风险事件标签识别，">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://z3.ax1x.com/2021/10/01/47nQm9.png">
<meta property="article:published_time" content="2021-10-01T07:25:41.000Z">
<meta property="article:modified_time" content="2021-10-03T14:26:03.625Z">
<meta property="article:author" content="Coding-Zuo">
<meta property="article:tag" content="DataGame">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://z3.ax1x.com/2021/10/01/47nQm9.png"><link rel="shortcut icon" href="https://i.loli.net/2021/03/22/reFlcYOnP3dSuJX.png"><link rel="canonical" href="http://example.com/2021/10/01/%E7%AC%AC%E4%BA%94%E5%B1%8A%E8%BE%BE%E8%A7%82%E6%9D%AF%E2%80%94%E2%80%94%E9%A3%8E%E9%99%A9%E4%BA%8B%E4%BB%B6%E6%A0%87%E7%AD%BE%E8%AF%86%E5%88%AB%E6%AF%94%E8%B5%9B%E5%A4%8D%E7%9B%98/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.json","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2021-10-03 22:26:03'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
          const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
          const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
          const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

          if (t === undefined) {
            if (isLightMode) activateLightMode()
            else if (isDarkMode) activateDarkMode()
            else if (isNotSpecified || hasNoSupport) {
              const now = new Date()
              const hour = now.getHours()
              const isNight = hour <= 6 || hour >= 18
              isNight ? activateDarkMode() : activateLightMode()
            }
            window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
              if (saveToLocal.get('theme') === undefined) {
                e.matches ? activateDarkMode() : activateLightMode()
              }
            })
          } else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const fontSizeVal = saveToLocal.get('global-font-size')
    if (fontSizeVal !== undefined) {
      document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
    }
    })(window)</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/sviptzk/HexoStaticFile@latest/Hexo/css/footer.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css"><meta name="generator" content="Hexo 5.3.0"><link rel="alternate" href="/atom.xml" title="Coding-Zuo" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="https://i.loli.net/2021/03/22/YP2oqk7lOAfceTD.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">108</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">16</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https:www.baidu.com"><i class="fa-fw fas fa-heart"></i><span> 我的简历</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 清单</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/%E9%9F%B3%E4%B9%90"><i class="fa-fw /music/"></i><span> 0</span></a></li><li><a class="site-page child" href="/%E7%94%B5%E5%BD%B1"><i class="fa-fw /movies/"></i><span> 1</span></a></li><li><a class="site-page child" href="/%E7%85%A7%E7%89%87"><i class="fa-fw /Gallery/"></i><span> 2</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://z3.ax1x.com/2021/10/01/47nQm9.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Coding-Zuo</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https:www.baidu.com"><i class="fa-fw fas fa-heart"></i><span> 我的简历</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 清单</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/%E9%9F%B3%E4%B9%90"><i class="fa-fw /music/"></i><span> 0</span></a></li><li><a class="site-page child" href="/%E7%94%B5%E5%BD%B1"><i class="fa-fw /movies/"></i><span> 1</span></a></li><li><a class="site-page child" href="/%E7%85%A7%E7%89%87"><i class="fa-fw /Gallery/"></i><span> 2</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">第五届达观杯——风险事件标签识别比赛复盘</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2021-10-01T07:25:41.000Z" title="发表于 2021-10-01 15:25:41">2021-10-01</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2021-10-03T14:26:03.625Z" title="更新于 2021-10-03 22:26:03">2021-10-03</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="第五届达观杯——风险事件标签识别比赛复盘"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="第五届达观杯Rank4——风险事件标签识别比赛复盘"><a href="#第五届达观杯Rank4——风险事件标签识别比赛复盘" class="headerlink" title="第五届达观杯Rank4——风险事件标签识别比赛复盘"></a>第五届达观杯Rank4——风险事件标签识别比赛复盘</h1><p>成绩：A榜第5，B榜第4，最终分数分别为：0.62411600、0.58140504</p>
<p>比赛链接：<a target="_blank" rel="noopener" href="https://www.datafountain.cn/competitions/512">https://www.datafountain.cn/competitions/512</a></p>
<p>代码：<a target="_blank" rel="noopener" href="https://github.com/Coding-Zuo/DaguanFengxian">https://github.com/Coding-Zuo/DaguanFengxian</a></p>
<h2 id="赛题任务"><a href="#赛题任务" class="headerlink" title="赛题任务"></a>赛题任务</h2><p>这个比赛的全名是叫：基于大规模预训练模型的风险事件标签识别，在技术层面上可以提取为两个任务，一个是预训练一个是文本分类。</p>
<p>针对预训练赛题方给了一个70g的无标注预训练文本，训练集有14009条，测试集6004条（包含AB榜数据）</p>
<p>赛题全部为脱敏数据（所有文字都转换成了数字表达）脱敏前的数据样例为：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">资讯文本</th>
<th style="text-align:center">风险事件标签</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">新冠肺炎疫情给美国劳动力市场造成巨大冲击，首次申请失业救济人数已经连续19周超过100万人，约为疫情暴发前平均水平的6倍</td>
<td style="text-align:center">宏观_经济数据下滑</td>
</tr>
<tr>
<td style="text-align:center">石化公司双苯厂发生爆炸事故，造成大量苯类污染物进入江河水体，造成重大环境污染</td>
<td style="text-align:center">事故_生产设施</td>
</tr>
<tr>
<td style="text-align:center">市场监管局执法人员对5家品牌奶茶店进行了检查，发现多家门店存在工作人员健康证不齐全、原材料管理不善等问题</td>
<td style="text-align:center">卫生_食品安全</td>
</tr>
<tr>
<td style="text-align:center">脱敏后</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">210 21048 4210 751252 10 21048 4210 75 125210 21048 4210 75125…..</td>
<td style="text-align:center">1-3</td>
</tr>
</tbody>
</table>
</div>
<p>在标签列可以看到样本有一级和二级标签之分，共有10个一级，35个二级标签。评价指标为macro F1。</p>
<p>我们尝试过一级标签和二级标签的联合预测，效果不好。</p>
<p>标签类别很多而且不平衡，多的类别上千条，少的类别只有十几个：</p>
<p><img src="https://z3.ax1x.com/2021/10/01/47Mv7j.png" alt=""></p>
<p>接下来我将分别从预训练模型、模型结构、提分技巧、模型融合复盘整个比赛过程。</p>
<h2 id="预训练模型"><a href="#预训练模型" class="headerlink" title="预训练模型"></a>预训练模型</h2><p>预训练模型百度网盘地址：链接：<a target="_blank" rel="noopener" href="https://pan.baidu.com/s/1GCs1m6HiXenurGbjUBetFw">https://pan.baidu.com/s/1GCs1m6HiXenurGbjUBetFw</a> 提取码：fxth</p>
<p>对应代码部分：<a target="_blank" rel="noopener" href="https://github.com/Coding-Zuo/DaguanFengxian/tree/main/bert_model/pretrain">https://github.com/Coding-Zuo/DaguanFengxian/tree/main/bert_model/pretrain</a></p>
<p>运行过程 处理数据 process_data —&gt; 构建词表 build_vocab —&gt; run pretrain</p>
<p>我们在无标注数据中根据cosine距离选择了四万条和训练集中样本相似的数据进行预训练。</p>
<p>分别预训练了bert-base模型 nezha-base模型，nezha与bert的区别主要是</p>
<p>nezha相比于google开源中文bert使用了更大的预训练语料，还使用了相对位置编码是一种有效的位置编码方案，全字掩蔽策略，混合精度训练和LAMB优化器。</p>
<p>nezha首次将函数型的相对位置编码加入了模型中。好处：主要是因为它可以使模型外推到比训练中遇到的序列长的序列长度。Bert针对每个位置合并了绝对位置编码，该绝对位置编码是嵌入向量，并且直接添加到token embedding。</p>
<p>我们对每种模型保存不同训练步数的checkpoint，可以用于后面的模型融合。</p>
<p>其实预训练策略可以做很多花样的文章，但由于机器有限，我们将主要的精力放在了微调方面。预训练策略只是遵循mlm和nsp。</p>
<p>我们主要使用过的预训练模型有：</p>
<ul>
<li>Bert-base-wwm-ext : 哈工大开源版本</li>
<li>Nezha-wwm-base: 哪吒官方开源版本</li>
<li>Bert120k: 预训练12万step</li>
<li>Bert150k: 预训练15万step</li>
<li>Bert80k: 预训练8万step</li>
<li>Nezha80k：预训练8万step</li>
<li>Nezha110k：预训练11万step</li>
<li>Nezha150k：预训练15万step</li>
</ul>
<p>最一开始是使用了word2vec在语料库上进行训练，代码：<a target="_blank" rel="noopener" href="https://github.com/Coding-Zuo/DaguanFengxian/tree/main/baseline/src/classic_models/word2vec">https://github.com/Coding-Zuo/DaguanFengxian/tree/main/baseline/src/classic_models/word2vec</a> 线上第一次提交是 48点多分 排了七十多名。</p>
<p>然后开始使用bert等开源的权重，那么问题来了脱敏数据里词都是那样的，bert词表用不了怎么办？</p>
<ul>
<li>统计脱敏数据的词频，将对应词频与开源词表上的词频进行对换 (最开始使用的是这种) 线上可达50分左右</li>
<li>将word2vec训练好的embedding替换到bert上</li>
</ul>
<p>虽然无法还原句子，但频率估计可以还原一部分词，两个频率高的文本，在同一种语境下出现的概率更大，从语义相关性角度来说，可能会有一些语义相关性，改用明文后就可以随便用预训练语言模型了。</p>
<h2 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h2><p>我们最终的模型结构大致是：</p>
<p>Bert  —&gt;  BiLSTM 1层 —&gt; BiGRU 1层 —&gt; bert_pooler + 胶囊网络 —&gt; Multi-Sample Dropout预测输出</p>
<p>同时加BiLSTM和BiGRU大概有接近一个点的提高。胶囊网络有的预训练模型有一点点提高，但有的有负效果。</p>
<p>还尝试过 用 max_pooling + avg_pooling + 胶囊网络 + bert_pooling等组合，效果均不如直接使用bert_pooler和胶囊网络。</p>
<h2 id="提分技巧"><a href="#提分技巧" class="headerlink" title="提分技巧"></a>提分技巧</h2><h3 id="面对不均衡-dice-loss-amp-focal-loss-amp-cross-entropy-loss"><a href="#面对不均衡-dice-loss-amp-focal-loss-amp-cross-entropy-loss" class="headerlink" title="面对不均衡 dice loss &amp; focal loss &amp; cross entropy loss"></a>面对不均衡 dice loss &amp; focal loss &amp; cross entropy loss</h3><p>代码位置：<a target="_blank" rel="noopener" href="https://github.com/Coding-Zuo/DaguanFengxian/tree/main/bert_model/training">https://github.com/Coding-Zuo/DaguanFengxian/tree/main/bert_model/training</a></p>
<p>样本不均衡会带来什么问题呢？</p>
<p>模型训练的本质是最小化损失函数，当某个类别的样本数量非常庞大，损失函数的值大部分被样本数量较大的类别所影响，导致的结果就是模型分类会倾向于样本量较大的类别。</p>
<p>通过类别加权Loss解决, 下图截自香侬科技的论文《Dice Loss for Data-imbalanced NLP Tasks》，分别列举了加权loss，Focal loss（FL）和他们提出的dice loss。我们的实验效果是：FL &lt; Weigth CE &lt; dice loss。所以主要采用了weight ce和dice loss。</p>
<p><img src="https://i.loli.net/2021/09/01/YkHOMIlVSPjG5aw.png" alt=""></p>
<p>Weight CE通过基于类别的加权的方式可以从不同类别的样本数量角度来控制Loss值，从而一定程度上解决了样本不均衡的问题。</p>
<p>基于类别加权Loss虽然在一定程度上解决了样本不均衡的问题，但是实际的情况是不仅样本不均衡会影响Loss，而且样本的难易区分程度也会影响Loss。</p>
<p>何恺明在论文《Focal Loss for Dense Object Detection》中提出了的Focal Loss，上图第三个公式。对于模型预测为正例的样本也就是p&gt;0.5的样本来说，如果样本越容易区分那么(1-p)的部分就会越小，相当于乘了一个系数很小的值使得Loss被缩小，也就是说对于那些比较容易区分的样本Loss会被抑制，同理对于那些比较难区分的样本Loss会被放大，这就是Focal Loss的核心：<strong>通过一个合适的函数来度量简单样本和困难样本对总的损失函数的贡献。</strong></p>
<p>dice loss香侬科技的这篇论文可以参考：<a target="_blank" rel="noopener" href="https://coding-zuo.github.io/2021/09/01/Dice-Loss-for-Data-imbalanced-NLP-Tasks/">Dice Loss for Data-imbalanced NLP Tasks</a></p>
<p>交叉熵“平等”地看待每一个样本，无论正负，都尽力把它们推向1（正例）或0（负例）。但实际上，对分类而言，将一个样本分类为负只需要它的概率＜0.5即可，完全没有必要将它推向0。Dice Loss的自适应损失——DSC，在训练时推动模型更加关注困难的样本，降低简单负例的学习度，从而在整体上提高基于F1值的效果。</p>
<h3 id="对比学习"><a href="#对比学习" class="headerlink" title="对比学习"></a>对比学习</h3><p>代码位置：<a target="_blank" rel="noopener" href="https://github.com/Coding-Zuo/DaguanFengxian/blob/main/bert_model/models/modeling_nezha1.py">https://github.com/Coding-Zuo/DaguanFengxian/blob/main/bert_model/models/modeling_nezha1.py</a></p>
<p>对比损失可以关注判别更困难的样本。</p>
<p>Feature学习是各类深度学习模型的一个基础、重要的功能。好的feature，将有助于文本任务性能的提升。</p>
<p>表示学习的目标是为输入x 学习一个表示 z，那么如何衡量一个表示z 的好坏可以通过互信息的形式；</p>
<p>互信息：代表我们知道了 z 之后 x的信息量减少了多少，</p>
<p>InfoNCE （又称ntxent loss）</p>
<script type="math/tex; mode=display">
L_q = - log\frac{exp(q\cdot k_+ /\tau)}{\sum_{i=0}^K exp(q\cdot k_i / \tau)}</script><p>实质：核心是通过计算样本表示的距离，拉近正样本，拉远负样本</p>
<p>自监督的时候可以自行构造正负样本，那么有监督的时候就可以根据不同的样本标签来构建正负样本。</p>
<p><img src="https://z3.ax1x.com/2021/10/03/4LineI.png" alt=""></p>
<p>最大化相同标签的样本相似度，让不同样本标签的相似度比较小。</p>
<p>参考论文 《Supervised Contrastive Learning》、《SUPERVISED CONTRASTIVE LEARNING FOR PRE-TRAINED LANGUAGE MODEL FINE-TUNING》</p>
<h3 id="对抗训练"><a href="#对抗训练" class="headerlink" title="对抗训练"></a>对抗训练</h3><p>代码位置：<a target="_blank" rel="noopener" href="https://github.com/Coding-Zuo/DaguanFengxian/blob/main/bert_model/training/Adversarial.py">https://github.com/Coding-Zuo/DaguanFengxian/blob/main/bert_model/training/Adversarial.py</a></p>
<p>很多人反映对抗训练没有效果，我最一开始的结果也是这样的。在开源版的nezha和bert上都会降分。</p>
<p>但随着预训练模型越来越多，模型越来越稳定，对抗训练就可以提分了。在预训练后的nezha上基本上是pgd比较好，但比较耗时，在bert上fgm有时会好一点。每个预训练模型的使用效果都不太一样。</p>
<p>我们还尝试了，不仅在bert的word_embedding上做扰动，还在encoder的第0层做扰动，同时随机在某个batch上不扰动，效果相差不多。</p>
<p>在验证集的效果对比：</p>
<ul>
<li>Nezha110k_noAdv: 0.5598</li>
<li>Nezha110k_fgm: 0.5639</li>
<li>Nezha110k_pgd: 0.5687</li>
<li>Bert80k_noAdv: 0.5542</li>
<li>Bert80k_fgm:0.5557</li>
<li>Bert80k_pgd:0.5650</li>
<li>Bert80k_fgm_advEncoder_random:0.5585</li>
<li>Bert80k_pgd_advEncoder_random:0.5684</li>
</ul>
<h3 id="Multi-Exit"><a href="#Multi-Exit" class="headerlink" title="Multi-Exit"></a>Multi-Exit</h3><p>代码位置：<a target="_blank" rel="noopener" href="https://github.com/Coding-Zuo/DaguanFengxian/blob/main/bert_model/models/modeling_bert_pabee.py">https://github.com/Coding-Zuo/DaguanFengxian/blob/main/bert_model/models/modeling_bert_pabee.py</a></p>
<p>Bert 究竟在哪一层做输出会比较好呢？下图是在nezha80k上进行的实验，普遍发现在第layer9，也就是第10层的输出下普遍较好。其实实验下来发现整体效果不好就放弃了，但后来想想可能是因为12层输出联合训练导致的F1值偏低。其实发现第10层可能比较好，就干脆只用第十层的输出计算loss就好。但后来没有继续尝试。</p>
<p><img src="https://z3.ax1x.com/2021/10/03/4qBq9x.png" alt=""></p>
<h3 id="flooding洪泛法"><a href="#flooding洪泛法" class="headerlink" title="flooding洪泛法"></a>flooding洪泛法</h3><p>在最开始使用开源未经预训练的bert进行探索的过程中发现，验证集loss上升，acc也上升。但随着预训练模型的越来越稳定，这种现象就不存在了。</p>
<p><img src="https://z3.ax1x.com/2021/10/03/4qwGKe.png" alt=""></p>
<p>这种现象很常见，原因是过拟合或者训练验证数据分布不一致导致，即在训练后期，预测的结果趋向于极端，使少数预测错的样本主导了loss，但同时少数样本不影响整体的验证acc情况。ICML2020发表了一篇文章：《<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/2002.08709.pdf">Do We Need Zero Training Loss After Achieving Zero Training Error?</a>》，描述了上述现象出现的原因，同时提出了一种flooding策略，通过超参数b控制训练loss不要过小，阻止进一步过拟合，在此情况下，使model”random walk”至一个泛化能力更好的结果，参考 <a target="_blank" rel="noopener" href="https://wmathor.com/index.php/archives/1551/">我们真的需要把训练集的损失降到零吗？</a> 。上图左是加洪泛之前， 上图右是加洪泛之后的，训练集验证集每轮的loss。超参数b的值大概0.2左右小一些。对于模型效果来说，整体影响不大，训练的稍微稳定一点，比赛后期没有再用。</p>
<h3 id="Multi-sample-Dropout"><a href="#Multi-sample-Dropout" class="headerlink" title="Multi-sample Dropout"></a>Multi-sample Dropout</h3><p>代码位置：<a target="_blank" rel="noopener" href="https://github.com/Coding-Zuo/DaguanFengxian/blob/main/bert_model/models/layers.py">https://github.com/Coding-Zuo/DaguanFengxian/blob/main/bert_model/models/layers.py</a></p>
<p>dropout目前是NLP任务中很流行的数据扩充手段。Multi-Sample Dropout是对Dropout方法的一种改进，是2019年的一篇工作。Multi-Sample Dropout相比于dropout加快了模型训练过程的收敛速度和提高了泛化能力。</p>
<p><img src="https://z3.ax1x.com/2021/10/03/4L7NfP.png" alt=""></p>
<p>假设样本经过网络的编码层部分进行编码后得到一个向量表征。这时候，传统的Dropout会对向量表征作用一次，然后输入到分类层进行预测。而Multi-sample Dropout由多个Dropout操作完成。对一个向量表征进行多次dropout后，相当于形成了向量表征的多个版本的。这些不同版本的向量表征通过分类器得到标签的不同概率预测，最终的预测概率分布通过求和或者平均得到。</p>
<p>在比赛的实验中发现，dropout的数量为4，聚合的方式以加和的形式比average效果要好。dropout_rate最开始设为0.4。但后来慢慢发现有时，模型训着训着F1直接变成0了，而且只在bert模型上出现这种问题。找了几天原因发现dropout_rate不能设的太大，改成了0.2。</p>
<h3 id="伪标签"><a href="#伪标签" class="headerlink" title="伪标签"></a>伪标签</h3><p>关于伪标签，我个人认为总体指标达不到八十以上的比赛可能不太好管用。尤其这个赛题还是样本极其不均匀的就更不适合。因为第一，模型预测的把握度不大，根据我们线上59分的模型，预测概率为百分之40以上的测试集数据不到1500条，这在伪标签准确度上带来了不确定性。第二样本不均匀，如果直接把这1500条插入到训练集，可能会破坏训练集的一些分布，造成模型不稳定，学跑偏了。</p>
<p>测试结果：线上58.7的模型，在伪标签上重新训练后是58.3分。</p>
<h2 id="模型融合"><a href="#模型融合" class="headerlink" title="模型融合"></a>模型融合</h2><p>代码位置： <a target="_blank" rel="noopener" href="https://github.com/Coding-Zuo/DaguanFengxian/tree/main/bert_model/ensemble">https://github.com/Coding-Zuo/DaguanFengxian/tree/main/bert_model/ensemble</a></p>
<h3 id="stacking"><a href="#stacking" class="headerlink" title="stacking"></a>stacking</h3><p><img src="https://z3.ax1x.com/2021/10/03/4qrZz6.png" alt=""></p>
<p>跑了四折的四种预训练模型的stacking。最后的第二层预测使用的是xgboost，整体效果没有达到预期，线上得分仅0.5707</p>
<p>四折的四种模型效果如下：</p>
<p><img src="https://z3.ax1x.com/2021/10/03/4qrqOO.png" alt=""></p>
<p>效果不佳的原因可能和拆分四折的数据分布有关，导致单模分数不是很高。由于样本不均衡，原先的拆分方法是针对不同类别有放回的随机取样做五折，随机性比较大，不容易过拟合。</p>
<p>为了让模型凑齐所有训练集的预测特征，且不让数据有重复，我使用了无放回的采样，针对不同类别的样本，按顺序分段提取每折样本，并且根据数据id去了一遍重。 在实验的时候发现不同折的数据分布对模型效果影响还蛮大的。</p>
<h3 id="投票-rank-概率平均"><a href="#投票-rank-概率平均" class="headerlink" title="投票+rank/概率平均"></a>投票+rank/概率平均</h3><p>投票在这次比赛效果非常好。</p>
<p>第一次融七个模型，模型平均分大概五十四五。</p>
<ul>
<li>投票线上结果：0.5809</li>
<li>投票，针对票数相同的结果，选择结果在每个模型的预测rank最靠前的作为结果：0.5852</li>
<li>投票，针对票数相同的结果，选择每个预测结果的概率平均值最大的作为结果：0.5850</li>
<li>根据七个模型的logits选最大的作为预测结果：0.5549</li>
<li>根据预测的概率加和取平均的线上结果：0.5618</li>
</ul>
<p>模型平均分大概57.5分左右</p>
<ul>
<li>投票+rank ：0.6201</li>
</ul>
<p>最后将所有线上得分超过60分的测试集结果再放到一起，再进行投票得到最后的最终成绩：0.6241</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a target="_blank" rel="noopener" href="https://kexue.fm/archives/8213">短文本匹配Baseline：脱敏数据使用预训练模型的尝试</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/823316627bandeng/2021-Daguan-Cup">https://github.com/823316627bandeng/2021-Daguan-Cup</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/412897603/">【2021 第五届“达观杯” 基于大规模预训练模型的风险事件标签识别】1 初赛Rank12的总结与分析</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/u011630575/article/details/81302994">模型融合—— stacking详细讲解</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/141172794?ivk_sa=1024320u">对比学习（Contrastive Learning）</a></p>
</article><div class="post-reward"><div class="reward-button button--animated"><i class="fas fa-qrcode"></i> 打赏</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="https://i.loli.net/2021/03/22/HzNFBbkvZ2QMOKV.jpg" target="_blank"><img class="post-qr-code-img" src="https://i.loli.net/2021/03/22/HzNFBbkvZ2QMOKV.jpg" alt="wechat"/></a><div class="post-qr-code-desc">wechat</div></li><li class="reward-item"><a href="https://i.loli.net/2021/03/22/wMGegPYTAXx9cJo.jpg" target="_blank"><img class="post-qr-code-img" src="https://i.loli.net/2021/03/22/wMGegPYTAXx9cJo.jpg" alt="alipay"/></a><div class="post-qr-code-desc">alipay</div></li></ul></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="gitalk-container"></div></div></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2021/10/02/MeLL-Large-scale-Extensible-User-Intent-Classification-for-Dialogue-Systems-with-Meta-Lifelong-Learning/"><img class="prev-cover" src="https://i.loli.net/2021/10/02/JhPKZISwTXdqLs5.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Large-scale Extensible User Intent Classification for Dialogue Systems with Meta Lifelong Learning</div></div></a></div><div class="next-post pull-right"><a href="/2021/09/30/22-%E6%8B%AC%E5%8F%B7%E7%94%9F%E6%88%90-%E5%9B%9E%E6%BA%AF-%E6%B7%B1%E6%90%9C/"><img class="next-cover" src="https://z3.ax1x.com/2021/09/30/4IKIhT.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">22-括号生成(回溯&amp;深搜)</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span> 相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2021/01/29/16080066587381/" title="天池赛题:天猫重复购学习笔记(我的EDA模板)"><img class="cover" src="https://images6.alphacoders.com/977/thumbbig-977917.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-01-29</div><div class="title">天池赛题:天猫重复购学习笔记(我的EDA模板)</div></div></a></div><div><a href="/2021/04/15/Kaggle上传dataset的方法/" title="Kaggle上传dataset的方法"><img class="cover" src="https://i.loli.net/2021/04/15/p6FQI8tvTfmR3XE.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-04-15</div><div class="title">Kaggle上传dataset的方法</div></div></a></div><div><a href="/2021/03/27/Pytorch多GPU并行实例/" title="Pytorch多GPU并行实例"><img class="cover" src="https://i.loli.net/2021/03/27/bBWz3dgpP2AIHGJ.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-03-27</div><div class="title">Pytorch多GPU并行实例</div></div></a></div><div><a href="/2021/05/01/海华阅读理解比赛复盘/" title="海华阅读理解比赛复盘"><img class="cover" src="https://i.loli.net/2021/05/01/dizZGI2DktTPlJj.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-05-01</div><div class="title">海华阅读理解比赛复盘</div></div></a></div><div><a href="/2021/04/06/海华中文阅读理解比赛梳理-多卡并行-transformers/" title="海华中文阅读理解比赛梳理/多卡并行/transformers"><img class="cover" src="https://i.loli.net/2021/04/06/BLiKPmD6Mwve1FQ.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-04-06</div><div class="title">海华中文阅读理解比赛梳理/多卡并行/transformers</div></div></a></div></div></div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Coding-Zuo</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2021/10/01/%E7%AC%AC%E4%BA%94%E5%B1%8A%E8%BE%BE%E8%A7%82%E6%9D%AF%E2%80%94%E2%80%94%E9%A3%8E%E9%99%A9%E4%BA%8B%E4%BB%B6%E6%A0%87%E7%AD%BE%E8%AF%86%E5%88%AB%E6%AF%94%E8%B5%9B%E5%A4%8D%E7%9B%98/">http://example.com/2021/10/01/%E7%AC%AC%E4%BA%94%E5%B1%8A%E8%BE%BE%E8%A7%82%E6%9D%AF%E2%80%94%E2%80%94%E9%A3%8E%E9%99%A9%E4%BA%8B%E4%BB%B6%E6%A0%87%E7%AD%BE%E8%AF%86%E5%88%AB%E6%AF%94%E8%B5%9B%E5%A4%8D%E7%9B%98/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://example.com" target="_blank">Coding-Zuo</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/DataGame/">DataGame</a></div><div class="post_share"><div class="addthis_inline_share_toolbox"></div><script src="//s7.addthis.com/js/300/addthis_widget.js#pubid=null" async="async"></script></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E4%BA%94%E5%B1%8A%E8%BE%BE%E8%A7%82%E6%9D%AFRank4%E2%80%94%E2%80%94%E9%A3%8E%E9%99%A9%E4%BA%8B%E4%BB%B6%E6%A0%87%E7%AD%BE%E8%AF%86%E5%88%AB%E6%AF%94%E8%B5%9B%E5%A4%8D%E7%9B%98"><span class="toc-number">1.</span> <span class="toc-text">第五届达观杯Rank4——风险事件标签识别比赛复盘</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%B5%9B%E9%A2%98%E4%BB%BB%E5%8A%A1"><span class="toc-number">1.1.</span> <span class="toc-text">赛题任务</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.2.</span> <span class="toc-text">预训练模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84"><span class="toc-number">1.3.</span> <span class="toc-text">模型结构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8F%90%E5%88%86%E6%8A%80%E5%B7%A7"><span class="toc-number">1.4.</span> <span class="toc-text">提分技巧</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9D%A2%E5%AF%B9%E4%B8%8D%E5%9D%87%E8%A1%A1-dice-loss-amp-focal-loss-amp-cross-entropy-loss"><span class="toc-number">1.4.1.</span> <span class="toc-text">面对不均衡 dice loss &amp; focal loss &amp; cross entropy loss</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0"><span class="toc-number">1.4.2.</span> <span class="toc-text">对比学习</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AF%B9%E6%8A%97%E8%AE%AD%E7%BB%83"><span class="toc-number">1.4.3.</span> <span class="toc-text">对抗训练</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Multi-Exit"><span class="toc-number">1.4.4.</span> <span class="toc-text">Multi-Exit</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#flooding%E6%B4%AA%E6%B3%9B%E6%B3%95"><span class="toc-number">1.4.5.</span> <span class="toc-text">flooding洪泛法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Multi-sample-Dropout"><span class="toc-number">1.4.6.</span> <span class="toc-text">Multi-sample Dropout</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BC%AA%E6%A0%87%E7%AD%BE"><span class="toc-number">1.4.7.</span> <span class="toc-text">伪标签</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E8%9E%8D%E5%90%88"><span class="toc-number">1.5.</span> <span class="toc-text">模型融合</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#stacking"><span class="toc-number">1.5.1.</span> <span class="toc-text">stacking</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8A%95%E7%A5%A8-rank-%E6%A6%82%E7%8E%87%E5%B9%B3%E5%9D%87"><span class="toc-number">1.5.2.</span> <span class="toc-text">投票+rank&#x2F;概率平均</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%82%E8%80%83"><span class="toc-number">1.6.</span> <span class="toc-text">参考</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2021 By Coding-Zuo</div><div class="footer_custom_text">Hi, welcome to my BLOG</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font-plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    loader: {
      source: {
        '[tex]/amsCd': '[tex]/amscd'
      }
    },
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        addClass: [200,() => {
          document.querySelectorAll('mjx-container:not([display=\'true\']').forEach( node => {
            const target = node.parentNode
            if (!target.classList.contains('has-jax')) {
              target.classList.add('mathjax-overflow')
            }
          })
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><script>if (document.getElementsByClassName('mermaid').length) {
  if (window.mermaidJsLoad) mermaid.init()
  else {
    getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(() => {
      window.mermaidJsLoad = true
      mermaid.initialize({
        theme: 'default',
      })
      false && mermaid.init()
    })
  }
}</script><script>function addGitalkSource () {
  const ele = document.createElement('link')
  ele.rel = 'stylesheet'
  ele.href= 'https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css'
  document.getElementsByTagName('head')[0].appendChild(ele)
}

function loadGitalk () {
  function initGitalk () {
    var gitalk = new Gitalk(Object.assign({
      clientID: 'd652112bf81876e00118',
      clientSecret: 'a5abed418c7cc2736af5b4d0cbd7ff97d460a5b3',
      repo: 'Coding-Zuo.github.io',
      owner: 'Coding-Zuo',
      admin: ['Coding-Zuo'],
      id: '82f87fefdfb5f8d9b6311920db43cd93',
      language: 'zh-CN',
      perPage: 10,
      distractionFreeMode: false,
      pagerDirection: 'last',
      createIssueManually: false,
      updateCountCallback: commentCount
    },null))

    gitalk.render('gitalk-container')
  }

  if (typeof Gitalk === 'function') initGitalk()
  else {
    addGitalkSource()
    getScript('https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.js').then(initGitalk)
  }
}

function commentCount(n){
  let isCommentCount = document.querySelector('#post-meta .gitalk-comment-count')
  if (isCommentCount) {
    isCommentCount.innerHTML= n
  }
}

if ('Gitalk' === 'Gitalk' || !true) {
  if (true) btf.loadComment(document.getElementById('gitalk-container'), loadGitalk)
  else loadGitalk()
} else {
  function loadOtherComment () {
    loadGitalk()
  }
}</script></div><script src="/js/custom.js"></script><script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script><script defer="defer" id="fluttering_ribbon" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-fluttering-ribbon.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script src="//code.tidio.co/mak6nokafytw9mgrsuzglwzfxiy3fpdl.js" async="async"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>