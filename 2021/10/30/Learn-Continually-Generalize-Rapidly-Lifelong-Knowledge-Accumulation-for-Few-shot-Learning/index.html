<!DOCTYPE html><html lang="zh-CN" data-theme="dark"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Learn Continually, Generalize Rapidly, Lifelong Knowledge Accumulation for Few-shot Learning | Coding-Zuo</title><meta name="keywords" content="context detection"><meta name="author" content="Coding-Zuo"><meta name="copyright" content="Coding-Zuo"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#0d0d0d"><meta name="description" content="Learn Continually, Generalize Rapidly: Lifelong Knowledge Accumulation for Few-shot Learning随着时间的推移不断扩展知识，并利用这些知识迅速归纳到新的任务中，这是人类语言智能的一个关键特征。 现有的追求快速泛化到新任务的模型（如few-shot learning），大多是在固定的数据集上进行单次训练，无法动态">
<meta property="og:type" content="article">
<meta property="og:title" content="Learn Continually, Generalize Rapidly, Lifelong Knowledge Accumulation for Few-shot Learning">
<meta property="og:url" content="http://example.com/2021/10/30/Learn-Continually-Generalize-Rapidly-Lifelong-Knowledge-Accumulation-for-Few-shot-Learning/index.html">
<meta property="og:site_name" content="Coding-Zuo">
<meta property="og:description" content="Learn Continually, Generalize Rapidly: Lifelong Knowledge Accumulation for Few-shot Learning随着时间的推移不断扩展知识，并利用这些知识迅速归纳到新的任务中，这是人类语言智能的一个关键特征。 现有的追求快速泛化到新任务的模型（如few-shot learning），大多是在固定的数据集上进行单次训练，无法动态">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://i.loli.net/2021/10/30/L9XTOjA4csqBRMt.png">
<meta property="article:published_time" content="2021-10-30T03:32:36.000Z">
<meta property="article:modified_time" content="2022-01-04T06:35:17.744Z">
<meta property="article:author" content="Coding-Zuo">
<meta property="article:tag" content="context detection">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.loli.net/2021/10/30/L9XTOjA4csqBRMt.png"><link rel="shortcut icon" href="https://i.loli.net/2021/03/22/reFlcYOnP3dSuJX.png"><link rel="canonical" href="http://example.com/2021/10/30/Learn-Continually-Generalize-Rapidly-Lifelong-Knowledge-Accumulation-for-Few-shot-Learning/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.json","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-01-04 14:35:17'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
          const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
          const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
          const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

          if (t === undefined) {
            if (isLightMode) activateLightMode()
            else if (isDarkMode) activateDarkMode()
            else if (isNotSpecified || hasNoSupport) {
              const now = new Date()
              const hour = now.getHours()
              const isNight = hour <= 6 || hour >= 18
              isNight ? activateDarkMode() : activateLightMode()
            }
            window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
              if (saveToLocal.get('theme') === undefined) {
                e.matches ? activateDarkMode() : activateLightMode()
              }
            })
          } else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const fontSizeVal = saveToLocal.get('global-font-size')
    if (fontSizeVal !== undefined) {
      document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
    }
    })(window)</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/sviptzk/HexoStaticFile@latest/Hexo/css/footer.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css"><meta name="generator" content="Hexo 5.3.0"><link rel="alternate" href="/atom.xml" title="Coding-Zuo" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="https://i.loli.net/2021/03/22/YP2oqk7lOAfceTD.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">136</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">17</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https:www.baidu.com"><i class="fa-fw fas fa-heart"></i><span> 我的简历</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 清单</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/%E9%9F%B3%E4%B9%90"><i class="fa-fw /music/"></i><span> 0</span></a></li><li><a class="site-page child" href="/%E7%94%B5%E5%BD%B1"><i class="fa-fw /movies/"></i><span> 1</span></a></li><li><a class="site-page child" href="/%E7%85%A7%E7%89%87"><i class="fa-fw /Gallery/"></i><span> 2</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://i.loli.net/2021/10/30/L9XTOjA4csqBRMt.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Coding-Zuo</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https:www.baidu.com"><i class="fa-fw fas fa-heart"></i><span> 我的简历</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 清单</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/%E9%9F%B3%E4%B9%90"><i class="fa-fw /music/"></i><span> 0</span></a></li><li><a class="site-page child" href="/%E7%94%B5%E5%BD%B1"><i class="fa-fw /movies/"></i><span> 1</span></a></li><li><a class="site-page child" href="/%E7%85%A7%E7%89%87"><i class="fa-fw /Gallery/"></i><span> 2</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Learn Continually, Generalize Rapidly, Lifelong Knowledge Accumulation for Few-shot Learning</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2021-10-30T03:32:36.000Z" title="发表于 2021-10-30 11:32:36">2021-10-30</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-01-04T06:35:17.744Z" title="更新于 2022-01-04 14:35:17">2022-01-04</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Learn Continually, Generalize Rapidly, Lifelong Knowledge Accumulation for Few-shot Learning"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="Learn-Continually-Generalize-Rapidly-Lifelong-Knowledge-Accumulation-for-Few-shot-Learning"><a href="#Learn-Continually-Generalize-Rapidly-Lifelong-Knowledge-Accumulation-for-Few-shot-Learning" class="headerlink" title="Learn Continually, Generalize Rapidly: Lifelong Knowledge Accumulation for Few-shot Learning"></a>Learn Continually, Generalize Rapidly: Lifelong Knowledge Accumulation for Few-shot Learning</h1><p>随着时间的推移不断扩展知识，并利用这些知识迅速归纳到新的任务中，这是人类语言智能的一个关键特征。</p>
<p>现有的追求快速泛化到新任务的模型（如few-shot learning），大多是在固定的数据集上进行单次训练，无法动态地扩展其知识；而持续学习算法则不是专门为快速泛化设计的。</p>
<p>作者提出了一个新的学习设置，即 “ Continual Learning of Few-Shot Learners”（CLIF），以在一个统一的设置中解决这两种学习设置的挑战。</p>
<p>CLIF假设一个模型从一连串不同的NLP任务中依次学习，积累知识以提高对新任务的概括能力，同时也保留了之前学习的任务的性能。</p>
<p>本文研究了在持续学习设置中泛化能力是如何受到影响的，评估了一些持续学习算法，并提出了一种新颖的<strong>带有正则化的Adapter的双级超网络</strong>。</p>
<p><img src="https://i.loli.net/2021/10/30/3o5X2RKGhSDivAP.png" alt=""></p>
<p>挑战：模型在一连串的NLP任务中学习（逐一到达；不重复访问），然后在以下方面进行评估：（1）对新的（few-shot learning）任务的泛化；以及（2）保留其在解决已见任务上的性能。</p>
<blockquote>
<p>作者认为此类任务与LifeLong的区别:</p>
<p>此任务研究了NLP模型是否可以在一连串的任务中不断积累可归纳的知识，并迅速学习归纳到新的任务。</p>
<p>相关的工作是希望从连续到达的任务中学习，被称为持续学习（CL），主要关注的是当模型在新任务中被持续更新时，保留在所见任务中的表现。在后续的分析中，发现，现有的大多数CL方法几乎不利于模型的泛化能力，即使它们被证明可以缓解灾难性遗忘。</p>
</blockquote>
<hr>
<h2 id="Problem-Formulation"><a href="#Problem-Formulation" class="headerlink" title="Problem Formulation"></a>Problem Formulation</h2><h3 id="The-CLIF-Problem"><a href="#The-CLIF-Problem" class="headerlink" title="The CLIF Problem"></a>The CLIF Problem</h3><p>我们假设有一个NLP模型 $f$ 随着时间的推移在不同的任务上不断地训练（即持续学习），然后通过少量的例子迅速概括到许多未见过的任务（即few-shot适应）</p>
<p>在持续学习阶段，模型遇到一个有序的 $N_u$ 上游任务列表 : $[T_u^1,…,T^{N_u}_u]$ ，其中每个任务有自己的训练集和测试集。</p>
<p>为了测试连续选了的模型 $f$ 的 few-shot 学习能力，在一组单独的 $N<em>v$ 少量任务 ${T_v^i}</em>{i=1}^{N_v} $ 上对其进行adapt ，其中每个未见的任务只有几个训练样本。</p>
<p>在CLIF中，除了传统的CL目标是保持在所见任务上的性能外，在CLIF中，保持可概括的知识以在训练结束时获得更好的few-shot learning性能也是至关重要的。 </p>
<h3 id="Evaluation-Protocol"><a href="#Evaluation-Protocol" class="headerlink" title="Evaluation Protocol"></a>Evaluation Protocol</h3><p>如图所示，针对CLIF设置评估方法有三个主要方面：few-shot性能、最终性能和即时性能。</p>
<p><img src="https://i.loli.net/2021/10/30/b2W3lNhOngXmQv9.png" alt=""></p>
<ul>
<li><em>Few-shot Performance</em>: 首先，在一组未见过的任务上评估持续训练的模型 $f$,  在上游任务 $T^1<em>u,…,T_u^{N_u}$ 训练结束后，用几个标注的样本对每个任务 $T_v^i$ 进行微调。因此，我们可以评估 few-shot 的泛化能力。把一个任务 $T_v^i$ 的 few-shot accuracy 记为 $s</em>{FS}^i = F(Y<em>v^i, \hat Y_v^i)$, 其中 $\hat Y_v^i$ 是对任务 $T</em>{v}^i$ 的测试样本进行预测， $Y<em>v^i$ 是真实标签。$F$ 是度量函数如accuracy。 记录所有few-shot 任务，例如：$s</em>{FS}= \frac{1}{N<em>v} \sum</em>{i=1}^{N<em>v} s</em>{FS}^i$ 。 还计算了在每个 few-shot 任务上单独训练的模型的相对改进 $\Delta_{FS}$</li>
<li><em>Instant Performance</em> : 在模型完成对上游任务 $T<em>u^i$ 的学习后，立即评估其性能，在模型$f$ 将任务 $j$ 学习为 $\hat Y</em>{u}^{i,j}$ 之后，记录在任务 $T<em>u^i$ 的测试集上的预测。 Instant performance 在任务 $T_u^i$ 上被定义为 $s</em>{inst.}^i = F(Y<em>u^i,\hat Y_u^{i,i})$ 。例如，模型 $f$ 在 $T_u^1$ 和 $T_u^2 $ 的数据上训练之后，在 $T_u^3$ 上进一步训练之前评估 $f$ 在 $T_u^2$ 上的性能。因此，$f$ 在 $T_u^2 $ 上的表现可以告诉我们，模型将其知识从学习 $T_u^1 $ 转移到学习 $T_u^2 $  的情况 —— 使用 $f$ 仅只在 $T_u^2 $ 上训练时的表现作为参考。我们计算所有上游任务的 Instant performance，$s</em>{inst.} = \frac {1}{N<em>u} \sum</em>{i=1}^{N<em>u} s</em>{inst.}^i $  ，此外还计算了相对于在每个上游任务上单独训练的改进 $\Delta_{inst.}$， 以表明上游学习的好处。</li>
<li><em>Final Performance</em> ：评估 $f$ 在对上游任务的持续学习结束时的表现，以了解模型 $f$ 在学习解决更多任务后对任务知识的遗忘程度。一个任务 $T<em>u^i $ 的最终 accuracy 被定义为 $F(Y_u^i,\hat Y_u^{i,N_u})$ 。同样地，我们报告了所有任务的平均最终准确度，记为 $s</em>{final} = \frac{1}{N} \sum<em>{i=1}^{N_u} s</em>{final}^i$。遗忘可以被量化为 $s<em>{inst} - s</em>{final}$ 。</li>
</ul>
<h3 id="Challenges"><a href="#Challenges" class="headerlink" title="Challenges"></a>Challenges</h3><p>CLIF 的设置对现有的 few-shot learning 方法来首特别具有挑战，大多数 few-shot 学习方法假定所有任务的上游数据集总是可用的，并且没有按时序去学习。因此，上游的任务可以在多任务学习的环境下共同学习。然而，CLIF问题采用的是持续学习的设置，即任务是按顺序访问的，没有重新访问。因此，依靠从任务分布中随机抽样的方法并不适用。</p>
<h3 id="Tasks-and-Data-Streams"><a href="#Tasks-and-Data-Streams" class="headerlink" title="Tasks and Data Streams"></a>Tasks and Data Streams</h3><p>为了将CLIF挑战推向一个更实际的设置，考虑了一组多样化的NLP任务来进行CL和few-shot learning。我们考虑了两个数据集的组合，被称为CLIF-26和CLIF-55任务：</p>
<p><img src="https://i.loli.net/2021/10/30/kdeHY4IvltMXyBw.png" alt=""></p>
<p>将CLIF-26中每个GLUE任务中的训练样本数量限制在10,000个，以避免数据集过度失衡。对于CLIF-55，每类使用90个样本进行连续学习。</p>
<p>在CLIF-26和CLIF-55的 few-shot 学习任务中，如果没有指定的话，每类使用 k=16 个样本，并在实验中包括更多的 k 的设置。由于GLUE的测试标签没有公开，仅报告了验证集的性能。</p>
<hr>
<h2 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h2><p>首先介绍我们研究中的 baseline。然后，我们介绍一些现有的持续学习和持续元学习的方法。最后，提出了一个新颖的正则化双级适配器生成框架，以更好地解决CLIF问题。</p>
<h3 id="Base-NLP-Models"><a href="#Base-NLP-Models" class="headerlink" title="Base NLP Models"></a>Base NLP Models</h3><h4 id="BART-and-BART-Adapter"><a href="#BART-and-BART-Adapter" class="headerlink" title="BART and BART-Adapter"></a>BART and BART-Adapter</h4><p>由于将CLIF问题中的NLP任务制定为统一的文本到文本格式，我们使用预先训练好的语言模型（LM）作为模型f的架构，并在训练期间对整个模型进行微调。</p>
<p>我们还包括Adapter训练，作为对整个BART模型进行微调的一种改变。这里，适配器是插在BART每层之后的两层MLPs。</p>
<p>给出 transformer的第 $l$ 层的输出 $h_l$ , adapter的输出被计算为 $h_l’ = h_l + f_l^a(h_l)$， 其中 $f_l^a$ 是在 $l$ 层的adapter。只有adapter在训练中被学习，BART模型被frozen。</p>
<h4 id="Hyper-Networks-for-Adapter-Generation"><a href="#Hyper-Networks-for-Adapter-Generation" class="headerlink" title="Hyper-Networks for Adapter Generation"></a>Hyper-Networks for Adapter Generation</h4><p>除了BART和BART适配器之外，还使用考虑HyperNetwork（HNet）架构。HyperNetwork 记为 $g$ ，将任务表示 $z$ 作为输入，并生成另一个预测模型的模型参数，记为 $f$ 来解决该任务。在 few-shot learning 中，$z$ 通常被计算为任务的训练实例的平均表示，即 任务的平均表示: $z = \frac{1}{|D<em>{tr}^i|} \sum</em>{(x<em>j,y_j)\in D</em>{tr}^i} f<em>e(x_j, y_j) $ ，其中 $D</em>{tr}^i$ 是任务 $T^i$ 的训练集，$f_e$ 是encoder。</p>
<p>我们使用一个BART编码器作为 $f_e$，并将 $x$ 和标签 $y$ 的文本格式串联起来，得到任务表示 $z$。</p>
<h3 id="Baseline-Learning-Algorithms"><a href="#Baseline-Learning-Algorithms" class="headerlink" title="Baseline Learning Algorithms"></a>Baseline Learning Algorithms</h3><h4 id="Single-Task-Learning"><a href="#Single-Task-Learning" class="headerlink" title="Single Task Learning"></a>Single Task Learning</h4><p>为了了解基础模型在没有任何知识转移的情况下对上游任务的参考性能，应用了单一任务学习（STL）方法，该方法在每个任务的数据集上单独地训练和测试模型 $f$。</p>
<p>在这种情况下，我们忽略了CLIF问题的顺序性，所以我们可以用这个STL的性能来评估不同的持续方法（下面介绍）的有效性。理想情况下，<strong>一个有效的 CL 算法应该具有比 STL 结果更好的几率准确性，这意味着它积累了并有效地迁移了知识，用于学习。</strong></p>
<p>同样地，<strong>为了了解 few-shot 任务的参考性能，我们在没有任何上游训练的情况下，为每个 few-shot 任务学习一个模型 $f$ ，这样我们就可以用这种性能来评估CLIF方法对泛化能力的改善程度。</strong></p>
<h4 id="Continual-Learning-Algorithms"><a href="#Continual-Learning-Algorithms" class="headerlink" title="Continual Learning Algorithms"></a>Continual Learning Algorithms</h4><p>作为一种简单的基线方法，我们使用 Vanilla 表示简单地在上游任务上按顺序训练模型 $f$。</p>
<p>具体来说，它在 $T_u^i$ 上训练模型 $f$，直到其性能收敛，然后在 $T_u^{i+1}$ 的数据上不断训练 $f$。</p>
<p>请注意，CL 中不允许访问先前任务的数据，还考虑在实验中考虑 CL 算法，例如 EWC、MbPA++和 meta-MbPA。</p>
<p>EWC 正则化了训练过程中重要模型参数的变化，MbPA++ 方法对存储在内存中的几个训练样本执行测试 test-time 调整。 meta-MbPA 方法包括快速适应元学习目标。</p>
<h4 id="Hyper-Networks-for-CL"><a href="#Hyper-Networks-for-CL" class="headerlink" title="Hyper-Networks for CL"></a>Hyper-Networks for CL</h4><p>《Continual learning with hypernetworks》 提出了 hypernetwork-based continual learning。其中减轻灾难性遗忘的高级想法是惩罚超网络在其学习新任务时为先前任务生成的模型权重的改变。虽然原始工作生成模型的整个参数，但我们仅通过生成适配器的权重来使其适应 PTLMs。 将这种方法记为 HNet-Reg。</p>
<p>具体来说，当模型刚刚完成学习任务 $T<em>{u}^{i-1}$ 并且在持续学习阶段学习任务 $T_u^i$ 之前，我们存储当前超网络为所有先前任务 $T_u^1…T_u^{i=1}$ 生成的适配器权重，记为 ${\hat\theta_1^{i-1},\hat\theta_2^{i-1},…,\hat\theta</em>{i-1}^{i-1}}$ ，其中生成是通过超网络 $h$ 应用于先前任务 $1,..,{i-1}$ 的存储任务表示来控制的，记为 $M = {z_h^1,…,z_h^{i-1}}$ 。在这里，任务 $T_u^i$ 的任务表示 $z_i$ 在学习任务之前随机初始化，并在学习任务时联合优化。</p>
<p>然后，在学习 $T_u^i$  的每一步中，我们随机抽样一个先验任务 $T_u^j \ \ (j &lt; i)$ 来规范超网络学习。 它惩罚在当前步骤 $\theta_j$ 生成的适配器权重与预先计算的权重之间的 $l_2$ 距离，例如 $||\theta_j-\hat \theta_j^{i-1}||_2^2$</p>
<p>因此，避免了超网络 g 在持续学习阶段过多地改变其先前任务的输出，从而更好地保证学习模型的知识积累。</p>
<h4 id="Limitations"><a href="#Limitations" class="headerlink" title="Limitations"></a>Limitations</h4><p>EWC 和 HNET-Reg 不是为 CLIF 问题精心设计的，CLIF还试图在持续学习后改进对未知任务的 few-shot 泛化。 虽然 MbPA 和 meta-MbPA 中的 test-time 适应可能有利于 few-shot learning，但这些工作并未研究这种能力。 此外，由于这两种算法存储了先前训练任务的真实数据，因此不适用于无法再访问来自早期任务的数据的隐私敏感应用，这是持续学习中的典型场景。</p>
<h3 id="Our-Extension-Bi-level-Hypernetworks-for-Adapters-with-Regularization"><a href="#Our-Extension-Bi-level-Hypernetworks-for-Adapters-with-Regularization" class="headerlink" title="Our Extension: Bi-level Hypernetworks for Adapters with Regularization"></a>Our Extension: Bi-level Hypernetworks for Adapters with Regularization</h3><p>受用于 few-shot 和 CL的超网络方法的启发，我们将基于超网络的CL方法扩展到CLIF。我们提出了一种新的方法，即带有正则化的双级超网络Adapters（BiHNet+Reg），该方法学习使用双级任务表示来生成Adapters权重，以便在一连串的任务中学习快速适应模型，同时通过正则化来减轻遗忘效应。</p>
<p>方法由三个组件组成：</p>
<p><img src="https://i.loli.net/2021/10/30/usniAeI3GEyHXL7.png" alt=""></p>
<ul>
<li>Context Predictor 上下文预测器，从训练实例中生成双级任务表征（即高资源和few-shot表征）</li>
<li>Adapter-Wise Hypernetworks 超网络，根据任务表征生成适配器的权重；</li>
<li>Regularization 正则化项，阻止所见任务的权重变化以避免遗忘</li>
</ul>
<h4 id="Context-Predictor"><a href="#Context-Predictor" class="headerlink" title="Context Predictor"></a>Context Predictor</h4><p>为每个任务 $t$ 生成两个任务表征，分别在高资源和 few-shot 的情况下为其建模，表示为 $z_h^t$ 和 $z_f^t$，用frozne BART编码器。高资源表征用于鼓励持续学习过程中的知识转移；few-shot 任务表征帮助我们在 few-shot learning 模仿 few-shot任务，以获得更好的泛化，类似于元学习。</p>
<p>然后，高资源任务表示被计算为任务 $t$ 中所有样本的上下文向量的平均值。 记为：$z<em>h^t = \frac{1}{|D_t|} \sum</em>{(x_i,y_i)\in D_t} R(x_i, y_i)$</p>
<p>然而，few-shot 任务表示 $z<em>f^t$ 使用有限数量 K 个采样样本 $z_f^t = \frac{1}{k} \sum</em>{(x<em>i,y_i)\in \Tau(D_t, K)} R(x_i, y_i)$， 其中$\Tau(D_t,K)$ 是在 $D_t$ 中采样K 个样本。请注意，在不断的学习过程中，上游任务的高资源表征被长期储存在一个记忆模块中，$M={z_h^t| t\in {\Tau_u^i}</em>{i=1}^{N_u}}$ 。在few-shot的学习阶段，我们设定 K为给定的样本的数量，因此对于任何任务，$z_h=z_f$。</p>
<h4 id="Adapter-Wise-Hypernetworks"><a href="#Adapter-Wise-Hypernetworks" class="headerlink" title="Adapter-Wise Hypernetworks"></a>Adapter-Wise Hypernetworks</h4><p>使用超网络 $g$ 来生成frozen BART模型 $f$ 的各层之间的适配器的权重。</p>
<p>在训练过程中，使用高资源和采样的任务表征 $z_h^t$ 和 $z_f^t$ 来产生适配器权重 分别记为 $\theta_t^h$ 和 $\theta_t^f$。我们对这两个适配器的预测损失进行了优化。</p>
<h4 id="Regularization"><a href="#Regularization" class="headerlink" title="Regularization"></a>Regularization</h4><p>HyperNetwork是模型中唯一可训练的部分，对生成的适配器施加正则化以减轻遗忘。</p>
<p>虽然 BiHNet 被训练为从高资源和低资源任务表示生成适配器，但发现仅存储和正则化来自高资源任务表示的输出就足够了。</p>
<h4 id="Summary-and-Highlights"><a href="#Summary-and-Highlights" class="headerlink" title="Summary and Highlights"></a>Summary and Highlights</h4><p>总而言之，提出的方法首先生成了双级任务表征，用于训练具有正则化项的适配超网络，以避免随时间推移而遗忘。</p>
<p>与基于重放记忆的CL方法（例如MbPA）不同，我们的方法不存储任何真实的训练实例。相反，它使用任务表示来存储记忆，因此允许该方法应用于对隐私敏感的场景中。</p>
<hr>
<h2 id="Results-and-Analysis"><a href="#Results-and-Analysis" class="headerlink" title="Results and Analysis"></a>Results and Analysis</h2><p>在本节中，将讨论两个主要研究问题：</p>
<ul>
<li>考虑到潜在的灾难性遗忘，与离线设置相比，模型如何在CL设置中长期积累可推广的知识？</li>
<li>持续学习的方法是否能减少对所见任务的表现和可归纳知识的灾难性遗忘。</li>
</ul>
<p>作者在试验了各种模型架构的组合和学习算法。通过其模型结构和应用的CL算法来说明一种方法，例如BART-Vanilla, BiHNet-EWC。</p>
<p><img src="https://i.loli.net/2021/10/30/M9NOlJoS64AYhGy.png" alt=""></p>
<h3 id="Examining-Knowledge-Accumulation"><a href="#Examining-Knowledge-Accumulation" class="headerlink" title="Examining Knowledge Accumulation"></a>Examining Knowledge Accumulation</h3><p>在这一节中，提出了对模型在离线和CL设置中获得可归纳知识的能力的分析。</p>
<p>我们注意到BiHNet方法，对应于学习生成适配器，应与BiHNet-Single和BART-Adapter-Single进行比较，后者是零知识基线，其学习生成或从随机初始化中学习适配器；</p>
<p>同样，BART方法应与BART-Single进行比较。重点是确定CLIF的挑战，并将方法论的讨论留在下一小节。</p>
<h4 id="问题1：来自上游任务的知识是否有助于模型在在线学习和持续学习设置中的few-shot泛化？"><a href="#问题1：来自上游任务的知识是否有助于模型在在线学习和持续学习设置中的few-shot泛化？" class="headerlink" title="问题1：来自上游任务的知识是否有助于模型在在线学习和持续学习设置中的few-shot泛化？"></a>问题1：来自上游任务的知识是否有助于模型在在线学习和持续学习设置中的few-shot泛化？</h4><p>看表2，在CLIF-26和CLIF-55数据集上，我们看到BiHNet-MTL在 few-shot 情况下的表现比零知识基线要好0.4%和1.0%，这意味着在标准的离线学习设置中，上游任务对few-shot 情况下的泛化有帮助。</p>
<p>对于BART模型，我们注意到BART-MTL在Clif-55数据集上比BART-Single提高了2.5%。然而，我们注意到CLIF-26的情况正好相反。鉴于在这些模型中整个BART参数都被优化了，我们假设BART-MTL可能受到了预训练的BART模型本身的知识遗忘的影响；而在适配器和BiHNet模型中，BART模型被冻结了。</p>
<p>因此，在本节的其余部分，我们更关注 侧重于BiHNet方法。</p>
<h4 id="问题2：模型的泛化能力是如何随时间变化的？"><a href="#问题2：模型的泛化能力是如何随时间变化的？" class="headerlink" title="问题2：模型的泛化能力是如何随时间变化的？"></a>问题2：模型的泛化能力是如何随时间变化的？</h4><p><img src="https://i.loli.net/2021/10/30/GJhbKFcu3sAHVYj.png" alt=""></p>
<p>我们专注于BiHNet-Vanilla和BART-Vanilla方法，并回答三个子问题。</p>
<ul>
<li><p><strong>知识是否在上游任务中被单调地积累？</strong>与两个零知识基线相比，我们注意到BiHNet-Vanilla普遍提高了即时准确率（在CLIF-26上为6.5%，在CLIF-55上为8.9%）和少数次准确率（在CLIF-55上为0.8%），但在CLIF-26上的few-shot准确率除外（-0.4%）。这些结果在一定程度上证实了积极的知识积累。在图4中，我们绘制了模型依次访问每个上游训练任务时在CLIF-26上的few-shot精度。我们注意到BiHNet-Vanilla的几率并没有单调地增加，这意味着这些上游学习任务之间的干扰或对可概括的知识的遗忘。</p>
</li>
<li><p><strong>任务的顺序是否重要？</strong>图5显示了在CLIF-26上不同任务顺序下的方法性能。我们通过增加和减少与few-shot学习任务的相关性来排列任务，其中相关性被定义为模型从单一上游任务转移时的few-shot准确性。结果显示，在这两个顺序中，BiHNet-Vanilla的竞争力都不如BART- Adapter-Single。这意味着在持续学习中，如果没有CL算法，知识积累就不那么稳健。</p>
<p><img src="https://i.loli.net/2021/11/29/og8kGxFzUNDpP7H.png" alt=""></p>
</li>
</ul>
<h4 id="问题3：模型的灾难性遗忘是否阻碍了其知识积累？"><a href="#问题3：模型的灾难性遗忘是否阻碍了其知识积累？" class="headerlink" title="问题3：模型的灾难性遗忘是否阻碍了其知识积累？"></a>问题3：模型的灾难性遗忘是否阻碍了其知识积累？</h4><p>在表2中，我们看到Vanilla和MTL方法的最终准确率之间存在明显的差异（大约20分），这验证了当训练实例不是i.i.d.时对所见任务性能的灾难性遗忘。然而，我们发现MTL和Vanilla训练之间的差距对于 few-shot 学习性能是接近的，其中BART-Vanilla甚至比BART-MTL更好，这可能是充分遗忘缓解过拟合的一个积极结果（王等人，2020）。<strong>这表明灾难性遗忘对泛化能力的影响与它对所见任务表现的影响相比</strong>，程度较小。</p>
<h3 id="Effect-of-Continual-Learning-Algorithms"><a href="#Effect-of-Continual-Learning-Algorithms" class="headerlink" title="Effect of Continual Learning Algorithms"></a>Effect of Continual Learning Algorithms</h3><p>有了对前面问题的认识，我们现在分析基线持续学习算法和所提出的方法是否有助于知识积累和提高模型的（few-shot）f泛化能力。</p>
<h4 id="问题1：持续学习算法能缓解灾难性遗忘吗？"><a href="#问题1：持续学习算法能缓解灾难性遗忘吗？" class="headerlink" title="问题1：持续学习算法能缓解灾难性遗忘吗？"></a>问题1：持续学习算法能缓解灾难性遗忘吗？</h4><p> 从表2中，我们注意到MbPA++、meta-MbPA、EWC在CLIF-26上明显比 BART-Vanilla 或 BiHNetVanilla 提高了最终准确率，这证实了对缓解灾难性遗忘的积极作用。 在CLIF-55上，其特点是训练任务更多，每个任务的样本更少，我们发现基线CL算法未能提高最终的准确性。对于基于记忆的方法，如MbPA++和meta-MbPA，这可能是因为对存储的例子有明显的过度拟合。相比之下，BiHNet-Reg在两个数据集中都很有效。</p>
<h4 id="问题2：缓解灾难性遗忘能更好地保留泛化能力吗？"><a href="#问题2：缓解灾难性遗忘能更好地保留泛化能力吗？" class="headerlink" title="问题2：缓解灾难性遗忘能更好地保留泛化能力吗？"></a>问题2：缓解灾难性遗忘能更好地保留泛化能力吗？</h4><p>通过比较BiHNet-Vanilla和BiHNet-Reg的 few-shot 准确性，我们发现在两个数据集上，few-shot 准确性和即时准确性分别提高了1.9%和4.2%。从图5中，我们看到BiHNet-Reg在默认的和递减的相关性顺序中优于BiHNet-Vanilla；而我们观察到BiHNet-Reg在递增的相关性顺序中出现了异常。从图4中，我们看到随着BiHNet-Reg学习更多的上游任务，few-shot的学习精度提高得更加稳定。</p>
<h4 id="问题3：BiHNet-REG比HNet-REG有改进吗？"><a href="#问题3：BiHNet-REG比HNet-REG有改进吗？" class="headerlink" title="问题3：BiHNet-REG比HNet-REG有改进吗？"></a>问题3：BiHNet-REG比HNet-REG有改进吗？</h4><p>BiHNet-Reg与HNet-Reg（Oswald等人，2020）的主要区别是：（1）few-shot 任务表征；（2）用上下文预测器推断任务表征，而不是将其作为可训练的嵌入学习。作为一项消融研究，我们逐步替换掉BiHNet中的两个组件，如表3所示。我们看到，在两个数据集上，去掉 few-shot 任务表示会导致 few-shot 准确率下降1.08和0.33个点；而用可训练的任务嵌入取代上下文预测器会导致最终准确率明显下降10个点以上。我们注意到，在CLIF-26上，可训练的em-beddings的几率略高1.5分，但在CLIF-55上则低了2.3分，因为它有更多的上游训练任务。</p>
<p><img src="https://i.loli.net/2021/11/29/qG7y1uslxtZdrNM.png" alt=""></p>
<h4 id="问题4：敏感度分析：模型如何在不同数量的few-shot训练样本下执行。"><a href="#问题4：敏感度分析：模型如何在不同数量的few-shot训练样本下执行。" class="headerlink" title="问题4：敏感度分析：模型如何在不同数量的few-shot训练样本下执行。"></a>问题4：敏感度分析：模型如何在不同数量的few-shot训练样本下执行。</h4><p>图6总结了不同方法在CLIF-26上每类不同数量的训练实例下的几率表现。我们观察到BiHNet-Reg总是能达到最好的性能，而且当训练集较小时，改进更为显著。</p>
<p><img src="https://i.loli.net/2021/11/29/IhUeVGqH96WvJRQ.png" alt=""></p>
<p>讨论。我们的研究结果表明，与类似的适配器学习框架（BiHNet-Single和BART-Adapter-Single）相比，BiHNet-Reg可以有效地提高知识积累的时间。然而，BiHNet-Reg并不能与BART-Single的几次学习准确性相媲美。我们认为这是由于适配器的模型容量有限，与整个transformer的微调相比。这为改进与PTLM微调兼容的持续学习算法开辟了未来的工作。</p>
<h2 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h2><h3 id="Continual-Learning"><a href="#Continual-Learning" class="headerlink" title="Continual Learning"></a>Continual Learning</h3><p>CL文献中涉及的主要挑战是克服解决灾难性的遗忘。一般来说，现有的持续学习方法包括基于记忆和生成重放的方法（Robins，1995；Lopez-Paz和Ranzato，2017；Shin等人，2017）、基于正则化的方法（Kirkpatrick等人，2017；Nguyen等人，2018）和基于模型扩展的方法（Shin等人，2017）。最近，持续学习在NLP领域引起了关注（Sun等人，2020；Wang等人，2019b；Huang等人，2021）。</p>
<h3 id="Continual-Meta-Learning"><a href="#Continual-Meta-Learning" class="headerlink" title="Continual Meta Learning"></a>Continual Meta Learning</h3><p>有文献研究了NLP应用之外的持续元学习，对问题有各种定义。</p>
<p>一些前期工作目的是开发一种算法，当早期任务的少数训练实例在测试时再次可用时，可以快速恢复以前的性能。</p>
<p>Caccia等人（2020）提出了一种设置，即模型访问一连串可能重新出现的任务，并测量在线累积性能作为衡量标准。Antoniou等人（2020）假设模型访问了一连串的  few-shot 照片的分类任务，而测试任务由训练时看到的类组成。Jerfel等人（2019）的问题设置与我们的问题设置最为相关，我们的问题设置可以更好地在新任务上进行  few-shot 照片的学习，但只针对图像分类任务进行研究，任务数量少得多。据我们所知，我们的工作是第一个研究在不同的NLP任务中对大规模转化器模型进行少数次学习的持续知识积累。</p>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>我们提出了 “少数学习者的持续学习”（CLIF）挑战，以模拟学习者在一连串的NLP任务中不断积累（可归纳的）知识，同时保持其在所见任务中的表现的情景。我们提出了评估协议来研究现有的持续学习算法的性能，并介绍了我们的方法BiHNet-Reg。我们展示了建立一个NLP系统的潜力，该系统通过持续的训练，可以完成更多的任务，并且在掌握新任务方面变得更有效率。未来的工作包括将我们的工作扩展到数据分布可能不断变化的任务无关的场景，以及研究用新出现的数据不断完善大规模预训练模型的算法。</p>
</article><div class="post-reward"><div class="reward-button button--animated"><i class="fas fa-qrcode"></i> 打赏</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="https://i.loli.net/2021/03/22/HzNFBbkvZ2QMOKV.jpg" target="_blank"><img class="post-qr-code-img" src="https://i.loli.net/2021/03/22/HzNFBbkvZ2QMOKV.jpg" alt="wechat"/></a><div class="post-qr-code-desc">wechat</div></li><li class="reward-item"><a href="https://i.loli.net/2021/03/22/wMGegPYTAXx9cJo.jpg" target="_blank"><img class="post-qr-code-img" src="https://i.loli.net/2021/03/22/wMGegPYTAXx9cJo.jpg" alt="alipay"/></a><div class="post-qr-code-desc">alipay</div></li></ul></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="gitalk-container"></div></div></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2021/11/03/A-Survey-on-Natural-Language-Processing-for-Fake-News-Detection/"><img class="prev-cover" src="https://i.loli.net/2021/11/03/TydEsXVebj85QWm.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">谣言、虚假信息综述</div></div></a></div><div class="next-post pull-right"><a href="/2021/10/28/Pattern-Exploiting-Training-PET/"><img class="next-cover" src="https://i.loli.net/2021/10/28/DjK6qxmT9cA7Ov3.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Pattern Exploiting Training (PET)</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span> 相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2022/02/21/ZeroPrompt-Scaling-Prompt-Based-Pretraining-to-1-000-Tasks-Improves-Zero-Shot-Generalization/" title="ZeroPrompt- Scaling Prompt-Based Pretraining to 1,000 Tasks Improves Zero-Shot Generalization"><img class="cover" src="https://s4.ax1x.com/2022/02/21/HXcFxA.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-02-21</div><div class="title">ZeroPrompt- Scaling Prompt-Based Pretraining to 1,000 Tasks Improves Zero-Shot Generalization</div></div></a></div><div><a href="/2022/02/10/Prompt-Guided-Few-Shot-Event-Detection/" title="Prompt-Guided Few-Shot Event Detection"><img class="cover" src="https://i.loli.net/2021/10/28/DjK6qxmT9cA7Ov3.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-02-10</div><div class="title">Prompt-Guided Few-Shot Event Detection</div></div></a></div><div><a href="/2022/02/10/MetaPrompting-Learning-to-Learn-Better-Prompts/" title="MetaPrompting: Learning to Learn Better Prompts"><img class="cover" src="https://s4.ax1x.com/2022/01/22/7fJ3lV.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-02-10</div><div class="title">MetaPrompting: Learning to Learn Better Prompts</div></div></a></div><div><a href="/2022/01/04/Exploring-Low-dimensional-Intrinsic-Task-Subspace-via-Prompt-Tuning/" title="Exploring Low-dimensional Intrinsic Task Subspace via Prompt Tuning"><img class="cover" src="https://i.loli.net/2021/08/29/7pyGPBNQZRmv3Tr.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-01-04</div><div class="title">Exploring Low-dimensional Intrinsic Task Subspace via Prompt Tuning</div></div></a></div><div><a href="/2021/12/27/Unsupervised-Domain-Adaptation-of-a-Pretrained-Cross-Lingual-Language-Model/" title="Unsupervised Domain Adaptation of a Pretrained Cross-Lingual Language Model"><img class="cover" src="https://i.loli.net/2021/11/17/hMK8qF4Jne6sTYC.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-12-27</div><div class="title">Unsupervised Domain Adaptation of a Pretrained Cross-Lingual Language Model</div></div></a></div><div><a href="/2021/12/22/Contrastive-Representation-Distillation/" title="Contrastive Representation Distillation"><img class="cover" src="https://s2.loli.net/2021/12/22/aCcIO7GKrPo5DV3.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-12-22</div><div class="title">Contrastive Representation Distillation</div></div></a></div></div></div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Coding-Zuo</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2021/10/30/Learn-Continually-Generalize-Rapidly-Lifelong-Knowledge-Accumulation-for-Few-shot-Learning/">http://example.com/2021/10/30/Learn-Continually-Generalize-Rapidly-Lifelong-Knowledge-Accumulation-for-Few-shot-Learning/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://example.com" target="_blank">Coding-Zuo</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/context-detection/">context detection</a></div><div class="post_share"><div class="addthis_inline_share_toolbox"></div><script src="//s7.addthis.com/js/300/addthis_widget.js#pubid=null" async="async"></script></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Learn-Continually-Generalize-Rapidly-Lifelong-Knowledge-Accumulation-for-Few-shot-Learning"><span class="toc-number">1.</span> <span class="toc-text">Learn Continually, Generalize Rapidly: Lifelong Knowledge Accumulation for Few-shot Learning</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Problem-Formulation"><span class="toc-number">1.1.</span> <span class="toc-text">Problem Formulation</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#The-CLIF-Problem"><span class="toc-number">1.1.1.</span> <span class="toc-text">The CLIF Problem</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Evaluation-Protocol"><span class="toc-number">1.1.2.</span> <span class="toc-text">Evaluation Protocol</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Challenges"><span class="toc-number">1.1.3.</span> <span class="toc-text">Challenges</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Tasks-and-Data-Streams"><span class="toc-number">1.1.4.</span> <span class="toc-text">Tasks and Data Streams</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Method"><span class="toc-number">1.2.</span> <span class="toc-text">Method</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Base-NLP-Models"><span class="toc-number">1.2.1.</span> <span class="toc-text">Base NLP Models</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#BART-and-BART-Adapter"><span class="toc-number">1.2.1.1.</span> <span class="toc-text">BART and BART-Adapter</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Hyper-Networks-for-Adapter-Generation"><span class="toc-number">1.2.1.2.</span> <span class="toc-text">Hyper-Networks for Adapter Generation</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Baseline-Learning-Algorithms"><span class="toc-number">1.2.2.</span> <span class="toc-text">Baseline Learning Algorithms</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Single-Task-Learning"><span class="toc-number">1.2.2.1.</span> <span class="toc-text">Single Task Learning</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Continual-Learning-Algorithms"><span class="toc-number">1.2.2.2.</span> <span class="toc-text">Continual Learning Algorithms</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Hyper-Networks-for-CL"><span class="toc-number">1.2.2.3.</span> <span class="toc-text">Hyper-Networks for CL</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Limitations"><span class="toc-number">1.2.2.4.</span> <span class="toc-text">Limitations</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Our-Extension-Bi-level-Hypernetworks-for-Adapters-with-Regularization"><span class="toc-number">1.2.3.</span> <span class="toc-text">Our Extension: Bi-level Hypernetworks for Adapters with Regularization</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Context-Predictor"><span class="toc-number">1.2.3.1.</span> <span class="toc-text">Context Predictor</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Adapter-Wise-Hypernetworks"><span class="toc-number">1.2.3.2.</span> <span class="toc-text">Adapter-Wise Hypernetworks</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Regularization"><span class="toc-number">1.2.3.3.</span> <span class="toc-text">Regularization</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Summary-and-Highlights"><span class="toc-number">1.2.3.4.</span> <span class="toc-text">Summary and Highlights</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Results-and-Analysis"><span class="toc-number">1.3.</span> <span class="toc-text">Results and Analysis</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Examining-Knowledge-Accumulation"><span class="toc-number">1.3.1.</span> <span class="toc-text">Examining Knowledge Accumulation</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%97%AE%E9%A2%981%EF%BC%9A%E6%9D%A5%E8%87%AA%E4%B8%8A%E6%B8%B8%E4%BB%BB%E5%8A%A1%E7%9A%84%E7%9F%A5%E8%AF%86%E6%98%AF%E5%90%A6%E6%9C%89%E5%8A%A9%E4%BA%8E%E6%A8%A1%E5%9E%8B%E5%9C%A8%E5%9C%A8%E7%BA%BF%E5%AD%A6%E4%B9%A0%E5%92%8C%E6%8C%81%E7%BB%AD%E5%AD%A6%E4%B9%A0%E8%AE%BE%E7%BD%AE%E4%B8%AD%E7%9A%84few-shot%E6%B3%9B%E5%8C%96%EF%BC%9F"><span class="toc-number">1.3.1.1.</span> <span class="toc-text">问题1：来自上游任务的知识是否有助于模型在在线学习和持续学习设置中的few-shot泛化？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%97%AE%E9%A2%982%EF%BC%9A%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%B3%9B%E5%8C%96%E8%83%BD%E5%8A%9B%E6%98%AF%E5%A6%82%E4%BD%95%E9%9A%8F%E6%97%B6%E9%97%B4%E5%8F%98%E5%8C%96%E7%9A%84%EF%BC%9F"><span class="toc-number">1.3.1.2.</span> <span class="toc-text">问题2：模型的泛化能力是如何随时间变化的？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%97%AE%E9%A2%983%EF%BC%9A%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%81%BE%E9%9A%BE%E6%80%A7%E9%81%97%E5%BF%98%E6%98%AF%E5%90%A6%E9%98%BB%E7%A2%8D%E4%BA%86%E5%85%B6%E7%9F%A5%E8%AF%86%E7%A7%AF%E7%B4%AF%EF%BC%9F"><span class="toc-number">1.3.1.3.</span> <span class="toc-text">问题3：模型的灾难性遗忘是否阻碍了其知识积累？</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Effect-of-Continual-Learning-Algorithms"><span class="toc-number">1.3.2.</span> <span class="toc-text">Effect of Continual Learning Algorithms</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%97%AE%E9%A2%981%EF%BC%9A%E6%8C%81%E7%BB%AD%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E8%83%BD%E7%BC%93%E8%A7%A3%E7%81%BE%E9%9A%BE%E6%80%A7%E9%81%97%E5%BF%98%E5%90%97%EF%BC%9F"><span class="toc-number">1.3.2.1.</span> <span class="toc-text">问题1：持续学习算法能缓解灾难性遗忘吗？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%97%AE%E9%A2%982%EF%BC%9A%E7%BC%93%E8%A7%A3%E7%81%BE%E9%9A%BE%E6%80%A7%E9%81%97%E5%BF%98%E8%83%BD%E6%9B%B4%E5%A5%BD%E5%9C%B0%E4%BF%9D%E7%95%99%E6%B3%9B%E5%8C%96%E8%83%BD%E5%8A%9B%E5%90%97%EF%BC%9F"><span class="toc-number">1.3.2.2.</span> <span class="toc-text">问题2：缓解灾难性遗忘能更好地保留泛化能力吗？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%97%AE%E9%A2%983%EF%BC%9ABiHNet-REG%E6%AF%94HNet-REG%E6%9C%89%E6%94%B9%E8%BF%9B%E5%90%97%EF%BC%9F"><span class="toc-number">1.3.2.3.</span> <span class="toc-text">问题3：BiHNet-REG比HNet-REG有改进吗？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%97%AE%E9%A2%984%EF%BC%9A%E6%95%8F%E6%84%9F%E5%BA%A6%E5%88%86%E6%9E%90%EF%BC%9A%E6%A8%A1%E5%9E%8B%E5%A6%82%E4%BD%95%E5%9C%A8%E4%B8%8D%E5%90%8C%E6%95%B0%E9%87%8F%E7%9A%84few-shot%E8%AE%AD%E7%BB%83%E6%A0%B7%E6%9C%AC%E4%B8%8B%E6%89%A7%E8%A1%8C%E3%80%82"><span class="toc-number">1.3.2.4.</span> <span class="toc-text">问题4：敏感度分析：模型如何在不同数量的few-shot训练样本下执行。</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Related-Work"><span class="toc-number">1.4.</span> <span class="toc-text">Related Work</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Continual-Learning"><span class="toc-number">1.4.1.</span> <span class="toc-text">Continual Learning</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Continual-Meta-Learning"><span class="toc-number">1.4.2.</span> <span class="toc-text">Continual Meta Learning</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Conclusion"><span class="toc-number">1.5.</span> <span class="toc-text">Conclusion</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2022 By Coding-Zuo</div><div class="footer_custom_text">Hi, welcome to my BLOG</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font-plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    loader: {
      source: {
        '[tex]/amsCd': '[tex]/amscd'
      }
    },
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        addClass: [200,() => {
          document.querySelectorAll('mjx-container:not([display=\'true\']').forEach( node => {
            const target = node.parentNode
            if (!target.classList.contains('has-jax')) {
              target.classList.add('mathjax-overflow')
            }
          })
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><script>if (document.getElementsByClassName('mermaid').length) {
  if (window.mermaidJsLoad) mermaid.init()
  else {
    getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(() => {
      window.mermaidJsLoad = true
      mermaid.initialize({
        theme: 'default',
      })
      false && mermaid.init()
    })
  }
}</script><script>function addGitalkSource () {
  const ele = document.createElement('link')
  ele.rel = 'stylesheet'
  ele.href= 'https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css'
  document.getElementsByTagName('head')[0].appendChild(ele)
}

function loadGitalk () {
  function initGitalk () {
    var gitalk = new Gitalk(Object.assign({
      clientID: 'd652112bf81876e00118',
      clientSecret: 'a5abed418c7cc2736af5b4d0cbd7ff97d460a5b3',
      repo: 'Coding-Zuo.github.io',
      owner: 'Coding-Zuo',
      admin: ['Coding-Zuo'],
      id: 'd5919355bdaea4d64eaf7442dfd7e5ba',
      language: 'zh-CN',
      perPage: 10,
      distractionFreeMode: false,
      pagerDirection: 'last',
      createIssueManually: false,
      updateCountCallback: commentCount
    },null))

    gitalk.render('gitalk-container')
  }

  if (typeof Gitalk === 'function') initGitalk()
  else {
    addGitalkSource()
    getScript('https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.js').then(initGitalk)
  }
}

function commentCount(n){
  let isCommentCount = document.querySelector('#post-meta .gitalk-comment-count')
  if (isCommentCount) {
    isCommentCount.innerHTML= n
  }
}

if ('Gitalk' === 'Gitalk' || !true) {
  if (true) btf.loadComment(document.getElementById('gitalk-container'), loadGitalk)
  else loadGitalk()
} else {
  function loadOtherComment () {
    loadGitalk()
  }
}</script></div><script src="/js/custom.js"></script><script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script><script defer="defer" id="fluttering_ribbon" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-fluttering-ribbon.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script src="//code.tidio.co/mak6nokafytw9mgrsuzglwzfxiy3fpdl.js" async="async"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>