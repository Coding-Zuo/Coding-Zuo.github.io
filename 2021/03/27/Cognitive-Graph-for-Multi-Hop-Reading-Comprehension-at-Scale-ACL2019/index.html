<!DOCTYPE html><html lang="zh-CN" data-theme="dark"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Cognitive Graph for Multi-Hop Reading Comprehension at Scale(ACL2019) | Coding-Zuo</title><meta name="keywords" content="GNN&amp;nlp"><meta name="author" content="Coding-Zuo"><meta name="copyright" content="Coding-Zuo"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#0d0d0d"><meta name="description" content="Cognitive Graph for Multi-Hop Reading Comprehension at Scale(ACL2019)ppt : https:&#x2F;&#x2F;coding-zuo.github.io&#x2F;CogQA_RevealJS&#x2F;  认知图谱知识图谱+认知推理+逻辑表达。认知图谱依据人类认知的双加工理论，动态构建带有上下文信息的知识图谱并进行推理。认知图谱可以被解释为“基于原始文本数据，针">
<meta property="og:type" content="article">
<meta property="og:title" content="Cognitive Graph for Multi-Hop Reading Comprehension at Scale(ACL2019)">
<meta property="og:url" content="http://example.com/2021/03/27/Cognitive-Graph-for-Multi-Hop-Reading-Comprehension-at-Scale-ACL2019/index.html">
<meta property="og:site_name" content="Coding-Zuo">
<meta property="og:description" content="Cognitive Graph for Multi-Hop Reading Comprehension at Scale(ACL2019)ppt : https:&#x2F;&#x2F;coding-zuo.github.io&#x2F;CogQA_RevealJS&#x2F;  认知图谱知识图谱+认知推理+逻辑表达。认知图谱依据人类认知的双加工理论，动态构建带有上下文信息的知识图谱并进行推理。认知图谱可以被解释为“基于原始文本数据，针">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://i.loli.net/2021/03/27/548YCMeHJnoBtDZ.png">
<meta property="article:published_time" content="2021-03-27T14:27:38.000Z">
<meta property="article:modified_time" content="2021-04-18T16:04:47.000Z">
<meta property="article:author" content="Coding-Zuo">
<meta property="article:tag" content="GNN&amp;nlp">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.loli.net/2021/03/27/548YCMeHJnoBtDZ.png"><link rel="shortcut icon" href="https://i.loli.net/2021/03/22/reFlcYOnP3dSuJX.png"><link rel="canonical" href="http://example.com/2021/03/27/Cognitive-Graph-for-Multi-Hop-Reading-Comprehension-at-Scale-ACL2019/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.json","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2021-04-19 00:04:47'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
          const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
          const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
          const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

          if (t === undefined) {
            if (isLightMode) activateLightMode()
            else if (isDarkMode) activateDarkMode()
            else if (isNotSpecified || hasNoSupport) {
              const now = new Date()
              const hour = now.getHours()
              const isNight = hour <= 6 || hour >= 18
              isNight ? activateDarkMode() : activateLightMode()
            }
            window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
              if (saveToLocal.get('theme') === undefined) {
                e.matches ? activateDarkMode() : activateLightMode()
              }
            })
          } else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const fontSizeVal = saveToLocal.get('global-font-size')
    if (fontSizeVal !== undefined) {
      document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
    }
    })(window)</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/sviptzk/HexoStaticFile@latest/Hexo/css/footer.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css"><meta name="generator" content="Hexo 5.3.0"><link rel="alternate" href="/atom.xml" title="Coding-Zuo" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="https://i.loli.net/2021/03/22/YP2oqk7lOAfceTD.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">116</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">16</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https:www.baidu.com"><i class="fa-fw fas fa-heart"></i><span> 我的简历</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 清单</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/%E9%9F%B3%E4%B9%90"><i class="fa-fw /music/"></i><span> 0</span></a></li><li><a class="site-page child" href="/%E7%94%B5%E5%BD%B1"><i class="fa-fw /movies/"></i><span> 1</span></a></li><li><a class="site-page child" href="/%E7%85%A7%E7%89%87"><i class="fa-fw /Gallery/"></i><span> 2</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://i.loli.net/2021/03/27/548YCMeHJnoBtDZ.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Coding-Zuo</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https:www.baidu.com"><i class="fa-fw fas fa-heart"></i><span> 我的简历</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 清单</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/%E9%9F%B3%E4%B9%90"><i class="fa-fw /music/"></i><span> 0</span></a></li><li><a class="site-page child" href="/%E7%94%B5%E5%BD%B1"><i class="fa-fw /movies/"></i><span> 1</span></a></li><li><a class="site-page child" href="/%E7%85%A7%E7%89%87"><i class="fa-fw /Gallery/"></i><span> 2</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Cognitive Graph for Multi-Hop Reading Comprehension at Scale(ACL2019)</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2021-03-27T14:27:38.000Z" title="发表于 2021-03-27 22:27:38">2021-03-27</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2021-04-18T16:04:47.000Z" title="更新于 2021-04-19 00:04:47">2021-04-19</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Cognitive Graph for Multi-Hop Reading Comprehension at Scale(ACL2019)"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="Cognitive-Graph-for-Multi-Hop-Reading-Comprehension-at-Scale-ACL2019"><a href="#Cognitive-Graph-for-Multi-Hop-Reading-Comprehension-at-Scale-ACL2019" class="headerlink" title="Cognitive Graph for Multi-Hop Reading Comprehension at Scale(ACL2019)"></a>Cognitive Graph for Multi-Hop Reading Comprehension at Scale(ACL2019)</h1><p>ppt : <a target="_blank" rel="noopener" href="https://coding-zuo.github.io/CogQA_RevealJS/">https://coding-zuo.github.io/CogQA_RevealJS/</a> </p>
<h2 id="认知图谱"><a href="#认知图谱" class="headerlink" title="认知图谱"></a>认知图谱</h2><p>知识图谱+认知推理+逻辑表达。<br>认知图谱依据人类认知的双加工理论，动态构建带有上下文信息的知识图谱并进行推理。<br>认知图谱可以被解释为“基于原始文本数据，针对特定问题情境，使用强大的机器学习模型动态构建的，节点带有上下文语义信息的知识图谱”。</p>
<p><strong>认知图谱和知识图谱的区别？</strong><br>认知图谱是包含知识图谱的相关技术的。知识图谱的任务主要是包括知识图谱的表示、构建和存储。这些是构建知识库的过程。认知推理的底层是知识推理，而知识图谱目的是完善知识。面向知识图谱的认知推理可以基于已有的知识推理出新的知识，或者发现错误矛盾的知识。认知图谱是为了解决复杂理解问题或少样本知识图谱推理问题如歧义问题、链接困难、关系的冗余与组合爆炸等。认知推理其实更具有人脑特性，相对更动态一些，可以基于知识感知来调整推理，也可以基于推理来调整知识和感知。交叉了认知科学对人类知识的总结，有助于划分和处理知识图谱的相关问题。</p>
<p>认知图谱主要有三方面创新，分别对应人类认知智能的三个方面：</p>
<p>1.（长期记忆）直接存储带索引的文本数据，使用信息检索算法代替知识图谱的显式边来访问相关知识。</p>
<p>2.（系统1推理）图谱依据查询动态、多步构建，实体节点通过相关实体识别模型产生。</p>
<p>3.（系统2推理）图中节点产生的同时拥有上下文信息的隐表示，可通过图神经网络等模型进行可解释的关系推理。</p>
<p>本质上，认知图谱的改进思路是减少图谱构建时的信息损失(两元一谓)，将信息处理压力转移给检索和自然语言理解算法，同时保留图结构进行可解释关系推理。</p>
<p><img src="https://i.loli.net/2021/03/27/2mdSVkFas3NlWhQ.png" alt=""></p>
<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><ul>
<li>提出新的多跳QA框架CogQA</li>
<li>基于双过程理论System1:隐式提取，System2:显式推理</li>
<li>可以给出答案的解释路径</li>
<li>基于Bert和GNN处理HotpotQA数据集</li>
<li>评估指标F1 score</li>
</ul>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>现在的单段阅读理解机器已经超过人了，像SQuAD。但要跨过机器阅读理解和人阅读理解的鸿沟还很难。</p>
<p>主要有三个主要挑战：</p>
<ul>
<li>理解能力：如对抗性测试所揭示的那样，单段问答模型倾向于在与问题匹配的意义中寻找答案，这不涉及复杂的推理。因此多跳阅读是要克服的。</li>
<li>可解释性：显式推理路径能够验证逻辑严格性，对质量保证系统的可靠性至关重要。数据集中给出的是无序的句子级别的解释，但我们人可以通过逻辑一步一步给出有序的、实体级别的解释。</li>
<li>大规模的(时间成本)：任何QA系统都要处理大规模的知识。现在已有的DrQA是通过预检索来减少规模到几个段落的范围。这个框架是单段阅读和多段阅读的结合，但和人脑中大量记忆和知识而言是一种折中的做法。时间成本不会随着段落增加而增加。</li>
</ul>
<h3 id="两个系统的工作"><a href="#两个系统的工作" class="headerlink" title="两个系统的工作"></a>两个系统的工作</h3><p><strong>隐式提取System1</strong>：模仿大脑通过隐式注意提取相关信息，是直觉和无意识的系统。<br>从段落中提取与问题相关的实体和答案日期，并对其语义信息进行编码。</p>
<p><img src="https://i.loli.net/2021/03/27/jY967V5RuPvpgm8.jpg" alt=""></p>
<p>如上图，系统一从段落和语义信息中提取问题相关的实体和答案候选。</p>
<p><strong>显式推理System2</strong>：在System1基础上进行有意识的的可控的推理。</p>
<p>系统一根据提出的问题提供给系统二资源，系统二根据信息进行深度推理，挖掘相关信息。两个系统协作，迭代的给出快慢思考。</p>
<p>在信息一提出出的信息图上，搜集线索。并且指导系统一更好的提取下一跳实体。</p>
<p>迭代直到所有可能的答案都被找到，再由系统二推理出最终答案。</p>
<p><img src="https://i.loli.net/2021/03/27/lO9sy8hDARqk3uI.jpg" alt=""></p>
<p><code>系统1(system 1)负责经验性的直觉判断，这一黑盒过程提取重要信息，并动态构建认知图谱；系统2(system 2)则在图上进行关系推理，由于认知图谱保留了实体节点上语义信息的隐表示，所以在符号逻辑之外，比如图神经网络等深度学习模型也可以大显身手。</code></p>
<p><img src="https://i.loli.net/2021/03/27/SPXlQ4nOkLcpARH.jpg" alt=""></p>
<p>这块有一个缺点，GCN在有节点新加入的时候要重新训练图模型？这个要等我研究研究源码</p>
<p>前沿节点(frontier node)有两种:</p>
<ul>
<li>新添加的节点</li>
<li>图中新添加边的节点(需重新访问)</li>
</ul>
<p>系统1在线索和问题Q的指导下读取para[x]，提取跨度并生成语义向量sem[x，Q，clues]。同时，系统2更新隐藏表示X，并为任何后继节点y准备线索clues[y，G]。基于X进行最终预测。</p>
<p>算法流程<br>1.提取在问题Q中提到的实体作为认知图的初始化，并且标记为前沿节点。<br>2.重复下面过程直到21(在每一步中，我们访问一个前沿节点x)<br>3.从前沿节点中跳出一个节点x<br>4.从前沿节点收集线索clues[x,G],例如线索可以是提及x的句子。(线索句可以是提到的x的句子)<br>5.在词库W中找到包含x的段落para[x]<br>6.system1生成语义向量sem[x,Q,clues],初始化X[x]<br>7.如果x是一个hop节点<br>8.system1在para[x]中找到hop和answer的局部<br>9.遍历hop内容，每个内容为y<br>10.如果内容y不在G内并且y在词库W内<br>11.用y创建一个新的hop节点<br>12.如果y属于G，并且x和y的边不在图内<br>13.在图中添加x和y的连线<br>14.让节点y作为一个前沿节点<br>15.循环结束<br>16.答案部分，每个答案是y<br>17.添加一个新的答案节点y和edge(x,y)到G中<br>18.循环结束<br>19.x过程结束<br>20.用System2更新隐含X的表示<br>21.直到G中没有前沿节点或G足够大；<br>22.返回答案节点中概率最大的节点作为最终答案。</p>
<p>关于可解释性，认知图谱有显式的路径，除了简单的路径，认知图还可以清楚地显示联合或循环推理过程。<br>在这些过程中，可能会带来关于答案的新线索。</p>
<p>尺度可伸缩性，框架理论上是可伸缩的，因为引用所有段落的唯一操作是通过标题索引访问哪些段落。</p>
<p>对于多跳问题，传统的检索-抽取框架可能会牺牲后续模型的潜力，因为距离问题多跳的段落可能共享的常用词很少，与问题的语义关系也很小，导致检索失败。然而，这些段落可以通过在我们的框架中使用线索迭代展开来发现。</p>
<h2 id="实施方案"><a href="#实施方案" class="headerlink" title="实施方案"></a>实施方案</h2><p><img src="https://i.loli.net/2021/03/27/A7W8mvJ1z2sioSc.jpg" alt=""></p>
<h3 id="System1"><a href="#System1" class="headerlink" title="System1"></a>System1</h3><p>系统1的作用，在线索clues和问题Q的指导下提取spans并生成语义向量sem[x,Q,clus]。<br>clues是前置节点段落的句子，从文中直接提取原始句子，这样做方便BERT训练。</p>
<p><img src="https://i.loli.net/2021/03/27/A7W8mvJ1z2sioSc.jpg" alt=""></p>
<p>Bert的输入句子分为A和B两部分：</p>
<script type="math/tex; mode=display">
    \begin{equation}\begin{split} 
    A:[CLE]Question[SEP]clues[x,G][SEP]B:Para[x]
    \end{split}\end{equation}</script><p>[CLE]:放在每个句子的第一位，classification用于下游分类任务。<br>为什么用CLS？因为self-attention，[CLS]的output含有整句话的完整信息。在每个词的时候，对自己这个词的评分会很大。用无意义的CLS可以公平的反应整个句子的特征。<br>[SEP]:separator分隔连接token序列的符号。</p>
<p><img src="https://i.loli.net/2021/03/27/7ROBPrVjkQfH91s.jpg" alt=""></p>
<script type="math/tex; mode=display">
    \begin{equation}\begin{split} 
    P^{start}_{ans}[i]=\frac{e^{S_{ans} \cdot T_i}}{\sum_je^{S_{ans}\cdot T_j}}
    \end{split}\end{equation}</script><p>$S<em>{hop}$、$E</em>{hop}$、$S<em>{ans}$、$E</em>{ans}$ :可学习的参数，用来预测目标span。<br>$T\in R^{L\times H}$:是bert的输出向量,L是输入序列长度，H是隐层维度。<br>$P^{start}_{ans}[i]$:是第i个输入token到ans范围内开始位置的概率。</p>
<p>我们只聚焦topK开始的概率${start_k}$,对于每个k的结束位置$end_k$:</p>
<script type="math/tex; mode=display">
    \begin{equation}\begin{split} 
    end_k = argmax_{start_k\leq j\leq start_k + maxL }P^{end}_{ans}[j]
    \end{split}\end{equation}</script><p>maxL：是最大概率的span长度。<br>$P^{end}_{ans}[j]$:是第j个输入token到ans范围内结束位置的概率。</p>
<p>文章说是这么区分下一跳和答案的：<br>答案和下一跳协议具有不同的属性。答案提取在很大程度上依赖于问题所指示的字符。例如，“纽约市”比“2019”更有可能是WHERE问题的答案，而下一跳实体通常是其描述与问题中的语句相匹配的实体。</p>
<p>为了识别不相关的段落，利用在§3.4.1中引入负抽样进行训练，系统1生成负阈值。在顶部<br>k个跨度，起始概率小于负阈值将被丢弃。因为对第0个token[CLS]进行预训练以合成<br>用于下一句预测的所有输入标记任务Pstart[0]充当ANS这是我们实施过程中的一个阈值。</p>
<h3 id="System2"><a href="#System2" class="headerlink" title="System2"></a>System2</h3><p>系统2，更新隐藏表示X，并为任何后继节点y准备clues[y，G]。基于X输出最终预测结果。</p>
<p>第一个功能是为前沿节点准备clues[x，G]，我们将其实现为收集提到x的x个前置节点的原始语句。<br>第二个功能是更新隐含表示X，这是系统2的核心功能。隐含表示$X∈R^{n×H}$代表G中所有n个实体的理解。要完全理解实体x与问题q之间的关系，仅仅分析语义sem[x，Q，clues]是不够的。由于图结构的归纳偏差，GNN已被提出用于对图进行深入学习，特别是关系推理。</p>
<script type="math/tex; mode=display">
    \begin{equation}\begin{split} 
    \Delta = \sigma((AD^{-1})^T\sigma(XW_1))
    \end{split}\end{equation}</script><script type="math/tex; mode=display">
    \begin{equation}\begin{split} 
    X’=\sigma(XW_2+\Delta)
    \end{split}\end{equation}</script><p>$W_1,W_2 \in R^{H\times H}$:权重矩阵<br>$\sigma(XW_1)$ 左乘$(AD^{-1})^T$(列归一化A):可以解释为局部化光谱过滤.<br>在访问边界节点x的迭代步骤中，其隐藏表示X[x]按照公式(4)(5)更新。<br>在实验中发现“异步更新”在性能上没有明显的差别，在G最终确定后，将所有节点的X一起分多步更新，效率更高，在实践中被采用。</p>
<h3 id="训练细节"><a href="#训练细节" class="headerlink" title="训练细节"></a>训练细节</h3><p>模型采用负采样，在训练集的段落中预先提取下一跳hop和answer span。<br>对于每个para[x]和问题Q有下面这种字典数据。</p>
<script type="math/tex; mode=display">
    \begin{equation}\begin{split} 
    D[x,Q] = \{(y_1,start_1,end_1),...,(y_n,start_n,end_n)\}
    \end{split}\end{equation}</script><p>$start_i$和$end_i$ 是在para[x] 中根据一个实体或者答案$y_i$模糊匹配出来的。</p>
<h3 id="任务1：Span-Extraction"><a href="#任务1：Span-Extraction" class="headerlink" title="任务1：Span Extraction"></a>任务1：Span Extraction</h3><p>基于$D[x,Q]$，得到$P^{start}<em>{ans}$,$P^{end}</em>{ans}$,$P^{start}<em>{hop}$,$P^{end}</em>{hop}$<br>在每个段落中最多出现一个$answer(y,start,end)$<br>因此，定义一个one-hot向量$g<em>{ans}^{start}$ ，其中$g</em>{ans}^{start}[start]=1$。然而，一个段落中可能出现多个不同的ans next-hop spans，因此$g_{hop}^{start_i}[start]=1/k$ ，其中k是下一跳跨度的数量。</p>
<p>为了能够区分不相关的段落，在G中预先增加了不相关的negative-hop节点。</p>
<h3 id="任务2：预测答案节点"><a href="#任务2：预测答案节点" class="headerlink" title="任务2：预测答案节点"></a>任务2：预测答案节点</h3><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p>使用HotpotQA的全维基设置来构建实验。基于维基百科文档中的第一段图，众包收集了112,779个问题，其中84%的问题需要多跳推理。数据被分成训练集(90,564个问题)、发展集(7,405个问题)和测试集(7,405个问题)。开发和测试集中的所有问题都是困难的多跳案例。</p>
<h2 id="总结-amp-展望"><a href="#总结-amp-展望" class="headerlink" title="总结&amp;展望"></a>总结&amp;展望</h2><p>系统2的推理如何实现？现在的方法（如图神经网络）虽然使用关系边作为归纳偏置，却仍然无法执行可控、可解释、鲁棒的符号计算。系统1如何为现有的神经-符号计算方法提供可行前续工作？</p>
<p>文本库应该如何预处理或预训练，才能有助于访问相关知识的检索？</p>
<p>另辟蹊径？本文介绍的认知图谱是基于认知科学的双通道理论，是否还存在其他支撑理论？或者直接构建一个符号推理和深度学习相结合的新型学习架构？</p>
<p>如何与人类记忆机理相结合？人类记忆机理包括长期记忆和短期记忆，但其工作模式和工作机理并不清楚。长期记忆可能存储的是一个记忆模型，记忆模型不再是一个概念的网络，而是一个计算模型的网络。</p>
<p>认知图谱如何与外界反馈相结合是一个全新的问题。当然这里可以考虑通过反馈强化学习来实现，但具体方法和实现模式还需要深入探讨。</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/133483274">浅谈多跳阅读理解</a><br><a target="_blank" rel="noopener" href="https://www.pianshen.com/article/5232700066/">BERT的[CLS]有什么用</a><br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/49271699">从Word Embedding到Bert模型—自然语言处理中的预训练技术发展史</a><br><a target="_blank" rel="noopener" href="http://toutiao.secjia.com/knowledge-map-to-cognitive-map-0820/">从知识图谱到认知图谱：历史、发展与展望</a><br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/208697908?utm_source=wechat_timeline">图神经网络及其在知识图谱中的应用</a><br><a target="_blank" rel="noopener" href="http://www.360doc.com/content/20/1227/10/7673502_953710193.shtml">还在用[CLS]？从BERT得到最强句子Embedding的打开方式！</a></p>
</article><div class="post-reward"><div class="reward-button button--animated"><i class="fas fa-qrcode"></i> 打赏</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="https://i.loli.net/2021/03/22/HzNFBbkvZ2QMOKV.jpg" target="_blank"><img class="post-qr-code-img" src="https://i.loli.net/2021/03/22/HzNFBbkvZ2QMOKV.jpg" alt="wechat"/></a><div class="post-qr-code-desc">wechat</div></li><li class="reward-item"><a href="https://i.loli.net/2021/03/22/wMGegPYTAXx9cJo.jpg" target="_blank"><img class="post-qr-code-img" src="https://i.loli.net/2021/03/22/wMGegPYTAXx9cJo.jpg" alt="alipay"/></a><div class="post-qr-code-desc">alipay</div></li></ul></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="gitalk-container"></div></div></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2021/03/30/Heterogeneous-Graph-Neural-Network/"><img class="prev-cover" src="https://i.loli.net/2021/03/30/joZhFfytV4YGSBg.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Heterogeneous Graph Neural Network</div></div></a></div><div class="next-post pull-right"><a href="/2021/03/27/Multi-hop-Reading-Comprehension-across-Multiple-Documents-by-Reasoning-over-Heterogeneous-Graphs/"><img class="next-cover" src="https://i.loli.net/2021/03/27/fCj9ordWQJygFIA.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Multi-hop Reading Comprehension across Multiple Documents by Reasoning over Heterogeneous Graphs</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span> 相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2021/08/17/Breadth-First-Reasoning-Graph-for-Multi-hop-Question-Answering/" title="Breadth First Reasoning Graph for Multi-hop Question Answering"><img class="cover" src="https://i.loli.net/2021/08/17/3ngFqGzAlSJXDrH.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-08-17</div><div class="title">Breadth First Reasoning Graph for Multi-hop Question Answering</div></div></a></div><div><a href="/2021/07/23/Heterogeneous-Graph-Transformer-for-Graph-to-Sequence-Learning/" title="Heterogeneous Graph Transformer for Graph-to-Sequence Learning"><img class="cover" src="https://i.loli.net/2021/07/23/fda45whDJNAYu1j.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-07-23</div><div class="title">Heterogeneous Graph Transformer for Graph-to-Sequence Learning</div></div></a></div><div><a href="/2021/07/23/Graph-Transformer-for-Graph-to-Sequence-Learning/" title="Graph Transformer for Graph-to-Sequence Learning"><img class="cover" src="https://i.loli.net/2021/07/23/fEt4wdMJTLlp8kA.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-07-23</div><div class="title">Graph Transformer for Graph-to-Sequence Learning</div></div></a></div><div><a href="/2021/06/29/A-Generalization-of-Transformer-Networks-to-Graphs/" title="A Generalization of Transformer Networks to Graphs"><img class="cover" src="https://z3.ax1x.com/2021/06/30/R0NHXt.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-06-29</div><div class="title">A Generalization of Transformer Networks to Graphs</div></div></a></div><div><a href="/2021/06/23/Do-Transformers-Really-Perform-Bad-for-Graph-Representation/" title="Do Transformers Really Perform Bad for Graph Representation?"><img class="cover" src="https://i.loli.net/2021/06/23/GToCgpqhurvwJXl.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-06-23</div><div class="title">Do Transformers Really Perform Bad for Graph Representation?</div></div></a></div><div><a href="/2021/06/10/TRANSFORMER-XH-MULTI-EVIDENCE-REASONING-WITH-EXTRA-HOP-ATTENTION/" title="TRANSFORMER-XH: MULTI-EVIDENCE REASONING WITH EXTRA HOP ATTENTION"><img class="cover" src="https://i.loli.net/2021/06/10/TWh3IVnfCw85ySo.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-06-10</div><div class="title">TRANSFORMER-XH: MULTI-EVIDENCE REASONING WITH EXTRA HOP ATTENTION</div></div></a></div></div></div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Coding-Zuo</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2021/03/27/Cognitive-Graph-for-Multi-Hop-Reading-Comprehension-at-Scale-ACL2019/">http://example.com/2021/03/27/Cognitive-Graph-for-Multi-Hop-Reading-Comprehension-at-Scale-ACL2019/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://example.com" target="_blank">Coding-Zuo</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/GNN-nlp/">GNN&amp;nlp</a></div><div class="post_share"><div class="addthis_inline_share_toolbox"></div><script src="//s7.addthis.com/js/300/addthis_widget.js#pubid=null" async="async"></script></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Cognitive-Graph-for-Multi-Hop-Reading-Comprehension-at-Scale-ACL2019"><span class="toc-number">1.</span> <span class="toc-text">Cognitive Graph for Multi-Hop Reading Comprehension at Scale(ACL2019)</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%A4%E7%9F%A5%E5%9B%BE%E8%B0%B1"><span class="toc-number">1.1.</span> <span class="toc-text">认知图谱</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%91%98%E8%A6%81"><span class="toc-number">1.2.</span> <span class="toc-text">摘要</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Introduction"><span class="toc-number">1.3.</span> <span class="toc-text">Introduction</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%A4%E4%B8%AA%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%B7%A5%E4%BD%9C"><span class="toc-number">1.3.1.</span> <span class="toc-text">两个系统的工作</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9E%E6%96%BD%E6%96%B9%E6%A1%88"><span class="toc-number">1.4.</span> <span class="toc-text">实施方案</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#System1"><span class="toc-number">1.4.1.</span> <span class="toc-text">System1</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#System2"><span class="toc-number">1.4.2.</span> <span class="toc-text">System2</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E7%BB%86%E8%8A%82"><span class="toc-number">1.4.3.</span> <span class="toc-text">训练细节</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%BB%E5%8A%A11%EF%BC%9ASpan-Extraction"><span class="toc-number">1.4.4.</span> <span class="toc-text">任务1：Span Extraction</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%BB%E5%8A%A12%EF%BC%9A%E9%A2%84%E6%B5%8B%E7%AD%94%E6%A1%88%E8%8A%82%E7%82%B9"><span class="toc-number">1.4.5.</span> <span class="toc-text">任务2：预测答案节点</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C"><span class="toc-number">1.5.</span> <span class="toc-text">实验</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">1.5.1.</span> <span class="toc-text">数据集</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%BB%E7%BB%93-amp-%E5%B1%95%E6%9C%9B"><span class="toc-number">1.6.</span> <span class="toc-text">总结&amp;展望</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE"><span class="toc-number">1.7.</span> <span class="toc-text">参考文献</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2021 By Coding-Zuo</div><div class="footer_custom_text">Hi, welcome to my BLOG</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font-plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    loader: {
      source: {
        '[tex]/amsCd': '[tex]/amscd'
      }
    },
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        addClass: [200,() => {
          document.querySelectorAll('mjx-container:not([display=\'true\']').forEach( node => {
            const target = node.parentNode
            if (!target.classList.contains('has-jax')) {
              target.classList.add('mathjax-overflow')
            }
          })
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><script>if (document.getElementsByClassName('mermaid').length) {
  if (window.mermaidJsLoad) mermaid.init()
  else {
    getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(() => {
      window.mermaidJsLoad = true
      mermaid.initialize({
        theme: 'default',
      })
      false && mermaid.init()
    })
  }
}</script><script>function addGitalkSource () {
  const ele = document.createElement('link')
  ele.rel = 'stylesheet'
  ele.href= 'https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css'
  document.getElementsByTagName('head')[0].appendChild(ele)
}

function loadGitalk () {
  function initGitalk () {
    var gitalk = new Gitalk(Object.assign({
      clientID: 'd652112bf81876e00118',
      clientSecret: 'a5abed418c7cc2736af5b4d0cbd7ff97d460a5b3',
      repo: 'Coding-Zuo.github.io',
      owner: 'Coding-Zuo',
      admin: ['Coding-Zuo'],
      id: '5a208119e0481d26b68d218c7db9e0a7',
      language: 'zh-CN',
      perPage: 10,
      distractionFreeMode: false,
      pagerDirection: 'last',
      createIssueManually: false,
      updateCountCallback: commentCount
    },null))

    gitalk.render('gitalk-container')
  }

  if (typeof Gitalk === 'function') initGitalk()
  else {
    addGitalkSource()
    getScript('https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.js').then(initGitalk)
  }
}

function commentCount(n){
  let isCommentCount = document.querySelector('#post-meta .gitalk-comment-count')
  if (isCommentCount) {
    isCommentCount.innerHTML= n
  }
}

if ('Gitalk' === 'Gitalk' || !true) {
  if (true) btf.loadComment(document.getElementById('gitalk-container'), loadGitalk)
  else loadGitalk()
} else {
  function loadOtherComment () {
    loadGitalk()
  }
}</script></div><script src="/js/custom.js"></script><script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script><script defer="defer" id="fluttering_ribbon" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-fluttering-ribbon.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script src="//code.tidio.co/mak6nokafytw9mgrsuzglwzfxiy3fpdl.js" async="async"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>