<!DOCTYPE html><html lang="zh-CN" data-theme="dark"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>PromptBERT: Improving BERT Sentence Embeddings with Prompts | Coding-Zuo</title><meta name="keywords" content="context detection"><meta name="author" content="Coding-Zuo"><meta name="copyright" content="Coding-Zuo"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#0d0d0d"><meta name="description" content="PromptBERT: Improving BERT Sentence Embeddings with Prompts在以前的工作中，原始的BERT在句子语义相似性方面的表现不佳，已经被广泛讨论。我们发现，不尽如人意的表现主要是由于静态 token 嵌入的偏差和无效的 BERT 层，而不是因为句子嵌入的高余弦相似度。 为此，我们提出了一种 prompt based 的句子嵌入方法，它可以减少 to">
<meta property="og:type" content="article">
<meta property="og:title" content="PromptBERT: Improving BERT Sentence Embeddings with Prompts">
<meta property="og:url" content="http://example.com/2021/12/02/PromptBERT-Improving-BERT-Sentence-Embeddings-with-Prompts/index.html">
<meta property="og:site_name" content="Coding-Zuo">
<meta property="og:description" content="PromptBERT: Improving BERT Sentence Embeddings with Prompts在以前的工作中，原始的BERT在句子语义相似性方面的表现不佳，已经被广泛讨论。我们发现，不尽如人意的表现主要是由于静态 token 嵌入的偏差和无效的 BERT 层，而不是因为句子嵌入的高余弦相似度。 为此，我们提出了一种 prompt based 的句子嵌入方法，它可以减少 to">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://i.loli.net/2021/12/02/MVzbTiL5glWvtj4.png">
<meta property="article:published_time" content="2021-12-02T12:31:29.000Z">
<meta property="article:modified_time" content="2021-12-21T07:07:19.885Z">
<meta property="article:author" content="Coding-Zuo">
<meta property="article:tag" content="context detection">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.loli.net/2021/12/02/MVzbTiL5glWvtj4.png"><link rel="shortcut icon" href="https://i.loli.net/2021/03/22/reFlcYOnP3dSuJX.png"><link rel="canonical" href="http://example.com/2021/12/02/PromptBERT-Improving-BERT-Sentence-Embeddings-with-Prompts/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.json","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2021-12-21 15:07:19'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
          const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
          const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
          const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

          if (t === undefined) {
            if (isLightMode) activateLightMode()
            else if (isDarkMode) activateDarkMode()
            else if (isNotSpecified || hasNoSupport) {
              const now = new Date()
              const hour = now.getHours()
              const isNight = hour <= 6 || hour >= 18
              isNight ? activateDarkMode() : activateLightMode()
            }
            window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
              if (saveToLocal.get('theme') === undefined) {
                e.matches ? activateDarkMode() : activateLightMode()
              }
            })
          } else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const fontSizeVal = saveToLocal.get('global-font-size')
    if (fontSizeVal !== undefined) {
      document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
    }
    })(window)</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/sviptzk/HexoStaticFile@latest/Hexo/css/footer.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css"><meta name="generator" content="Hexo 5.3.0"><link rel="alternate" href="/atom.xml" title="Coding-Zuo" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="https://i.loli.net/2021/03/22/YP2oqk7lOAfceTD.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">136</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">17</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https:www.baidu.com"><i class="fa-fw fas fa-heart"></i><span> 我的简历</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 清单</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/%E9%9F%B3%E4%B9%90"><i class="fa-fw /music/"></i><span> 0</span></a></li><li><a class="site-page child" href="/%E7%94%B5%E5%BD%B1"><i class="fa-fw /movies/"></i><span> 1</span></a></li><li><a class="site-page child" href="/%E7%85%A7%E7%89%87"><i class="fa-fw /Gallery/"></i><span> 2</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://i.loli.net/2021/12/02/MVzbTiL5glWvtj4.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Coding-Zuo</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https:www.baidu.com"><i class="fa-fw fas fa-heart"></i><span> 我的简历</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 清单</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/%E9%9F%B3%E4%B9%90"><i class="fa-fw /music/"></i><span> 0</span></a></li><li><a class="site-page child" href="/%E7%94%B5%E5%BD%B1"><i class="fa-fw /movies/"></i><span> 1</span></a></li><li><a class="site-page child" href="/%E7%85%A7%E7%89%87"><i class="fa-fw /Gallery/"></i><span> 2</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">PromptBERT: Improving BERT Sentence Embeddings with Prompts</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2021-12-02T12:31:29.000Z" title="发表于 2021-12-02 20:31:29">2021-12-02</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2021-12-21T07:07:19.885Z" title="更新于 2021-12-21 15:07:19">2021-12-21</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="PromptBERT: Improving BERT Sentence Embeddings with Prompts"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="PromptBERT-Improving-BERT-Sentence-Embeddings-with-Prompts"><a href="#PromptBERT-Improving-BERT-Sentence-Embeddings-with-Prompts" class="headerlink" title="PromptBERT: Improving BERT Sentence Embeddings with Prompts"></a>PromptBERT: Improving BERT Sentence Embeddings with Prompts</h1><p>在以前的工作中，原始的BERT在句子语义相似性方面的表现不佳，已经被广泛讨论。我们发现，不尽如人意的表现主要是由于静态 token 嵌入的偏差和无效的 BERT 层，而不是因为句子嵌入的高余弦相似度。</p>
<p>为此，我们提出了一种 prompt based 的句子嵌入方法，它可以减少 token 嵌入的偏差，使原来的BERT层更加有效。通过将句子嵌入任务重新表述为填空问题，我们的方法显著提高了原始BERT的性能。我们讨论了 prompt based 的句子嵌入的两种 prompt 表示方法和三种 prompt 搜索方法</p>
<p>此外，我们通过模板去噪技术提出了一个新的无监督训练目标，这大大缩短了有监督和无监督设置之间的性能差距。</p>
<p>在实验中，我们对我们的方法在非微调和微调的设置上进行评估。即使是一个非微调的方法，也可以在STS任务上超过微调的方法，如无监督的ConSERT。我们的微调方法在无监督和有监督的情况下都优于最先进的方法SimCSE。与SimCSE相比，在无监督设置下，我们在BERT和RoBERTa上分别取得了2.29和2.58分的改进。</p>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>以前的研究将各向异性与解释原始BERT的不良性能联系起来（Li等人，2020；Yan等人，2021；Gao等人，2021）。各向异性使得 token 嵌入占据一个狭窄的锥体，导致任何句子对之间的高相似度 </p>
<p>Li 等人（2020）提出了一种归一化 flows 方法，将句子嵌入分布转化为平滑和各向同性的高斯分布，Yan等人（2021）提出了一个对比性框架来迁移句子表示。这些方法的目标是消除句子嵌入中的各向异性。然而，我们发现，各向异性并不是导致语义相似性差的主要原因。例如，在语义文本相似性任务中，对原始BERT的最后一层进行平均，甚至比对其静态token 嵌入进行平均更差，但最后一层的句子嵌入比静态 token 嵌入的各向异性要小。</p>
<p>根据这一结果，我们发现原始的 BERT层 实际上损害了句子嵌入的质量。然而，如果我们将静态 token 嵌入视为单词嵌入，与GloVe相比，它产生的结果仍然不能令人满意。受（Li等人，2020）的启发，他们发现 token 频率偏向其分布，我们发现分布不仅偏向频率，还偏向WordPiece（Wu等人，2016）中的大小写和子词。 </p>
<p>我们设计了一个简单的实验来测试我们的猜想，只需去除这些有偏的token（如高频子词和标点符号），并使用剩余token嵌入的平均值作为句子表示。它可以超越Glove，甚至取得与后处理方法BERT-flow（Li等人，2020）和BERT-whitening（Su等人，2021）相当的结果。</p>
<p>在这些发现的激励下，避免嵌入偏差可以提高句子表述的性能。然而，手动消除嵌入偏差是很费力的，而且如果句子太短，可能会导致一些有意义的词被遗漏。</p>
<p>受(Brown et al., 2020)的启发，将不同的NLP任务通过不同的 prompt 重新表述为填空问题，我们提出了一种基于 prompt 的方法，使用模板来获得BERT中的句子表述。</p>
<p>Prompt based 的方法可以避免嵌入偏差并利用原始BERT层。我们发现原始的BERT在句子嵌入的模板帮助下可以达到合理的性能，它甚至超过了一些基于BERT的方法，这些方法在下游任务中对BERT进行了微调。</p>
<p>我们的方法同样适用于微调的设置。目前的方法利用对比学习来帮助BERT学习更好的句子嵌入（Gao等人，2021；Yan等人，2021）。然而，无监督的方法仍然存在泄漏适当积极对的问题。Yan等人（2021）讨论了四种数据增强方法，但其性能似乎比直接使用BERT中的 dropout 作为噪声要差（Gao等人，2021）。</p>
<p>我们发现 prompt 可以提供一个更好的方法，通过不同模板的不同观点来生成正数对。为此，我们提出了一种基于prompt的对比学习方法，该方法带有模板去噪功能，可以在无监督的情况下利用BERT的力量，这大大缩短了有监督和无监督性能之间的差距。我们的方法在无监督和有监督的情况下都取得了最先进的结果。</p>
<h2 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h2><p>学习句子嵌入作为一个基本的NLP问题已经被大量研究。目前，如何在句子嵌入中利用BERT的力量已经成为一个新的趋势。许多工作（Li等人，2020年；Gao等人，2021年）在有监督和无监督的情况下都用BERT取得了强大的性能。在这些工作中，基于对比学习的方法取得了最先进的成果。这些工作（Gao等人，2021；Yan等人，2021）注意构建积极的句子对。Gao等人（2021）提出了一个新颖的对比性训练目标，直接使用内部 dropout 作为噪声来构建正向句对。Yan等人（2021）讨论了四种构建积极句对的方法。</p>
<p>虽然BERT在句子嵌入方面取得了巨大的成功，但原始BERT的表现并不令人满意。原始BERT的上下文令牌嵌入甚至比GloVe等词嵌入的表现还差。一种解释是原始BERT中的各向异性，这导致句子对具有高相似性。根据这一解释，BERT-flow（Li等人，2020）和 BERT-whitening（Su等人，2021）已被提出，通过对原始BERT的句子嵌入进行后处理来减少各向异性。</p>
<h2 id="Rethinking-the-Sentence-Embeddings-of-Original-BERT"><a href="#Rethinking-the-Sentence-Embeddings-of-Original-BERT" class="headerlink" title="Rethinking the Sentence Embeddings of Original BERT"></a>Rethinking the Sentence Embeddings of Original BERT</h2><p>以前的工作（Yan等人，2021年；Gao等人，2021年）解释了原始BERT的不良性能是由学习的各向异性的 token 嵌入空间限制的，其中 token 嵌入占据一个狭窄的锥体。然而，我们通过研究各向异性和性能之间的关系发现，各向异性并不是诱发不良语义相似性的关键因素。我们认为主要原因是无效的BERT层和静态 token 嵌入偏差。</p>
<h3 id="Observation-1-Original-BERT-layers-fail-to-improve-the-performance"><a href="#Observation-1-Original-BERT-layers-fail-to-improve-the-performance" class="headerlink" title="Observation 1: Original BERT layers fail to improve the performance"></a>Observation 1: Original BERT layers fail to improve the performance</h3><p>在本节中，我们通过比较两种句子嵌入方法来分析 BERT 层的影响：平均静态 token 嵌入（BERT层的输入）和平均最后层（BERT层的输出）。我们报告了句子嵌入的性能和它的句子水平各向异性。</p>
<p>为了测量各向异性，我们遵循（Ethayarajh，2019）的工作，测量句子嵌入中的句子水平各向异性。让 $s_i$ 是出现在语料库${s_1, …, s_n }$ 中的一个句子。该各向异性可按以下方式测量:</p>
<script type="math/tex; mode=display">
\frac{1}{n^2-n} |\sum_i\sum_{j\neq i} cos(M(s_i), M(s_j))|</script><p>其中 M 定义为表示语句嵌入方法，它将原始句子映射到其嵌入，cos是余弦相似度。换句话说，M的各向异性是通过一组句子的平均余弦相似度来衡量的。</p>
<p>如果句子嵌入是各向同性的（即方向均匀），那么均匀随机抽样的句子之间的平均余弦相似度将是0（Arora等人，2016）。它越接近于1，句子的各向异性就越大。我们从维基百科语料库中随机抽取100,000个句子来计算各向异性。</p>
<p>我们比较了不同的预训练模型（Bert-base-uncased、Bert-base-cased和Roberta-base）和不同的句子嵌入方法（最后一层平均法、最后一个隐藏层token作为句子嵌入和静态token嵌入的平均法、直接对静态token嵌入的平均法）。我们在表1中显示了这些方法的spearman相关性和句子水平各向异性。</p>
<p><img src="https://s2.loli.net/2021/12/20/mHGx3YdhwRoKCfM.png" alt=""></p>
<p>如表1所示，我们发现bert-base-uncased和roberta-base中的BERT层明显损害了句子嵌入性能。即使在bert-base-cased中，BERT层的增益也是微不足道的，只有0.28的改善。我们还展示了每种方法的句子层面的各向异性。BERT层的性能下降似乎与句子水平各向异性无关。例如，最后一层的平均值比bert-base-uncased中的静态标记嵌入平均值更加各向同性。然而，静态标记嵌入平均数实现了更好的句子嵌入性能。</p>
<h3 id="Observation-2-Embedding-biases-harms-the-sentence-embeddings-performance"><a href="#Observation-2-Embedding-biases-harms-the-sentence-embeddings-performance" class="headerlink" title="Observation 2: Embedding biases harms the sentence embeddings performance."></a>Observation 2: Embedding biases harms the sentence embeddings performance.</h3><p>Li等人（2020）发现，token嵌入会对 token 频率产生偏差。Yan等人（2021）也研究了类似的问题。BERT静态令牌嵌入的各向异性对令牌频率很敏感。因此，我们研究了嵌入偏差是否会产生不理想的句子嵌入性能。我们观察到，token嵌入不仅对token频率有偏见，而且对WordPiece（Wu等人，2016）中的子词和大小写敏感。</p>
<p>如图1所示，我们在bert-base-uncased、bert-base-cased 和 roberta-base 的token embeddings 中直观地看到这些偏差。三种预训练模型的 token 嵌入受到 token 频率、子词和大小写的高度偏向。根据子词和大小写的偏差，token 嵌入可以大致分为三个区域：1）小写的词首token，2）大写的词首token和3）子词token。对于无大小写的预训练模型bert-base-uncased，token嵌入也可以大致分为两个区域。1）词首token，2）子词token。</p>
<p>对于频率偏差，我们可以观察到，在所有的模型中，高频率的token是聚集的，而低频率的 token 是稀疏地分散的（Yan等人，2021）。在BERT中，词首 token 比子词token 更容易受到频率的影响。然而，在RoBERTa中，子词 token 更容易受到影响。</p>
<p>以前的工作（Yan等人，2021；Li等人，2020）经常将 “token嵌入偏见 “的概念与token嵌入各向异性作为偏见的原因。然而，我们认为各向异性与偏见无关。偏差意味着嵌入的分布被一些不相关的信息，如token频率所干扰，这可以根据PCA直接可视化。对于各向异性，它意味着整个嵌入在高维向量空间中占据了一个狭窄的锥体，这不能被直接可视化。</p>
<p><img src="https://s2.loli.net/2021/12/21/M2gTN4HvDZxEkdf.png" alt=""></p>
<p>表2显示了图1中三个预训练模型的静态token embeddings各向异性，根据任意两个token embeddings之间的平均余弦相似度计算。与之前的结论相反（Yan等人，2021；Li等人，2020），我们发现只有Bert-base-uncased的静态令牌嵌入是高度各向异性的。像roberta-base的静态 token 嵌入是各向同性的，平均余弦相似度为0.0235。对于偏差，这些模型受到静态标记嵌入中的偏差的影响，这与各向异性无关。</p>
<p><img src="https://s2.loli.net/2021/12/21/GlATLnuCBDia6ye.png" alt=""></p>
<p>为了证明偏见的负面影响，我们用平均的静态 token 嵌入作为句子嵌入（没有BERT层）来展示偏见对句子嵌入的影响。在表3中的三个预训练模型上，消除嵌入偏差的结果相当可观。仅仅去除一组token，结果就可以分别提高9.22、7.08和11.76。roberta-base的最终结果可以超过后处理方法，如BERT-flow（Li等人，2020）和BERT-whitening（Su等人，2021），只使用静态 token 嵌入。</p>
<p><img src="https://s2.loli.net/2021/12/21/9cTUVYF72pzC8XO.png" alt=""></p>
<p>手动消除嵌入偏差是提高句子嵌入性能的一个简单方法。但是，如果句子太短，这不是一个适当的解决方案，可能会导致一些有意义的词被遗漏。</p>
<h2 id="Prompt-Based-Sentence-Embeddings"><a href="#Prompt-Based-Sentence-Embeddings" class="headerlink" title="Prompt Based Sentence Embeddings"></a>Prompt Based Sentence Embeddings</h2><p>受（Brown等人，2020）的启发，我们提出了一种 基于提示的句子方法来获得句子嵌入。通过将句子嵌入任务重新表述为掩码语言任务，我们可以通过利用大规模的知识有效地使用原始BERT层。我们还通过从[MASK] token 表示句子来避免嵌入偏差。</p>
<p>然而，与文本分类或问题回答任务不同，句子嵌入中的输出不是MLM分类头预测的标签 token，而是表示句子的向量。我们按照这两个问题来讨论基于提示的句子嵌入的实现。1）如何用提示表示句子，以及2）如何为句子嵌入找到一个合适的提示。基于这些，我们提出了一种基于提示的对比学习方法来微调句子嵌入的BERT。</p>
<h3 id="Represent-Sentence-with-the-Prompt"><a href="#Represent-Sentence-with-the-Prompt" class="headerlink" title="Represent Sentence with the Prompt"></a>Represent Sentence with the Prompt</h3><p>在本节中，我们将讨论两种用提示语表示一个句子的方法。例如，我们有一个模板”[X]意味着[MASK]”，其中[X]是一个放置句子的占位符，[MASK]代表[MASK]token。给定一个句子 $x<em>{in}$，我们用模板将 $x</em>{in}$ 映射到 $x<em>{prompt}$。然后，我们将$x</em>{prompt}$送入一个预先训练好的模型，以生成句子表示 $h$。</p>
<p>一种方法是使用 $[MASK]$ token 的隐藏向量作为句子表示:</p>
<script type="math/tex; mode=display">
h = h_{[MASK]}</script><p>对于第二种方法，就像其他基于提示的任务一样，我们根据 $h_{[MASK]}$ 和MLM分类头得到top-k tokens，然后根据概率分布找到这些tokens的加权平均值。$h$ 可以被表述为:</p>
<script type="math/tex; mode=display">
h = \frac{\sum_{v\in V_{top-k}}W_v P([MASK] = v|h_{[MASK]})}{\sum_{v\in V_{top-k}} P ([MASK]=v|h_{[MASK]})}</script><p>其中，v 是 top-k token 集 $V<em>{top-k}$ 中的BERT标记，$W_v$ 是 $v$ 的静态 token 嵌入，$P([MASK] = v|h</em>{[MASK]})$表示token $v$被MLM头预测为 $h_{[MASK]}$ 的概率。</p>
<p>第二种方法是将句子映射到 token 上，比第一种方法更常规。但它的缺点也很明显：1）如前所述，由于句子嵌入来自静态 token 嵌入的平均化，它仍然存在偏差。2）权重平均化使BERT在下游任务中很难进行微调。由于这些原因，我们用第一种方法来表示带有提示的句子。</p>
<h3 id="Prompt-Search"><a href="#Prompt-Search" class="headerlink" title="Prompt Search"></a>Prompt Search</h3><p>第二种方法是将句子映射到 token 上，比第一种方法更常规。但它的缺点也很明显：1）如前所述，由于句子嵌入来自静态 token 嵌入的平均化，它仍然存在偏差。2）权重平均化使BERT在下游任务中很难进行微调。由于这些原因，我们用第一种方法来表示带有提示的句子。</p>
<p>对于人工搜索，我们需要手工制作模板，鼓励将整个句子用 $h_{[MASK]} $ 表示。为了搜索模板，我们将模板分为两部分：关系token，表示 $[X]$ 和 $[MASK]$ 之间的关系；前缀token，包裹 $[X]$ 。然后，我们贪婪地搜索遵循关系 token 和前缀 token的模板。</p>
<p><img src="https://s2.loli.net/2021/12/21/7uzvhb3feKsIoEt.png" alt=""></p>
<p>表4中显示了一些贪婪搜索的结果。当涉及到句子嵌入时，不同的模板产生了极其不同的结果。与简单地连接 $[X]$ 和$[MASK]$ 相比，复杂的模板如这句话：” $[X]$ “意味着 $[MASK]$，可以提高34.10的spearman相关度。</p>
<p>对于基于T5的模板生成，Gao等人（2020）提出了一种新颖的方法，通过使用T5根据句子和相应的标签来自动生成模板。在GLUE基准测试中，生成的模板可以胜过人工搜索的模板（Wang等人，2018）。</p>
<p>然而，实现它的主要问题是缺乏 token 标签。Tsukagoshi等人（2021年）通过根据字典将定义句子分类到其单词，成功地将句子嵌入任务转化为文本分类任务。受此启发，我们使用单词和相应的定义来生成500个模板（例如，橙子：一种大而圆的多汁柑橘类水果，有坚韧的鲜红黄色的外皮）。然后，我们在STS-B开发集中对这些模板进行评估，与模板 “也叫[MASK]”的最佳spearman相关度为64.75。[X]”. 也许这就是句子嵌入和单词定义之间的差距。与人工搜索相比，这种方法不能产生更好的模板。</p>
<p>OptiPrompt（Zhong等人，2021）用连续模板取代了离散模板。为了优化连续模板，我们按照(Gao et al., 2021)的设置，使用无监督的对比学习作为训练目标，冻结整个BERT参数，连续模板由手工模板的静态 token 嵌入初始化。与输入的人工模板相比，连续模板可以将STS-B开发集的spearman相关度从73.44提高到80.90。</p>
<h3 id="Prompt-Based-Contrastive-Learning-with-Template-Denoising"><a href="#Prompt-Based-Contrastive-Learning-with-Template-Denoising" class="headerlink" title="Prompt Based Contrastive Learning with Template Denoising"></a>Prompt Based Contrastive Learning with Template Denoising</h3><p>最近，对比性学习成功地利用了句子嵌入中的BERT的力量。句子嵌入对比学习中的一个挑战是如何构建适当的正向实例。Gao等人（2021）直接将BERT中的dropout作为正例。Yan等人（2021）讨论了四种数据增强策略，如对抗性攻击、token shuffling、cutoff 和输入 token 嵌入中的dropout来构建正面实例。在基于提示的句子嵌入的激励下，我们提出了一种新的方法来合理地生成基于提示的正面实例。</p>
<p>这个想法是用不同的模板来表示同一个句子的不同观点，这有助于模型产生更合理的正向对。为了减少模板本身对句子表述的影响，我们提出了一种新的方法来去掉模板信息。给定句子 $x_i$，我们首先用模板计算出相应的句子嵌入$h_i$。然后，我们通过直接给BERT输入模板和相同的模板位置 id 来计算模板偏差 $\hat h_i$。例如，如果 $x_i$ 有5个 token，那么 [X] 后面的模板标记的位置id将被加上 5，以确保模板的位置id是相同的。最后，我们可以直接使用 $h_i - \hat h_i$ 作为去噪后的句子表示。关于模板去噪，更多细节可以在讨论中找到。</p>
<p>形式上，让 $h_i’$ 和 $h_i$ 表示不同模板的 $x_i$ 的句子嵌入，$\hat h_i’$和 $\hat h_i$ 分别表示 $x_i$ 的两个模板偏差，最终训练目标如下:</p>
<script type="math/tex; mode=display">
l_i = -log \frac{e^{cos(h_i-\hat h_i, h'_i-\hat h'_i)/ \tau}}{\sum_{j=1}^N e^{cos(h_i-\hat h_i, h'_j-\hat h'_j)/ \tau}}</script><p>其中，$τ$ 是对比学习中的一个温度超参数，N 是小批量的大小。</p>
</article><div class="post-reward"><div class="reward-button button--animated"><i class="fas fa-qrcode"></i> 打赏</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="https://i.loli.net/2021/03/22/HzNFBbkvZ2QMOKV.jpg" target="_blank"><img class="post-qr-code-img" src="https://i.loli.net/2021/03/22/HzNFBbkvZ2QMOKV.jpg" alt="wechat"/></a><div class="post-qr-code-desc">wechat</div></li><li class="reward-item"><a href="https://i.loli.net/2021/03/22/wMGegPYTAXx9cJo.jpg" target="_blank"><img class="post-qr-code-img" src="https://i.loli.net/2021/03/22/wMGegPYTAXx9cJo.jpg" alt="alipay"/></a><div class="post-qr-code-desc">alipay</div></li></ul></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="gitalk-container"></div></div></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2021/12/03/Continual-Learning-with-Hypernetworks/"><img class="prev-cover" src="https://i.loli.net/2021/12/03/HXDsvWIFemhG37V.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Continual Learning with Hypernetworks</div></div></a></div><div class="next-post pull-right"><a href="/2021/11/30/Parameter-Efficient-Tuning-by-Manipulating-Hidden-States-of-Pretrained-Language-Models-For-Classification-Tasks/"><img class="next-cover" src="https://i.loli.net/2021/11/30/tzcKE3YZAfOvNkw.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Parameter-Efficient Tuning by Manipulating Hidden States of Pretrained Language Models For Classification Tasks</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span> 相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2022/02/21/ZeroPrompt-Scaling-Prompt-Based-Pretraining-to-1-000-Tasks-Improves-Zero-Shot-Generalization/" title="ZeroPrompt- Scaling Prompt-Based Pretraining to 1,000 Tasks Improves Zero-Shot Generalization"><img class="cover" src="https://s4.ax1x.com/2022/02/21/HXcFxA.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-02-21</div><div class="title">ZeroPrompt- Scaling Prompt-Based Pretraining to 1,000 Tasks Improves Zero-Shot Generalization</div></div></a></div><div><a href="/2022/02/10/Prompt-Guided-Few-Shot-Event-Detection/" title="Prompt-Guided Few-Shot Event Detection"><img class="cover" src="https://i.loli.net/2021/10/28/DjK6qxmT9cA7Ov3.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-02-10</div><div class="title">Prompt-Guided Few-Shot Event Detection</div></div></a></div><div><a href="/2022/02/10/MetaPrompting-Learning-to-Learn-Better-Prompts/" title="MetaPrompting: Learning to Learn Better Prompts"><img class="cover" src="https://s4.ax1x.com/2022/01/22/7fJ3lV.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-02-10</div><div class="title">MetaPrompting: Learning to Learn Better Prompts</div></div></a></div><div><a href="/2022/01/04/Exploring-Low-dimensional-Intrinsic-Task-Subspace-via-Prompt-Tuning/" title="Exploring Low-dimensional Intrinsic Task Subspace via Prompt Tuning"><img class="cover" src="https://i.loli.net/2021/08/29/7pyGPBNQZRmv3Tr.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-01-04</div><div class="title">Exploring Low-dimensional Intrinsic Task Subspace via Prompt Tuning</div></div></a></div><div><a href="/2021/12/27/Unsupervised-Domain-Adaptation-of-a-Pretrained-Cross-Lingual-Language-Model/" title="Unsupervised Domain Adaptation of a Pretrained Cross-Lingual Language Model"><img class="cover" src="https://i.loli.net/2021/11/17/hMK8qF4Jne6sTYC.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-12-27</div><div class="title">Unsupervised Domain Adaptation of a Pretrained Cross-Lingual Language Model</div></div></a></div><div><a href="/2021/12/22/Contrastive-Representation-Distillation/" title="Contrastive Representation Distillation"><img class="cover" src="https://s2.loli.net/2021/12/22/aCcIO7GKrPo5DV3.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-12-22</div><div class="title">Contrastive Representation Distillation</div></div></a></div></div></div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Coding-Zuo</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2021/12/02/PromptBERT-Improving-BERT-Sentence-Embeddings-with-Prompts/">http://example.com/2021/12/02/PromptBERT-Improving-BERT-Sentence-Embeddings-with-Prompts/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://example.com" target="_blank">Coding-Zuo</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/context-detection/">context detection</a></div><div class="post_share"><div class="addthis_inline_share_toolbox"></div><script src="//s7.addthis.com/js/300/addthis_widget.js#pubid=null" async="async"></script></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#PromptBERT-Improving-BERT-Sentence-Embeddings-with-Prompts"><span class="toc-number">1.</span> <span class="toc-text">PromptBERT: Improving BERT Sentence Embeddings with Prompts</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Introduction"><span class="toc-number">1.1.</span> <span class="toc-text">Introduction</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Related-Work"><span class="toc-number">1.2.</span> <span class="toc-text">Related Work</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Rethinking-the-Sentence-Embeddings-of-Original-BERT"><span class="toc-number">1.3.</span> <span class="toc-text">Rethinking the Sentence Embeddings of Original BERT</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Observation-1-Original-BERT-layers-fail-to-improve-the-performance"><span class="toc-number">1.3.1.</span> <span class="toc-text">Observation 1: Original BERT layers fail to improve the performance</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Observation-2-Embedding-biases-harms-the-sentence-embeddings-performance"><span class="toc-number">1.3.2.</span> <span class="toc-text">Observation 2: Embedding biases harms the sentence embeddings performance.</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Prompt-Based-Sentence-Embeddings"><span class="toc-number">1.4.</span> <span class="toc-text">Prompt Based Sentence Embeddings</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Represent-Sentence-with-the-Prompt"><span class="toc-number">1.4.1.</span> <span class="toc-text">Represent Sentence with the Prompt</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Prompt-Search"><span class="toc-number">1.4.2.</span> <span class="toc-text">Prompt Search</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Prompt-Based-Contrastive-Learning-with-Template-Denoising"><span class="toc-number">1.4.3.</span> <span class="toc-text">Prompt Based Contrastive Learning with Template Denoising</span></a></li></ol></li></ol></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2022 By Coding-Zuo</div><div class="footer_custom_text">Hi, welcome to my BLOG</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font-plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    loader: {
      source: {
        '[tex]/amsCd': '[tex]/amscd'
      }
    },
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        addClass: [200,() => {
          document.querySelectorAll('mjx-container:not([display=\'true\']').forEach( node => {
            const target = node.parentNode
            if (!target.classList.contains('has-jax')) {
              target.classList.add('mathjax-overflow')
            }
          })
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><script>if (document.getElementsByClassName('mermaid').length) {
  if (window.mermaidJsLoad) mermaid.init()
  else {
    getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(() => {
      window.mermaidJsLoad = true
      mermaid.initialize({
        theme: 'default',
      })
      false && mermaid.init()
    })
  }
}</script><script>function addGitalkSource () {
  const ele = document.createElement('link')
  ele.rel = 'stylesheet'
  ele.href= 'https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css'
  document.getElementsByTagName('head')[0].appendChild(ele)
}

function loadGitalk () {
  function initGitalk () {
    var gitalk = new Gitalk(Object.assign({
      clientID: 'd652112bf81876e00118',
      clientSecret: 'a5abed418c7cc2736af5b4d0cbd7ff97d460a5b3',
      repo: 'Coding-Zuo.github.io',
      owner: 'Coding-Zuo',
      admin: ['Coding-Zuo'],
      id: '3cc4850a6a3b1eec1aaec8e3aa728f7d',
      language: 'zh-CN',
      perPage: 10,
      distractionFreeMode: false,
      pagerDirection: 'last',
      createIssueManually: false,
      updateCountCallback: commentCount
    },null))

    gitalk.render('gitalk-container')
  }

  if (typeof Gitalk === 'function') initGitalk()
  else {
    addGitalkSource()
    getScript('https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.js').then(initGitalk)
  }
}

function commentCount(n){
  let isCommentCount = document.querySelector('#post-meta .gitalk-comment-count')
  if (isCommentCount) {
    isCommentCount.innerHTML= n
  }
}

if ('Gitalk' === 'Gitalk' || !true) {
  if (true) btf.loadComment(document.getElementById('gitalk-container'), loadGitalk)
  else loadGitalk()
} else {
  function loadOtherComment () {
    loadGitalk()
  }
}</script></div><script src="/js/custom.js"></script><script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script><script defer="defer" id="fluttering_ribbon" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-fluttering-ribbon.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script src="//code.tidio.co/mak6nokafytw9mgrsuzglwzfxiy3fpdl.js" async="async"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>