[{"title":"4-三种方法彻底解决中位数问题","url":"/2021/09/15/4-三种方法彻底解决中位数问题/","content":"\n# 4-三种方法彻底解决中位数问题\n\n#### 4. 寻找两个正序数组的中位数\n\n## 两种思想\n\n- 真合并：使用归并的方式，合并两个有序数组，得到一个大的有序数组，大的有序数组中的中间位置的元素即为中位数。$O(n+m),O(n+m)$\n- 假合并：不需要合并两个有序数组，只要找到中位数的位置即可。由于两个数组的长度已知，因此中位数对应的两个数组下标之和也是已知的。维护两个指针，初始时分别指向两个数组的下标为0的位置，每次将指向较小的指针后移一位（如果一个指针已经到达数组末尾，则只需要移动另一个数组的指针），直到达到中位数的位置。$O(n+m),O(1)$\n\n## 常见的思想改进：假合并、奇偶合并\n\n通过假合并的思想可以将空间复杂度优化到$O(1)$但对于时间复杂度并没有什么优化，此方法代码复杂，不仅要考虑奇偶问题，更需要高了一个数组遍历后的各种边界问题。\n\n假合并的一个优化点是 将奇偶两种情况合并到了一起：\n\n- 如果是奇数，我们需要知道第(len+1)/2 个数就可以了，如果遍历的话需要遍历int(len/2)+1次\n- 如果是偶数，需要知道第(len/2) 和 len/2 + 1个数，也是需要遍历len/2 + 1次\n- 返回中位数，奇数需要最后一次遍历结果就可以，偶数需要最后一次和上一次的结果。所以用两个变量left和right。right保存当前循环的结果，在每次循环前将right赋值给left。这样在最后一次循环的时候，left将得到right的值，也就是上一次的循环结果，加下来right更新为最后一次的结果len/2+1次\n\n另一种合并的思想是: 我们可以在奇数的时候, 在**末尾等处添加一个占位符**#等, 这样也是可以将奇数合并成偶数的情况的.此方法的另一个优化点就是 通过在if条件中**加入大量的限制条件**, 从而实现了对于各种边界问题的处理, 这也是一种很重要的思想.\n\n![](https://i.loli.net/2021/09/15/rwI2miAu4SPgOX7.jpg)\n\n![](https://i.loli.net/2021/09/15/G1OiltFhg24JmY8.jpg)\n\n此方法的时间复杂度相对于下面两种思想还是太高了, 大家不用特意掌握此方法, 但是这两个优化的思想还是很重要的, 要好好的理解一下.\n\n接下来我们就来详细讲解两个时间复杂度超低的算法代码思想.\n\n## 寻找第k小数(记住这个)\n\n 主要就是根据两个数的三种比较结果, 不断地去除不满足的元素的过程.\n\n![](https://i.loli.net/2021/09/15/hKBdPugr5fRxXeC.jpg)\n\n这个思想最难的点在于 **三种特殊情况的处理**, 我们能否想到这三种情况, 并将他们**完美的融入到代码之中**, 我感觉这才是真正的难点所在.\n\n![](https://i.loli.net/2021/09/15/AdgYMm3xTtQSup8.jpg)\n\n最开始对于奇数和偶数的两种情况进行了判断, 其实是可以将两种情况合并的, 只需要在奇数时求两次同样的k就可以了.\n\n![](https://i.loli.net/2021/09/15/rmU7B5WJRGELvjd.jpg)\n\n接下来处理了三种特殊情况中的两种特殊情况: 一个数组为空 和 k=1.\n\n![](https://i.loli.net/2021/09/15/XGbolki98Dv6BCK.jpg)\n\n下面的**几个定义**就非常重要了, 一定要弄清这些定义的含义, 才能更轻松的理解代码.\n\n![](https://i.loli.net/2021/09/15/vkMmQjqNbPZGIwn.jpg)\n\nindex1, index2作为数组的起始点的下标, 初值都是0, 但是随着两个数组不断被删除元素, 这两个起始点也是在不断的进行变化, 具体变化方式就是 index1 = newIndex1 + 1, 因为在删除元素的时候 连同比较位置也一同删去了, 所以新的开始是 比较位置 的后一位.\n\nnewindex1, newindex2作为比较点就是图中被框中的两个数的下标, 它的赋值过程就涉及到了 最后一个边界情况. 因为当一个数组较短时, 其中一个比较点可能已经到达了数组的最后, 所以它的值是 两种情况下较小的那个数.\n\n![](https://i.loli.net/2021/09/15/mAW7YsNX5GBcKgH.jpg)\n\n接下来就是根据两个比较点的大小来进行不同的操作过程了, 这里最难理解的点就是 k -= (newIndex1 - index1 + 1), 也就是减去元素的个数问题了. 我们根据上面的图来举例, 图中index1的值为0, newindex1的值经过计算为1, 通过比较后, 可以看到 红色的数 就是被删除的数, 也就是两个, 所以我们需要在最后+1才是真实被删去的个数. 对于此类问题在确定最终个数的时候, 我们都可以通过这样的特例来决定代码的书写, 至此代码就全部讲解完成了.\n\n![](https://i.loli.net/2021/09/15/1hmHAU4Ets7iFJ9.jpg)\n\n## 理解中位数作用进行划分数组 \n\n最后这种思想时间复杂度比上面的还低，上面的思想每一轮循环可以将查找范围减少一半，因此时间复杂度是$O(log(m+n))$ ，但这种思想可以对确定的较短的数组进行二分查找，所以它的时间复杂度是$O(logmin(m,n))$\n\n划分数组正好和上面算法完全相反，它的思想特别复杂，但思想理解了，代码写起来倒是没太大难度。\n\n首先要明白中位数的作用：将一个集合划分为两个长度相等的子集，其中一个子集中的元素总是大于另一个子集中的元素。这种思想无论是在机构数组中都是适用的，这就衍生出了下面的思想。\n\n首先讨论奇偶两种不同情况的不同划分方式，\n\n![](https://i.loli.net/2021/09/16/8n9sSjVk7C3GKZM.jpg)\n\n然后在写代码时，由于计算机的取整操作，我们是可以将这两种情况合并成一种代码书写方式，其中的$i$和$j$分别是两个数组的划分位置。\n\n![](https://i.loli.net/2021/09/16/LzOv1Zxn8pBUVQo.jpg)\n\n同样我们也会遇到复杂的边界问题, 但下面这种处理方式是真的非常优秀.\n\n![](https://i.loli.net/2021/09/16/bBhSzkpAOunIXNj.jpg)\n\n上面问题都考虑完了, 其实就可以写代码了, 但是我们需要进行两个条件的判断: B[j−1]≤A[i] 以及A[i−1]≤B[j], 为了优化代码, 经过分析后, 我们发现这两种情况是可以等价转换的. 也就是只需要进行一个条件的判断即可.\n\n![](https://i.loli.net/2021/09/16/YZ2lJiL9IomnaKH.jpg)\n\n代码中有个注意点就是java中的**三目运算符? :** 在Python中是没有引入这个符号的, 但是Python利用了已有的关键字if...else实现了这个功能.\n\n![](https://i.loli.net/2021/09/16/gRSNcoWaidyOnhz.jpg)\n\n\n\n```java\nclass Solution {\n\n    //常规思想 假合并\n    public double findMedianSortedArrays(int[] nums1, int[] nums2) {\n        int m = nums1.length;\n        int n = nums2.length;\n        int len = m+n;\n        int left = -1, right= -1; // 记录前后两个数\n        int aStart=0, bStart=0;  // 记录两个数组的移动\n        for(int i=0;i<=len/2;i++){\n            left = right; // 每次循环前将right的值赋给left\n            // A移动的条件：B遍历到最后 或当前 A<B 满足一个即可\n            if(aStart < m && (bStart>=n || nums1[aStart] < nums2[bStart])){\n                right = nums1[aStart++];\n            }else{\n                right= nums2[bStart++];\n            }\n        }\n        if((len & 1) == 0) // 与1交，判断奇偶数，更快速\n            return (left+right)/2.0;\n        else\n            return right;\n    }\n\n\n\t\t// 第k小数\n    public double findMedianSortedArrays(int[] nums1, int[] nums2) {\n        int length1 = nums1.length;\n        int length2 = nums2.length;\n        int totallength = length1+ length2;\n        if(totallength % 2 == 1){ // 可以将两种情况合并，奇数会求两次同样的k\n            int midIndex = totallength/2;\n            double median = getKthElement(nums1, nums2, midIndex+1);\n            return median;\n        } else{\n            int midIndex1 = totallength/2 -1 , midIndex2 = totallength/2;\n            double median = (getKthElement(nums1, nums2, midIndex1 + 1) + getKthElement(nums1, nums2, midIndex2 + 1)) / 2.0;\n            return median;\n        }\n    }\n\n    public int getKthElement(int[] nums1, int[] nums2, int k){\n        /**\n        主要思路：要找到第k(k>1)小的元素，那么就取pivot1 = nums1[k/2-1] 和 pivot2 = nums2[k/2-1] 进行比较\n        这里的“/” 表示整除\n        nums1 中小于等于pivot1的元素有 nums1[0..k/2-2] 共计k/2-1个\n        nums2 中小于等于pivot2的元素有 nums2[0..k/2-2] 共计k/2-1个\n        取 pivot = min(pivot1 , pivot2) 两个数组中小于等于 pivot的元素共计不会超过(k/2-1)+(k/2-1) <=k-2个\n        这样pivot本身最大也只能是第k-1小的元素\n        * 如果 pivot = pivot1,那么 nums1[0 .. k/2-1] 都不可能是第 k 小的元素。把这些元素全部 \"删除\",剩下的作为新的 nums1 数组\n         * 如果 pivot = pivot2,那么 nums2[0 .. k/2-1] 都不可能是第 k 小的元素。把这些元素全部 \"删除\",剩下的作为新的 nums2 数组\n        由于我们 \"删除\" 了一些元素（这些元素都比第 k 小的元素要小）,因此需要修改 k 的值,减去删除的数的个数\n         */\n        int length1 = nums1.length, length2=nums2.length;\n        int index1 = 0, index2=0;\n        int kthElemnt=0;\n        while(true){\n            //特殊情况\n            if(index1==length1){//第二种特殊情况，一个数组为空\n                return nums2[index2+k-1];\n            }\n            if(index2==length2){//一个数组为空\n                return nums1[index1+k-1];\n            }\n            if(k==1){ // 第三种情况，k=1\n                return Math.min(nums1[index1], nums2[index2]);\n            }\n            // 正常情况， index1，index2作为起始点，newindex1,newindex2作为比较点 在不停的更新\n            int half = k/2;\n            int newIndex1 = Math.min(index1 + half, length1) -1;// 第一种情况，发生越界，需要记录比较的位置\n            int newIndex2 = Math.min(index2 + half, length2) - 1;\n            int pivot1 = nums1[newIndex1], pivot2=nums2[newIndex2]; //获取两个需要比较的数\n            if(pivot1<=pivot2){\n                // 将两种情况合并\n                k -= (newIndex1 -index1 +1); //两者相减后+1，这才是真正减去的长度\n                index1 = newIndex1+1; //连同比较位置也一同删去了，所以新的开始是 比较位置的后一位\n            } else{\n                k -= (newIndex2-index2+1);\n                index2 = newIndex2+1;\n            }\n        }\n    }\n  \n  \tpublic double findMedianSortedArrays(int[] nums1, int[] nums2) {\n        if (nums1.length > nums2.length) {\n            return findMedianSortedArrays(nums2, nums1);\n        }\n\n        int m = nums1.length;\n        int n = nums2.length;\n        int left = 0, right = m;\n        // median1：前一部分的最大值\n        // median2：后一部分的最小值\n        int median1 = 0, median2 = 0;\n\n        while (left <= right) { // 一直循环找到一个最大的i满足A[i-1]≤B[j]\n            // 前一部分包含 nums1[0 .. i-1] 和 nums2[0 .. j-1]\n            // 后一部分包含 nums1[i .. m-1] 和 nums2[j .. n-1]\n            int i = (left + right) / 2; //二分法,i从区间中间开始\n            int j = (m + n + 1) / 2 - i;//+1的操作将总数为奇数和偶数合并为一种情况\n\n            //nums_im1, nums_i, nums_jm1, nums_j 分别表示 nums1[i-1], nums1[i], nums2[j-1], nums2[j]\n            //当一个数组不出现在前一部分时,对应的值为负无穷,就不会对前一部分的最大值产生影响\n            int nums_im1 = (i == 0 ? Integer.MIN_VALUE : nums1[i - 1]);\n            //当一个数组不出现在后一部分时,对应的值为正无穷,就不会对后一部分的最小值产生影响\n            int nums_i = (i == m ? Integer.MAX_VALUE : nums1[i]);\n            int nums_jm1 = (j == 0 ? Integer.MIN_VALUE : nums2[j - 1]);\n            int nums_j = (j == n ? Integer.MAX_VALUE : nums2[j]);\n\n            if (nums_im1 <= nums_j) {\n                median1 = Math.max(nums_im1, nums_jm1);\n                median2 = Math.min(nums_i, nums_j);\n                left = i + 1;\n            }\n            else {\n                right = i - 1;\n            }\n        }\n        return (m + n) % 2 == 0 ? (median1 + median2) / 2.0 : median1;\n    }\n\n}\n```\n\n```python\nclass Solution(object):\n    # 常规思想\n    def findMedianSortedArrays1(self, nums1, nums2):\n        \"\"\"\n        :type nums1: List[int]\n        :type nums2: List[int]\n        :rtype: float\n        \"\"\"\n        m = len(nums1)\n        n = len(nums2)\n        lens = m+n\n        left, right = -1, -1\n        aStart,bStart = 0,0\n        for i in range(lens//2+1):\n            left = right  # 每次循环将right的值赋值给left\n            # A移动的条件，B遍历到最后 或A<B满足一个\n            if aStart<m and (bStart >= n or nums1[aStart] < nums2[bStart]):\n                right = nums1[aStart]\n                aStart+=1\n            else:\n                right = nums2[bStart]\n                bStart+=1\n        if (lens & 1)  == 0:\n            return (left+right)/2.0\n        else:\n            return right\n          \n          \n    # 第k小数\n    def findMedianSortedArrays(self, nums1, nums2):\n        def getKthElemnt(k):\n            index1, index2 = 0, 0\n            while True:\n                # 特殊情况\n                if index1 == m:\n                    return nums2[index2+k-1]\n                if index2 == n:\n                    return nums1[index1+k-1]\n                if k==1:\n                    return min(nums1[index1], nums2[index2])\n\n                newIndex1 = min(index1 + k//2 -1, m-1)\n                newIndex2 = min(index2 + k//2 -1, n-1)\n                privot1,privot2 =nums1[newIndex1], nums2[newIndex2]\n                if privot1<=privot2:\n                    k-=newIndex2-index1 +1\n                    index1 = newIndex2 + 1\n                else:\n                    k -= newIndex2 - index2 +1\n                    index2 = newIndex2 +1\n\n        m,n = len(nums1), len(nums2)\n        totalLength = m+n\n        if totalLength % 2==1:\n            return getKthElemnt((totalLength+1)//2)\n        else:\n            return (getKthElemnt(totalLength//2)+ getKthElemnt(totalLength//2+1)) /2 \n          \n    # 划分数组\n    def findMedianSortedArrays(self, nums1: List[int], nums2: List[int]) -> float:\n        if len(nums1) > len(nums2):\n            return self.findMedianSortedArrays(nums2, nums1)\n\n\n        infinty = 2**40  # 代表正无穷\n        m, n = len(nums1), len(nums2)\n        left, right = 0, m\n        # median1：前一部分的最大值\n        # median2：后一部分的最小值\n        median1, median2 = 0, 0\n\n\n        while left <= right: # 一直循环找到一个最大的i满足A[i−1]≤B[j]\n            # 前一部分包含 nums1[0 .. i-1] 和 nums2[0 .. j-1]\n            # // 后一部分包含 nums1[i .. m-1] 和 nums2[j .. n-1]\n            i = (left + right) // 2\n            j = (m + n + 1) // 2 - i\n\n\n            # nums_im1, nums_i, nums_jm1, nums_j 分别表示 nums1[i-1], nums1[i], nums2[j-1], nums2[j]\n            # 当一个数组不出现在前一部分时,对应的值为负无穷,就不会对前一部分的最大值产生影响\n            nums_im1 = (-infinty if i == 0 else nums1[i - 1]) # 注意写法与java不同\n            # 当一个数组不出现在后一部分时,对应的值为正无穷,就不会对后一部分的最小值产生影响\n            nums_i = (infinty if i == m else nums1[i])\n            nums_jm1 = (-infinty if j == 0 else nums2[j - 1])\n            nums_j = (infinty if j == n else nums2[j])\n\n\n            if nums_im1 <= nums_j:\n                median1, median2 = max(nums_im1, nums_jm1), min(nums_i, nums_j)\n                left = i + 1\n            else:\n                right = i - 1\n\n\n        return (median1 + median2) / 2 if (m + n) % 2 == 0 else median1\n\n\n```\n\n\n\n#### [](https://leetcode-cn.com/problems/median-of-two-sorted-arrays/)\n\n![](https://i.loli.net/2021/09/15/roqxyuNvdGnAlX7.jpg)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["LeetCode"]},{"title":"Multimodal Emergent Fake News Detection via Meta Neural Process Networks","url":"/2021/09/11/Multimodal-Emergent-Fake-News-Detection-via-Meta-Neural-Process-Networks/","content":"\n# Multimodal Emergent Fake News Detection via Meta Neural Process Networks\n\n基于深度学习的模型在对感兴趣事件的大量标注数据进行训练时表现出较好的性能，而在其他事件上由于领域漂移的影响，模型的性能往往会下降。因此，对于难以获得大规模标签数据集的突发事件假新闻的检测，现有的检测方法面临着巨大的挑战。此外，添加来自新出现的事件的知识需要从头开始构建新的模型或继续微调模型，这对于现实世界的设置来说是不切实际的。\n\nMetaFEND 将元学习(meta learning)和神经过程(np)方法集成在一起, 特别地，提出了标签嵌入模块和硬注意机制，通过处理分类信息和修剪无关帖子来提高效率。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["GNN"]},{"title":"1-两数之和到四数之和","url":"/2021/09/11/1-两数之和到四数之和/","content":"\n# 1-两数之和到四数之和\n\n给定一个整数数组 nums 和一个整数目标值 target，请你在该数组中找出 和为目标值 target  的那 两个 整数，并返回它们的数组下标。\n\n你可以假设每种输入只会对应一个答案。但是，数组中同一个元素在答案里不能重复出现。\n\n你可以按任意顺序返回答案。\n\n \n\n示例 1：\n\n输入：nums = [2,7,11,15], target = 9\n输出：[0,1]\n解释：因为 nums[0] + nums[1] == 9 ，返回 [0, 1] 。\n示例 2：\n\n输入：nums = [3,2,4], target = 6\n输出：[1,2]\n示例 3：\n\n输入：nums = [3,3], target = 6\n输出：[0,1]\n\n\n\n## 两数之和\n\n### 哈希表法\n\n哈希表的方法首先用在了两数之和(无序数组)上, 哈希表的使用最主要的目的就是为了降低时间复杂度, 缩减寻找第二个元素使用的时间(将时间复杂度由O(n)降为O(1)), 其中无序数组是哈希表使用的重要条件, 因为当数组有序后, 我们完全可以直接使用 双指针 的方法来降低时间复杂度, 它的使用比 哈希表 更加方便快捷, 空间复杂度也更低, 所以数组有序之后, 我们应该首选 双指针 的方法.\n\n在使用哈希表的时候, 也有一个很重要的优化点, 就是 遍历两遍哈希表 和 遍历一遍哈希表 的区别. 简单来说就是, 如果我们先将第一个元素放入哈希表中, 然后再寻找第二个元素, 那么我们就需要 遍历两遍哈希表, 如果我们先寻找第二个元素, 之后再将元素放入到哈希表中, 那么就只需要 遍历一遍哈希表.\n\n![](https://i.loli.net/2021/09/11/vUaHFiVBCbOrKlx.jpg)\n\n上面是我们第一次使用哈希表的情况, 第二次使用哈希表就到了 《四数之和II四数组相加》, 首先由于它具有四个独立的数组, 相当于四维空间, 所以我们很难在这么高的空间维度上直接使用 双指针 的方法, 其次它并没有要求 不重复元组 的情况, 这就给了我们使用 哈希表 的可能性, 因为不用担心复杂的去重操作, 但是使用哈希表一般也是两维的空间, 所以我们必须先进行降维操作, 也就是将四个数组进行分组, 由三种结果的时间复杂度来判断, 我们很容易就选择了 两两分组 的情况.\n\n![](https://i.loli.net/2021/09/11/Gi9Cge7pl1Uuhm5.jpg)\n\n之后对于哈希表的使用, 就是两种不同情况的使用了。如果需要直接返回相应数组的下标值, 那是很简单的, 我们只需要将 下标值 当做 哈希表的值 即可。(两数之和中的使用)\n\n```java\npublic int[] twoSum(int[] nums, int target){\n  \tMap<Integer,Integer> map = HashMap<Integer,Integer>();\n  \tfor(int i=0;i < nums.length;i++){\n      \tif(map.containsKey(target - nums[i])){\n          \treturn new int[]{map.get(target-nums[i]), i};\n        }\n      \tmap.put(nums[i], i);\n    }\n  \treturn new int[0];\n}\n```\n\n```python\nclass Solution(object):\n    def twoSum(self, nums, target):\n        \"\"\"\n        :type nums: List[int]\n        :type target: int\n        :rtype: List[int]\n        \"\"\"\n        hashtable = dict()\n        for i,num in enumerate(nums):\n          \tif target - num in hashtable:\n              \treturn [hashtable[target-nums], i]\n            hashtable[num] = i\n        return []\n```\n\n\n\n### 双指针法\n\n对于n数之和, 除了哈希表的方法, 最常用的就是 双指针 的方法了, 上文也提到了, 使用双指针最重要的条件就是数组是有序的, 当然这只是针对n数之和的题型, 对于其他题型, 并不需要要求数组是有序\n\n在n数之和中使用双指针必要条件就是数组是有序的, 这就需要我们根据实际情况来判断 数组是否需要进行排序. 比如在 两数之和 中, 就算使用暴力法也才$O(n^2)$, 但进行排序最快也需要$O(nlogn)$的时间复杂度, 所以对于两数之和来说, 是真的没必要.\n\n但是对于 三数之和 和 四数之和 就很有必要了, 因为它们时间复杂度实在太高了, 最关键的是它们元组的重复情况也比较多, 想利用哈希表进行去重是非常困难的, 最终只能选择将数组排序后使用 双指针 的方法.\n\n#### [167. 两数之和 II - 输入有序数组](https://leetcode-cn.com/problems/two-sum-ii-input-array-is-sorted/)\n\n![](https://z3.ax1x.com/2021/09/11/hxu1ER.png)\n\n#### 两数之和中有序和无序的区别\n\n在无序数组中寻找第二个数就没有多少捷径, 毕竟数组无序, 很多经典的方法都用不上, 最后只能牺牲空间来换取时间, 利用哈希表将空间复杂度增加到了$O(n)$, 从而降低了寻找第二个数的时间复杂度.\n\n但是当数组有序之后, 就能使用一些经典的算法同时仍然保证空间复杂度为O(1), 不需要牺牲空间来换取时间, 比如下面马上介绍的 二分法 和 双指针 方法.\n\n这里给我们提供了一种思维, 那我们是不是也可以将无序数组先进行排序后, 再使用这些经典算法呢? 当然可以这么做, 但对于两数之和来说, 必要性不是太大. 因为最快的排序算法也需要O(nlogn)的时间复杂度, 对于两数之和确实提升也不是太大, 但是对于 三数之和/四数之和 还是挺实用的, \n\n#### 二分法和寻找插入位置的区别\n\n数组有序了，使用二分法寻找第二个数可以将时间复杂度降到$O(nlogn)$ 。\n\n寻找插入位置无论，最终无论是否找到目标值，返回的位置结果都是相同的，而且题中说明数组中无重元素，保证了返回位置的唯一性，所以最终 left == right == mid，返回哪个都无所谓，也并不是需要特殊的将等于目标值这种情况单独写出来。所以代码只讨论了两种情况，最终返回一个值，非常简洁。\n\n本题使用的二分法，首先并没有要求数组无重复元素，其次我们要的是具体的等于目标值的位置，并不是寻找插入位置，所以在找不到的情况下，只能返回[-1,-1]。首先的返回结果就有了两种情况.\n\n其次由于有重复元素的存在, 若直接使用之前的只讨论两种情况的二分法是会出错的, 这里必须要讨论三种情况, 且在相等的情况下直接返回正确的结果, 在找不到的情况下返回 [-1, -1].\n\n本题另外的一个小的注意点是: 返回的下标从1开始, 只要在原本的返回结果上+1就可以了.\n\n还有一个注意点是, 为了避免重复寻找,在寻找第二个数时,只在第一个数的右侧寻找, 也就是left = i+1.\n\n```python\nclass Solution(object):\n    # 二分法\n    def twoSum(self, numbers, target):\n        \"\"\"\n        :type numbers: List[int]\n        :type target: int\n        :rtype: List[int]\n        \"\"\"\n        n = len(numbers)\n        for i in range(n):\n            left, right = i+1, n  # 采用左闭右开区间[left, right), left+1避免重复\n            while left<right:\n                mid = (right - left) //2 + left; # 防止溢出\n                if numbers[mid] == target - numbers[i]: # 数组中存在重复元素，必须判断相等\n                    return [i+1, mid+1]\n                elif numbers[mid] > target - numbers[i]:\n                    right = mid # 右开，真正右端点为mid-1\n                else:\n                    left = mid + 1 # 左闭，所以小+1\n        return [-1, -1]\n    # 双指针\n    def twoSum1(self, numbers, target):\n        low, high =0, len(numbers-1)\n        while low<high:\n            total = numbers[low] + numbers[high]\n            if total == target:\n                return [low+1, high+1] # 返回下标从1开始\n            elif total<target:\n                low+=1\n            else:\n                high-=1\n```\n\n```java\nclass Solution {\n    // 二分法\n    public int[] twoSum(int[] numbers, int target) {\n        for(int i=0;i<numbers.length;i++){\n            int left = i+1, rigth = numbers.length;  // 采用左闭右开区间[left,right),left+1避免重复\n            while(left<right){\n                mid = left + right /2 + left; // 防止溢出\n                if(numbers[mid] == target - numbers[i]){ // 数组中存在重复元素,必须判断相等\n                    return new int[]{i+1, mid+1} ; // 返回的下标从1开始,都+1\n                }else if(numbers[mid] > target-numbers[i]){ //中点大于目标值,在左侧\n                    right = mid;//右开，真正右端点为mid-1\n                }else{\n                    left = mid+1; // 左闭 +1\n                }\n            }\n        }\n        return new int[]{-1,-1};\n    }\n    // 双指针法\n    public int[] twoSum2(int[] numbers, int target){\n        int low = 0, high = numbers.length-1;\n        while (low < high) { // 指针移动条件\n            int sum = numbers[low] + numbers[high];\n            if (sum == target) {\n                return new int[]{low + 1, high + 1}; // 返回下标从1开始\n            } else if (sum < target) {\n                ++low;\n            } else {\n                --high;\n            }\n        }\n        return new int[]{-1, -1};\n    }\n}\n```\n\n\n\n## 三数之和\n\n#### [15. 三数之和](https://leetcode-cn.com/problems/3sum/)\n\n![](https://i.loli.net/2021/09/12/6x3jq9QeCmGfa2B.jpg)\n\n难点在于题目要求的不重复的三元组，它的可重复情况是非常多的，无法像两数之和那样，只要将第一个元素放入哈希表中，就可以轻松解决元素重复的问题了。\n\n对于三数之和，即使使用哈希表去重，它的操作也是比较困难的，所以不能简单的使用三重循环枚举所有的三元组，然后用哈希表去重，这样工作量比较大。\n\n因此必须换一种做法，从源头上解决元素重复问题，如果给定数组是有序的，那么其中可重复的情况就是可控的了，处理起来也简单，所以先把数组从小到大排序，随后用普通的三重循环就可。\n\n然后就会发现，重复的元素都是相邻元素，只要保证每一重循环时，相邻两次枚举的元素不是相同的元素，这样就可以避免元组重复的情况了。\n\n### 双指针\n\n使用普通的三层循环确实也能解决问题, 但是 $O(n^3)$ 的时间复杂度也确实太高了, 这时我们想到了在 有序数组的两数之和 中使用的双指针的方式, 虽然现在是三数之和, 但当我们正常遍历了第一层循环之后, 剩下的两个数不就形成了 有序数组的两数之和 了吗? 所以我们只要 保持第二重循环不变, 而将第三重循环变成一个从数组最右端开始向左移动的指针, 同时加上上述讨论的避免重复的条件, 最终代码就完成了.\n\n```java\nclass Solution {\n    public List<List<Integer>> threeSum(int[] nums) {\n        List<List<Integer>> res = new ArrayList<>();\n        if(nums.length==0 ||  (nums[0]==0 && nums.length==1))  return res;\n\n        Arrays.sort(nums);\n\n       \n        // 枚举a\n        for(int first=0;first<nums.length;first++){\n            //需要和上一次枚举的数不同\n            if(first>0 && nums[first] == nums[first-1]){\n                continue;\n            }\n            // c对应的指针初始指向数组的最右排\n            int third = nums.length-1;\n            int target = -nums[first];\n            //枚举b\n            for(int second= first+1 ;second<nums.length;second++){\n                // 需要和上一次枚举不同\n                if(second > first+1 && nums[second] == nums[second-1]) {\n                    continue;\n                }\n                // 需要保证b指针在c指针的左侧\n                while(second < third && nums[second]+nums[third] > target){\n                    --third;\n                }\n                //如果指针重合，后续也不会满足条件，可以退出循环\n                if(second==third) break;\n                if (nums[second] + nums[third] == target){\n                    res.add(Arrays.asList(nums[first],nums[second],nums[third]));\n                }\n            }\n\n        }\n        return res;\n\n    }\n}\n```\n\n\n\n```python\nclass Solution(object):\n    def threeSum(self, nums):\n        \"\"\"\n        :type nums: List[int]\n        :rtype: List[List[int]]\n        \"\"\"\n        res = list()\n        if len(nums) == 0: return res\n        nums.sort()\n\n        # 枚举a\n        for first in range(len(nums)):\n            if first>0 and nums[first] == nums[first-1]:\n                continue\n            thrid = len(nums) -1\n            target = -nums[first]\n            for second in range(first+1, len(nums)):\n                if second> first+1 and nums[second] == nums[second-1]:\n                    continue\n                while second<thrid and nums[second] + nums[thrid] > target:\n                    thrid-=1\n                if second==thrid:\n                    break\n                if nums[second]+nums[thrid] == target:\n                    res.append([nums[first], nums[second], nums[thrid]])\n        return res\n        \n```\n\n## 四数之和\n\n#### [18. 四数之和](https://leetcode-cn.com/problems/4sum/)\n\n![](https://i.loli.net/2021/09/13/mxBF4fzwX9Crky5.jpg)\n\n### 思想同三数之和：排序+双指针\n\n四数之和 本质上 和三数之和一样的，由于都有大量的重复元素在，都不能使用哈希表进行简单的去重，都需要先进行排序后才方便遍历处理，同时为了优化时间复杂度，再加上双指针方法的使用，如果只是想简单实现的话，那么在三数之和上直接多加一重循环。但在代码上不同点在于：并非只是简单的家一重循环而已，而是进行了优化处理。\n\n因为四数之和相比较于三数之和来说，情况更加复杂，时间复杂度也比较高，而且这个时间复杂度通过算法降下来很难。只能通过对代码的优化，直接减少大量不必要的遍历情况，从而来缩短代码的运行时间。\n\n对于代码的优化主要分为两大块：一部分是为了避免出现重复的四元组，在遍历上的优化，这部分和三数之和相似，不过更复杂。\n\n首先是对前两重循环进行的去重操作, 当 i 或者 j 的值与前面的值相等时忽略, 之后又对 双指针 进行了去重操作, 这里有个重要的注意点: 一定注意代码中是 先进行了指针的移动还是先进行了去重的比较, 对于不同的顺序, 比较的元素是完全不同的. 如果先进行了指针的移动, 对于左指针来说, 需要比较的元素就是 当前元素和前面的一个元素, 如果是先进行去重的比较, 那比较的元素就是 当前元素和后面的一个元素, 再进行指针的移动. 对于右指针的情况正好是完全相反的.\n\n第二部分就是在循环遍历中先通过计算特定的四个数之和, 以此来判断接下来的循环操作情况.\n\n比如 在确定第一个数 nums[i] 之后, 如果nums[i]+nums[i+1]+nums[i+2]+nums[i+3]>target, 也就是此时的最小的4个数之和都大于target, 说明此时剩下的三个数无论取什么值, 四数之和一定大于 target, 因此直接退出第一重循环就可以了\n\n在确定第一个数 nums[i] 之后,如果nums[i]+nums[n−3]+nums[n−2]+nums[n−1]<target, 也就是此时的最大的4个数之和都小于target, 说明此时剩下的三个数无论取什么值, 四数之和一定小于 target,因此第一重循环直接进入下一轮, 枚举nums[i+1], 使用 continue 关键字.\n\n对于第二层循环也是同样的判断方法, 通过这两层循环的判断优化, 能直接删去大量的不满足情况, 减少代码运行的时间. 这也能给我们带来启发, 在算法层面不能进行优化的时候, 可以选择对代码的细节进行优化, 同样可以起到节省时间的效果.\n\n```python\nclass Solution(object):\n    def fourSum(self, nums, target):\n        \"\"\"\n        :type nums: List[int]\n        :type target: int\n        :rtype: List[List[int]]\n        \"\"\"\n        res = list()\n        length = len(nums)\n        if not nums or length<4:\n            return res\n\n        nums.sort()\n        # 定义4个指针i,j,left,right  i从0开始遍历,j从i+1开始遍历,留下left和right作为双指针\n        for i in range(length - 3):\n            if i > 0 and nums[i] == nums[i - 1]: # 当i的值与前面的值相等时忽略\n                continue\n            # 获取当前最小值,如果最小值比目标值大,说明后面越来越大的值根本没戏\n            if nums[i] + nums[i + 1] + nums[i + 2] + nums[i + 3] > target:\n                break # 这里使用的break,直接退出此次循环,因为后面的数只会更大\n            # 获取当前最大值,如果最大值比目标值小,说明后面越来越小的值根本没戏,忽略\n            if nums[i] + nums[length - 3] + nums[length - 2] + nums[length - 1] < target:\n                continue # 这里使用continue,继续下一次循环,因为下一次循环有更大的数\n            # 第二层循环j,初始值指向i+1\n            for j in range(i + 1, length - 2):\n                if j > i + 1 and nums[j] == nums[j - 1]: # 当j的值与前面的值相等时忽略\n                    continue\n                if nums[i] + nums[j] + nums[j + 1] + nums[j + 2] > target:\n                    break\n                if nums[i] + nums[j] + nums[length - 2] + nums[length - 1] < target:\n                    continue\n                left, right = j + 1, length - 1\n                # 双指针遍历,如果等于目标值,left++并去重,right--并去重,当当前和大于目标值时right--,当当前和小于目标值时left++\n                while left < right:\n                    total = nums[i] + nums[j] + nums[left] + nums[right]\n                    if total == target:\n                        res.append([nums[i], nums[j], nums[left], nums[right]])\n                        left += 1 # left先+1之后,和它前面的left-1进行比较,若后+1,则和它后面的left+1进行比较\n                        while left < right and nums[left] == nums[left - 1]:\n                            left += 1\n                        right -= 1\n                        while left < right and nums[right] == nums[right + 1]:\n                            right -= 1   \n                    elif total < target:\n                        left += 1\n                    else:\n                        right -= 1\n        return res\n```\n\n\n\n```java\nclass Solution {\n    public List<List<Integer>> fourSum(int[] nums, int target) {\n        List<List<Integer>> res = new ArrayList<>();\n        if(nums==null || nums.length==0) return res;\n        int length=nums.length;\n\n        Arrays.sort(nums);\n\n        // 定义4个指针， i,j,left,right  i从0开始遍历，j从i+1开始遍历，留下left和right作为双指针\n        for(int i=0;i<length - 3;i++){\n            if(i > 0 && nums[i] == nums[i-1]) continue;\n\n            // 获取当前最小值，如果最小值比目标值大，说明后面越来越大的值根本没戏\n            if(nums[i] + nums[i+1] + nums[i+2] +nums[i+3] > target){\n                break; // 这里使用的break，直接退出此次循环，因为后面的数只会更大\n            }\n\n            // 获取当前最大值，如果最大值比目标值小，说明后面的值越来越小\n            if(nums[i] + nums[length-3] + nums[length-2] + nums[length-1] < target){\n                continue; // 继续下一次循环，因为下一次循环有更大的数\n            } \n\n            // 第二层循环j，初始值指向i+1\n            for(int j=i+1; j<length-2;j++){\n                if(j>i+1 && nums[j] == nums[j-1]){  // 当j的值与前面的值相等时忽略\n                    continue;\n                }\n\n                if(nums[i] + nums[j] + nums[j+1] + nums[j+1] > target) {\n                    break;\n                }\n\n                if(nums[i] + nums[j] + nums[length-2] + nums[length-1] < target){\n                    continue;\n                }\n\n                int left = j+1, right=length-1;\n                //双指针遍历，如果等于目标值，left++并去重，right--并去重，当当前和大于目标值时right-- 否则left++\n                while(left < right){\n                    int sum = nums[i] + nums[j] + nums[left] + nums[right];\n                    if(sum==target){\n                        res.add(Arrays.asList(nums[i], nums[j], nums[left], nums[right]));\n                        left++; // left先+1之后，和它前面的left-1进行比较，若后+1，则和它后面的left+1进行比较\n                        while(left < right && nums[left]==nums[left-1]){\n                            left++;\n                        }\n                        right--;\n                        while(left<right && nums[right]== nums[right+1]){\n                            right--;\n                        }\n                    }else if(sum<target){\n                        left++;\n                    }else{\n                        right--;\n                    }\n\n                }\n\n            }\n            \n        }\n        return res;\n    }\n}\n```\n\n## 四数之和二\n\n#### [454. 四数相加 II](https://leetcode-cn.com/problems/4sum-ii/)\n\n![](https://i.loli.net/2021/09/14/met83ga7UN9wGL2.jpg)\n\n### 维数太高，分治处理\n\n此题一看似乎和四数之和差不多，但本质上却有很大的区别，首先无论是三数之和还是四数之和，它们都是在一个数组上的操作，本质上都是一维的，同时它们都要求找到不重复的元组，这就限制了我们不能简单的使用哈希表进行去重操作。最终只能将数组排序后使用双指针。\n\n但本题是四个独立的数组，相当于是四个维度，想在四个维度上使用双指针的方法显然不现实。同时此题只要求我们找到所有4个元素的和为0的元组个数即可，并没有要求是不重复的元组，这样就简单了很多，也是可以使用哈希表法。\n\n此题是在使用哈希表的时候，会遇到如下三种情况：\n\n- hashmap存一个数组，如A。然后计算三个数组之和，如BCD。时间复杂度为：$O(n)+O(n^3)=O(n^3)$\n- hashmap存三个数组之和，如ABC。然后计算一个数组，如D。时间复杂度为：$O(n^3)+O(n) = O(n^3)$\n- hashmap存两个数组之和，如AB，然后计算两个数组之和，如CD，时间复杂度为：$O(n^2)+O(n^2) = O(n^2)$\n\n根据事件复杂度来看，选第三种情况\n\n确定了使用的方法(哈希表)以及分类方法(两两分组)。此题和两数之和中使用的哈希表有很大的区别，在两数之和中，我们需要的是满足条件的下标值，所以在哈希表中存的是元组的下标值。\n\n但在本题中，我们需要的是元组个数，所以哈希表中的值应存取出现的次数，这就有点难度。使用java map中的merge或getOrDefault\n\n```java\nclass Solution {\n    public int fourSumCount(int[] A, int[] B, int[] C, int[] D) {\n        int res = 0;\n        if(A.length==0) return res;\n\n        Map<Integer,Integer> countAB = new HashMap<>();\n        for(int u: A){\n            for(int v:B){\n                // 存储u+v的结果，不存在赋值为1，存在在原来基础上+1\n                // 另一种表达countAB.merge(u+v, 1, (old,new_)-> old+1);\n                countAB.put(u+v, countAB.getOrDefault(u+v, 0) + 1);\n            }\n        }\n\n        for(int u: C){\n            for(int v:D){\n                if(countAB.containsKey(-u-v)){\n                    res+=countAB.get(-u-v);\n                }\n            }\n        }\n        return res;\n\n    }\n}\n```\n\n```python\nclass Solution(object):\n    def fourSumCount(self, A, B, C, D):\n        \"\"\"\n        :type nums1: List[int]\n        :type nums2: List[int]\n        :type nums3: List[int]\n        :type nums4: List[int]\n        :rtype: int\n        \"\"\"\n        # Counter类是dict()子类，用于计数可哈希对象\n        # 它是一个集合，元素字段键(key) 一样存储，他们的技术存储为值\n        countAB = collections.Counter(u+v for u in A for v in B)\n        ans = 0 \n        for u in C:\n            for v in D:\n                if -u-v in countAB:\n                    ans+=countAB[-u-v]\n        return ans\n```\n\n\n\n##  n数之和方法总结\n\n对于两数之和，看它是否有序的，如果是无序的就用哈希表法，如果是有序的可以使用双指针。\n\n对于一个数组上的三数之和、四数之和等，无论数组是否有序，都排序后使用双指针法\n\n对于多个数组之和的情况，首先对它们进行分组来实现降维操作，一般来说分为两个相等的小组，之后再使用哈希表法。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["LeetCode"]},{"title":"Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks","url":"/2021/09/10/Model-Agnostic-Meta-Learning-for-Fast-Adaptation-of-Deep-Networks/","content":"\n# Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks\n\nMAML一种模型无关的元学习算法，即它可以与任何经过梯度下降训练的模型兼容，并适用于各种不同的学习问题，包括分类、回归和强化学习。\n\n元学习的目标是在各种学习任务上训练一个模型，它只需要少量的训练样本就可以解决新的学习任务。\n\nMAML模型的参数被显式地训练，使得少量的梯度步骤和来自新任务的少量训练数据将在该任务上产生良好的泛化性能，易于微调。\n\n核心思想是训练模型的初始参数，以便在参数通过一个或多个梯度步骤更新后，模型在新任务上具有最大性能，该梯度步骤使用来自该新任务的少量数据计算。\n\n这种快速灵活的学习是一种挑战，因为模型必须将其先前的经验与少量新信息相结合，同时避免过拟合新数据。此外，先验经验和新数据的形式将取决于任务。因此，为了获得最大的适用性，learn to learn (或元学习)的机制应该适用于任务和完成任务所需的计算形式。\n\n## Model-Agnostic Meta-Learning\n\n目标是训练能够实现快速适应的模型，这是一种通常被形式化为few-shot learning的问题设置。\n\n### Meta-Learning Problem Set-Up\n\nfew-shot learning元学习的目标是训练一个只使用几个数据点和训练迭代就能快速适应新任务的模型。\n\n实际上，元学习问题将整个任务视为训练示例。\n\n定义一个模型为f，它将观测值 $x$ 映射到输出 $a$ 。在元学习期间，模型被训练成能够适应大量或无限数量的任务。\n\n定义每个任务 $T =  \\{L(x_1,a_1,...,x_H,a_H) , q(x_1), q(x_{t+1}|x_t,a_t ), H\\}$\n\n$L$ 是loss function，初始观测 $q(x_1)$ 的分布，通过$q(x_{t+1}|x_t,a_t)$ 转换分布，事件长度$H$\n\n在独立同分布的有监督学习问题中，长度H=1。该模型可以通过在每个时间步 $t$ 选择一个输出来产生长度为 $H$ 的样本。Loss函数提供任务特殊的反馈。\n\n在元学习场景中，我们考虑希望模型能够适应的任务$p(T)$上的分布。在 K-shot 学习设置中，该模型被训练成仅从$q_i$ 中提取的K个样本和由任务 $T_i$ 生成的反馈 $L_{T_i}$ 中学习 从$p(T)$中提取的新任务$T_i$。\n\n在元训练过程中，从 $p(T)$ 中抽取一个任务 $T_i$，用K个样本训练模型，并从$T_i$中相应的$L_{T_i}$ 损失反馈，然后在$T_i$的新样品上进行测试。然后，通过考虑来自 $q_i$ 的新数据上的测试误差如何相对于参数变化来改进模型 $f$。\n\n实际上，采样任务 $T_i$ 上的测试误差充当元学习过程的训练误差。在元训练 (meta-training)结束时，从$p(T)$采样新任务，从K个样本中学习后，通过模型的性能来衡量元性能(meta-performance)。一般来说，元测试 (meta-testing) 任务是在元训练 (meta-training) 期间执行的。\n\n### A Model-Agnostic Meta-Learning Algorithm\n\n我们怎样才能鼓励这种通用型代表的出现呢？例如，神经网络可能学习广泛适用于 $p(T)$ 中所有任务的内部特征，而不是单个任务。\n\nMAML对这个问题采取了明确的方法：由于模型将在新任务上使用基于梯度的学习规则进行微调，因此我们的目标是学习一个模型，使此基于梯度的学习规则能够在从$p(T)$提取的新任务上取得快速进展，而不会过拟合。\n\n实际上，我们的目标是找到对任务变化敏感的模型参数，以便参数的微小变化将在沿损失梯度方向改变时，对从 $p(T)$ 得出的任何任务的损失函数产生较大的改进。如下图：\n\n![](https://i.loli.net/2021/09/11/UE2pXjfwd81z4hb.png)\n\n我们对模型的形式不做任何假设，只是假设它由一些参数向量 $θ$ 参数化，并且损失函数在 $θ$ 中足够平滑，因此我们可以使用基于梯度的学习技术。\n\n定义这个参数化的模型为$f_{\\theta}$ , 参数为$\\theta$。 当适应一个新的任务$T_i$时，模型的参数 $θ$ 变为 $θ_i'$。\n\n使用任务 $T_i$ 上的一个或多个梯度下降更新来计算更新后的参数向量 $θ_i'$。例如，当使用一个梯度更新时:\n$$\n\\theta_i' = \\theta - \\alpha ▽_{\\theta}L_{T_i}(f_{\\theta})\n$$\n步长 $α$ 可以固定为超参数。\n\n通过优化 $f_{θ_i'}$相对于从 $p(T)$ 采样的任务的 $θ$ 的性能，来训练模型参数。更具体地说，元目标如下：\n$$\nmin_{\\theta} \\sum_{T_i\\sim p(T)} L_{T_i}(f_{\\theta_i'}) = \\sum_{T_i\\sim p(T)} L_{T_i}(f_{\\theta - \\alpha ▽_{\\theta}L_{T_i}(f_{\\theta})})\n$$\n注意，元优化 （meta-optimization）是在模型参数θ上执行的，而目标是使用更新后的模型参数 $θ'$来计算的。实际上，MAML提出的方法旨在优化模型参数，使得新任务上的一个或少量梯度步骤将在该任务上产生最有效的行为。\n\n跨任务的元优化通过随机梯度下降（SGD），模型参数θ更新如下：\n$$\n\\theta \\leftarrow \\theta - \\beta ▽_{\\theta} \\sum_{T_i \\sim p(T)} L_{T_i}(f_{\\theta_i’})\n$$\n$β$ 是元步长。下图概述了一般情况下完整的算法：\n\n![](https://i.loli.net/2021/09/11/WxXC1fqEFamYi6n.png)\n\n输入任务不同分布的任务$p(T)$ 和两个学习步长超参数 $\\alpha, \\beta$ ,并且随机初始化模型参数。\n\n第一层循环，遍历每个任务 $T_i \\sim p(T)$ 中采样的batch\n\n第二层循环，在每个任务 $T_i$  中 评估关于 K 个样本的 $∇_θ L_{T_i}(f_θ)$  使用梯度下降计算自适应参数：$θ_i' = θ − α∇_θL_{T_i}(f_θ)$\n\n然后根据所有任务上的损失梯度更新模型的参数  $\\theta \\leftarrow \\theta - \\beta ▽_{\\theta} \\sum_{T_i \\sim p(T)} L_{T_i}(f_{\\theta_i’})$\n\nMAML元梯度更新涉及通过梯度的梯度, 在计算上，这需要额外的反向传播 $f$ 来计算Hessian-vector乘积。\n\n### Species of MAML\n\n监督学习和强化学习的元学习算法的具体实例。他们在损失函数的形式以及数据由任务生成并呈现给模型的方式上不同。\n\n#### Supervised Regression and Classification\n\n![](https://i.loli.net/2021/09/11/w39XVGQOYhamNUk.png)\n\nFew-shot 学习在监督任务领域得到了很好的研究，其目标是仅从该任务的几个输入/输出对中学习新函数，使用类似任务的先前数据进行元学习。\n\n我们可以定义horizon H=1并将timestep下标放到 $x_t$上，因为模型接受单个输入并生成单个输出，而不是一系列输入和输出。\n\n任务 $T_i$ 从 $q_i$生成K个观测值 $x$ ，并且任务损失由模型的输出 $x$ 与该观测值和任务对应的目标值 $y$ 之间的误差表示。\n\n用于监督分类和回归的两种常见损失函数是交叉熵和均方误差(MSE)，对于使用均方误差的回归任务，损失形式为：\n$$\nL_{T_i}f(\\phi) = \\sum_{x^{(j)},y^{(y)} \\sim T_i} ||f_{\\phi}(x^{(j)}) - y^{(j)}||_2^2\n$$\n其中 $x^{(j)}, y^{(j)}$ 是任务$T_i$的一对输入输出，类似地，对于具有交叉熵损失的离散分类任务，损失采取以下形式：\n$$\nL_{T_i}f(\\phi)= \\sum_{x^{(j)},y^{(y)} \\sim T_i} y^{(j)} log f_{\\phi}(x^{(j)}) + (1-y^{(j)})log(1-f_{\\phi}(x^{(j)}))\n$$\n\n#### Reinforcement Learning\n\n![](https://i.loli.net/2021/09/11/Jx6hAWtNTHg9B2O.png)\n\n在强化学习（RL）中，Few-shot 元学习的目标是使模型能够仅使用测试设置中的少量经验快速获取新测试任务的策略。\n\n例如，一个模型可能会学习如何快速找到如何导航迷宫，以便在面对新的迷宫时，只需几个样本就可以确定如何可靠地到达出口。\n\n每个RL 任务$T_i$ 包含一个初始化状态分布$q_i(x_1)$ 和一个转换分布 $q_i(x_{t+1}| x_i,a_t)$ , 损失函数为 $L_{T_i}$\n\n因此，整个任务是一个具有horizon H的马尔可夫决策过程（MDP），在该过程中，学习者可以查询有限数量的样本轨迹以进行少量镜头学习。\n\nMDP的任何方面都可以在 $p(T)$ 中的任务之间改变。正在学习的模型 $f_θ$ 是一个策略，它从状态 $x_t$映射到每个操作上的分布时间步长 $t∈\\{1，.，H\\}$。任务$T_i$ 的模型的损失:\n$$\nL_{T_i}(f_\\phi) = -\\mathbf{E} _{x_t,a_t\\sim f_{\\phi},q_{T_i}} [\\sum_{t=1}^H R_i(x_t, a_t)]\n$$\n\n## 实验\n\nMAML能实现新任务的快速学习吗？\n\nMAML是否可以用于多个不同领域的元学习，包括有监督的回归、分类和强化学习？\n\n用MAML学习的模型可以通过额外的渐变更新和/或示例继续改进吗？\n\n\n\n![](https://i.loli.net/2021/09/11/NRBL1JGZyIUeY9C.png)\n\n![](https://i.loli.net/2021/09/11/myPCEawdMIN1Yt2.png)\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["context detection"]},{"title":"Dynamically Addressing Unseen Rumor via Continual Learning","url":"/2021/09/07/Dynamically-Addressing-Unseen-Rumor-via-Continual-Learning/","content":"\n# Dynamically Addressing Unseen Rumor via Continual Learning\n\n谣言往往与新出现的事件联系在一起，因此，处理没见过的谣言的能力对于谣言真实性分类模型至关重要。\n\n以前的工作通过改进模型的泛化能力来解决这个问题，假设即使在新的事件爆发之后，模型也会保持不变。\n\n在这项工作中，提出了一种解决方案，以根据谣言域创建的动态不断更新模型。\n\n与这种新方法相关的最大技术挑战是由于新的学习而灾难性地忘记了以前的学习。\n\n作者采用持续学习策略来控制新的学习，以避免灾难性的遗忘，并提出了一种可以联合使用的额外策略来加强遗忘的缓解。\n\n谣言检测任务两个重要难点：\n\n- 处理没见过的谣言的能力 (处理训练阶段未见的新谣言)\n\n- 谣言早发现\n\n此前的方法试图通过关注静态设置中的模型泛化通用性来解决这一挑战，如下图a。目标是提高模型$M_{\\theta_{t=1}}$ 在不更新模型的情况下，在看不见的话题领域(“古尔利特”和“普京失踪”)上表现好。然而，增强模型的泛化能力是一个困难的问题，特别是对于总是引入新主题和词汇的任务。\n\n![](https://i.loli.net/2021/09/07/yUqli7RJVG489HX.png)\n\n因此，作为另一种解决方案，通过训练一个能够不断适应新出现的谣言的分类器，在动态设置中对未见过谣言进行分类。如上图b。\n\n通过这种方式，可以及时发现虚假谣言，而不必考虑可见谣言和不可见谣言之间的巨大分布差距。\n\n持续学习想解决的主要挑战是在学习新的Domain时灾难性地忘记以前学习的Domain。\n\n这篇文章作者采用了基于排练的(rehearsal- based)持续学习(CL)策略，利用以前遇到的领域的情景记忆来约束未来的学习，并提出了一种简单的技术TTOKENS，可以联合使用来进一步减少灾难性遗忘。\n\n## 方法\n\n### Task Definition\n\n谣言真实性分类是识别给定谣言文本 $X$ 是真、假还是无法核实的任务。\n\n谣言数据集及其对应的标签为集合 $D = \\{(X_i,y_i,Rm)\\}_i^N$ 其中 $y\\in\\{True, False,Unverifiabel\\}$\n\nRM是谣言域标签，N是数据集的大小。\n\n主要目标是训练一个谣言真实性分类模型M，该模型可以从传言领域流中学习，通过时间t而不会发生灾难性的遗忘。 \n\n将谣言域流定义为 $S=\\{D_1,···,D_T\\}$，其中 $D_t$ 表示流中第 $t$ 个谣言域的数据集，$T$ 是流的长度。\n\nT也等于时间戳的长度和谣言域的数量。\n\n在每个时间戳，使用一个新的谣言域数据集 $D_t$ 来顺序训练模型 $M$，并用时间 $k$ 处的谣言域表示训练后的模型参数，$θ_{t=k}$。\n\n### Base Model\n\nBERT-BASE 编码器和一个分类层。给定输入谣言 $X=x_1,···,x_m$，该模型计算：\n$$\nH= BERT([CLS] +X)\n$$\n\n$$\nP(y|X) = Softmax(WH_{[CLS]}+b)\n$$\n\n$H_{[cls]}$是 $[cls]$ 标记的嵌入,可训练参数为 $θ=[W，b]$ \n\n在训练期间，冻结编码层，并且仅使用交叉熵损失来训练分类器参数θ：\n$$\nL_{\\theta_t}(D_t) = -\\sum_j^{D_t}log P(y|X)\n$$\n\n### Rehearsal-based CL Strategies\n\n基于排练的CL策略依赖于“episodic memory” $M$ 来存储先前遇到的样本。$M$ 被定期重播，以避免灾难性遗忘，并加强过去知识和新知识之间的联系。\n\n#### REPLAY (Robins, 1995)\n\nCL的Memory M的一个简单利用是扩展当前任务数据 $D_t$，并使用 $L_{θ_t}(D_t+M)$来优化模型的参数。基本上，它可以被视为一个数据效率高的多任务框架，它只利用受Memory M大小限制的数据集的一小部分。\n\n#### Gradient Episodic Memory (GEM) (Lopez- Paz and Ranzato, 2017)\n\n另一种利用方法是使用当前域样本来约束梯度更新，使得Memory M中的样本的损失永远不会增加：\n$$\nL_{\\theta_t} s.t. L_{\\theta_t}(M) \\le L_{\\theta_{t-1}} (M)\n$$\nGEM通过随模型参数数量变化的二次规划求解器计算梯度约束。\n\n### Task-Specific Tokens (TTOKENS)\n\n各种工作表明，对大型预训练语言模型的输入上下文对模型的结果有巨大影响。换句话说，可以利用LM/MLM的这种上下文相关特性来有意地控制/区分不同域的表示。为了应用该策略，对输入文本 $X$ 进行预处理以从其对应的谣言域标签 Rm开始。形式上，给定第 $t$ 传言域Rm：\n$$\nH = BERT([CLS] + Rm + X)\n$$\n该策略可以很容易地与其他CL策略一起使用，因为它是在数据处理步骤中完成的。\n\n## 实验\n\n数据集PHEME的一个显著特点是根据谣言事件进行分类。总共有9个不同的事件/域，更多详细信息如表1所示。\n\n![](https://i.loli.net/2021/09/07/eyQsigEztvZm8Bf.png)\n\n以前的工作在静态设置中利用了这个数据集，其中8个域被组合成一个训练集，剩下的1个域用作单个不可见的测试域。在这项工作中，本文的任务是在动态设置中进行的。为了与动态设置结合，将PHEME的每个域视为单独的特定于域的数据集$D_T$，并以0.4/0.1/0.5的比率将它们拆分为Train/dev/test。\n\n### Evaluation Method\n\n在完成对第k个领域的学习后，对其在所有T领域测试集上的测试性能进行了评估。\n\n这一步的结果是矩阵 $R \\in \\mathbf{R}^{T×T}$，其中 $R_{i,j}$ 是在观察到来自第 $i$ 域的最后一个样本之后，模型在第 $j$ 域上的测试分类精度。\n\n基于此矩阵，计算了两个特定于CL的度量：\n\n- Avg. Accuracy (ACC) 对于了解模型在学习新领域时性能如何变化很有用。此指标的计算方法如下：\n\n$$\nACC = \\frac {1}{T}\\sum_{i=1}^T R_{T,i}\n$$\n\n请注意，在流的末尾，t=9，即Avg. Accuracy (ACC) 正好是所有任务的平均精确度。\n\n- Backward Transfer (BWT) 是一种用于测量新学习任务对先前学习任务影响的CL方法。此指标的计算公式为：\n\n$$\nBWT = \\frac{1}{T-1} \\sum_{i=1}^{T-1} R_{T,i} - R_{i,i}\n$$\n\n负的BWT表明模型灾难性地忘记了以前的任务。\n\n### model\n\n两个没有CL策略的基线模型，并在我们的动态设置中进行了评估。BERT-BL是指在PHEME数据集上微调的BERT基础模型。M2-BL是指对统一错误信息表示进行微调的另一个基线，该基线被证明能有效提高未发现领域的泛化性。\n\n![](https://i.loli.net/2021/09/07/Xcvu63ni5SpVJoQ.png)\n\n对于作者提出的模型，作者用上文提到的CL策略的各种组合来训练基于BERT的分类器，以评估所采用的策略在对不可见领域的鲁棒性方面的有效性。\n\n\n\n\n\n\n\n![](https://i.loli.net/2021/09/07/PUig5Oe9qcIFbjR.png)\n\n模型性能随时间变化的可视化分析。用于Replay的ACC热力图(A)没有TTOKENS和(B)有TTOKENS。比较(A)和(B)之间的每一列，使用TTO-KENS的(B)列通常显示较深的阴影，这代表更好的性能。\n\n对于TTOKENS成功背后的推理，作者有两个假设：1）TTOKENS隐含地充当了领域差异的信号，并鼓励模型为每个领域学习单独的知识。或者，2）TTOKENS作为一个良好的开端“上下文”，帮助基于LM的编码器在必要时将输入编码为更可分离的——这意味着，来自相同域的输入在向量空间中比来自不同域的输入更接近。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["context detection"]},{"title":"Rumor Detection on Social Media with Bi-Directional Graph Convolutional Networks","url":"/2021/09/04/Rumor-Detection-on-Social-Media-with-Bi-Directional-Graph-Convolutional-Networks/","content":"\n# Rumor Detection on Social Media with Bi-Directional Graph Convolutional Networks\n\nhttps://github.com/TianBian95/BiGCN\n\n从社交媒体上如此海量的信息中识别谣言正成为一项艰巨的挑战。\n\n一些深度学习方法被应用于通过谣言传播的方式来发现谣言，如递归神经网络(RvNN)等。然而，这些深度学习方法只考虑了深度传播的特点，而忽略了谣言检测中广泛分散的结构。\n\n实际上，propagation(传播)和dispersion(扩散)是谣言的两个关键特征。\n\n作者提出一种新的双向图模型，称为双向图卷积网络(Bi-GCN)，通过对谣言的自上而下和自下而上的传播进行操作，来探索这两个特性。\n\n- 利用具有自上而下谣言传播有向图的GCN来学习谣言传播模式\n- 具有相反方向的谣言扩散图，以捕获谣言扩散的结构\n\n此外，来自消息来源的信息涉及到GCN的每一层，以增强谣言根源的影响力。\n\n## 相关工作\n\n### 传统方法\n\n传统的检测方法主要采用用户特征、文本内容和传播模式等手工制作的特征来训练监督分类器，例如：Decision Tree、 Random Forest、Support Vector Machine (SVM)。\n\n一些研究应用了有效的特征，如用户评论、时间结构特征，以及帖子的情感态度。\n\n然而，这些方法主要依赖于特征工程，非常耗时费力。此外，这些手工制作的特征通常缺乏从谣言的传播和扩散中提取的高层次表示。\n\n### 深度学习方法\n\n最近的研究已经利用从传播路径/树或网络中挖掘高层表示的深度学习方法来识别谣言。也就是深度学习方法：\n\n#### RNN\n\n长短期记忆(LSTM)、门控递归单元(GRU)和递归神经网络(RvNN)，因为他们能够从随着时间的谣言传播中学习序列特征。\n\n然而，这些方法在效率上有很大的局限性，因为时间结构特征只关注谣言的顺序传播，而忽略了谣言散布的影响。\n\n#### CNN\n\n谣言传播的结构也表明了谣言的某些传播行为。因此，一些研究试图通过引用基于卷积神经网络(CNN)的方法来涉及谣言传播结构中的信息。基于CNN的方法可以获得局部邻域内的相关特征，但不能处理图或树中全局结构关系。因此，这些方法忽略了谣言传播的全局结构特征。实际上，CNN不是为从结构化数据中学习高级表示而设计的，但图形卷积网络(GCN)是。\n\n### GNN\n\nGCN，或称为无向GCN(UD-GCN)，只聚合依赖于相关帖子之间的关系的信息，而丢失了以下内容的顺序。\n\n虽然UD-GCN具有处理谣言传播的全局性结构特征的能力(其实传统基于消息传递的GNN只是局部特征)，但它没有考虑谣言传播的方向，但这已被证明是谣言检测的重要线索。\n\n具体而言，沿着关系链的深度传播和在社区的广泛扩散是谣言的两个主要特征。\n\n为了同时处理谣言的传播和扩散，本文提出了一种新的双向GCN(Bi-GCN)，它同时适用于谣言的自上而下和自下而上的传播。\n\n![](https://i.loli.net/2021/09/05/cs9LYDfpmCzixIV.png)\n\nTop-Down graph convolutional Networks (TD-GCN)         /     Bottom-Up graph convolutional Networks (BU-GCN)\n\nTD-GCN从谣言树中节点的父节点获取信息来制定谣言传播，而BU-GCN从树中节点的子节点收集信息来表示谣言的散布。\n\nDetect rumors on twitter by promoting information campaigns with generative adversarial learning.采用对抗性学习方法来提高谣言分类器的性能，其中鉴别器用作分类器，相应的生成器通过产生冲突噪声来改进鉴别器。\n\n## 方法\n\n### 符号\n\n$C = \\{c_1,c_2,...,c_m\\}$ 为数据集，$c_i$ 是第 $i$ 个事件，$m$是事件的数量。\n\n$c_i = \\{r_i,w_1^i,...,w_{n_i-1}^i,G_i\\}$ , $n_i$ 是事件$c_i$中帖子的数量，$r_i$是源帖子，每个$w_j^i$代表第$j$个相关回应帖子, $G_i$ 指的是传播结构。$ G_i$定义为 $⟨V_i，E_i⟩$其中 $r_i$是根节点\n\n类别标签${N,F,T,U}$ (Non-rumor, False Rumor, True Rumor, and Unverified Rumor)\n\n### DropEdge\n\nDropEdge是一种减少基于GCN模型的过拟合的新方法。在每个训练周期内，随机地从输入图中剔除边，以一定的速率生成不同的变形副本。\n\n因此，这种方法增加了输入数据的随机性和多样性，就像随机旋转或摆动图像一样。形式上，假设图 $A$ 中的边总数为$N_e$，dropping率为$p$，则DropEdge之后的邻接矩阵$A‘$计算如下：\n\n$$\nA' = A - A_{drop}\n$$\n其中$A_{drop}$ 是$N_e\\times p$ 随机采样原始边集合得到\n\n### Bi-GCN Rumor Detection Model\n\n![](https://i.loli.net/2021/09/06/YR7cEdVmlXPBwtb.png)\n\nBi-GCN的核心思想是从谣言传播和谣言扩散两个方面学习合适的高层表示。\n\n在Bi-GCN模型中，采用两层1stChebNet作为基本的GCN组件。如图2所示，分4个步骤详细阐述了使用Bi-GCN进行谣言检测的过程。\n\n首先讨论如何将Bi-GCN模型应用于一个事件，即第i个事件的$c_i→y_i$。其他事件的计算方式相同。为了更好地展示我们的方法，我们在下面的内容中省略了下标i。\n\n#### 1 Construct Propagation and Dispersion Graphs\n\n基于转发和回复关系，我们构造了传播结构 $⟨V, E⟩$ 对于谣言事件。\n\n然后，设 $A\\in R^{n_i×n_i}$和 $X$ 分别为其对应的基于谣言传播树$c_i$的邻接矩阵和特征矩阵。\n\n$A$ 经过drop变成$A'$ ,基于$A'$ 和 $X$ ，我们可以建立我们的Bi-GCN模型。我们的Bi-GCN由两个组件组成：\n\n Top-Down Graph Convolutional Network (TD- GCN)\n\nBottom-Up Graph Convolutional Network (BU- GCN)\n\n两个分量的邻接矩阵是不同的\n\nTD-GCN中，$A^{TD}=A'$  , 对于BU-GCN，邻接矩阵为 $A^{BU}=A'^⊤$。TD-GCN和BU-GCN采用相同的特征矩阵X。\n\n#### 2 Calculate the High-level Node Representations\n\nTD-GCN经过两层图卷积:\n$$\nH_1^{TD} = \\sigma(\\hat A^{TD}XW_0^{TD})\n$$\n\n$$\nH_2^{TD} = \\sigma(\\hat A^{TD}H_1^{TD}W_1^{TD})\n$$\n\nBU-GCN相同\n\n#### 3 Root Feature Enhancement\n\n众所周知，谣言事件的来源帖子总是信息丰富，影响广泛。要更好地利用源帖信息，从节点与源帖的关系中学习更准确的节点表示。\n\n对于第k个GCL处的TD-GCN，我们将每个节点的隐藏特征向量与来自第(k−1)个GCL的根节点的隐藏特征向量连接起来，以构造新的特征矩阵\n$$\n\\hat H_k^{TD} = concat(H_k^{TD},(H_{k-1}^{TD})^{root})\n$$\n其中$H_0^{TD}=X$\n\n#### 4 Representations of Propagation and Dispersion for Rumor Classification\n\n传播表示和扩散表示分别由TD-GCN和BU-GCN的节点表示聚合而成。\n\n在这里，我们使用均值合并算子来聚集来自这两组节点表示的信息。它的公式是\n$$\nS^{TD} = MEAN(\\hat H_2^{TD})\n$$\n\n$$\nS^{BU} = MEAN(\\hat H_2^{BU})\n$$\n\n然后，我们将传播的表示和扩散的表示连接起来，将信息合并为\n$$\nS=concat(S^{TD},S^{BU})\n$$\n最后，事件ˆy的标签通过几个全连接层和SoftMax层：\n$$\n\\hat y = Softmax(FC(S))\n$$\n$\\hat y \\in R^{1\\times C}$\n\n## 实验\n\n![](https://z3.ax1x.com/2021/09/06/hhosuq.png)\n\n![](https://z3.ax1x.com/2021/09/06/hhTFIS.png)\n\n\n\n![](https://z3.ax1x.com/2021/09/06/hhTQaT.png)\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["context detection"]},{"title":"Interpretable Rumor Detection in Microblogs by Attending to User Interactions","url":"/2021/09/04/Interpretable-Rumor-Detection-in-Microblogs-by-Attending-to-User-Interactions/","content":"\n# Interpretable Rumor Detection in Microblogs by Attending to User Interactions\n\nhttps://github.com/serenaklm/rumor_detection\n\n通过学习区分社区对微博中真假claim的响应来解决谣言检测问题。\n\n现有最先进的模型是基于对会话树建模的树模型。然而，在社交媒体中，发布回复的用户可能是对整个thread的回复，而不是对特定用户的回复。\n\n提出Multi-head post-level attention模型(PLAN)来构建推文之间的远距离交互。并提出几个变体：\n\n- 结构感知自注意模型(StA-PLAN)，将树形结构信息合并到Transformer中\n- 分层token和post-leve attention(StA-HiTPLAN), 通过token-level 自注意力学习句子表征\n\n这篇工作重点是利用社区对虚假claim的响应来检测虚假索赔。这一研究领域通过将自然语言处理应用于针对claim的评论来利用社区的集体智慧。这些工作背后的关键原则是，社交媒体上的用户会分享对不准确信息的看法、猜测和证据。\n\n## 样本\n\n![](https://i.loli.net/2021/09/04/FwWU2TKkf1Ji5B3.png)\n\n源贴：“沃尔玛捐赠1万美元支持达伦·威尔逊和正在进行的种族主义警察谋杀案#弗格森#抵制沃尔玛URL”。\n\n推特R_1及其回复推文R_1_1对消息来源的真实性表示怀疑。\n\n推特R_2_1和R_3_1提供了确凿的证据，揭穿了消息来源的说法是假的。\n\n虽然R_2_1和R_3_1分别是R_2和R_3的子节点，但它们可以为树上的所有其他节点(如R_1_1和R_1)提供重要信息。\n\n因此，应该考虑所有tweet之间的互动，而不仅仅是父节点和他们的孩子节点之间的互动。\n\n## 相关工作\n\n两篇使用树形结构进行建模的sota对社交媒体中谣言检测有限制。\n\nRumor detection on twitter with tree-structured recursive neural networks(2018) ，将来源claim及其回复推文组织成树形结构，使用递归神经网络对传播树中的信息传播进行建模。来自不同节点的信号以自下而上或自上而下的方式进行粗略地重新聚合。在自下而上的模型中，信息从子节点传播到父节点，在自上而下的模型中，信息从父节点传播到子节点，反之亦然。\n\nTree lstms with convolution units to predict stance and rumor veracity in social media conver- sations.(2019) ，组织了树状结构的对话线程，并探索了用于谣言检测的branch和tree LSTM的几种变体。\n\n这两篇论文都使用了树模型，目的是对会话线索中存在的结构信息进行建模。在树模型中，信息从父级传播到子级，反之亦然。然而，社交媒体对话中的线索结构有所不同，每个用户通常能够观察到对话的不同分支中的所有回复。揭穿假新闻的用户不能只针对他回复的人创建的内容也可能适用于该帖子中的其他推文。树模型不会对来自其他分支的节点之间的交互进行显式建模，这是对社交媒体会话建模时的一个关键限制。\n\n自动区分真假Claims的现有方法利用了各种特征：\n\n- Claims的内容\n- Claims来源的重点考虑和社交网络\n- 使用可信来源(例如，维基百科)进行事实核查\n- 社区对Claims的反应。\n\n这篇重点在社区响应，接下来展开介绍介绍。\n\n### Content Information\n\n早期关于欺骗性内容检测的工作研究了语言线索的使用，例如代词的百分比、词长、动词数量和词类。也有工作对关于虚假的评论，目击者的陈述，和讽刺。利用语言特征对假新闻的检测也进行了研究。这种对概念内容的分析依赖于可能是领域或主题所独有的语言特征。\n\n### Source and Social Network\n\n研究假新闻的来源及其社交网络，在内容中加入来源信息提高了假新闻分类准确率。为传播假新闻而创建的账户往往具有不同的社交网络特征。\n\n### Fact Checking\n\n事实核查网站，如PolitiFact。com和snopes.com依靠人工验证来揭穿假新闻，但无法匹配假新闻的生成速度(Funke 2019)。自动事实核查旨在对照诸如维基百科(Ciampaglia et al.2015年)。\n\n最近，索恩等人(2018)提出了FEVER共享任务，针对包含500万维基百科文档的数据库验证输入Claim，并将每个Claim分为三类：支持、驳斥或信息不足。\n\n事实核查是一种更有原则的假新闻检测方法。然而，它也需要建立一个经过核实的事实语料库，而且可能不适用于证据很少的新Claim。\n\n### Community Response\n\n研究人员致力于通过构建分类器来自动预测claim的有效性，分类器利用对社交媒体帖子的评论和回复，以及传播模式。\n\nMa(2018a)采用多任务学习方法构建了一个学习立场感知特征的分类器用于谣言检测。\n\nLi (2019)对他的模型采用了多任务学习方法，并在他的模型中包括了用户信息。\n\nChen(2017)提出汇集截然不同的特征，以捕捉帖子随时间的上下文变化。\n\n除了语言特征，其他研究人员也关注了用户的人口统计或交互预测来确定用户的可信度。\n\nYang(2012)收集了从事传播假新闻的用户特征，通过对传播路径进行分类，仅利用用户特征构建了假新闻检测器\n\nLi(2019)使用用户信息和内容特征相结合的方式训练具有多任务学习目标的LSTM。\n\n在本文中，仅从帖子和评论两个方面来检测谣言和假新闻。提出了一种用于谣言检测的Transformer，而不是递归树模型。\n\n## 任务定义\n\n问题陈述，将每个线程thread定义为：\n$$\nX = \\{x_1,x_2,...,x_n\\}\n$$\n其中$x_1$是源tweet，$x_i$是按时间顺序排列的第 $i$ 条tweet，$n$是线程中的tweet数量。\n\n会话树中除了文本信息外，还有可以利用的结构信息。在树形结构模型中，如果$x_i$对$x_j$进行应答，反之亦然，则只对Twitter $x_i$和$x_j$进行关联。\n\n本文模型允许任何帖子关注同一主题中的任何其他帖子。\n\n在提出的结构感知模型中，用关系标签来标记任何一对推文 $x_i$ 和 $x_j$之间的关系 $R(i,j)\\in \\{\\text{parent, child, before, after, self}\\}$ 。$R(i，j)$ 的值是通过依次应用以下规则集来获得的：\n\n- parent：如果 $x_i$ 直接回复 $x_j$\n- child：如果 $x_j$ 直接回复 $x_i$\n- before：如果 $x_i$ 在 $x_j$之前到来\n- after：如果 $x_i$ 在 $x_j$之后\n- self：如果i=j\n\n谣言检测任务简化为学习预测每个$(X，R)$到其谣言类别 $y$。\n\n在两个谣言检测数据集上进行了实验，即Twitter15和Twitter16数据，以及PHEME 5数据。\n\n对于我们正在处理的数据集，分类标签是不同的：\n\n- Twitter15 and Twitter16：$y\\in \\{\\text{non-rumor, false-rumor, true-rumor, unverified}\\}$\n- PHEME: $y\\in \\{\\text{false-rumor, true-rumor, unverified}\\}$\n\n## 方法\n\n然而，正如我们将在下表中的数据统计中看到的那样，数据集中的树非常浅，大部分评论直接回复源tweet，而不是回复其他tweet。\n\n![](https://i.loli.net/2021/09/05/2RAGI9fpbJ5D387.png)\n\n我们发现，在社交媒体中，由于整个帖子通常都是可见的，回复根帖子的用户可能会继续与更活跃的用户进行对话，而不是专门为根帖子撰写回复。因此，在对社交媒体对话进行建模时，没有对推文之间的每一种可能的成对交互进行显式建模的树模型是次优的，所以用Transformer-based模型。\n\n### Post-Level Attention Network (PLAN)\n\n![](https://i.loli.net/2021/09/05/aq5MoQL1iACXujd.png)\n\n首先将对话树的结构展平，并将推文按时间顺序排列成直线结构，源推文作为第一条推文。对于我们的计划模型，我们在线性结构中对每个推文 $x_i$ 应用最大池化来获得它的句子表示 $x_i$。\n\n然后传递一个句子嵌入序列 $X' = (x_1',x_2',...,x_n')$  通过s个数的多头注意力(MHA)层来模拟推文之间的交互。\n\n我们将这些MHA层称为post-level attention层。因此，这将改变 $X' =(x_1',x_2',...,x_n')$ 为 $U=(u_1,u_2,...,u_n)$\n\n最后，使用注意力机制对推文进行插值，然后通过一个全连接层进行预测。\n\n\n\n### Structure Aware Post-Level Attention Network (StA-PLAN)\n\n模型的一个可能的局限性是，我们通过以线性结构组织推文来丢失结构信息。转换树中固有存在的结构化信息对于假新闻检测可能仍然有用。\n\n树模型在这方面更优越，因为结构信息是显式建模的。为了将树模型的优点和自我注意机制结合起来，对计划模型进行了扩展，使其显式地包含了结构信息。\n$$\n\\alpha_{ij} = softmax(\\frac{q_ik_j^T+a_{ij}^K}{\\sqrt{d_k}})\n$$\n\n$$\nz_i = \\sum_{j=1}^n\\alpha_{ij}(v_j+a_{ij}^V)\n$$\n\n$a^V_{ij}$ 和 $a^K_{ij}$ 都是代表tweet对之间五种可能的结构关系(即parent, child, before, after, self)之一的向量\n\n### Structure Aware Hierarchical Token and Post-Level Attention Network (StA-HiTPLAN)\n\n![](https://i.loli.net/2021/09/05/Cx2RNBdOwAUcMI1.png)\n\nPLAN模型执行最大池化，以获得每条推文的句子表示。\n\n然而，让模型学习单词向量的重要性可能会更理想。因此，提出了一种分层的注意模型--token-level的注意和post-level的注意力。分层模型的概述如图所示。\n\n在使用注意机制插入输出之前，我们执行token-level自注意力，而不是使用最大池化来获得句子表示。\n\n每条推文可以表示为一系列单词记号$x_i=(x_{i,1}，x_{i,2}，...，x_{i,|xi|})$。我们在一条推文中通过MHA层传递了单词token的序列。这允许tweet中的token之间进行交互，将这些层称为token-level关注层。\n\n### Time Delay Embedding\n\n在不同的时间间隔创建的推文可以有不同的解释。首次创建源claim时表示不相信的推文可能很常见，因为claim可能尚未经过验证。然而，在传播的后期阶段，可疑的推文可能表明消息来源的说法是假的倾向很高。\n\n因此，提出的三个模型PLAN、STA-PLAN和STA-HiTPLAN研究了带有时延信息的Tweet编码的实用性。\n\n为了包括每个tweet的时间延迟信息，根据从源tweet创建时起的延迟将tweet绑定。\n\n将时间箱的总数设置为100，每个箱代表10分钟的间隔。延迟超过1000分钟的推文将落入最后一个时间段。\n$$\nTDE_{pos,2i} = sin\\frac{pos}{10000^{2i/d_model}}\n$$\n\n$$\nTDE_{pos,2i+1} = cos\\frac{pos}{10000^{2i/d_model}}\n$$\n\n其中pos表达为时间bin，$pos\\in[0,100)$\n\n## 实验\n\n### 数据集\n\n![](https://i.loli.net/2021/09/05/2RAGI9fpbJ5D387.png)\n\n![](https://i.loli.net/2021/09/05/MUWvDm5j36NYksw.png)\n\n- Twitter15 and Twitter16 ：对于Twitter15和Twitter16的数据集，每个声明中都有很大比例的转发：Twit-15和Twitter16分别为89%和90%。因为作者假设转发不会给模型带来新信息，所以删除了Twitter15和Twitter16的所有转发。在删除转发后，观察到少数索赔将只剩下来源Claim。既然作者的方法背后的原则是，我们可以利用人群的信号来侦测谣言，那么没有任何回复的说法就应该是“未经核实的(unverified)”。因此，在训练数据中修改了这类说法的标签为“未经证实”\n\n![](https://i.loli.net/2021/09/05/vaNkVL2UIAhD4n1.png)\n\n![](https://i.loli.net/2021/09/05/7riuNwZBWUvxjE6.png)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["context detection"]},{"title":"Dice Loss for Data-imbalanced NLP Tasks","url":"/2021/09/01/Dice-Loss-for-Data-imbalanced-NLP-Tasks/","content":"\n# Dice Loss for Data-imbalanced NLP Tasks\n\n许多自然语言处理任务，如序列标注和机器阅读理解(MRC)，都面临着严重的数据失衡问题：\n\n- 负样本明显多于正样本，占据绝大多数的负例会支配模型的训练过程，导致模型倾向于负例，而测试时使用的F1指标需要每个类都能准确预测；\n- 大量简单负例（easy-negative）使训练不堪重负。负例占绝大多数也意味着其中包含了很多简单样本，这些简单样本对于模型学习困难样本几乎没有帮助，反而会在交叉熵的作用下推动模型遗忘对困难样本的知识。\n\nloss中最常用的交叉熵实际上是以精度为导向的，这造成了训练和测试之间的差异。在训练时，每个训练样本对目标函数的贡献相等，而在测试时，F1 score更关注正例。\n\n本文认为这种问题是交叉熵本身的特点带来的：交叉熵“平等”地看待每一个样本，无论正负，都尽力把它们推向1（正例）或0（负例）。但实际上，对分类而言，将一个样本分类为负只需要它的概率＜0.5即可，完全没有必要将它推向0。\n\n基于这个观察，作者使用现有的Dice Loss，并提出一个基于Dice Loss的自适应损失——DSC，在训练时推动模型更加关注困难的样本，降低简单负例的学习度，从而在整体上提高基于F1值的效果。\n\n## 从Cross Entropy 到 Dice Losses\n\n### 交叉熵损失(CE)\n\n以二分类作为说明，记输入为 $x$, 输出为一个二值概率 $p = [p_0,p_1]$, 并且有一个二元真值 $y = [y_0,y_1]$\n\n首先交叉熵损失是：\n$$\nCE =  -(y_0log\\ p_0 + y_1log \\ p_1)\n$$\n显然，对每个样本，CE都对它们一视同仁，不管当前样本是简单还是复杂。当简单样本有很多时，模型训练就会被这些简单的样本占据，使得模型难以从复杂样本中学习。于是，一种简单的改进方法是，降低模型在简单样本上的学习速率，从而得到下述加权交叉损失：\n$$\nWeighted \\ CE = -\\alpha(y_0log \\ p_0+y_1log \\ p_1)\n$$\n对不同样本，我们可以设置不同的权重，从而控制模型在该样本上学习的程度。但是此时，权重的选择又变得比较困难。因为我们的目标是缓解数据集的不平衡问题，从而提高基于F1评测标准的效果，我们希望有一种损失函数能够直接作用于F1。\n\n### Sørensen–Dice系数（DSC）\n\n一种现有的方法——Sørensen–Dice系数（简称DSC）——去衡量F1。\n\nDSC是一种用于衡量两个集合之间相似度的指标：\n$$\nDSC(A,B) = \\frac{2|A\\cap B|}{|A|+|B|} \n$$\n\n$$\nF1 = \\frac{2(precision*recall)}{precision+recall}\n$$\n\n$$\nA = precision = \\frac{TP}{TP+FP} ,  B = recall =\\frac{TP}{TP+FN}\n$$\n\n如果我们令A是所有模型预测为正的样本的集合，令B是所有实际上为正的样本集合，那么DSC就可以重写为：\n$$\nDSC(D,f) = \\frac{2TP}{2TP+FN+FP}=F1\n$$\n其中D数据集，f是一个分类模型。于是在这个意义上DSC与F1是等价的。\n\n既然如此，就直接优化DSC，然而上述表达式是离散的，为此，需要把上述DSC表达式转化为连续的版本，从而可以视作一种soft F1。\n\n对于单个样本x，直接定义它的DSC：\n$$\nDSC(x,f) = \\frac{2p_1y_1}{p_1+y_1}\n$$\n可以看到如果x是父类，那么它的DSC就为0，从而不会对训练有贡献。为了让父类也能有所贡献，所以增加一个平滑项：\n$$\nDSC_s(x,f) = \\frac{2p_1y_1 + \\epsilon}{p_1+y_1+\\epsilon}\n$$\n但这样一来，又需要我们根据不同的数据集手动地调整平滑项。而且当easy-negative样本很多的时候，即便使用上述平滑项，整个模型训练过程仍然会被它们主导。基于此，我们使用一种“自调节”的DSC（这里就和focal loss很像）：\n$$\nDSC(x,f) = \\frac{2(1-p_1)p_1\\cdot y_1 + \\epsilon}{(1-p_1)p_1 + y_1 + \\epsilon}\n$$\n比较上面两个DSC，可以发现，$1-p_1$ 实际上充当了缩放系数，对于简单样本($p_1$ 趋向于1或0)，$(1-p_1)p_1$ 使得模型更少地去关注他们。\n\n从导数上看，一旦模型正确分类当前样本（刚刚经过0.5），DSC就会使模型更少关注它，而不是像交叉熵那样，鼓励模型迫近0或1这两个点。这就能有效避免因简单样本过多导致模型训练受到简单样本的支配。\n\n事实上，这比较类似Focal Loss(FL)，降低已分好类的样本的学习权重：\n$$\nFL = -(y_0(1-p_0)^\\gamma log p_0 + y_1(1-p_1)^\\gamma log p_1)\n$$\n不过，FL即使能对简单样本降低学习权重，但它本质上仍然是在鼓励简单样本趋向于0或1，这就和DSC有了本质上的区别。因此，说DSC通过“平衡”简单样本和困难样本的学习过程，从而提高了最终的F1值（因为F1要求各类都有比较好的结果）\n\n### Dice Loss(DL)与Tversky Loss(TL)\n\n除了上述DSC外，还比较了两种$DSC_s(x,f)$的变体，分别是Dice Loss（DL）和Tversky Loss（TL）：\n$$\nDL = 1 - \\frac{2p_1y_1+\\epsilon}{p_1^2+y_1^2+\\epsilon}\n$$\n\n$$\nTL = 1-\\frac{p_1y_1 + \\epsilon}{p_1y_1+\\alpha p_1y_0+\\beta p_0y_1 + \\epsilon}\n$$\n\n在$\\alpha=\\beta=0.5$时，TL就退化为DSC。           \n\n### 损失总结\n\n![](https://i.loli.net/2021/09/01/YkHOMIlVSPjG5aw.png)\n\n后三个统称为Dice loss\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["nlp"]},{"title":"Edge-augmented Graph Transformers: Global Self-attention is Enough for Graphs","url":"/2021/08/29/Edge-augmented-Graph-Transformers-Global-Self-attention-is-Enough-for-Graphs/","content":"\n# Edge-augmented Graph Transformers: Global Self-attention is Enough for Graphs\n\n--do_train --do_eval --train_batch_size 64 --num_train_epochs 50 --embeddings_learning_rate 0.7e-4 --encoder_learning_rate 0.7e-4 --classifier_learning_rate 7e-4 --warmup_steps 200 --max_seq_len 132 --dropout_rate 0.15 --metric_key_for_early_stop \"macro avg__f1-score__level_2\" --logging_steps 200 --patience 6 --label2freq_level_1_dir /data2/code/DaguanFengxian/bert_model/data/label2freq_level_1.json --label2freq_level_2_dir /data2/code/DaguanFengxian/bert_model/data/label2freq_level_2.json --processor_sep \"\\t\" --loss_fct_name dice ","tags":["GNN"]},{"title":"Breadth First Reasoning Graph for Multi-hop Question Answering","url":"/2021/08/17/Breadth-First-Reasoning-Graph-for-Multi-hop-Question-Answering/","content":"\n# Breadth First Reasoning Graph for Multi-hop Question Answering\n\n为了解决GNNs不必要的更新和简单的边结构阻碍直接提取准确的答案跨度，和更可解释性。\n\n作者提出了一种新的广度优先推理图(BFR-Graph)模型，它提供了一种新的更符合推理过程的消息传递方式。\n\n在BFR-Graph中，推理信息要求从问题结点开始，逐跳传递到下一个句子结点，直到所有的边都经过，可以有效地防止每个结点的过度平滑或不必要的多次更新。\n\n为了引入更多的语义，我们还将推理图定义为考虑了共现关系数和句子间距离的加权图。\n\n然后基于GNN提出了一种更直接、更易解释的方法来聚合不同粒度级别的分数。\n\n## 现有GNN方法的几个问题\n\n- 首先，当前的方法将所有节点（包括一些不必要的节点）一起更新到每一层中，这可能导致节点收敛到相似的值，并失去对具有更多层的GNN的识别能力。\n- 第二，虽然GNN设计了不同类型的边，但是在没有考虑句子之间的其他关系信息的情况下，相同类型的边之间没有更细粒度的区别。\n- 第三，现有的方法只是潜在地融合了GNN和上下文编码器的隐藏表示，而没有以直接和可解释的方式进行答案广度提取。\n\n## 方法\n\n![](https://i.loli.net/2021/08/19/NlBA3uLTydzhVwi.png)\n\n与现有的基于GNN的方法不同，BFR-Graph对消息传递引入了新的限制：消息只从问题开始，然后逐跳传递到后面的句子节点。此外，考虑到共现实体和句子之间的距离，图被构造成一个加权图。此外，利用BFR图的推理结果，设计了多分数答案预测。\n\n简言之，我们在加权图上提出了广度优先推理，然后在多任务联合训练的框架下，结合多级分数进行回答预测。\n\n### Paragraph Selection\n\n训练一个二分类bert，对每个段落进行打分，选择得分在前N位的段落作为有用的段落，然后将这些段落连接在一起作为上下文C。\n\n### Context Encoding\n\nbert输出+bi-attention后获得问题和上下文的编码表达\n$$\nH = \\{h_0, ..., h_{L-1}\\}\n$$\n其中L是输入序列的长度(连接问题和上下文)，d是双关注层的输出维度(也是BERT的维度)。\n\n为了实现句子级表示，首先获得每个句子的标记级表示：\n$$\nS_i^{seq} = H[s_i^{start}:s_i^{end}]\\in \\mathbb{R}^{L_{s_i}\\times d}\n$$\n获得每个句子的表示是用了Bi-LSTM的方法\n$$\ns_i = \\sum_{k=0}^{L_s}\\alpha_k^iS_i^{seq}[k, :]\\in \\mathbb{R}^d\n$$\n$\\alpha_k^i$ 是第i个句子中第k个token的权重，通过两层MLP output size=1获得\n\n### Weighted Graph Construction\n\n为了更好地挖掘句子之间复杂的关系信息，定义了正相关和负相关两种类型的相关性：\n\n- 正相关：如果表示句子 $i$ 和 $j$ 的节点具有 n(n≥1) 个相同命名实体，则添加一条边，该边的权重为：\n\n$$\nw_{ij} = \\frac{1}{1+e^{-n+K_1}}\n$$\n\n- 负相关：否则，如果两个节点最初来自同一段落，则添加一条边，该边的权重为：\n\n$$\nw_{ij} = \\frac{1}{1+e^{d+K_2}}\n$$\n\n其中d是两个句子的距离(例如，如果该句子紧跟在段落中的另一个句子之后，则d=1，如果它们之间有句子，则d=2，依此类推)。K1和K2是超参数。\n\n是同质图，它包含单一类型的节点和边。\n\n### Breadth First Reasoning\n\n下图直观地显示了BFR-Graph和典型GNN之间的区别。\n\n![](https://i.loli.net/2021/08/19/oCzcsTeIHXZGW3f.png)\n\n当我们在段落上推理来回答一个问题时，我们从问题开始，一跳一跳地找到下一个句子。\n\n对于节点表示句子的GNN，以下消息传递是不必要的，可能会抑制无用节点的干扰：\n\n- 从后一个节点到前一个节点\n- 某个节点尚未收到来自问题的消息，但它会更新其他节点。\n\n具体地说，当同时满足以下条件时，节点i由节点j更新：\n\n- 节点 $i$ 和节点 $j$ 是邻居\n- 节点 $j$ 是Active的\n- 节点 $i$ 和节点 $j$ 之间的边以前没有经过\n\nBFR-Graph的整个消息传递过程:\n\n![](https://z3.ax1x.com/2021/08/19/fqlv7j.png)\n\n消息更新传递的函数还是GAT\n\n### Multi-score Answer Prediction\n\nHotpotQA数据集中的答案是上下文的span。现有工作仅计算编码器输出（如BERT）上的跨度概率，或额外连接GNN的隐藏输出。不同的是，我们通过计算从GNN获得的句子分数和段落分数来使用更易于解释的方法。如下图：\n\n![](https://z3.ax1x.com/2021/08/19/fq3Cad.png)\n\n通常，作为答案跨度的开始/结束的上下文中的第y个单词的分数通过以下方式计算：\n$$\n\\phi_{start}(y) = MLP_1(H[y,:])\n$$\n\n$$\n\\phi_{end}(y) = MLP_2(H[y,:])\n$$\n\n然后，计算GNN中每个节点对应的句子得分：\n$$\n\\phi_{sent}(s_i) =MLP_3(s_i)\n$$\n计算段落分数, 通过全局最大池：\n$$\n\\phi_{para}(p_j) = MLP_4(Max(\\{s_0^{p_j},...,s_{L_{p_j}-1}^{P_j}\\}))\n$$\n$s_i^{P_j}$是第$i$句话在第Pj段中的表达。这也可以通过在所有语句节点上取每个维度上的最大隐藏值来实现。\n\n最后，上下文中第y个单词作为答案范围开始的概率由以下公式确定：\n$$\np_{start}(y) = softmax(\\phi'_{start}(y))\n$$\n\n$$\n\\phi'_{start}(y) = \\phi_{start}(y) + \\phi_{sent}(s_i) + \\phi_{para}(p_j)\n$$\n\n并且可以类似地计算上下文中的第y个单词作为答案跨度结束的概率。\n\n如果一个句子或段落的得分较高，则位于其中的单词更有可能是答案。\n\n最后是一个多任务预测\n\n## 消融实验\n\n![](https://z3.ax1x.com/2021/08/19/fqGFjf.png)\n\n\n\n\n\n\n\n\n\n\n\n","tags":["GNN&nlp"]},{"title":"RealFormer: Transformer Likes Residual Attention","url":"/2021/08/15/RealFormer-Transformer-Likes-Residual-Attention/","content":"\n# RealFormer: Transformer Likes Residual Attention\n\n提出了一个简单的基于Transformer的体系结构，创建一条“直接”路径在整个网络中传播原始注意力分数\n\n如下图(c), 每个RealFormer层都获取前一层中所有注意力头部的原始注意力分数，并在顶部添加“残差分数”(计算方式与常规Transformers中的注意力分数相同)。\n\n换句话说，RealFormer可以被视为向Post-LN Transformer添加一个简单的跳跃连接。不会向计算图中添加任何乘法运算，因此预期性能与之相当。\n\nRealFormer中的AT往往更稀疏，跨层相关性更强，我们认为这可能具有一些正则化效应，可以稳定训练，有利于微调。\n\n![](https://i.loli.net/2021/08/15/jZrDYmkL5EzFqi6.png)t\n\n- (a) 传统transformer的PostLN\n- (b) PreLN 论文：ON LAYER NORMALIZATION IN THE TRANSFORMER ARCHITECTURE，这种设计为每个子层增加了LN作为“预处理”步骤。\n\n## 方法\n\n标准Transformer Encoder\n$$\n\\text{MultiHead}(Q,K,V) = Concat(head_1,...,head_h)W^O\n$$\n\n$$\nhead_i = Attention(QW_i^Q, KW^K_i,VW^V_i)\n$$\n\n$$\nAttention(Q',K',V') = Softmax(\\frac{Q'K'^T}{\\sqrt{d_k}})V'\n$$\n\n$$\nFFN(x) = \\sigma(xW_1+b_1)W_2+b_2\n$$\n\nPost-LN是Vaswani等人提出的原创体系结构。对每个子层末尾的输出进行标准化。\n\n相反，Pre-LN规格化子层输入，并创建直接路径(没有LN)来传播序列中的令牌嵌入。\n\n### Residual Attention Layer Transformer\n\nRealFormer紧跟Post-LN设计，简单地增加了一个skip edge来连接相邻层中的多头注意力，如上图c所示。\n\n形式上添加一个$Prev$，是上一个softmax的注意力分数也就是pre-softmax，形状为$(heads,\\text{from_seq_len},\\text{to_seq_len})^2$\n$$\n\\text{ResidualMultiHead}(Q,K,V,Prev) = Concat(head1,...,head_h)W^O\n$$\n\n$$\nhead_i = \\text{ResidualAttention}(QW_i^Q,KW_i^K,VW_i^V,Prev_i)\n$$\n\n$Prev_i$ 的形状为$(\\text{from_seq_len,to_seq_len})$ 对应于每个$head_i$\n$$\n\\text{ResidualAttention}(Q',K',V',Prev') = \\text{Softmax}(\\frac{Q'K'^T}{\\sqrt{d_k}}+Prev')V'\n$$\n新的注意力分数$\\frac{Q'K'^T}{\\sqrt{d_k}}+Prev'$\n\n## 实验\n\n![](https://i.loli.net/2021/08/15/K86nvAXLs954SMf.png)\n\n值得特别指出的是第一张图和第四张图。从第一张图我们可以看到，对于RealFormer结构，加大模型规模（large到xlarge）可以带来性能的明显提升，而ALBERT论文曾经提到加大BERT的模型规模并不能带来明显受益，结合两者说明这可能是PostLN的毛病而不是BERT的固有毛病，换成RealFormer可以改善这一点。从第四张图我们可以看到，RealFormer结构训练50万步，效果就相当于PostLN训练100万步，这表明RealFormer有着很高的训练效率。\n\n除了上述实验外，论文还对比了不同学习率、不同Dropout比例的效果，表明RealFormer确实对这些参数是比较鲁棒的。原论文还分析了RealFormer的Attention值分布，表明RealFormer的Attention结果更加合理。\n\n### 分析\n\nRealFormer对梯度下降更加友好，这不难理解，因为$A_n = \\frac{Q_nK_n^T}{\\sqrt{d_k}} + A_{n-1}$的设计确实提供了一条直通路，使得第一层的Attention能够直通最后一层，自然就没有什么梯度消失的风险了。相比之下，PostLN是 $LayerNorm(x+f(x))$ 的结构，看上去$x+f(x)$防止了梯度消失，但是LayerNorm这一步会重新增加了梯度消失的风险，造成的后果是初始阶段前面的层梯度很小，后面的层梯度很大，如果用大学习率，后面的层容易崩，如果用小学习率，前面的层学不好，因此PostLN更难训练，需要小的学习率加warmup慢慢训。\n\n还有一个就是叠加的问题PreLN每一步都是$x+f(x)$的形式，到了最后一层变成了$x+f_1(x)+f_2(x)+...++f_n(x)$的形式，一层层累加，可能导致数值和方差都很大，最后迫不得已强制加一层Layer Norm让输出稳定下来。这样，尽管PreLN改善了梯度状况，但它本身设计上就存在一些不稳定因素。\n\nRealformer的$A_n = \\frac{Q_nK_n^T}{\\sqrt{d_k}} + A_{n-1}$存在叠加问题吗？如果只看A，那么确实有这样的问题，但A后面还要做个softmax归一化后才参与运行，也就是说，模型对矩阵A是自带归一化功能的，所以它不会有数值发散的风险。而且刚刚相反，随着层数的增加，A的叠加会使得A的元素绝对值可能越来越大，Attention趋近于onehot形式，造成后面的层梯度消失，但是别忘了，我们刚才说PostLN前面的层梯度小后面的大，而现在也进一步缩小了后面层的梯度，反而使得两者更同步，从而更好优化了；\n\n另一方面Attention的概率值可能会有趋同的趋势，也就是说Attention的模式可能越来越稳定了。带来类似ALBERT参数共享的正则化效应，这对模型效果来说可能是有利的。同时，直觉上来想，用RealFormer结构去做FastBert之类的自适应层数的改进，效果会更好，因为RealFormer的Attention本身会有趋同趋势，更加符合FastBert设计的出发点。\n\n此外，我们也可以将RealFormer理解为还是使用了常规的残差结构，但是残差结构只用在**Q**,**K**而没有用在**V**上。\n\n为啥**V**“不值得”一个残差呢？从近来的一些相对位置编码的改进中，笔者发现似乎有一个共同的趋势，那就是去掉了**V**的偏置，比如像NEZHA的相对位置编码，是同时在Attention矩阵（即**Q**,**K**）和**V**上施加的，而较新的XLNET和T5的相对位置编码则只施加在Attention矩阵上，所以，似乎去掉**V**的不必要的偏置是一个比较好的选择，而RealFormer再次体现了这一点。\n\n\n\n### RealFormer与Baseline Transformers在本质上有什么不同？\n\ndev set中随机抽样了8,192个示例，并可视化了这些示例中每个token(不包括padding)在表2中的三个预先训练的BERT-Base模型中的所有层和所有头部的注意概率分布。\n\n特别地，对于每个(token、layer、head)三元组，我们计算关注权重(概率)的熵作为关注度的“稀疏度量”。直观地说，熵越低，注意力权重分布就越偏斜，因此注意力就越稀疏。\n\n![](https://i.loli.net/2021/08/15/av6cdqPg5HxWShY.png)\n\n用RealFormer训练好的BERT-BASE对8192个突出例子的标记注意概率的熵分布\n\n为了更好地辨认，每一层中的注意力都是按照熵的中位数排序的。根据熵的中位数对分布重新进行颜色编码：红色(中位数>4.5)、黄色(1.5≤中位数≤4.5)、蓝色(中位数<1.5)。也就是说，颜色越冷意味着注意力越稀疏。有一个明显的趋势是，较高的层往往具有较稀疏的注意力。\n\n\n\n下面的是post-LN和pre-LN的熵分布\n\n![](https://i.loli.net/2021/08/15/MIfAtTSK6QV1a4h.png)\n\n![](https://i.loli.net/2021/08/15/yIdzx7tDBTnNuUM.png)\n\n\n\n\n\n\n\n\n\n\n\n","tags":["NLP"]},{"title":"Centos 6无法使用yum解决办法","url":"/2021/08/12/Centos-6无法使用yum解决办法/","content":"\n# Centos 6无法使用yum解决办法\n\n12月后Centos 6 系统无法使用yum出现错误(文章底部看)\n\n相信已经有一部分朋友今天连接到CentOS 6的服务器后执行yum后发现报错，那么发生了什么？\n\nCentOS 6已经随着2020年11月的结束进入了EOL（Reaches End of Life），不过有一些老设备依然需要支持，CentOS官方也给这些还不想把CentOS 6扔进垃圾堆的用户保留了最后一个版本的镜像，只是这个镜像不会再有更新了\n\n官方便在12月2日正式将CentOS 6相关的软件源移出了官方源，随之而来逐级镜像也会陆续将其删除。\n\n不过有一些老设备依然需要维持在当前系统，CentOS官方也给这些还不想把CentOS 6扔进垃圾堆的用户保留了各个版本软件源的镜像，只是这个软件源不会再有更新了。\n\n## 错误详情\n\n```bash\n[root@c8-20 ~]# yum makecache\nLoaded plugins: fastestmirror\nLoading mirror speeds from cached hostfile\nYumRepo Error: All mirror URLs are not using ftp, http[s] or file.\n Eg. Invalid release/repo/arch combination/\nremoving mirrorlist with no valid mirrors: /var/cache/yum/x86_64/6/base/mirrorlist.txt\nError: Cannot find a valid baseurl for repo: base\n```\n\n或\n\n```bash\n[root@li496-237 ~]# yum -y install unzip zip\nLoaded plugins: fastestmirror\nSetting up Install Process\nDetermining fastest mirrors\nYumRepo Error: All mirror URLs are not using ftp, http[s] or file.\nEg. Invalid release/repo/arch combination/\nYumRepo Error: All mirror URLs are not using ftp, http[s] or file.\nEg. Invalid release/repo/arch combination/\nYumRepo Error: All mirror URLs are not using ftp, http[s] or file.\nEg. Invalid release/repo/arch combination/\nhttp://mirrors.linode.com/centos/6/os/x86_64/repodata/repomd.xml: [Errno 14] PYCURL ERROR 22 - \"The requested URL returned error: 404 Not Found\"\nTrying other mirror.\nTo address this issue please refer to the below knowledge base article \n\nhttps://access.redhat.com/articles/1320623\n\nIf above article doesn't help to resolve this issue please open a ticket with Red Hat Support.\n\nError: Cannot retrieve repository metadata (repomd.xml) for repository: base. Please verify its path and try again\n```\n\n一键修复\n\n```\nsed -i \"s|enabled=1|enabled=0|g\" /etc/yum/pluginconf.d/fastestmirror.conf\nmv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup\ncurl -o /etc/yum.repos.d/CentOS-Base.repo https://www.xmpan.com/Centos-6-Vault-Aliyun.repo \nyum clean all\nyum makecache\n```\n\n手动修复教程:\n\n首先把fastestmirrors关了\n\n```\n#编辑\nvi /etc/yum/pluginconf.d/fastestmirror.conf\n#修改\nenable=0\n#或者执行以下命令\nsed -i \"s|enabled=1|enabled=0|g\" /etc/yum/pluginconf.d/fastestmirror.conf\n```\n\n先把之前的repo挪到备份，然后下面两个二选一\n\n```\nmv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.bak\n```\n\n替换为官方Vault源(海外服务器用)\n\n```\ncurl -o /etc/yum.repos.d/CentOS-Base.repo https://www.xmpan.com/Centos-6-Vault-Official.repo\n```\n\n或者替换为阿里云Vault镜像(国内服务器用)\n\n```\ncurl -o /etc/yum.repos.d/CentOS-Base.repo https://www.xmpan.com/Centos-6-Vault-Aliyun.repo\n```\n\n\n\n\n\n\n\n\n\n\n\n","tags":["配置记录"]},{"title":"从 SGD 到 AdamW 原理和代码解读","url":"/2021/08/12/从-SGD-到-AdamW-原理和代码解读/","content":"\n# 从 SGD 到 AdamW 原理和代码解读\n\n深度学习优化算法经历了 SGD -> SGDM -> NAG ->AdaGrad -> AdaDelta -> Adam -> Nadam -> AdamW 这样的发展历程。\n\n接下来用一个框架来梳理所有的优化算法。\n\n首先定义：待优化参数：$w$ , 目标函数：$f(x)$ , 初始学习率 $\\alpha$\n\n然后，开始进行迭代优化。在每个epoch $t$:\n\n1. 计算目标函数关于当前参数的梯度: $g_t = ∇f(w_t)$\n2. 根据历史梯度计算一阶动量和二阶动量: $m_t = \\phi(g_1,g_2,...,g_t); V_t =\\psi(g_1,g_2,...,g_t)$\n3. 计算当前时刻的下降梯度: $\\eta = \\alpha \\cdot m_t/\\sqrt V_t$\n4. 根据下降梯度进行更新: $w_{t+1} = w_t -\\eta_t$\n\n步骤3、4对于各个算法几乎都是一致的，主要的差别就体现在1和2上。\n\n也就是计算一阶动量$m_t$ 和 二阶动量$V_t$时采用不同的套路。\n\n此外在所有优化器代码里有一些函数作用是相通的：\n\n> 共性的方法有：\n\n- add_param_group(param_group) : 把参数放进优化器中，这在Fine-tune预训练时可以使冻结层可训练，并随着训练的进行添加到优化器中。\n- load_state_dict(state_dict): 把优化器的状态加载进去。\n- state_dict():返回优化器状态，以dict形式\n- step(closure=None):优化一步参数\n- zero_grad(set_to_none=False):把所有的梯度值设为0\n\n> 使用方法：\n\n```python\nfor input, target in dataset:\n  def closure():\n    optimizer.zero_grad()\n    output = model(input)\n    loss = loss_fn(output, target)\n    return loss\n  optimizer.step(closure)\n```\n\n## SGD\n\nSGD没有动量的概念，也就是说：\n$$\nm_t = g_t ; V_t=I^2\n$$\n代入步骤3，可以看到下降梯度就是最简单的\n$$\n\\eta_t = \\alpha \\cdot g_t\n$$\nSGD最大的缺点就是下降速度慢，而且可能会在沟壑的两边持续震荡，停留在一个局部最优点。\n\n## SGD with Momentum\n\n为了抑制震荡，SGDM认为梯度下降过程可以加入惯性。下坡的时候，如果发现是陡坡，那就利用惯性跑的快一点。\n\n在SGD的基础上引入了一阶动量：\n$$\nm_t = \\beta_1\\cdot m_{t-1} +(1-\\beta_1)\\cdot g_t\n$$\n一阶动量就是各个时刻梯度方向的指数移动平均，约等于最近$1/(1-\\beta_1)$个时刻的梯度向量和的平均值。\n\n也就是说，t 时刻的下降方向，不仅由当前点的梯度方向决定，而且由此前累积的下降方向决定。\n\n$\\beta_1$的经验值为0.9，这意味着下降方向主要是此前累积的下降方向，并略微偏向当前时刻的下降方向。想象高速公路上汽车转弯，在高速向前的同时略微偏向，急转弯可是要出事的。\n\n## SGD with Nesterov Acceleration\n\nSGD还有一个问题是困在局部最优的沟壑里震荡。想象一下你走到一个盆地，四周都是略高的小山，你觉得没有下坡的方向，那就只能呆在这里了。可是你如果爬上高地，就会方向外卖的世界还很广阔。\n\n因此外卖不能停留在当前位置去观察未来的方向，而是要向前一步，多看一步，看远一些。\n\nNAG全称Nesterov Accelerated Gradient，是在SGD、SGDM的基础上的进一步改进，改进点在于步骤1。\n\n我们知道在时刻 t 的主要下降方向是由累积动量决定的，自己的梯度方向说了也不算。那与其看当前梯度方向，不如先看看如果跟着累积动量走了一步，那个时候再怎么走。\n\n因此NAG在步骤1，不计算当前位置的梯度方向，而是计算如果按照累积动量走了一步，那个时候的下降方向：\n$$\ng_t =∇ f(w_t-\\beta_1\\cdot m_{t-1}/\\sqrt{V_{t-1}})\n$$\n然后用下一个点的梯度方向，与历史累积动量结合，计算步骤2中当前时刻的累加动量。\n\n> 定义优化器：\n\n```\nCLASS torch.optim.SGD(params, lr=<required parameter>, momentum=0, dampening=0, weight_decay=0, nesterov=False)\n```\n\n> 参数：\n\n- **params** (iterable) – 优化器作用的模型参数。\n- **lr** (float) – learning rate，相当于是统一框架中的 $\\alpha$\n- **momentum** (float, optional) – 动量参数。(默认值：0)\n- **weight_decay** (float, optional) – 权重衰减系数 weight decay (L2 penalty) (默认值：0)\n- **dampening** (float, optional) – dampening for momentum (默认值：0)\n- **nesterov** (bool, optional) – 允许 Nesterov momentum (默认值：False)\n\n> 源码解读：\n\n```python\nimport torch\nfrom .optimizer import Optimizer, required\n\n\n[docs]class SGD(Optimizer):\n    r\"\"\"Implements stochastic gradient descent (optionally with momentum).\n\n    Nesterov momentum is based on the formula from\n    `On the importance of initialization and momentum in deep learning`__.\n\n    Args:\n        params (iterable): iterable of parameters to optimize or dicts defining\n            parameter groups\n        lr (float): learning rate\n        momentum (float, optional): momentum factor (default: 0)\n        weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n        dampening (float, optional): dampening for momentum (default: 0)\n        nesterov (bool, optional): enables Nesterov momentum (default: False)\n\n    Example:\n        >>> optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n        >>> optimizer.zero_grad()\n        >>> loss_fn(model(input), target).backward()\n        >>> optimizer.step()\n\n    __ http://www.cs.toronto.edu/%7Ehinton/absps/momentum.pdf\n\n    .. note::\n        The implementation of SGD with Momentum/Nesterov subtly differs from\n        Sutskever et. al. and implementations in some other frameworks.\n\n        Considering the specific case of Momentum, the update can be written as\n\n        .. math::\n            \\begin{aligned}\n                v_{t+1} & = \\mu * v_{t} + g_{t+1}, \\\\\n                p_{t+1} & = p_{t} - \\text{lr} * v_{t+1},\n            \\end{aligned}\n\n        where :math:`p`, :math:`g`, :math:`v` and :math:`\\mu` denote the \n        parameters, gradient, velocity, and momentum respectively.\n\n        This is in contrast to Sutskever et. al. and\n        other frameworks which employ an update of the form\n\n        .. math::\n            \\begin{aligned}\n                v_{t+1} & = \\mu * v_{t} + \\text{lr} * g_{t+1}, \\\\\n                p_{t+1} & = p_{t} - v_{t+1}.\n            \\end{aligned}\n\n        The Nesterov version is analogously modified.\n    \"\"\"\n\n    def __init__(self, params, lr=required, momentum=0, dampening=0,\n                 weight_decay=0, nesterov=False):\n        if lr is not required and lr < 0.0:\n            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n        if momentum < 0.0:\n            raise ValueError(\"Invalid momentum value: {}\".format(momentum))\n        if weight_decay < 0.0:\n            raise ValueError(\"Invalid weight_decay value: {}\".format(weight_decay))\n\n        defaults = dict(lr=lr, momentum=momentum, dampening=dampening,\n                        weight_decay=weight_decay, nesterov=nesterov)\n        if nesterov and (momentum <= 0 or dampening != 0):\n            raise ValueError(\"Nesterov momentum requires a momentum and zero dampening\")\n        super(SGD, self).__init__(params, defaults)\n\n    def __setstate__(self, state):\n        super(SGD, self).__setstate__(state)\n        for group in self.param_groups:\n            group.setdefault('nesterov', False)\n\n[docs]    @torch.no_grad()\n    def step(self, closure=None):\n        \"\"\"Performs a single optimization step.\n\n        Arguments:\n            closure (callable, optional): A closure that reevaluates the model\n                and returns the loss.\n        \"\"\"\n        loss = None\n        if closure is not None:\n            with torch.enable_grad():\n                loss = closure()\n\n        for group in self.param_groups:\n            weight_decay = group['weight_decay']\n            momentum = group['momentum']\n            dampening = group['dampening']\n            nesterov = group['nesterov']\n\n            for p in group['params']:\n                if p.grad is None:\n                    continue\n                d_p = p.grad  # 得到每个参数的梯度，也就是g_t\n                if weight_decay != 0: # 如果使用weight_decay的话，相当于目标函数上加上 L2正则\n                    d_p = d_p.add(p, alpha=weight_decay)\n                if momentum != 0:\n                    param_state = self.state[p]\n                    if 'momentum_buffer' not in param_state:\n                        buf = param_state['momentum_buffer'] = torch.clone(d_p).detach()\n                    else:\n                        buf = param_state['momentum_buffer']\n                        # 计算动量，momentum参数beta_1一般取0.9，相当于之前的动量buf乘以0.9再加上此次梯度\n                        # d_p乘以(1-beta_1)=0.1\n                        buf.mul_(momentum).add_(d_p, alpha=1 - dampening)\n                    if nesterov:\n                      \t# 如果通过nesterov方式更新参数，那么eta_t就相当于g_t+m_t*beta_1\n                        d_p = d_p.add(buf, alpha=momentum)\n                    else:\n                      \t# 如果不通过nesterov方式更新参数，那么\\eta_t就是相当于是上一步计算出的动量m_t\n                        d_p = buf\n\n                p.add_(d_p, alpha=-group['lr']) #最后用学习率更新梯度\n\n        return loss\n```\n\n\n\n## AdaGrad\n\n此前我们都没有用到二阶动量。二阶动量的出现，才意味着“自适应学习率”优化算法时代的到来。\n\nSGD及其变种以同样的学习率更新每个参数，但深度神经网络往往包含大量的参数，这些参数并不是总会用得到(想想大规模的embedding)。\n\n对于偶尔更新的参数，我们了解的信息太少，希望能从每个偶然出现的样本身上多学习一些，即学习率大一些。\n\n怎么样去度量历史更新频率呢？那就是二阶动量——该维度上，迄今为止所有梯度值的平方和：\n$$\nV_t = \\sum_{\\tau=1}^t g_{\\tau}^2\n$$\n我们在回顾一些步骤3中的下降梯度：\n$$\n\\eta_t = \\alpha\\cdot m_t/\\sqrt{V_t}\n$$\n可以看出，此时实质上的学习率由$\\alpha$ 变成了，$\\alpha/\\sqrt{V_t}$。\n\n一般为了避免分母为0，会在分母上加一个小的平滑项。因此$\\sqrt{V_t}$是恒大于0的，而且参数更新越频繁，二阶动量越大，学习率就越小。\n\n这一方法在稀疏数据场景下表现非常好，但也存在一些问题：因为$\\sqrt{V_t}$ 是单调递增的，会使学习率单调递减至0，可能会使训练过程提前结束，即便后续还有数据也无法学到必要的知识。\n\n> 定义优化器：\n\n```\nCLASS torch.optim.Adagrad(params,lr=0.01,lr_decay=0,weight_decay=0,initial_accumulator_value=0,eps=1e-10)\n```\n\n> 参数：\n\n- **params** (iterable) – 优化器作用的模型参数。\n- **lr** (float) – learning rate – 相当于是统一框架中的 。\n- **lr_decay**(float,optional) – 学习率衰减 (默认值：0)\n- **weight_decay** (float, optional) – 权重衰减系数 weight decay (L2 penalty) (默认值：0)\n- **eps**(float,optional)：防止分母为0的一个小数 (默认值：1e-10)\n\n> 源码解读：\n\n```python\n[docs]class Adagrad(Optimizer):\n    \"\"\"Implements Adagrad algorithm.\n\n    It has been proposed in `Adaptive Subgradient Methods for Online Learning\n    and Stochastic Optimization`_.\n\n    Arguments:\n        params (iterable): iterable of parameters to optimize or dicts defining\n            parameter groups\n        lr (float, optional): learning rate (default: 1e-2)\n        lr_decay (float, optional): learning rate decay (default: 0)\n        weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n        eps (float, optional): term added to the denominator to improve\n            numerical stability (default: 1e-10)\n\n    .. _Adaptive Subgradient Methods for Online Learning and Stochastic\n        Optimization: http://jmlr.org/papers/v12/duchi11a.html\n    \"\"\"\n\n    def __init__(self, params, lr=1e-2, lr_decay=0, weight_decay=0, initial_accumulator_value=0, eps=1e-10):\n        if not 0.0 <= lr:\n            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n        if not 0.0 <= lr_decay:\n            raise ValueError(\"Invalid lr_decay value: {}\".format(lr_decay))\n        if not 0.0 <= weight_decay:\n            raise ValueError(\"Invalid weight_decay value: {}\".format(weight_decay))\n        if not 0.0 <= initial_accumulator_value:\n            raise ValueError(\"Invalid initial_accumulator_value value: {}\".format(initial_accumulator_value))\n        if not 0.0 <= eps:\n            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n\n        defaults = dict(lr=lr, lr_decay=lr_decay, eps=eps, weight_decay=weight_decay,\n                        initial_accumulator_value=initial_accumulator_value)\n        super(Adagrad, self).__init__(params, defaults)\n\n        for group in self.param_groups:\n            for p in group['params']:\n                state = self.state[p]\n                state['step'] = 0\n                state['sum'] = torch.full_like(p, initial_accumulator_value, memory_format=torch.preserve_format)\n\n    def share_memory(self):\n        for group in self.param_groups:\n            for p in group['params']:\n                state = self.state[p]\n                state['sum'].share_memory_()\n\n[docs]    @torch.no_grad()\n    def step(self, closure=None):\n        \"\"\"Performs a single optimization step.\n\n        Arguments:\n            closure (callable, optional): A closure that reevaluates the model\n                and returns the loss.\n        \"\"\"\n        loss = None\n        if closure is not None:\n            with torch.enable_grad():\n                loss = closure()\n\n        for group in self.param_groups:\n            params_with_grad = []\n            grads = []\n            state_sums = []\n            state_steps = []\n\n            for p in group['params']:\n                if p.grad is not None:\n                    params_with_grad.append(p)\n                    grads.append(p.grad)\n                    state = self.state[p]\n                    state_sums.append(state['sum'])\n                    # update the steps for each param group update\n                    state['step'] += 1\n                    # record the step after step update\n                    state_steps.append(state['step'])\n\n            F.adagrad(params_with_grad,\n                      grads,\n                      state_sums,\n                      state_steps,\n                      group['lr'],\n                      group['weight_decay'],\n                      group['lr_decay'],\n                      group['eps'])\n\n        return loss\n```\n\n## AdaDelta \n\n由于AdaGrad 单调递减的学习率变化过于激进，我们考虑一个改变二阶动量计算方法的策略：不累积全部历史梯度，而只关注过去一段时间窗口的下降梯度。这也是就是AdaDelta名称中Delta的来历。\n\n修改思路很简单，前面讲到，指数移动平均值大约就是过去一段时间的平均值，因此我们用这一方法来计算二阶累积动量：\n$$\nV_t = \\beta_2 * V_{t-1} + (1-\\beta_2)g_t^2\n$$\n接下来还是步骤3：\n$$\n\\eta_t = \\alpha \\cdot g_t/\\sqrt{V_t}\n$$\n这就避免了二阶动量持续累积、导致训练过程提前结束的问题了。\n\n## RMSProp\n\n> 定义优化器：\n\n```\nCLASS torch.optim.RMSprop(params, lr=0.01, alpha=0.99, eps=1e-08, weight_decay=0, momentum=0, centered=False)\n```\n\n> 参数：\n\n- **params** (iterable) – 优化器作用的模型参数。\n- **lr** (float) – learning rate – 相当于是统一框架中的 $\\alpha$。\n- **momentum** (float, optional) – 动量参数。(默认值：0)。\n- **alpha**(*float,optional*) – 平滑常数 (默认值：0.99)。\n- **centered**(bool,optional) – if`True`, compute the centered RMSProp, the gradient is normalized by an estimation of its variance，就是这一项是 True 的话就把方差使用梯度作归一化。\n- **weight_decay** (float, optional) – 权重衰减系数 weight decay (L2 penalty) (默认值：0)\n- **eps**(float,optional)：防止分母为0的一个小数 (默认值：1e-10)\n\n> **源码解读：**\n\n```python\nimport torch\nfrom .optimizer import Optimizer\n\n\n[docs]class RMSprop(Optimizer):\n    r\"\"\"Implements RMSprop algorithm.\n\n    Proposed by G. Hinton in his\n    `course <https://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf>`_.\n\n    The centered version first appears in `Generating Sequences\n    With Recurrent Neural Networks <https://arxiv.org/pdf/1308.0850v5.pdf>`_.\n\n    The implementation here takes the square root of the gradient average before\n    adding epsilon (note that TensorFlow interchanges these two operations). The effective\n    learning rate is thus :math:`\\alpha/(\\sqrt{v} + \\epsilon)` where :math:`\\alpha`\n    is the scheduled learning rate and :math:`v` is the weighted moving average\n    of the squared gradient.\n\n    Arguments:\n        params (iterable): iterable of parameters to optimize or dicts defining\n            parameter groups\n        lr (float, optional): learning rate (default: 1e-2)\n        momentum (float, optional): momentum factor (default: 0)\n        alpha (float, optional): smoothing constant (default: 0.99)\n        eps (float, optional): term added to the denominator to improve\n            numerical stability (default: 1e-8)\n        centered (bool, optional) : if ``True``, compute the centered RMSProp,\n            the gradient is normalized by an estimation of its variance\n        weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n\n    \"\"\"\n\n    def __init__(self, params, lr=1e-2, alpha=0.99, eps=1e-8, weight_decay=0, momentum=0, centered=False):\n        if not 0.0 <= lr:\n            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n        if not 0.0 <= eps:\n            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n        if not 0.0 <= momentum:\n            raise ValueError(\"Invalid momentum value: {}\".format(momentum))\n        if not 0.0 <= weight_decay:\n            raise ValueError(\"Invalid weight_decay value: {}\".format(weight_decay))\n        if not 0.0 <= alpha:\n            raise ValueError(\"Invalid alpha value: {}\".format(alpha))\n\n        defaults = dict(lr=lr, momentum=momentum, alpha=alpha, eps=eps, centered=centered, weight_decay=weight_decay)\n        super(RMSprop, self).__init__(params, defaults)\n\n    def __setstate__(self, state):\n        super(RMSprop, self).__setstate__(state)\n        for group in self.param_groups:\n            group.setdefault('momentum', 0)\n            group.setdefault('centered', False)\n\n[docs]    @torch.no_grad()\n    def step(self, closure=None):\n        \"\"\"Performs a single optimization step.\n\n        Arguments:\n            closure (callable, optional): A closure that reevaluates the model\n                and returns the loss.\n        \"\"\"\n        loss = None\n        if closure is not None:\n            with torch.enable_grad():\n                loss = closure()\n\n        for group in self.param_groups:\n            for p in group['params']:\n                if p.grad is None:\n                    continue\n                grad = p.grad\n                if grad.is_sparse:\n                    raise RuntimeError('RMSprop does not support sparse gradients')\n                state = self.state[p]\n\n                # State initialization\n                if len(state) == 0:\n                    state['step'] = 0\n                    state['square_avg'] = torch.zeros_like(p, memory_format=torch.preserve_format)\n                    if group['momentum'] > 0:\n                        state['momentum_buffer'] = torch.zeros_like(p, memory_format=torch.preserve_format)\n                    if group['centered']:\n                        state['grad_avg'] = torch.zeros_like(p, memory_format=torch.preserve_format)\n\n                square_avg = state['square_avg']\n                alpha = group['alpha']\n\n                state['step'] += 1\n\n                if group['weight_decay'] != 0:\n                    grad = grad.add(p, alpha=group['weight_decay'])\n\n                square_avg.mul_(alpha).addcmul_(grad, grad, value=1 - alpha)\n\n                if group['centered']:\n                    grad_avg = state['grad_avg']\n                    grad_avg.mul_(alpha).add_(grad, alpha=1 - alpha)\n                    avg = square_avg.addcmul(grad_avg, grad_avg, value=-1).sqrt_().add_(group['eps']) # 计算当前步的动量\n                else:\n                    avg = square_avg.sqrt().add_(group['eps'])\n\n                if group['momentum'] > 0:\n                    buf = state['momentum_buffer']\n                    buf.mul_(group['momentum']).addcdiv_(grad, avg)\n                    p.add_(buf, alpha=-group['lr'])\n                else:\n                    p.addcdiv_(grad, avg, value=-group['lr'])\n\n        return loss\n```\n\nRMSprop算是Adagrad的一种发展，和Adadelta的变体，效果趋于二者之间\n\n\n\n## Adam\n\n谈到这里，Adam和Nadam的出现就很自然而然了——他们是前述方法的集大成者。\n\nSGDM在SGD基础上增加了一阶动量，AdaGrad和AdaDelta在SGD基础上增加的二阶动量。\n\n把一阶动量和二阶动量都用起来就是Adam了——Adaptive + Momentum\n\nSGD的一阶动量：\n$$\nm_t = \\beta_1 \\cdot m_{t-1} +(1-\\beta_1)\\cdot g_t\n$$\n加上AdaDelta的二阶动量：\n$$\n\\hat m_t =\\frac{m_t}{1-\\beta_1^t}\n$$\n\n$$\n\\hat V_t = \\frac{V_t}{1-\\beta_2^t}\n$$\n\n优化算法里最常见的两个超参数$\\beta_1,\\beta_2$就都在这里了，前者是控制一阶动量，后者控制二阶动量。\n\n## Nadam\n\n都说Adam是集大成者，但它遗漏了Nesterov，安装NAG的步骤1：\n$$\ng_t = ∇f(w_t-\\alpha\\cdot m_{t-1}/\\sqrt{V_t})\n$$\nNesterov+Adam = Nadam\n\n> 定义优化器：\n\n```\nCLASS torch.optim.Adam(params, lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n```\n\n> 参数：\n\n- **params** (iterable) – 优化器作用的模型参数。\n- **lr** (float) – learning rate – 相当于是统一框架中的 。\n- **betas**(Tuple[float,float],optional) – coefficients used for computing running averages of gradient and its square ((默认值：(0.9, 0.999))\n- **weight_decay** (float, optional) – 权重衰减系数 weight decay (L2 penalty) (默认值：0)\n- **eps**(float,optional)：防止分母为0的一个小数 (默认值：1e-10)\n\n```python\nimport math\nimport torch\nfrom .optimizer import Optimizer\n\n\n[docs]class Adam(Optimizer):\n    r\"\"\"Implements Adam algorithm.\n\n    It has been proposed in `Adam: A Method for Stochastic Optimization`_.\n\n    Arguments:\n        params (iterable): iterable of parameters to optimize or dicts defining\n            parameter groups\n        lr (float, optional): learning rate (default: 1e-3)\n        betas (Tuple[float, float], optional): coefficients used for computing\n            running averages of gradient and its square (default: (0.9, 0.999))\n        eps (float, optional): term added to the denominator to improve\n            numerical stability (default: 1e-8)\n        weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n        amsgrad (boolean, optional): whether to use the AMSGrad variant of this\n            algorithm from the paper `On the Convergence of Adam and Beyond`_\n            (default: False)\n\n    .. _Adam\\: A Method for Stochastic Optimization:\n        https://arxiv.org/abs/1412.6980\n    .. _On the Convergence of Adam and Beyond:\n        https://openreview.net/forum?id=ryQu7f-RZ\n    \"\"\"\n\n    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8,\n                 weight_decay=0, amsgrad=False):\n        if not 0.0 <= lr:\n            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n        if not 0.0 <= eps:\n            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n        if not 0.0 <= betas[0] < 1.0:\n            raise ValueError(\"Invalid beta parameter at index 0: {}\".format(betas[0]))\n        if not 0.0 <= betas[1] < 1.0:\n            raise ValueError(\"Invalid beta parameter at index 1: {}\".format(betas[1]))\n        if not 0.0 <= weight_decay:\n            raise ValueError(\"Invalid weight_decay value: {}\".format(weight_decay))\n        defaults = dict(lr=lr, betas=betas, eps=eps,\n                        weight_decay=weight_decay, amsgrad=amsgrad)\n        super(Adam, self).__init__(params, defaults)\n\n    def __setstate__(self, state):\n        super(Adam, self).__setstate__(state)\n        for group in self.param_groups:\n            group.setdefault('amsgrad', False)\n\n[docs]    @torch.no_grad()\n    def step(self, closure=None):\n        \"\"\"Performs a single optimization step.\n\n        Arguments:\n            closure (callable, optional): A closure that reevaluates the model\n                and returns the loss.\n        \"\"\"\n        loss = None\n        if closure is not None:\n            with torch.enable_grad():\n                loss = closure()\n\n        for group in self.param_groups:\n            for p in group['params']:\n                if p.grad is None:\n                    continue\n                grad = p.grad\n                if grad.is_sparse:\n                    raise RuntimeError('Adam does not support sparse gradients, please consider SparseAdam instead')\n                amsgrad = group['amsgrad']\n\n                state = self.state[p]\n\n                # State initialization\n                if len(state) == 0:\n                    state['step'] = 0\n                    # Exponential moving average of gradient values\n                    state['exp_avg'] = torch.zeros_like(p, memory_format=torch.preserve_format)\n                    # Exponential moving average of squared gradient values\n                    state['exp_avg_sq'] = torch.zeros_like(p, memory_format=torch.preserve_format)\n                    if amsgrad:\n                        # Maintains max of all exp. moving avg. of sq. grad. values\n                        state['max_exp_avg_sq'] = torch.zeros_like(p, memory_format=torch.preserve_format)\n\n                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n                if amsgrad:\n                    max_exp_avg_sq = state['max_exp_avg_sq']\n                beta1, beta2 = group['betas']\n\n                state['step'] += 1\n                bias_correction1 = 1 - beta1 ** state['step']\n                bias_correction2 = 1 - beta2 ** state['step']\n\n                if group['weight_decay'] != 0:\n                    grad = grad.add(p, alpha=group['weight_decay'])\n\n                # Decay the first and second moment running average coefficient\n                exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n                exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=1 - beta2)\n                if amsgrad:\n                    # Maintains the maximum of all 2nd moment running avg. till now\n                    torch.max(max_exp_avg_sq, exp_avg_sq, out=max_exp_avg_sq)\n                    # Use the max. for normalizing running avg. of gradient\n                    denom = (max_exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(group['eps'])\n                else:\n                    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(group['eps'])\n\n                step_size = group['lr'] / bias_correction1\n\n                p.addcdiv_(exp_avg, denom, value=-step_size)\n\n        return loss\n```\n\n## AdamW\n\nAdam的另一个改进版AdamW\n\nAdamW就是Adam优化器加上L2正则，来限制参数值不可太大。\n\n以往的L2正则是直接加在损失函数上，比如这样：加入正则， 损失函数就会变成：\n$$\nL_{l_2}(\\theta) = L(\\theta) + 1/2\\gamma||\\theta||^2\n$$\n所以在计算梯度$g_t$时要加上粉色的这一项。\n\n但AdamW稍有不同，如下图所示，将正则加在了绿色位置。\n\n![](https://i.loli.net/2021/08/13/C37Bz8jYiwRI4fF.png)\n\n至于为何这么做？直接摘录BERT里面的原话看看：\n\n> **Just** adding the square of the weights to the loss function is *not* the correct way of using L2 regularization/weight decay with Adam, since that will interact with the m and v parameters in strange ways. Instead we want to decay the weights in a manner that doesn't interact with the m/v parameters. This is equivalent to adding the square of the weights to the loss with plain (non-momentum) SGD. Add weight decay at the end (fixed version).\n\n意思s 如果直接将L2正则加到loss上去，由于Adam优化器的后续操作，该正则项将会与$m_t$和$v_t$产生奇怪的作用。因而，AdamW选择将L2正则项加在了Adam的$m_t$和$v_t$等参数被计算完之后，在于学习率$\\eta$相乘之前，所以这也表明了weight_decay和L2正则虽目的一致、公式一致，但用法还是不同，二者有明显的区别。\n\n以 PyTorch1.7.0 中的AdamW代码为例：\n\n> 定义优化器：\n\n```\nCLASS torch.optim.AdamW(params, lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01, amsgrad=False)\n```\n\n- **params** (iterable) – 优化器作用的模型参数。\n- **lr** (float) – learning rate – 相当于是统一框架中的 。\n- **betas**(Tuple[float,float],optional) – coefficients used for computing running averages of gradient and its square ((默认值：(0.9, 0.999))\n- **weight_decay** (float, optional) – 权重衰减系数 weight decay (L2 penalty) (默认值：0)\n- **eps**(float,optional)：防止分母为0的一个小数 (默认值：1e-10)\n\n```python\nimport math\nimport torch\nfrom .optimizer import Optimizer\n\n\n[docs]class AdamW(Optimizer):\n    r\"\"\"Implements AdamW algorithm.\n\n    The original Adam algorithm was proposed in `Adam: A Method for Stochastic Optimization`_.\n    The AdamW variant was proposed in `Decoupled Weight Decay Regularization`_.\n\n    Arguments:\n        params (iterable): iterable of parameters to optimize or dicts defining\n            parameter groups\n        lr (float, optional): learning rate (default: 1e-3)\n        betas (Tuple[float, float], optional): coefficients used for computing\n            running averages of gradient and its square (default: (0.9, 0.999))\n        eps (float, optional): term added to the denominator to improve\n            numerical stability (default: 1e-8)\n        weight_decay (float, optional): weight decay coefficient (default: 1e-2)\n        amsgrad (boolean, optional): whether to use the AMSGrad variant of this\n            algorithm from the paper `On the Convergence of Adam and Beyond`_\n            (default: False)\n\n    .. _Adam\\: A Method for Stochastic Optimization:\n        https://arxiv.org/abs/1412.6980\n    .. _Decoupled Weight Decay Regularization:\n        https://arxiv.org/abs/1711.05101\n    .. _On the Convergence of Adam and Beyond:\n        https://openreview.net/forum?id=ryQu7f-RZ\n    \"\"\"\n\n    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8,\n                 weight_decay=1e-2, amsgrad=False):\n        if not 0.0 <= lr:\n            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n        if not 0.0 <= eps:\n            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n        if not 0.0 <= betas[0] < 1.0:\n            raise ValueError(\"Invalid beta parameter at index 0: {}\".format(betas[0]))\n        if not 0.0 <= betas[1] < 1.0:\n            raise ValueError(\"Invalid beta parameter at index 1: {}\".format(betas[1]))\n        if not 0.0 <= weight_decay:\n            raise ValueError(\"Invalid weight_decay value: {}\".format(weight_decay))\n        defaults = dict(lr=lr, betas=betas, eps=eps,\n                        weight_decay=weight_decay, amsgrad=amsgrad)\n        super(AdamW, self).__init__(params, defaults)\n\n    def __setstate__(self, state):\n        super(AdamW, self).__setstate__(state)\n        for group in self.param_groups:\n            group.setdefault('amsgrad', False)\n\n[docs]    @torch.no_grad()\n    def step(self, closure=None):\n        \"\"\"Performs a single optimization step.\n\n        Arguments:\n            closure (callable, optional): A closure that reevaluates the model\n                and returns the loss.\n        \"\"\"\n        loss = None\n        if closure is not None:\n            with torch.enable_grad():\n                loss = closure()\n\n        for group in self.param_groups:\n            for p in group['params']:\n                if p.grad is None:\n                    continue\n\n                # Perform stepweight decay\n                p.mul_(1 - group['lr'] * group['weight_decay'])\n\n                # Perform optimization step\n                grad = p.grad\n                if grad.is_sparse:\n                    raise RuntimeError('Adam does not support sparse gradients, please consider SparseAdam instead')\n                amsgrad = group['amsgrad']\n\n                state = self.state[p]\n\n                # State initialization\n                if len(state) == 0:\n                    state['step'] = 0\n                    # Exponential moving average of gradient values\n                    state['exp_avg'] = torch.zeros_like(p, memory_format=torch.preserve_format)\n                    # Exponential moving average of squared gradient values\n                    state['exp_avg_sq'] = torch.zeros_like(p, memory_format=torch.preserve_format)\n                    if amsgrad:\n                        # Maintains max of all exp. moving avg. of sq. grad. values\n                        state['max_exp_avg_sq'] = torch.zeros_like(p, memory_format=torch.preserve_format)\n\n                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n                if amsgrad:\n                    max_exp_avg_sq = state['max_exp_avg_sq']\n                beta1, beta2 = group['betas']\n\n                state['step'] += 1\n                bias_correction1 = 1 - beta1 ** state['step']\n                bias_correction2 = 1 - beta2 ** state['step']\n\n                # Decay the first and second moment running average coefficient\n                exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n                exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=1 - beta2)\n                if amsgrad:\n                    # Maintains the maximum of all 2nd moment running avg. till now\n                    torch.max(max_exp_avg_sq, exp_avg_sq, out=max_exp_avg_sq)\n                    # Use the max. for normalizing running avg. of gradient\n                    denom = (max_exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(group['eps'])\n                else:\n                    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(group['eps'])\n\n                step_size = group['lr'] / bias_correction1\n\n                p.addcdiv_(exp_avg, denom, value=-step_size)\n\n        return loss\n```\n\n与Adam不一样的地方是：\n\nAdam如果使用weight_decay的话，那么相当于目标函数上加了$1/2\\gamma||\\theta||^2$，所以相当于是梯度加上$\\gamma\\theta$故Adam使用了\n\ngrad = grad.add(p, alpha=group['weight_decay'])\n\n而 AdamW 是 p.mul_(1 - group['lr'] * group['weight_decay']) 直接让参数：\n\n$\\theta_t =\\theta_{t-1}-\\alpha\\cdot\\lambda\\cdot\\theta_{t-1}-\\alpha\\cdot\\eta_t$\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["ML&DL"]},{"title":"TreeMap红黑树","url":"/2021/08/10/TreeMap红黑树/","content":"\n# TreeMap红黑树\n\n- 前言\n- 二叉查找树BST\n- BST存在的问题\n- 2-3-4树\n- 红黑树\n\n## 前言\n\n除了要学会着色、旋转规则，还要了解为什么变色，为什么旋转。\n\n五大性质的缘由\n\njdk的TreeMap在红黑树上做了一些优化，原版红黑树删除操作它是找的前驱节点替代原删除节点，而TreeMap源码里是用的后继节点替代原删除节点，这两种方案实际效果一样，只不过树的结构不一样，但是对应的红黑树都是平衡的。\n\n\n\n## 二叉查找树(BST)\n\n### 定义\n\n二叉查找树，就是一颗二叉树，他的左节点比父节点小，右节点比父节点大，他的高度决定查找效率。\n\n![](https://i.loli.net/2021/08/10/K6rNGpl3tUue714.png)\n\n### 操作\n\n查找(红黑树通用)：查找每个节点从根开始\n\n- 查找值比当前大，搜右子树\n- 查找值等于当前值，停止查找，返回\n- 查找值比当前值小，则搜右子树\n\n插入：要插入节点，必须先找到插入节点位置，按照搜索的流程，找到左子树或右子树为空的位置插入。\n\n遍历(红黑树通用)：前中后序遍历。\n\n查找最小值(红黑树通用)：沿着根节点的左子树一路查找，直到最后一个不为空的节点\n\n查找最大值(红黑树通用)：沿着根节点的右子树一路查找，直到最后一个不为空的节点\n\n查找前驱节点(红黑树通用)：小于当前节点的最大值\n\n查找后继节点(红黑树通用)：大于当前节点的最小值\n\n![](https://z3.ax1x.com/2021/08/20/fX2DBT.png)\n\n删除 : 本质上是找前驱或后继节点来替代\n\n- 叶子节点直接删除(没有前驱或或后继)\n- 只有一个子节点的用子节点替代(本质上就是找的前驱节点或者后继节点，左节点就是前驱节点，右节点就是后继节点)\n- 有两个子节点的，需要找到替代节点(替代节点也是前驱或者后继)\n\n删除操作和红黑树一样，只不过红黑树多了着色和旋转过程。\n\n\n\n### BST存在的问题\n\nBST存在的问题是，树在插入的时候会导倾斜，不同的插入顺序会导致高度不一样，而树的高度直接影响了树的查找效率。\n\n基于这个问题平衡二叉树产生了，平衡树的插入和删除时，会通过旋转操作将高度保持在LogN。\n\n其中两款有代表性的平衡树分别为\n\n- AVL树（高度平衡树，具备二叉搜索树的全部特性，而且左右子树高度差不超过1）\n- 红黑树\n\n面试题：有了AVL树为什么还要红黑树？\n\nAVL树由于实现比较复杂，而且插入和删除性能差。AVL很多性能耗在旋转操作上\n\n在实际环境下的应用不如红黑树。\n\n红黑树的实际应用范围广，如java中的HashMap和TreeSet，java8中HashMap的实现因为用RBTree代替链表(链表长度大于8时)，性能有提升。\n\n\n\n## 2-3-4树\n\n### 定义\n\n2-3-4树是四阶B树(Balance Tree)，他属于一种多路查找树，他的结构有以下限制：\n\n- 所有叶子节点都拥有相同的深度。\n- 节点只能是2-节点、3-节点、4-节点之一。\n- - 2-节点：包含1个元素的节点，有2个子节点；\n  - 3-节点：包含2个元素的节点，有3个子节点；\n  - 4-节点：包含3个元素的节点，有4个子节点；\n  - 所有节点必须至少包含1个元素\n- 元素始终保持排序顺序，整体上保持二叉查找树的性质，即父结点大于左子节点，小于右子结点；而且结点有多个元素时，每个元素必须大于它左边的和它的右子树中元素。\n\n![](https://i.loli.net/2021/08/14/dVxDmrkuKgUv6M9.png)\n\n### 结点插入\n\n2-3-4树中结点添加需要遵循以下规则：\n\n- 插入都是向最下面一层插入\n- 升元：将插入结点由2-节点升级成3-节点，或由3-结点升级成4-结点\n- 向4-结点插入元素后，需要将中间元素提到父节点升元，原节点变成两个2-节点，再把元素插入2-结点中，如果父节点也是4-结点，则递归向上层升元，直到根节点后将树高加1。\n\n而将这些规则对应到红黑树里，就是：\n\n- 新插入的结点颜色为**红色**，这样才可能不会对红黑树的高度产生影响。\n- 2-结点对应红黑树中的单个黑色结点，插入时直接成功(对应2-结点升元)\n- 3-结点对应红黑树中的**黑+红**子树，插入后将其修复成**红+黑+红**子树\n- 4-结点对应红黑树中的**红+黑+红**子树，插入后将其修复成**红色祖父+黑色父叔+红色孩子**子树，然后再把祖父结点当成新插入的红色结点递归向上层修复，直至修复成功或遇到root结点。\n\n公式：**红黑树+新增一个节点(红色) = 对等的2-3-4树+新增一个节点**\n\n\n\n### 删除结点\n\n2-3-4树的删除可以全部转换为叶子节点的删除\n\n删除原则是先看能不能和下面的叶子节点合并，能合并的直接合并完后删除，不能合并的就要找个元素替换上去，最终都是要保持平衡。\n\n合并-->删除\n\n合并-->替换-->删除\n\n合并-->无法替换-->再合并-->删除\n\n**红色结点一定全部都在多元素节点中**\n\n红黑树的删除要比插入复杂，还是类比2-3-4树：\n\n- 查找最近的叶子结点的元素替代被删除元素，删除替代元素后，从替代元素所处叶子结点开始处理\n- 降元：4-结点变3-结点，3-结点变2-结点。\n- 2-结点中只有一个元素，所以借兄弟结点中的元素来补充删除后的造成的空结点。\n- 当兄弟结点中也没有多个元素可以补充时，尝试将父节点降元，失败时向上递归，直到子树降元成功或root结点树高减一\n\n将这些规则对应到红黑树中即：\n\n- 查找离当前结点最近的叶子结点作为替代节点，(左子树的最右结点或右子树的最左结点都能保证替换后二叉树的节点排序性质，叶子节点的替代结点是自身) 替换掉被删除结点，从替代的叶子结点向上递归修复。\n- 替代结点颜色为红色(对应2-3-4树中 4-节点或3-结点) 时删除子结点直接成功\n- 替代节点为黑色(对应2-3-4树中 2-节点)时， 意味着替代结点所在的子树会降一层，需要依次检验以下三项，以恢复子树高度：\n- - 兄弟结点的子结点中有红色节点(兄弟结点对应3-结点或4-结点) 能够“借用”，旋转过来后修正颜色。\n  - 父结点是红色结点（父结点对应3-结点或4-结点，可以降元）时，将父结点变为黑色，自身和兄弟结点变红色后删除。\n  - 父结点和兄弟结点都是黑色时，将子树降一层后把 **父结点当做替代结点** 递归向上处理。\n\n\n\n### 红黑树对应一颗2-3-4数，一颗2-3-4树对应多颗红黑树\n\n红黑树和2-3-4树的结点添加和删除都有一共基本规则：避免子树高度变化，因为无论是2-3-4树还是红黑树，一旦子树高度有变动，势必会影响其他子树进行调整。所以我们在插入和删除节点时尽量通过子树内部调整来达到平衡。\n\n2-3-4树实现平衡是通过结点的旋转和结点元素变化，红黑树是通过结点旋转和变色。\n\n![](https://i.loli.net/2021/08/14/kgC4yNQ5frcoXBm.png)\n\n2节点全是黑色，3节点有左倾右倾两种情况，4节点上黑下红\n\n2-3-4树的裂变状态: 红黑树新增都是以红色节点进来的，11裂变上去变成红色，下面两个变成黑色\n\n![](https://i.loli.net/2021/08/14/ykrG7CEatD3hULF.png)\n\n整体对比2-3-4树和红黑树\n\n![](https://i.loli.net/2021/08/14/2OrLtl73KcwIunk.png)\n\n![](https://i.loli.net/2021/08/14/5DzbNJyHqQRv8dx.png)\n\n\n\n\n\n\n\n## 红黑树\n\n<img src=\"https://i.loli.net/2021/08/14/CmA461TBsgPtdjG.png\" style=\"zoom:50%;\" />\n\n### 定义\n\n红黑树是一种结点带有颜色属性的二叉查找树，但它在二叉查找树之外还有以下五大性质：\n\n- 结点是红色或黑色\n- 根是黑色\n- 所有叶子都是黑色(叶子是NIL节点，这类节点不可忽视，否则代码会看不懂)\n- 每个红色节点必须有两个黑色子节点（从每个叶子到根的所有路径上不能有两个连续的红色结点）\n- 从任意一节点到其每个叶子的所有简单路径都包含相同数目的黑色结点（黑色平衡）\n\n### 常见操作\n\n**变色、左旋、右旋**\n\n```java\n    private RBNode root;\n\n    /**\n     * 围绕p左旋\n     * @param p\n     *              pf                  pf\n     *            /                   /\n     *           p                   pr(r)\n     *          / \\                 /  \\\n     *         pl  pr(r)    ->     p   rr\n     *             / \\            / \\\n     *            rl rr          pl  rl\n     */\n    private void leftRotate(RBNode p) {\n        if (p != null) {\n            RBNode r = p.right;\n            p.right = r.left;\n            if (r.left != null) {\n                r.left.parent = p;\n            }\n            r.parent = p.parent;\n            if (p.parent == null) {\n                root = r;\n            } else if (p.parent.left == p) {\n                p.parent.left = r;\n            } else {\n                p.parent.right = r;\n            }\n            r.left = p;\n            p.parent = r;\n        }\n    }\n\n    /**\n     * 围绕p右旋\n     * @param p\n     *          pf                        pf\n     *           \\                         \\\n     *            p                         pl(l)\n     *           / \\           ->           /  \\\n     *       pl(l)  pr                    ll    p\n     *       / \\                               / \\\n     *     ll   lr                            lr  pr\n     */\n    private void rightRotate(RBNode p) {\n        if (p != null) {\n            RBNode l = p.left;\n            p.left = l.right;\n            if (l.right != null) {\n                l.right.parent = p;\n            }\n            l.parent = p.parent;\n            if (p.parent != null) {\n                root = l;\n            } else if (p.parent.right == p) {\n                p.parent.right = l;\n            } else {\n                p.parent.left = l;\n            }\n            l.right = p;\n            p.parent = l;\n        }\n    }\n```\n\n**新增** （七种情况，五种情况需要考虑自平衡）\n\n![](https://i.loli.net/2021/08/30/1zoZ7HYrsJDvkUy.png)\n\n分情况讨论，主要是找到插入位置，然后自平衡(左旋或者右旋) 且插入结点是红色节点(如果是黑色的话那么当前分支上就会多出一个黑色结点出来，从而破坏了黑色平衡)，以下分析全部以左子树为例，右子树的情况则相反。\n\n- 情况1、如果插入的是第一个节点(根节点)，红色变黑色\n- 情况2、如果父节点为黑色，则直接插入，不需要变色\n- 如果父节点为红色，叔叔节点也是红色（此种情况爷爷节点一定是黑色），则父节点和叔叔节点变黑色，爷爷节点变红色（如果爷爷节点是根节点，则再变成黑色），爷爷节点此时需要递归（把爷爷节点当做新插入的节点再次进行比较）\n- 如果父节点是红色，没有叔叔节点或者叔叔节点是黑色（此时只能是NIL节点），则以爷爷节点为支点右旋，旋转之后原来的爷爷节点变红色，原来的父节点变黑色。\n\n还是与2-3-4树对比，新增一定在叶子节点上\n\n情况1\n\n![](https://i.loli.net/2021/08/14/cNnouZS7wDbf48r.png)\n\n情况2——右边相当于左右旋了\n\n![](https://i.loli.net/2021/08/14/rWCDmgQLfAUb7s3.png)\n\n与3节点合并情况\n\n![](https://i.loli.net/2021/08/14/rWPIiuGDKaRx8UQ.png)\n\n![](https://i.loli.net/2021/08/14/yDrf4qQhVX2t65a.png)\n\n![](https://i.loli.net/2021/08/14/8D9eqhpGnMKFwTZ.png)\n\n裂变情况\n\n![](https://i.loli.net/2021/08/14/ahr8mFQO14gBfCY.png)\n\n![](https://z3.ax1x.com/2021/08/20/fXRvW9.png)\n\n![](https://z3.ax1x.com/2021/08/20/fXfK39.png)\n\n\n\n**删除** (重点) 五种情况、两种需要考虑自平衡，又细分八种情况，其中四种为镜像情况\n\n先看二叉搜索树的删除：\n\n- 删除叶子节点，直接删除\n- 删除的节点有一个子节点，那么用子节点来替代\n- 如果删除的节点有2个子节点，此时需要找到前驱节点或者后继节点来替代\n\n写代码时，删除方案：\n\n- 找到前驱节点，复制前驱节点值覆盖准备删除的节点值，然后删除前驱节点\n- 找到后继节点，复制后继节点的值覆盖准备删除的节点值，然后删除后继节点\n- 被删除的前驱节点或者后继节点只有两种情况：1、被删除节点是叶子节点。2、被删除节点只有一个孩子。\n\n找前驱后继代码：\n\n```java\n/**\n     * 找到指定节点的前驱节点，即找小于node节点的最大值\n     *\n     * @param node\n     */\n    private RBNode preedecessor(RBNode node) {\n        if (node == null) return null;\n        else if (node.left != null) {\n            RBNode p = node.left;\n            while (p.right != null) {\n                p = p.right;\n            }\n            return p;\n        } else {\n            // 删除时不一定用到，但找前驱时，左子树就得向上找了\n            // 找到第一个左拐的地方\n            RBNode p = node.parent;\n            RBNode ch = node;\n            while (p != null && p.left == ch) {\n                ch = p;\n                p = p.parent;\n            }\n            return p;\n        }\n    }\n\n    /**\n     * 找到指定节点的后继节点，大于节点的最小值\n     *\n     * @param node\n     * @return\n     */\n    private RBNode sucessor(RBNode node) {\n        if (node == null) return null;\n        else if (node.right != null) {\n            RBNode p = node.right;\n            while (p.left != null) {\n                p = p.left;\n            }\n            return p;\n        } else {\n            // 删除时不一定用到，但找前驱时，左子树就得向上找了\n            // 找到第一个左拐的地方\n            RBNode p = node.parent;\n            RBNode ch = node;\n            while (p != null && p.right == ch) {\n                ch = p;\n                p = p.parent;\n            }\n            return p;\n        }\n    }\n```\n\n\n\n红黑树的删除：1先找到节点，2删除\n\n红黑树上面的删除节点一定是2-3-4树上的叶子节点\n\n![](https://z3.ax1x.com/2021/08/20/fXVpDA.png)\n\n三局话：\n\n- **自己能搞定的自己搞定**：\n- - 如果删除的节点对应于2-3-4树的3节点或者4节点，则直接删除，不用和兄弟或父亲借。\n  - 如果删除的是红色节点，则直接删除；如果是黑色节点，则红色节点上来替代，变黑即可\n- **搞不定的找兄弟和父亲帮忙**:\n- - 前提是找到真正的可用的兄弟结点 (真正的兄弟节点是对应于2-3-4树中的兄弟节点，如上图左，5的兄弟节点是8，图右中5的兄弟节点应该是7和7.5，可以通过旋转来找)\n  - 兄弟节点有的借(此时兄弟节点一定是黑色，如果是红色那说明这个节点不是真正的兄弟节点，需要回到上一步找真正的兄弟节点)\n  - 兄弟节点有两个子节点的情况(两个子节点肯定是红色，如果是黑色的话相当于此时兄弟节点对应2-3-4树是2节点，不可能有多余的元素可以借)，此时需要旋转变色\n  - 兄弟节点只有一个子节点的情况，此时需要旋转变色\n- **父亲和兄弟帮不了那有福同享，有难同当(父亲和兄弟自损)**：\n- - 前提还是找到真正的兄弟节点\n  - 兄弟节点没有多余的元素可借（此时兄弟节点一定为黑色的2节点），此时兄弟节点所在分支也要自损一个黑色节点以达到黑色平衡，最快的方式就是兄弟节点直接变红(相当于减少一个黑色节点)，此时以父节点为root的子树又达到了平衡(两边都比之前少了一个黑色)。但是以祖父结点为root的树依然是不平衡的，此时需要递归处理。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["数据结构"]},{"title":"并查集","url":"/2021/08/10/并查集/","content":"\n# 并查集\n\n## 用途\n\n解决元素分组问题，管理一系列不相交的集合\n\n## 操作\n\n- 合并(Union)：把两个不相交的集合合并为一个集合\n- 查询(Find)：查询两个元素是否在同一个集合\n\n### 以一个应用场景为例应用场景\n\n(洛谷P1551) 亲戚\n\n>**题目背景**\n>若某个家族人员过于庞大，要判断两个是否是亲戚，确实还很不容易，现在给出某个亲戚关系图，求任意给出的两个人是否具有亲戚关系。\n>**题目描述**\n>规定：x和y是亲戚，y和z是亲戚，那么x和z也是亲戚。如果x,y是亲戚，那么x的亲戚都是y的亲戚，y的亲戚也都是x的亲戚。\n>**输入格式**\n>第一行：三个整数n,m,p，（n<=5000,m<=5000,p<=5000），分别表示有n个人，m个亲戚关系，询问p对亲戚关系。\n>以下m行：每行两个数Mi，Mj，1<=Mi，Mj<=N，表示Mi和Mj具有亲戚关系。\n>接下来p行：每行两个数Pi，Pj，询问Pi和Pj是否具有亲戚关系。\n>**输出格式**\n>P行，每行一个’Yes’或’No’。表示第i个询问的答案为“具有”或“不具有”亲戚关系。\n\n把所有人划分到若干个不相交的集合中，每个集合里的人彼此是亲戚。为了判断两个人是否为亲戚，只需看它们是否属于同一个集合即可。因此，这里就可以考虑用并查集进行维护。\n\n\n## 思想\n\n**用集合中的一个元素代表集合**。我曾看过一个有趣的比喻，把集合比喻成**帮派**，而代表元素则是**帮主**。接下来我们利用这个比喻，看看并查集是如何运作的。\n\n![](https://i.loli.net/2021/08/10/2xK7tBoWcLDlghy.png)\n\n最开始，每个元素的代表元素是自己。每个元素的最顶端是自己，是一个自环节点。\n\n在比较两人是不是一个帮派的时候，就找自己的帮主，看看是不是一个帮主。每个元素向上找，找到不能再找了就是了。\n\n然而帮派规模大了，肯定会造成等级(树的深度)变深。\n\n有两个操作可以优化一个是路径压缩，一个是按秩压缩。\n\n之前说找帮主来判断两个元素是否在同一集合内。找到帮主一样说明是一个集合里的，不一样把较小集合的帮主指向较大集合的帮主，这样做就是按秩压缩：\n\n![](https://i.loli.net/2021/08/10/QYl1ZJRFnekUhCB.png)\n\n按秩压缩了之后其实还是可以发现树是深度是越来越深的，那么再采取路径压缩。\n\n在每次向上查找的过程中，将路过的节点之间指向帮主，这是通过栈来实现的。\n\n\n\n## 代码\n\n```java\npublic class 并查集 {\n\n    // 样本进来会包一层，叫做元素\n    public static class Element<V> {\n        public V value;\n\n        public Element(V value) {\n            this.value = value;\n        }\n    }\n\n    public static class UnionFindSet<V> {\n\n        public HashMap<V, Element<V>> elementMap;\n        // key 某个元素value 该元素的父\n        public HashMap<Element<V>, Element<V>> fatherMap;\n        // key 某个集合的代表元素， value该集合的大小\n        public HashMap<Element<V>, Integer> sizeMap;\n\n        public UnionFindSet(List<V> list) {\n            elementMap = new HashMap<>();\n            fatherMap = new HashMap<>();\n            sizeMap = new HashMap<>();\n\n            for (V value : list) {\n                Element element = new Element(value);\n                elementMap.put(value, element);\n                fatherMap.put(element, element);\n                sizeMap.put(element, 1);\n            }\n        }\n\n        // 给定一个element，网上找，把代表元素返回\n        private Element<V> findHead(Element<V> element) {\n            Stack<Element<V>> path = new Stack<>();\n            while (element != fatherMap.get(element)) {\n                path.push(element);\n                element = fatherMap.get(element);\n            }\n            while (!path.isEmpty()) {  // 路径铺平\n                fatherMap.put(path.pop(), element);\n            }\n            return element;\n        }\n\n        public boolean isSameSet(V a, V b) {\n            if (elementMap.containsKey(a) && elementMap.containsKey(b)) {\n                return findHead(elementMap.get(a)) == findHead(elementMap.get(b));\n            }\n            return false;\n        }\n\n        public void union(V a, V b) {\n            if (elementMap.containsKey(a) && elementMap.containsKey(b)) {\n                Element<V> aF = findHead(elementMap.get(a));\n                Element<V> bF = findHead(elementMap.get(b));\n                if (aF != bF) {\n                    Element<V> big = sizeMap.get(aF) >= sizeMap.get(bF) ? aF : bF;\n                    Element<V> small = big == aF ? bF : aF;\n                    fatherMap.put(small, big);\n                    sizeMap.put(big, sizeMap.get(aF) + sizeMap.get(bF));\n                    sizeMap.remove(small);\n                }\n            }\n        }\n\n    }\n\n\n}\n```\n\n\n\n## 应用\n\n洛谷P1551亲戚\n\n```java\npublic static void main(String[] args) {\n        Scanner scanner = new Scanner(System.in);\n        int n = scanner.nextInt(); // 人数\n        int m = scanner.nextInt(); // 关系数\n        int p = scanner.nextInt(); // 询问多少个关系\n\n        List<Integer> personList = new ArrayList<>();\n        int[][] relation = new int[m][2];\n        for (int i = 0; i < m; i++) {\n            int p1 = scanner.nextInt();\n            int p2 = scanner.nextInt();\n            if (!personList.contains(p1)) personList.add(p1);\n            if (!personList.contains(p2)) personList.add(p2);\n            relation[i][0] = p1;\n            relation[i][1] = p2;\n//            relationMap.put(p2, p1);\n        }\n\n        UnionFindSet<Integer> unionSet = new UnionFindSet<>(personList);\n\n\n//        for (Map.Entry<Integer, Integer> entry : relationMap.entrySet()) {\n//            unionSet.union(entry.getKey(), entry.getValue());\n//        }\n\n        for (int i = 0; i < m; i++) {\n            unionSet.union(relation[i][0], relation[i][1]);\n        }\n\n        for (int i = 0; i < p; i++) {\n            int p1 = scanner.nextInt();\n            int p2 = scanner.nextInt();\n            if (unionSet.isSameSet(p1, p2)) {\n                System.out.println(\"Yes\");\n            } else {\n                System.out.println(\"No\");\n            }\n        }\n    }\n```\n\n\n\n\n\n\n\n\n\n\n\n","tags":["数据结构"]},{"title":"Docker学习(四) 网络","url":"/2021/08/06/Docker学习-四-网络/","content":"\n# Docker学习(四) 网络\n\n## 理解docker0\n\n![](https://i.loli.net/2021/08/06/Aln7NGbIr8FKL2h.png)\n\n```shell\n# docker 是如何处理容器网络访问的\n\n(base) root@linux:/home/cpss# docker run -d -P --name tomcat01 tomcat\n\n# 查看容器的内部网络地址 ip addr\n# 发现容器启动的时候会得到一个 eth0@if34 ip地址，docker分配的\n(base) root@linux:/home/cpss# docker exec -it tomcat01 ip addr\n1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n33: eth0@if34: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default \n    link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff link-netnsid 0\n    inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0\n       valid_lft forever preferred_lft forever\n\n# 思考：linux能不能ping通容器内部\n(base) root@linux:/home/cpss# ping 172.17.0.2\nPING 172.17.0.2 (172.17.0.2) 56(84) bytes of data.\n64 bytes from 172.17.0.2: icmp_seq=1 ttl=64 time=0.107 ms\n64 bytes from 172.17.0.2: icmp_seq=2 ttl=64 time=0.055 ms\n\n# linux 可以ping通docker容器内部\n```\n\n> 原理\n\n- 我们每启动一个docker容器，docker就会给docker容器分配一个ip，只要安装了docker，就会有一个网卡docker0 桥接模式，使用的技术是 evth-pair技术\n\n  现在再在宿主机执行ip addr，发现多了一个\n\n  ![](https://i.loli.net/2021/08/06/nkoUMcDPLG6KRax.png)\n\n再启动一个容器测试\n\n```sh\n(base) root@linux:/home/cpss# docker run -d -P --name tomcat02 tomcat\n# 每启动一个就多一个网卡\n\n# 发现这个容器带来的网卡，都是一对一对的\n# evth-pair 就是一对的虚拟设备端口，他们都是成对出现的，一段连着协议，一段彼此相连\n# 正因为有这个特性，evth-pair 充当一个桥梁,连接各种虚拟网络设备的\n# Openstac，Docker容器之间的链接，ovs的链接，都是使用这个技术\n```\n\n测试一下tomcat01和tomcat02是否能ping通\n\n```\n(base) root@linux:/home/cpss# docker exec -it tomcat02 ping 172.17.0.2\nPING 172.17.0.2 (172.17.0.2) 56(84) bytes of data.\n64 bytes from 172.17.0.2: icmp_seq=1 ttl=64 time=0.135 ms\n64 bytes from 172.17.0.2: icmp_seq=2 ttl=64 time=0.086 ms\n64 bytes from 172.17.0.2: icmp_seq=3 ttl=64 time=0.067 ms\n\n\n# 结论 容器之间可以互相ping通的\n```\n\n![](https://i.loli.net/2021/08/06/8x9nU6PVTZepR7b.png)\n\nTomcat01 和tomcat02 是公用的一个路由器，docker0\n\n所有的容器不指定网络的情况下，都是使用docker0路由的，docker会给我们的容器分配一个默认的可用ip\n\n> 小结\n\ndocker 使用的是桥接，宿主机中是一个docker容器的网桥 docker0\n\n![](https://i.loli.net/2021/08/06/bTBl5Qsh7qVCXI4.png)\n\ndocker 中所有的网络端口都是虚拟的，虚拟的转发效率高(内网传递)\n\n> 思考一个场景，编写了一个微服务，database url=ip:, 项目不重启，数据库ip换掉了，我们希望可以处理这个问题，可以通过名字来进行访问容器\n\n###  --link\n\n```shell\n(base) root@linux:/home/cpss# docker exec -it tomcat02 ping tomcat01\nping: tomcat01: Name or service not known\n\n(base) root@linux:/home/cpss# docker run -d -P --name tomcat03 --link tomcat02 tomcat\n6f62526ba5484b2c542bc31b0891a1f06c1baedbdb8667322b9b051a1f443e06\n\n# 通过--link 可以解决\n(base) root@linux:/home/cpss# docker exec -it tomcat03 ping tomcat02\nPING tomcat02 (172.17.0.3) 56(84) bytes of data.\n64 bytes from tomcat02 (172.17.0.3): icmp_seq=1 ttl=64 time=0.108 ms\n64 bytes from tomcat02 (172.17.0.3): icmp_seq=2 ttl=64 time=0.066 ms\n64 bytes from tomcat02 (172.17.0.3): icmp_seq=3 ttl=64 time=0.069 ms\n\n# 反向 ping不通\n(base) root@linux:/home/cpss# docker exec -it tomcat02 ping tomcat03\nping: tomcat03: Name or service not known\n\n\n(base) root@linux:/home/cpss# docker network ls\nNETWORK ID     NAME      DRIVER    SCOPE\n27abb1e4b0d3   bridge    bridge    local\ne69e785a705e   host      host      local\n2412989a4eb3   none      null      local\n\n\n# 其实这个tomcat03就是在本地配置了tomcat02的配置\n# --link 就是我们在hosts配置中增加了一个 映射\n(base) root@linux:/home/cpss# docker exec -it tomcat03 cat /etc/hosts\n127.0.0.1\tlocalhost\n::1\tlocalhost ip6-localhost ip6-loopback\nfe00::0\tip6-localnet\nff00::0\tip6-mcastprefix\nff02::1\tip6-allnodes\nff02::2\tip6-allrouters\n172.17.0.3\ttomcat02 9de7a985a568\n172.17.0.4\t6f62526ba548\n```\n\n现在玩docker已经不建议使用 --link了\n\n自定义网络! 不适用docker0\n\ndocker0问题：他不支持容器名链接访问\n\n\n\n### 自定义网络 （容器互联）\n\n```shell\n(base) root@linux:/home/cpss# docker network --help\nCommands:\n  connect     Connect a container to a network\n  create      Create a network\n  disconnect  Disconnect a container from a network\n  inspect     Display detailed information on one or more networks\n  ls          List networks\n  prune       Remove all unused networks\n  rm          Remove one or more networks\n```\n\n\n\n```\n(base) root@linux:/home/cpss# docker network ls\nNETWORK ID     NAME      DRIVER    SCOPE\n27abb1e4b0d3   bridge    bridge    local\ne69e785a705e   host      host      local\n2412989a4eb3   none      null      local\n```\n\n网络模式\n\n- bridge：桥接docker (默认)\n- none: 不配置网络\n- host: 和宿主机共享网络\n- container：容器内网络连通 (用的少，局限性大)\n\n测试\n\n```shell\n# 我们之间启动的命令 --net bridge 而这个就是我们的docker0\ndocker run -d -P --name tomcat01 tomcat\ndocker run -d -P --name tomcat01 --net bridge tomcat\n\n# docker0 特点。默认，域名不能访问， --link可以打通\n\n# 我们可以自定义个网络\n(base) root@linux:/home/cpss# docker network create --help\nOptions:\n      --attachable           Enable manual container attachment\n      --aux-address map      Auxiliary IPv4 or IPv6 addresses used by Network driver (default map[])\n      --config-from string   The network from which to copy the configuration\n      --config-only          Create a configuration only network\n  -d, --driver string        Driver to manage the Network (default \"bridge\")\n      --gateway strings      IPv4 or IPv6 Gateway for the master subnet\n      --ingress              Create swarm routing-mesh network\n      --internal             Restrict external access to the network\n      --ip-range strings     Allocate container ip from a sub-range\n      --ipam-driver string   IP Address Management Driver (default \"default\")\n      --ipam-opt map         Set IPAM driver specific options (default map[])\n      --ipv6                 Enable IPv6 networking\n      --label list           Set metadata on a network\n  -o, --opt map              Set driver specific options (default map[])\n      --scope string         Control the network's scope\n      --subnet strings       Subnet in CIDR format that represents a network segment\n      \n      \n      \ndocker network create --driver bridge --subnet 192.168.0.0/16 --gateway 192.168.0.1 mynet\n```\n\n![](https://i.loli.net/2021/08/06/vcuabfSy6KpP9rl.png)\n\n不使用--link 也能连接了\n\n我们自定义的网络docker都已经帮我们维护好了对应的关系\n\n好处：\n\n不同的集群使用不同的网络，保证集群是安全健康的。\n\n\n\n### 网络连通\n\n```sh\n(base) root@linux:/home/cpss# docker network --help\n  connect     Connect a container to a network\n  \n(base) root@linux:/home/cpss# docker network connect --help\nOptions:\n      --alias strings           Add network-scoped alias for the container\n      --driver-opt strings      driver options for the network\n      --ip string               IPv4 address (e.g., 172.30.100.104)\n      --ip6 string              IPv6 address (e.g., 2001:db8::33)\n      --link list               Add link to another container\n      --link-local-ip strings   Add a link-local address for the container\n      \n      \n\n# 测试打通 tomcat01 - mynet\n# 连通之后就是将tomcat01 放到了mynet网络下\n\n```\n\n结论：假设要跨网络操作别人，就需要使用docker network connect\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["Docker"]},{"title":"Docker学习(三)","url":"/2021/08/05/Docker学习-三/","content":"\n# Docker学习(三)\n\n## 可视化\n\n### portainer (不常用)\n\nDocker的图形化界面管理工具\n\n```\n# 外部8088 内部9000 \n# -v 挂载\ndocker run -d -p 8088:9000\\\n--restart=always -v /var/run/docker.sock:/var/run/docker.sock --privileged=true portainer/portainer\n```\n\n### Rancher(CI/CD再用)\n\n\n\n---\n\n## 镜像是什么\n\n是一种轻量级、可执行的独立软件包，用来打包软件运行环境和基于运行环境开发的软件。它包含某个软件所需的所有内容，包括代码、运行时、库、环境变量和配置文件。\n\n如何得到：\n\n- 远程仓库下载\n- 拷贝\n- 自己制作一个镜像DockerFile\n\n### 镜像加载原理\n\n>UnionFS(联合文件系统)\n\n我们下载的时候看到的一层层就是这个\n\nUnionFS是一种分层、轻量级且高性能的文件系统，它支持文件系统的修改作为一次提交来一层层的叠加，同时可以将不同目录挂载到同一个虚拟文件系统下.\n\n特性：一次同时加载多个文件系统，但从外面看起来，只能看到一个文件系统，联合加载会把各层文件系统叠加起来，这样最终的文件系统会包含所有底层的文件和目录。\n\ndocker的镜像实际上由一层一层的文件系统组成，这种层级文件系统就是UnionFS\n\nbootfs(boot file system)，在Docker镜像的最底层是bootfs，这一层与典型的Linux、Unix系统是一样的，它主要包含bootloader和kernel，bootloader主要是引导加载kernel，Linux刚启动时会加载bootfs文件系统。当boot加载完成之后整个内核就都在内存中了，此时内存的使用权已由bootfs转交给内核，此时系统也会卸载掉bootfs\n\nrootfs(root file system)，在bootfs之上，包含的是Linux系统中的/dev /proc /bin /etc 等标准目录和文件，rootfs就是各种不同的操作系统发行版，如ubantu，centos\n\n对于一个精简的OS，rootfs可以很小，只包含最基本的命令，因为底层直接用host的kernel。\n\n\n\n## 分层理解\n\n> 分层的镜像\n\n下载的日志输出，可以看到是一层一层的在下载\n\n![](https://i.loli.net/2021/08/05/SmgOoLaUYiwG6sr.png)\n\n为什么采用这种分层结构 ？\n\n最大的好处就是资源共享，比如有多个镜像都从相同的Base镜像构建而来，那么宿主机只需在磁盘上保留一份base镜像，同时内存中也只需要加载一份base镜像，这样就可以为所有的容器服务了，而且镜像的每一层都可以被共享。\n\n查看镜像分层方式可以通过docker image inspect命令\n\n> 特点\n\nDocker镜像都是只读的，当容器启动时，一个新的可写层被加载到镜像的顶部。\n\n这一层就是通常说的容器层，容器之下的都叫镜像层。\n\n![](https://i.loli.net/2021/08/05/Bo3v1qXJnadp5Kh.png)\n\n## 如何commit镜像\n\n```\ndocker commit 提交容器成为一个新的副本\n# 和git类似\ndocker commit -m=\"提交的描述信息\" -a=\"作者\" 容器id 容器镜像名:[TAG]\n```\n\n## 容器数据卷\n\n数据？如果数据都在容器中，那么容器删除，数据就会丢失！需求：数据可以持久\n\n容器之间可以有一个数据共享的技术，docker容器中产生的数据，同步到本地\n\n目录挂载，将容器内的目录挂载到linux上。\n\n![](https://i.loli.net/2021/08/06/cCQPLRghqlwpUZr.png)\n\n总结一句话，容器的持久化和同步操作，容器间也是可以数据共享的。\n\n### 使用\n\n> 方式1：直接使用命令挂载 -v\n\n```\n-v 主机目录:容器内目录\n-p 主机端口:容器内端口\n\ndocker run -it -v /home/ceshi:/home centos /bin/bash\n```\n\n![](https://i.loli.net/2021/08/06/TpZcrXgRi3SV9hB.png)\n\n是双向的同步，哪怕容器已经停止。\n\n好处：以后修改只需在本地修改即可。\n\n### 安装mysql\n\n思考：mysql的数据持久化问题 \n\n```shell\n(base) root@linux:/home/cpss# docker pull mysql:5.7\n\n# 运行，需要数据挂载\n# 安装启动mysql时，需要配置密码的！\n# -d 后台运行\n(base) root@linux:/home/cpss# docker run -d -p 3310:3306 -v /data2/mysql/conf:/etc/mysql/conf.d -v /data2/mysql/data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=root --name mysql01 mysql:5.7\n72180bd20207e871aebdc0a06fddfe10e30d39561620c78558328b9ac0a30b9c\n```\n\n### 具名和匿名挂载\n\n```shell\n# 匿名挂载\n-v 容器内路径\ndocker run -d -P --name nginx01 -v /etc/nginx nginx\n\n# 查看所有的volume情况，匿名卷挂载\n(base) root@linux:/data2/mysql# docker volume ls\n# 这种就是匿名挂载，在-v只写了容器内的路径，没有写容器外的路径！\n\n# 具名挂载\ndocker run -d -P --name nginx02 -v juming-nginx:/etc/nginx nginx\n(base) root@linux:/data2/mysql# docker volume ls\nDRIVER    VOLUME NAME\nlocal     juming-nginx\n\n# 通过-v 卷名：容器内路径\n# 查看一下这个卷\n\n```\n\n![](https://i.loli.net/2021/08/06/HStUJkLaIY9sXm7.png)\n\n所有的docker容器内的卷，没有指定目录的情况下都是在 /var/lib/docker/volumes/xxxxx/_data\n\n通过具名挂载可以方便的找到一个卷，大多数情况在使用的是具名挂载。\n\n```sh\n# 如何确定是具名挂载还是匿名挂载， 还是指定路径挂载\n-v 容器内路径 # 匿名挂载\n-v 卷名：容器内路径 # 具名挂载\n-v /宿主机路径:容器内路径 # 指定路径挂载\n```\n\n扩展\n\n```shell\ndocker run -d -P --name nginx02 -v juming-nginx:/etc/nginx:ro nginx\ndocker run -d -P --name nginx02 -v juming-nginx:/etc/nginx:rw nginx\n\n# 通过 -v 容器内路径:ro rw改变读写权限\n#  容器对我们挂载出来的内容就有限定了\n# ro readonly 只要看到ro就说明这个路径只能通过宿主机来操作，容器内部是无法操作的。\n```\n\n> 方式二、dockerfile 创建镜像时就挂载出来\n\nDockerfile 就是用来构建docker镜像的构建文件\n\n通过脚本可以生成镜像，镜像是一层一层的，脚本一个个的命令，每个命令都是一层\n\n```shell\n(base) root@linux:/data2/docker-volume# pwd\n/data2/docker-volume\n(base) root@linux:/data2/docker-volume# vim dockerfile1\n(base) root@linux:/data2/docker-volume# cat dockerfile1 \nFROM centos\n\nVOLUME [\"volume01\",\"volume02\"]\n\nCMD echo \"---end---\"\n\nCMD /bin/bash\n(base) root@linux:/data2/docker-volume# docker build -f dockerfile1 -t zuo/centos:1.0 .\nSending build context to Docker daemon  2.048kB\nStep 1/4 : FROM centos\n ---> 300e315adb2f\nStep 2/4 : VOLUME [\"volume01\",\"volume02\"]\n ---> Running in 26da05b75834\nRemoving intermediate container 26da05b75834\n ---> 5ae4812f35a4\nStep 3/4 : CMD echo \"---end---\"\n ---> Running in 29c52fec2f47\nRemoving intermediate container 29c52fec2f47\n ---> cb1793533f3d\nStep 4/4 : CMD /bin/bash\n ---> Running in c4bc1543fe44\nRemoving intermediate container c4bc1543fe44\n ---> c635584bb2a8\nSuccessfully built c635584bb2a8\nSuccessfully tagged zuo/centos:1.0\n\n\n(base) root@linux:/data2/docker-volume# docker images\nREPOSITORY      TAG       IMAGE ID       CREATED          SIZE\nzuo/centos      1.0       c635584bb2a8   59 seconds ago   209MB\n\n\n\n# 创建dockerfile文件，名字可以随机\n# 文件中的内容 指令(大写) 参数\nFROM centos\n每个命令就是镜像的一层\n```\n\n![](https://i.loli.net/2021/08/06/9LG7RVIYzOsK4Sc.png)\n\n这个卷是匿名挂载，一定有外部的目录\n\n![](https://i.loli.net/2021/08/06/g9H4moazDAIJUTj.png)\n\n### 数据卷容器\n\n两个mysql同步数据 --volumes-from\n\n![](https://i.loli.net/2021/08/06/nZx8FVqjUbBS1I2.png)\n\n```shell\n# 启动3个容器，通过我们刚才自己的写镜像启动\n(base) root@linux:/data2/docker-volume# docker run -it --name docker01 zuo/centos:1.0\n\n(base) root@linux:/data2/docker-volume# docker run -it --name docker02 --volumes-from docker01 zuo/centos:1.0\n```\n\n容器之间配置信息的传递，数据卷容器的生命周期一直持续到没有容器为止\n\n一旦持久化到了本地，本地的数据是不会删除的。\n\n\n\n\n\n## DockerFile\n\ndockerfile 是用来构建docker镜像的文件，命令参数脚本\n\n构建步骤：\n\n- 编写一个dockerfile文件\n- docker build构建成为一个镜像\n- docker run 运行镜像\n- docker push 发布镜像(docker hub，阿里云镜像仓库)\n\n### 构建过程\n\n基础知识\n\n- 每个保留关键字指令都是大写字母\n- 执行从上到下顺序执行\n- 每个指令都会创建提交一个新的镜像层\n\n![](https://i.loli.net/2021/08/06/3JdmShcx4r6znqw.png)\n\ndockerfile是面向开发的，我们以后要发布项目做镜像，要写。\n\n### 指令\n\n```dockerfile\nFROM          # 基础镜像，一切从这里开始构建\nMAINTAINER    # 镜像是谁写的，姓名+邮箱\nRUN           # 镜像构建时要运行的命令\nADD           # 步骤，添加内容\nWORKERDIR     # 镜像的工作目录\nVOLUME         # 挂载的目录\nEXPOSE         # 暴露端口\nCMD            # 指定容器启动时需要运行的命令,只有最后一个会生效，可被替代\nENTRYPOINT     # 指定容器启动时需要运行的命令，可以追加命令\nONBUILD        # 当构建一个被继承 Dockerfile \nCOPY           #  类似ADD 将文件拷贝到镜像中\nENV            # 构建的时候设置环境变量\n```\n\n\n\n```dockerfile\nFROM ubuntu:18.04  # 指定基础镜像 如果为scratch代表从下一行开始是镜像的第一层\nRUN echo '<h1>Hello, Docker!</h1>' > /usr/share/nginx/html/index.html # RUN指令用来执行命令，每一行代表新建docker的一个layer\n#能在一个layer内执行的指令就通过&& 进行联接，并可应用shell中的换行符\\\n#在dockerfile每层都要检查，下载，展开的多余文件，以及缓存等能删除的尽量都去掉\n\nCOPY #COPY 指令将从构建上下文目录中 <源路径> 的文件/目录复制到新的一层的镜像内的 <目标路径> 位置。\nCOPY package.json /usr/src/app/ # 将当前上下文路径的json文件复制到image的指定路径下\n\nAND #丰富了COPY的功能，但是会降低构件image速度，如果不需要自动解压缩，则不推荐使用该指令\n\nCMD # ？？？？？？？？？ 还没理解\n\nENTRYPOINT # 当存在 ENTRYPOINT 后，CMD 的内容将会作为参数传给ENTRYPOINT，从而达到了我们预期的效果。\n\nENV #用来设置环境变量  ENV <key> <value> 或 ENV <key1>=<value1> <key2>=<value2>...\nENV VERSION=1.0 DEBUG=on \\\n    NAME=\"Happy ONE\"\n\nENV LD_LIBRARY_PATH=\\\n$LD_LIBRARY_PATH:\\\n$NAME/alpha\n\nARG # ARG <参数名>[=<默认值>] Dockerfile 中的 ARG 指令是定义参数名称，以及定义其默认值。该默认值可以在构建命令 docker build 中用 --build-arg <参数名>=<值> 来覆盖\n\nARG DOCKER_USERNAME=library # 注意：在FROM之前定义的ARG参数，会消失，在FROM后需要重新定义\n# ARG 所设置的构建环境的环境变量，在将来容器运行时是不会存在这些环境变量的。但是不要因此就使用 ARG 保存密码之类的信息，因为 docker history 还是可以看到所有值的。\n\nVOLUME # 用于指定image启动时挂载到容器中的默认卷，而不是写入容器存储层\nVOLUME /data # VOLUME [\"<路径1>\", \"<路径2>\"...] 或 VOLUME <路径>\n在image启动时可替换\ndocker run -d -v mydata:/data xxxx #其中的 -v mydata:/data 就是挂载宿主机的卷到容器内\n\nEXPOSE # EXPOSE <端口1> [<端口2>...] EXPOSE 指令是声明容器运行时提供服务的端口，这只是一个声明，在容器运行时并不会因为这个声明应用就会开启这个端口的服务\n# 在 Dockerfile 中写入这样的声明有两个好处，一个是帮助镜像使用者理解这个镜像服务的守护端口，以方便配置映射；另一个用处则是在运行时使用随机端口映射时，也就是 docker run -P 时，会自动随机映射 EXPOSE 的端口\n\nWORKDIR # WORKDIR <工作目录路径> 使用 WORKDIR 指令可以来指定工作目录（或者称为当前目录），以后各层的当前目录就被改为指定的目录，如该目录不存在，WORKDIR 会帮你建立目录。\n\nUSER  # USER <用户名>[:<用户组>] 指定当前用户\nHEALTHCHECK\nONBUILD\nLEBEL\nSHELL #SHELL 指令可以指定 RUN ENTRYPOINT CMD 指令的 shell，Linux 中默认为 [\"/bin/sh\", \"-c\"]   \nDockerfile 多阶段构建\n```\n\n> 创建一个字节的centos\n\n```dockerfile\n# 1 编写dockerfile文件\nFROM centos\nMAINTAINER zuo<com>\n\nENV MYPATH /usr/local\nWORKERDIR $MYPATH\n\nRUN yum -y install vim  # 你想让他干啥\n\nEXPOSE 80\n\nCMD echo $MYPATH\nCMD echo \"----end----\"\nCMD /bin/bash\n\n# 2通过这个文件构建镜像\ndocker build -f mydockerfile-centos -t mycentos:0.1 .\n\n# 3测试运行\ndocker run -it mycentos\n\n```\n\n查看docker镜像构建历史\n\n![](https://i.loli.net/2021/08/06/VuB78orZcqWGS5v.png)\n\n> CMD 和 ENTRYPOINT 的区别\n\n![](https://i.loli.net/2021/08/06/rpFZ8xUYwROiauC.png)\n\nENTRYPOINT 是可以追加命令的\n\n### 做一个tomcat镜像\n\n- 准备镜像文件，tomcat压缩包，jdk的压缩包\n- 编写dockerfile文件，官方命名 Dockerfile，build会自动寻找这个文件，就不需要-f 指定了\n\n```dockerfile\nFROM centos\nMAINTAINER zuo<com>\n\nCOPY readme.txt /usr/local/readme.txt\nADD jdk-8ull-linux-x64.tar.gz /usr/local/   # 会自动解压\nADD apache-tomcat-9.0.22.tar.gz /usr/local/ \n\nRUN  yum -y install vim\nENV MYPATH /usr/local\nWORKDIR $MYPATH\n\nENV JAVA_HOME /user/local/jdk1.8.0_11\nENV CLASSPATH $JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar\nENV CLASSPATH_HOME /usr/local/apache-tomcat-9.0.22\nENV CLASSPATH_BASH /usr/local/apache-tomcat-9.0.22\nENV PATH $PATH:$JAVA_HOME/bin:$CATALINA_HOME/lib:$CATALINA_HOME/bin\n\nEXPOSE 8080\n\nCMD /usr/local/apache-tomcat-9.0.22/bin/startup.sh && tail -F /usr/local/apache-tomcat-9.0.22/bin/logs\n```\n\n构建镜像\n\n```dockerfile\ndocker build -t diytomcat .\n\ndocker run -d -p 9090:8080 --name zuotomcat -v /home/zuo/build/tomcat/test:/usr/local/apache-tomcat-9.0.22/webapps/test -v /home/zuo/build/tomcat/tomcatlogs/:/usr/local/apache-tomcat-9.0.22/logs diytomcat\n```\n\n## 发布自己的镜像\n\n```dockerfile\n(base) root@linux:/home/cpss# docker login --help\n\nUsage:  docker login [OPTIONS] [SERVER]\n\nLog in to a Docker registry.\nIf no server is specified, the default is defined by the daemon.\n\nOptions:\n  -p, --password string   Password\n      --password-stdin    Take the password from stdin\n  -u, --username string   Username\n  \n  \n(base) root@linux:/home/cpss# docker login -u zzuuoo666\nPassword: \nWARNING! Your password will be stored unencrypted in /root/.docker/config.json.\nConfigure a credential helper to remove this warning. See\nhttps://docs.docker.com/engine/reference/commandline/login/#credentials-store\n\nLogin Succeeded\n\n\ndocker push zzuuoo666/diytomcat:1.0 # 就可以了 不加信息可能会被拒绝\n# 如果镜像上传过被拒绝，可以添加一个tag\ndocker tag ID zzuuoo666/tomcat:1.0\ndocker push zzuuoo666/tomcat:1.0\n```\n\n\n\n## 小结\n\n![](https://i.loli.net/2021/08/06/VmDSgJkyvzeHXtZ.png)\n\n\n\n\n\n## \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["Docker"]},{"title":"Docker学习(二)例子练习","url":"/2021/08/01/Docker学习-二-例子练习/","content":"\n# Docker学习(二)例子练习\n\n## 部署Nginx\n\n- 搜索镜像去docker hub上\n- 下载镜像 docker pull nginx\n- docker run -d 后台运行 --name nginx01 -p 10024:80\n\n```\n(base) root@localhost:/home/cpss# docker run -d --name nginx01 -p 10024:80 nginx\n84960293d8409dc9f7e70be88027c2149ece57d7cf02dc4d71eb81fe1651fc96\n```\n\n```\n(base) root@localhost:/home/cpss# docker ps\nCONTAINER ID   IMAGE     COMMAND                  CREATED          STATUS          PORTS                                     NAMES\n84960293d840   nginx     \"/docker-entrypoint.…\"   21 seconds ago   Up 20 seconds   0.0.0.0:10024->80/tcp, :::10024->80/tcp   nginx01\n```\n\n```\n(base) root@localhost:/home/cpss# curl localhost:10024\n<!DOCTYPE html>\n<html>\n<head>\n<title>Welcome to nginx!</title>\n<style>\n    body {\n        width: 35em;\n        margin: 0 auto;\n        font-family: Tahoma, Verdana, Arial, sans-serif;\n    }\n</style>\n</head>\n<body>\n<h1>Welcome to nginx!</h1>\n<p>If you see this page, the nginx web server is successfully installed and\nworking. Further configuration is required.</p>\n\n<p>For online documentation and support please refer to\n<a href=\"http://nginx.org/\">nginx.org</a>.<br/>\nCommercial support is available at\n<a href=\"http://nginx.com/\">nginx.com</a>.</p>\n\n<p><em>Thank you for using nginx.</em></p>\n</body>\n</html>\n```\n\n-p 暴露端口的概念\n\n![](https://i.loli.net/2021/08/04/4Bx8PzGlrD1T6vA.png)\n\n\n\n```shell\ndocker exec -it nginx01 /bin/bash 进入容器\nroot@84960293d840:/# whereis nginx\nnginx: /usr/sbin/nginx /usr/lib/nginx /etc/nginx /usr/share/nginx\n\n\n(base) root@localhost:/home/cpss# docker ps\nCONTAINER ID   IMAGE     COMMAND                  CREATED         STATUS         PORTS                                     NAMES\n84960293d840   nginx     \"/docker-entrypoint.…\"   8 minutes ago   Up 8 minutes   0.0.0.0:10024->80/tcp, :::10024->80/tcp   nginx01\n(base) root@localhost:/home/cpss# docker stop 84960293d840\n84960293d840\n```\n\n思考：每次改动nginx配置文件，都需要进入容器内部，十分麻烦\n\n可以在容器外部提供一个映射路径，达到在容器修改文件名，内部容器就可以自动修改。\n\n这个技术是  -v 数据卷技术  \n\n\n\n\n\n\n\n## 部署 ES+Kibana\n\nES暴露端口很多，也耗内存，数据一般需要放到安全目录，挂载\n\n```shell\n# --net somenetwork 网络配置\n# --rm 用完就删掉\n\n# 启动 elasticsearch 比较耗内存\ndocker run -d --name elasticsearch -p 9200:9200 -p 9300:9300 -e \"discovery.type=single-node\" elasticsearch:7.14.0\n\n\nCONTAINER ID   NAME            CPU %     MEM USAGE / LIMIT     MEM %     NET I/O           BLOCK I/O       PIDS\na9057d9c6e50   elasticsearch   2.54%     32.49GiB / 125.8GiB   25.83%    11.1kB / 1.94kB   100MB / 292MB   98\n\n(base) root@linux:/home/cpss# curl localhost:9200\n{\n  \"name\" : \"a9057d9c6e50\",\n  \"cluster_name\" : \"docker-cluster\",\n  \"cluster_uuid\" : \"lkLPT_ssQ2CV30B55gn4bg\",\n  \"version\" : {\n    \"number\" : \"7.14.0\",\n    \"build_flavor\" : \"default\",\n    \"build_type\" : \"docker\",\n    \"build_hash\" : \"dd5a0a2acaa2045ff9624f3729fc8a6f40835aa1\",\n    \"build_date\" : \"2021-07-29T20:49:32.864135063Z\",\n    \"build_snapshot\" : false,\n    \"lucene_version\" : \"8.9.0\",\n    \"minimum_wire_compatibility_version\" : \"6.8.0\",\n    \"minimum_index_compatibility_version\" : \"6.0.0-beta1\"\n  },\n  \"tagline\" : \"You Know, for Search\"\n}\n\n# 增加内存限制，修改卑职文件 -e 环境修改\ndocker run -d --name elasticsearch -p 9200:9200 -p 9300:9300 -e \"discovery.type=single-node\" -e ES_JAVA_OPTS=\"-Xms64m -Xmx512m\"   elasticsearch:7.14.0\n\nCONTAINER ID   NAME             CPU %     MEM USAGE / LIMIT     MEM %     NET I/O       BLOCK I/O         PIDS\ne40105c39e81   elasticsearch1   281.21%   676.5MiB / 125.8GiB   0.53%     2.84kB / 0B   26.9MB / 1.22MB   103\n\n```\n\n![](https://i.loli.net/2021/08/05/PiIaTA4C1DsMZz3.png)\n\n\n\n\n\n\n\n\n\n\n\n","tags":["Docker"]},{"title":"Docker学习(一)","url":"/2021/07/30/Docker学习-一/","content":"\n# Docker学习(一)\n\n文档：https://docs.docker.com/\n\nHub : https://hub.docker.com/\n\n## 路线\n\n- Docker概述\n- Docker安装\n- Docker命令\n- - 镜像命令\n  - 容器命令\n  - 操作命令\n  - ......\n- Docker镜像\n- 容器数据卷\n- DockerFile\n- Docker网络原理\n- Docker Compose\n- Docker Swarm\n- CI\\CD Jenkins\n\n## Docker概述\n\nDocker为什么会出现？\n\n> 环境配置十分麻烦，每个机器都要部署环境，很难跨平台，集群环境更浪费时间。项目能不能带上环境打包(镜像)。\n\n能干嘛？\n\n> 之前的虚拟机技术,浪费资源比较多\n\n![](https://i.loli.net/2021/07/30/cG1EzWbCX5ArsTf.png)\n\n缺点：\n\n- 资源占用多\n- 冗余步骤多\n- 启动很慢\n\n> 容器化技术\n\n不是模拟一个完整的操作系统\n\n![](https://i.loli.net/2021/07/30/MojI6CL2lqRapYW.png)\n\n不同之处：\n\n- 传统虚拟机，虚拟出一套硬件，运行一个完整的操作系统，然后在这个系统上运行安装软件\n- 容器的应用直接运行在宿主机上的内核中，容器是没有自己的内核的，没有虚拟硬件，比较轻便\n- 每个容器间是互相隔离的，每个容器内都有一共自己的文件系统，互不影响。\n\n> DevOps（开发 运维）\n\n更快速的交付和部署\n\n传统：一堆帮助文档，安装程序\n\nDocker: 打包镜像发布测试，一键运行\n\n更便捷的升级和扩容缩容，更高效的计算资源利用，测试环境都高度一致。\n\nDocker是内核级别的虚拟化，可以再一个物理机上运行很多的容器实例。\n\n## Docker 基本组成\n\n![](https://i.loli.net/2021/07/30/XMPGFCdjvi96tey.png)\n\n从左到右，依次是客户端、服务器和仓库。\n\n- 镜像（Image）：docker镜像就好比是一个模板，可以通过这个模板来创建容器服务。如：tomcat镜像--->run--->tomcat01容器。通过这个镜像可以创建多个容器，最终服务运行或者项目运行就是在容器中的\n\n- 容器（Containers）：Docker利用容器技术，可以独立运行一个或者一组应用，通过镜像来创建。启动，\n\n  停止，删除基本命令。目前可把这个容器简单理解为就是一个简易的linux系统。\n\n- 仓库（Repository）：存放镜像的地方。分为公有仓库和私有仓库，和GitHub差不多。Docker hub默认是国外的，可以配阿里云镜像加速。\n\n\n\n## Hello World\n\n![](https://i.loli.net/2021/07/30/oyDtNArhC1qmlXV.png)\n\n如何查看hello world镜像\n\n```\n(base) root@localhost:/home/cpss# docker images\nREPOSITORY      TAG       IMAGE ID       CREATED         SIZE\nhello-world     latest    d1165f221234   4 months ago    13.3kB\nstudyfang/hgn   latest    37553493935b   10 months ago   8.88GB\n```\n\ndocker默认工作路径\n\n```\n(base) root@localhost:/home/cpss# ls /var/lib/docker/\nbuildkit  containers  image  network  overlay2  plugins  runtimes  swarm  tmp  trust  volumes\n```\n\n## 镜像加速\n\n创建或修改 /etc/docker/daemon.json 文件，修改为如下形式\n\n```\n{\n  \"registry-mirrors\": [\n    \"https://registry.docker-cn.com\",\n    \"http://hub-mirror.c.163.com\",\n    \"https://docker.mirrors.ustc.edu.cn\"\n  ]\n}\n```\n\n```\n(base) root@localhost:/etc/docker# vim daemon.json\n(base) root@localhost:/etc/docker# systemctl daemon-reload\n(base) root@localhost:/etc/docker# systemctl restart docker\n(base) root@localhost:/etc/docker# systemctl status docker\n```\n\n使用docker info 查看镜像改变。\n\n![](https://i.loli.net/2021/07/30/AJiXGsvMfug9jc5.png)\n\n\n\n## run流程原理\n\n ![](https://i.loli.net/2021/07/30/6jbSgOziPhAYNkd.png)\n\ndocker是怎么工作的？\n\n> docker是一个client-server结构的系统，docker的守护进程运行在主机上，通过socket从客户端访问。\n>\n> docker server 接收到docker client的指令就会执行这个命令\n\n![](https://i.loli.net/2021/07/30/vFZk7yGAHVgfad1.png)\n\ndocker为什么比VM快？\n\n>docker有比虚拟机更少的抽象层。\n>\n>docker利用的是宿主机的内核，vm需要Guest OS\n\n<img src=\"https://i.loli.net/2021/07/30/wormWUzExPMNBsh.png\" style=\"zoom:150%;\" />\n\n所以新建一个容器的时候，docker不需要向虚拟机一样重新加载一个操作系统内核。避免引导操作，虚拟机是加载GuestOS，docker是利用宿主机的操作系统，省略了这个复杂的过程。\n\n<img src=\"https://i.loli.net/2021/07/30/ode6RsjDH1Y5yF3.png\" style=\"zoom:150%;\" />\n\n## Docker的常用命令\n\n```bash\ndocker version     # docker的版本信息\ndocker info\t\t\t\t # 显示docker的系统信息，包括镜像和容器的数量\ndocker 命令 --help  # 帮助命令\n```\n\n---\n\n### 镜像命令\n\ndocker images\n\n```sh\n(base) root@localhost:/home/cpss# docker images\nREPOSITORY      TAG       IMAGE ID       CREATED         SIZE\nhello-world     latest    d1165f221234   4 months ago    13.3kB\nstudyfang/hgn   latest    37553493935b   10 months ago   8.88GB\n```\n\n- REPOSITORY 镜像的仓库源\n\n- TAG 镜像的标签\n\n- IMAGE ID 镜像的id\n\n- CREATED 镜像的创建时间\n\n- SIZE 镜像大小\n\n  ```shell\n  Options:\n    -a, --all             Show all images (default hides intermediate images)\n    -q, --quiet           Only show image IDs\n  ```\n\ndocker search 搜索镜像\n\n```shell\n(base) root@localhost:/home/cpss# docker search hotpotqa\nNAME                                  DESCRIPTION                     STARS     OFFICIAL   AUTOMATED\nqipeng/hotpotqa-eval                                                  0                    \nstudyfang/hotpotqa                                                    0                    \nqipeng/hotpotqa-base                                                  0                    \ntuming1990/hotpotqa-docker                                            0                    \nhamishivi/hotpotqa-base               Hotpotqa with extra packages.   0                    \nqipeng/hotpotqa_submission_cuda10.2                                   0                    \ntswings2018/hotpotqa                  by deng                         0        \n```\n\ndocker pull\n\n```\n# 下载镜像 docker pull 镜像名[:tag]\n```\n\n![](https://i.loli.net/2021/07/30/r9qWyoDSOTk7QKh.png)\n\ndocker rmi 删除镜像\n\n可通过id 或者 名称来删\n\n```\ndocker rmi -f 镜像id\n```\n\n\n\n### 容器命令\n\n有了镜像才可以创建容器\n\n这里下载一个centos镜像来测试学习\n\n```\ndocker pull centos\n```\n\n新建容器并启动\n\n```shell\ndocker run [可选参数] image\n# 参数说明\n--name=\"Name\" 容器名字  tomcat01 tomcat02 用来区分容器\n-d            后台方式运行 nohup\n-it           使用交互方式运行，进入容器查看内容\n-p            指定容器的端口  ip:主机端口:容器端口 主机端口:容器端口(常用)   容器端口\n-P\t\t\t\t\t\t随机指定端口\n# 测试 启动并进入容器\n(base) root@linux:/home/cpss# docker run -it centos /bin/bash\n[root@ef41db25d696 /]# 容器内就是自己的服务器环境\n\ndocker ps # 查看正在运行的容器\ndocker ps -a # 查看曾经运行过的容器\ndocker ps -a -n=1 # 显示个数\ndocker ps -aq # 只显示编号\n```\n\n退出容器\n\n```shell\nexit # 直接退出容器并停止\nctrl +p +q # 容器不停止退出\n```\n\n删除容器\n\n删除容器\n\n```shell\ndocker rm 容器id                # 删除指定的容器 不能删除正在运行的容器 -f强制删除\ndocker rm -f $(docker ps -aq)  # 删除所有的容器\n\ndocker ps -a -q|xargs docker rm # 删除所有的容器\n```\n\n启动和停止容器的操作\n\n```sh\ndocker start 容器id\ndocker restart 容器id\ndocker stop 容器id\ndocker kill 容器\n```\n\n### 常用其他命令\n\n后台启动容器\n\n```shell\ndocker run -d centos\n# 问题 docker ps时发现centos停止了\n# 常见的坑，docker 容器使用后台运行，就必须要有一个前台进程。docker发现没有应用就会自动停止。\n# 容器启动后，发现自己没有提供服务，就会立即停止\n```\n\n查看日志\n\n```shell\n(base) root@linux:/home/cpss# docker logs --help\nOptions:\n      --details        Show extra details provided to logs\n  -f, --follow         Follow log output\n      --since string   Show logs since timestamp (e.g. 2013-01-02T13:23:37Z) or relative (e.g. 42m for 42 minutes)\n  -n, --tail string    Number of lines to show from the end of the logs (default \"all\")\n  -t, --timestamps     Show timestamps\n      --until string   Show logs before a timestamp (e.g. 2013-01-02T13:23:37Z) or relative (e.g. 42m for 42 minutes)\n\n\n# -tf 显示日志\n# --tail number 要显示日志条数\ndocker logs -tf --tail 10 f3c59b35b738\n# 容器没有日志\n# 自己写一段shell\n(base) root@linux:/home/cpss# docker run -d centos /bin/sh -c \"while true;do echo 111;sleep 1;done\"\nba0ae87cb0949d44e179f03e2bb3e25a38b394bb98b7aa0f4a1a2b9ad68ca86d\n(base) root@linux:/home/cpss# docker ps\nCONTAINER ID   IMAGE     COMMAND                  CREATED         STATUS        PORTS     NAMES\nba0ae87cb094   centos    \"/bin/sh -c 'while t…\"   3 seconds ago   Up 1 second             determined_bouman\n(base) root@linux:/home/cpss# docker logs -tf --tail 10 ba0ae87cb094\n```\n\n查看容器中的进程信息\n\n```\ndocker top 容器id\n```\n\n查看镜像的元数据\n\n```shell\ndocker inspect 容器id\n\n(base) root@linux:/home/cpss# docker inspect ba0ae87cb094\n[\n    {\n        \"Id\": \"ba0ae87cb0949d44e179f03e2bb3e25a38b394bb98b7aa0f4a1a2b9ad68ca86d\",\n        \"Created\": \"2021-08-01T03:10:14.298411164Z\",\n        \"Path\": \"/bin/sh\",\n        \"Args\": [\n            \"-c\",\n            \"while true;do echo 111;sleep 1;done\"\n        ],\n        \"State\": {\n            \"Status\": \"exited\",\n            \"Running\": false,\n            \"Paused\": false,\n            \"Restarting\": false,\n            \"OOMKilled\": false,\n            \"Dead\": false,\n            \"Pid\": 0,\n            \"ExitCode\": 137,\n            \"Error\": \"\",\n            \"StartedAt\": \"2021-08-01T03:10:15.270494437Z\",\n            \"FinishedAt\": \"2021-08-01T03:12:01.287526932Z\"\n        },\n        \"Image\": \"sha256:300e315adb2f96afe5f0b2780b87f28ae95231fe3bdd1e16b9ba606307728f55\",\n        .....\n]\n\n```\n\n进入当前正在运行的容器\n\n```shell\n# 我们通常容器都是使用后台方式运行的，需要进入容器，修改一些配置\n# 方式1\ndocker exec -it 容器id bashShell\n# 方式2\ndocker attach 容器id \n# 区别\n# attach 正在执行的代码 进入正在执行的终端，不会启动新的进程\n# exec 进入容器后开启一个新的终端，可以在里面操作\n```\n\n从容器内拷贝文件到主机上\n\n```sh\n# 容器停止也可以拷贝，容器在数据就在\ndocker cp 容器id:容器内路径 目的的主机路径\n# 拷贝是一个手动过程，以后可以使用 -v 卷的技术 可以实现自动同步\n```\n\n### 命令小结\n\n![](https://i.loli.net/2021/08/01/ha7fdJZE2jnNIOU.png)\n\n现在学的是Images 和 Cotainer里的命令，其他的还没学\n\n![](https://i.loli.net/2021/08/01/FH1ZyqXoS3wx2Dg.png)\n\n![](https://i.loli.net/2021/08/01/YTrjW8M1c3I5sQ9.png)\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["Docker"]},{"title":"HotpotQA Submission Guide","url":"/2021/07/28/HotpotQA-Submission-Guide/","content":"\n# HotpotQA Submission Guide\n\n记录如何提交模型在HotpotQA test\n\n## codalab安装与注册\n\n先去注册 https://worksheets.codalab.org/\n\n首先安装codalab\n\n```\npip install codalab -U \n```\n\n如果ERROR: Cannot uninstall 'PyYAML'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\n\n使用 pip install codalab -U --ignore-installed PyYAML\n\nCodalab wiki ： https://github.com/codalab/codalab-worksheets/wiki\n\n注册安装完成后可以再命令行登录：\n\n```bash\n$ cl work\nRequesting access at https://worksheets.codalab.org\nUsername: guest1\nPassword:\nCurrently on worksheet https://worksheets.codalab.org::home-guest1(0x39729afdca6140869a11e055e4cc0649).\n```\n\n`cl work`命令的意思就是切换工作表（worksheet），默认的工作表指向主页工作表 （`home-<username>`）。\n\n## 先一个例子提交Hotpot QA的baseline\n\ndistractor setting 是需要提交代码的，full wiki不需要。先主要攻克 distractor setting吧\n\n尝试完baseline再上传我自己的模型。\n\n> 你的分数想要在排行榜上出现，需要预留最多一个月的时间。\n\n在干扰项设置中，要求您将代码提交给Codalab，并根据隐藏的测试集对其进行评估。您应该首先确保您的代码能够正确生成dev的输出和评估结果，以便可以更容易地将您的设置转移到测试集。下面，提供一个提交baseline模型的示例。\n\n### Step 1: Preparing code and data\n\n首先将基线模型的GitHub存储库克隆到Codalab包中（在codalab上代码是公开的，想要不公开。。）\n\n在命令行中运行\n\n```bash\ncl run --request-network 'git clone https://github.com/hotpotqa/hotpot.git' -n repo\n```\n\n--request-network：需要网络环境， -n是添加别名为repo，以后可以更容易地引用它(而不是每次都使用长UUID)。\n\n注意这里git克隆的要是https的ssh的路径会失败。\n\n成功后刷新网页控制台：\n\n![](https://i.loli.net/2021/07/28/mo35I4yMLEDawFH.png)\n\n然后，我们上传对训练集进行预处理后生成的词汇映射文件。\n\n创建包含所有必要预处理文件的mappings.zip文件，即idx2char.json、idx2word.json、char2idx.json、word2idx.json、char_emb.json和word_emb.json。这个是baseline运行所需要的。\n\n作者提供了下载mappings.zip的下载地址：http://curtis.ml.cmu.edu/datasets/hotpot/mappings.zip\n\n要上传数据到Codalab CLI，只需运行\n\n```bash\ncl upload mappings.zip -n mappings\n```\n\n完全上传后，Codalab会为您解压zip文件。\n\n当然，还需要上传预先训练好的模型文件。我们已经准备好了预先训练好的文件model.pt。\n\n下载地址：http://curtis.ml.cmu.edu/datasets/hotpot/model.pt\n\n```bash\ncl upload model.pt -n model\n```\n\n如果超时就重新执行\n\n![](https://i.loli.net/2021/07/28/eDSWJn71hkAIlGr.png)\n\n### Step 2: Preparing the environment\n\n现在基本已经准备好对新的输入进行预测。我们只需要设置代码需要在其中运行的适当环境。\n\n> 要做到这一点，最简单的方法是使用Docker镜像，我们在[qipeng/hotpotqa-base](https://hub.docker.com/r/qipeng/hotpotqa-base)上提供了一个镜像，其中预装了nvidia GPU相关库和Anaconda 3。我们还安装了运行此docker映像中的基线模型所需的所有软件包，这样我们就不必在Codalab包中安装所有东西。\n\n如果确实忘记了环境中的某些内容，也可以在Codalab中轻松设置：\n\n```bash\ncl run -n download_spacy_model --request-docker-image qipeng/hotpotqa-base:gpu --request-network :repo 'cp -r repo/hotpot .; python -m spacy download en'\n```\n\n注意：由于评估期间禁止使用网络，此捆绑包仅用于演示目的。对于需要下载的软件依赖项，强烈建议下载到您准备的Docker镜像中。\n\n![](https://i.loli.net/2021/07/28/JzasC3nmrFNPI1U.png)\n\n### Step 3: Running evaluation\n\n现在，继续根据刚刚上传的模型进行预测，并评估输出。\n\n要在dev集上运行上传的基线模型的预测，我们运行以下命令：\n\n```bash\ncl run -n predict --request-docker-image qipeng/hotpotqa-base:gpu --request-gpus 1 --request-cpus 4 --request-memory 32g repo:download_spacy_model :mappings input.json:0xbdd8f3 :model 'cp -r repo/hotpot .; cp mappings/* hotpot; mkdir hotpot/model; cp model hotpot/model/model.pt; cp input.json hotpot; cd hotpot; python main.py --mode prepro --data_file input.json --para_limit 2250 --data_split dev; python main.py --mode test --data_split dev --para_limit 2250 --batch_size 24 --init_lr 0.1 --keep_prob 1.0 --sp_lambda 1.0 --save model --prediction_file pred.json; cp pred.json ../;'\n```\n\n> 让我们看看上面的命令中发生了什么。在第一部分中，我们使用-n predic命名包，并使用指定所需的资源\n>\n> --request-docker-image qipeng/hotpotqa-base:gpu\n>\n> --request-gpus 1\n>\n> --request-cpus 4\n>\n> --request-memory 32g\n>\n> 请注意，您不能在此捆绑包中使用--request-network\n>\n> 然后指定对其他包的依赖关系。repo:download_spacy_model表示将包download_spacy_model别名为repo\n>\n> :mappings指定对捆绑包mapping的依赖关系，而不使用别名。\n>\n> input.json:hotpotqa-data//dev_distractor_input_v1.0将输入json文件重命名为input.json，其中包id指向dev json文件。0xbdd8f3\n>\n> 请不要上传您自己版本的开发集文件并使用它，因为我们依赖官方的开发文件UUID来确定在评估期间用测试集替换什么(如果您使用自己的开发集文件，评估将失败)。\n\n然后，使用一系列cp命令从不同的包复制文件，并以我们的预测脚本可以处理的方式组织它们。\n\n请注意，可以将每个引用的捆绑包视为当前捆绑包中的一个目录。例如，通过cp -r repo/hotpot。我们将repo捆绑包中的hotot子目录复制到当前捆绑包的“根”目录(开始运行捆绑包中的代码时所在的目录，而不是/root！)。\n\n然后，我们调用main.py两次，第一次使用--mode prepro预处理dev集，第二次使用--mode test进行预测。如果您使用代码，则可以相应地更改此设置。\n\n请注意，如果您的代码涉及预训练的特征提取(例如，Elmo或BERT)，则应该将其合并为此处命令的一部分，而不是作为包上传，因为您事先没有访问测试集的权限。（也就是说要预处理测试集的话要在一个捆绑包里进行多次运行python文件吧）\n\n还要注意，您的模型不应该依赖于键类型和级别来进行预测，因为这些键没有出现在测试集中。\n\n之后，我们将文件pred.json复制到当前包的“根”目录。请注意，文件名必须命名为pred.json，并且该文件必须放在包的“根”目录下，评估命令才能正常工作。\n\n![](https://i.loli.net/2021/07/28/cvhExjYFiz8bka9.png)\n\n使用以下命令（将predict替换为您自己的prediction bundle的名称），确保您能够在dev set上评估您的模型而不会遇到任何问题：\n\n```bash\ncl macro hotpotqa-utils//dev-eval-distractor-v1.0 predict -n evaluate\n```\n\n![](https://i.loli.net/2021/07/28/EJ1SVlTsnHdZ9rq.png)\n\n![](https://i.loli.net/2021/07/28/jkswd5B198ZbqDi.png)\n\n\n\n### Step 4: Describe and tag your submission 描述并标记您的提交\n\n准备好后，编辑预测捆绑包的说明，以反映在排行榜上显示所需的信息：\n\n```\nModel name (Affiliation) (single model / ensemble) [paper name](paper link) (code link)\n```\n\n如果您在使用深渊翻滚时愿意，可以使用匿名Anonymous作为您的从属关系，之后可以通过编辑您的深渊翻滚捆绑包的描述来修改它。\n\n[paper名称] 和(代码链接)部分是可选的 \n\n请注意，虽然[paper名称]和(paper链接)之间没有空格，因为这会造成代码链接的歧义。以下是一些示例\n\n```\nBaseline Model (Carnegie Mellon University, Stanford University, & Universite de Montreal) (single model) [(Yang, Qi, Zhang, et al. 2018)](https://arxiv.org/pdf/1809.09600.pdf) (https://github.com/hotpotqa/hotpot)\n\nMy Awesome Model (Awesome Institute) (ensemble) [(Awesome et al., 2018)](https://arxiv.org/pdf/1812.12345.pdf)\n\nPotLuck (Culinary University) (single model) [](https://arxiv.org/pdf/1901.12345.pdf) (https://github.com/potluck/potluck)\n```\n\n第一个示例正是我们用来描述基线模型的。第二个没有代码链接，第三个没有指定论文名称。\n\n请注意，Codalab在捆绑描述中使用非ASCII字符有问题，因此请避免使用它们。\n\n要提交您的捆绑包，请使用hotpotqa-diditor-test-submit标记您的预测捆绑包(这可以在Web UI上通过选择捆绑包并修改右侧面板上的标签来完成)，然后向彭琪(pengqi@cs.stanford.edu)发送一封简短的电子邮件，其中包含您的捆绑包UUID(0x后跟32个字符)或指向您的捆绑包的链接(不是您的工作表或工作表UUID！)。\n\n请确保您的预测所依赖的所有捆绑包都是公开可读的(这是Codalab中的默认可见性)。\n\n> 重要信息：\n>\n> 1.请仅在dev集合上执行改善模型性能所需的任何模型选择或消融。不能在测试集上支持同一模型的多个提交。\n>\n> 2.请避免删除您的Submission捆绑包，即使在填写排行榜条目之后也是如此。这是您更新与您的Submission相关的信息的最佳方式，包括但不限于其名称、隶属关系、纸质链接、代码链接等。\n>\n> 3.如果你提交了多份报告(单一模型和集成模型)，请确保你的预测捆绑包有不同的名称。例如，predict-single和`predict-ensemble`。这是唯一一种我们在30天内容纳的多次提交。\n\n\n\n## 1总结\n\n- 从github下载代码\n- 上传模型和需要的数据\n- 设置环境用docker\n- run\n\n![](https://i.loli.net/2021/08/01/S6ik5vh4ImFxqCt.png)\n\nhttps://zhuanlan.zhihu.com/p/196343938","tags":["nlp"]},{"title":"Heterogeneous Graph Transformer for Graph-to-Sequence Learning","url":"/2021/07/23/Heterogeneous-Graph-Transformer-for-Graph-to-Sequence-Learning/","content":"\n# Heterogeneous Graph Transformer for Graph-to-Sequence Learning\n\nGraph2Seq学习的目的是将图结构的表示转换为单词序列，以便生成文本。\n\nAMR-to-text是从抽象意义表示(AMR)图中生成文本的任务，其中节点表示语义概念，边表示概念之间的关系。\n\n传统GNN只考虑了直接相连节点之间的关系，而忽略了远距离节点之间的间接关系。\n\nGraph2Seq的其他两个和Graph Transformer的论文\n\n- Graph transformer for graph-to-sequence learning AAAI 2020\n\n- Modeling graph structure in transformer for better AMR-to-text gen- eration  EMNLP 2019\n\n使用节点之间的最短关系路径来编码语义关系。但是，它们忽略了关系路径中节点的信息，对直接关系和间接关系没有区别地进行编码。当从直接邻居那里聚集信息时，可能会干扰信息的传播过程。\n\n作者使用Heterogeneous Graph Transformer来独立地建模原始图的各个子图中的不同关系，包括节点之间的直接关系、间接关系和多种可能的关系。\n\n\n\n## Input Graph Transformer\n\n为了缓解语料库中的数据稀疏问题，作者将进一步将字节对编码(BPE)引入Levi图。\n\n将原始节点拆分成多个子词节点。除了添加缺省连接外，我们还在子词之间添加了反向边和自循环边。\n\n如下图：\n\n![](https://i.loli.net/2021/07/23/fswuO1n4J7bptHG.png)\n\n例如，图中的单词Country被分割为co@@、un@@、try  它们之间有三种类型的边。\n\n\n\n<img src=\"https://i.loli.net/2021/07/23/LUmRx6udzNeJyAr.png\" style=\"zoom:67%;\" />\n\n该任务一般先将抽象概念图(上图a)，转换成Levi图(上图b)。将AMR图转换为扩展的Levi图，该图可以看作是一个异构图，因为它具有不同类型的边。\n\n## Heterogeneous Graph Transformer\n\n![](https://i.loli.net/2021/07/23/MvH7kQdb2KFwert.png)\n\n给定一个经过预处理的扩展Levi图，根据其异构性将扩展Levi图分成多个子图。\n\n在每个Graph Encoder中，基于其在当前子图中的相邻节点来更新不同子图中的节点表示。然后，将该节点在不同子图中的所有表示组合在一起，以获得其最终表示。\n\n### Graph Encoder\n\n与其他Graph Transformer不同的是仅使用相对位置编码来隐藏结构信息。\n\n在更新每个节点的表示时，直接屏蔽了非相邻节点的注意力。mask attention $\\alpha_{ij}\\notin N_i$  ，此外这个作者还尝试用了加性注意力这就和GAT几乎很像了。\n\n因此，给定输入序列 $x=(x_1,...,x_n)$，每个关注头中表示为 $z_i$ 的节点i的输出表示如下计算：\n$$\nz_i = \\sum_{j\\in N_i} \\alpha_{ij}(x_j W^V)\n$$\n\n### Heterogeneous Mechanism\n\n在多头机制成功的激励下，提出了异质机制。考虑到一个句子，多头注意允许模型隐含地注意到来自不同位置的不同表示子空间的信息。相应地，异构机制使得模型显式地关注不同子图中的信息，对应于图的不同表示子空间，从而增强了模型的编码能力。\n\n首先将所有的边类型组合成一个单一的边类型，从而得到一个同质连通子图。该连通子图实际上是一个包含原始图中完全连通信息的无向图。除了学习直连关系，还引入了一个完全连通子图来学习间接连接节点之间的隐含关系。\n\n每个编码层中的输出z计算如下：\n$$\n\\begin{equation}\\begin{split} \n z &= FFN(concat(z^{G^{sub}_1},...,z^{G_M^{sub}})W^O)\\\\\n z_i^{G_m^sub} &= \\sum_{j\\in N_i^{G^{sub}_m} }\\alpha_{ij}(x_jW^V), m\\in[1,M] \n    \\end{split}\\end{equation}\n$$\n$W^O\\in R^{Md_z\\times d_z}$参数矩阵 \n\n作者还采用了子层之间的残差连接、FFN以及层归一化。\n\n### Layer Aggregation\n\n编码层之间更好的信息传播可能带来更好的性能。\n\n因此，我们研究了三种不同的Layer Aggregation方法，如图3所示。\n\n![](https://i.loli.net/2021/07/23/gfL3GKQDxzCamqX.png)\n\n当更新第 $l$ 层节点的表示时，最近的方法是先聚合邻居，然后将聚合结果与来自 $(l−1)$ 层的节点表示相结合。此策略可视为不同图层之间跳过连接的一种形式。\n$$\n\\begin{equation}\\begin{split} \n z_{N_i}^{(l)} &= AGGREGATE(\\{z_j^{(l-1)}, \\forall j \\in N_i\\})\\\\\n z_i^{(l)} &= COMBINE(z_{N_i}^{(l)}, z_i^{(l-1)})\n    \\end{split}\\end{equation}\n$$\n\n\n残差连接是另一种著名的跳跃连接，它使用identity mapping作为组合函数来帮助信号传播，但这些跳跃连接不能独立自适应地调整最后一层表示的邻域大小。\n\n如果我们为$z_i^{(l)}$ skip一个层，则所有后续的单元例（如使用此表示的$z_i^{(l+j)}$) 都将隐式的使用此skip\n\n因此，为了有选择地聚合前几层的输出，我们在模型中引入了跳跃体系。\n\n在编码器的最后一层L，通过concat的方式组合前几个编码层的所有输出，以帮助模型有选择地聚合所有这些中间表示。\n$$\nz_i^{final} = Concat(z_i^{(L)},...,z_i^{(1)},x_i) W_{jump}\n$$\n$W_{jump}\\in R^{(Ld_z+d_x)\\times d_z}$\n\n此外，为了更好地改善信息传播，还可以引入稠密连通性。通过密集连接，l层中的节点不仅从第(l−1)层获取输入，而且还从所有前面的层提取信息： \n$$\nz_i^{(l)} = Concat(z_i^{(l-1)},..,z_i^{(1)},x_i) W^{(l)}_{dense}\n$$\n$W^{(l)}_{dense} \\in R^{d^{(l)}\\times d_z}, d^{(l)}=d_x+d_z\\times(l-1)$\n\n![](https://i.loli.net/2021/07/23/kqOvxdBz6YrnXj8.png)\n\n\n\n\n\n\n\n\n\n","tags":["GNN&nlp"]},{"title":"Graph Transformer for Graph-to-Sequence Learning","url":"/2021/07/23/Graph-Transformer-for-Graph-to-Sequence-Learning/","content":"\n# Graph Transformer for Graph-to-Sequence Learning\n\n这篇论文应用于在基于抽象语义表示(AMR)的文本生成和基于句法的神经机器翻译，句法机器翻译并入源端语法信息可以提高翻译质量。如图给出了AMR到文本生成的示例。\n\n![](https://i.loli.net/2021/07/23/QDi75OPI64YbHgA.png)\n\n论文应用Graph Transformer，其与限制近邻之间信息交换的图神经网络不同，Graph Transformer使用显式关系编码，允许两个远距离节点之间的直接通信。它为全局图结构建模提供了一种更有效的方法。\n\n这篇论文想解决的是打破传统GNN的局部邻接特性，使用高效的全局信息。\n\n## Methed\n\n对于n个节点的图，以前的图神经网络将节点表示$v_i$计算为输入节点 $i$ 及其所有一阶邻域 $N(i)$的函数。图结构由每个节点表示的感受野隐式反映。然而，这种本地通信设计对于远程信息交换可能是低效的。\n\n所以引入Graph Transformer，它提供了一种截然不同的范例，可以实现关系感知的全球通信。\n\n![](https://i.loli.net/2021/07/23/FtimYg4NB5MTkoS.png)\n\n作者提出的是关系增强的全局注意力机制，和Graphromer一样任何节点对之间的关系被描述为它们之间的最短关系路径。\n\n### Graph Encoder\n\n责将输入图形转换为一组相应的节点嵌入。核心问题是如何在允许全连通通信的同时保持图的拓扑结构。\n\n 作者的想法是将两个节点之间的显式关系表示融入到它们的表示学习中。在标准的多头注意中，元素 $x_i$ 和元素 $x_j$之间的注意分数简单地分别是它们的查询向量和键向量的点积：\n$$\ns_{ij} = f(x_i,x_j) =x_iW^T_qW_kx_j\n$$\n假设我们已经学习了节点i和节点j之间的关系 $r_{ij}$ 的矢量表示，我们将其称为关系编码。\n$$\n[r_{i\\to j};r_{j\\to i}] = W_r r_{ij}\n$$\n$r_{i\\to j};r_{j\\to i}$ 为正向和反向关系编码。\n\n如果把正反两个关系编码加到节点embedding中，注意力分数计算可以为：\n$$\n\\begin{equation}\\begin{split} \ns_{ij} &= g(x_i, x_j, r_{ij})\\\\\n\t\t\t& = (x_i + r_{i\\to j})W_q^TW_k(x_j + r_{j\\to i})\\\\\n\t\t\t&= \\underbrace{x_iW_q^TW_kx_j}_{(a)} +  \\underbrace{x_iW_q^TW_kr_{j\\to i}}_{(b)} \\\\\n\t\t\t&+ \\underbrace{r_{i\\to j}W_q^TW_kx_j}_{(c)} + \\underbrace{r_{i\\to j}W_q^TW_kr_{j\\to i}}_{(d)}\n \n    \\end{split}\\end{equation}\n$$\n直观上，等式项意义:\n\n- (a) 捕获纯粹基于内容的content-based addressing,，这是普通注意力机制中的原始term。\n- (b) 依赖于源节点的关系偏置。\n- (c) 依赖于目标节点的关系偏置。\n- (d) 对通用的关系偏差进行编码。\n\n在这里作者使用的是节点间的最短路径来表示关系。\n\n#### Relation Encoder\n\n从概念上讲，关系编码为模型提供了关于应该如何收集和分发信息的全局指导，即在哪里关注。\n\n对于NLP中的大多数图形结构，边标签传达了相邻节点之间的直接关系(例如，概念到概念所扮演的语义角色，以及两个单词之间的依存关系)。\n\n作者将这种单跳关系定义扩展到多跳关系推理中，以刻画任意两个节点之间的关系。\n\n例如第一个图中 want-01 到 girl的最短路径概念为，$\\text{want-01} \\to^{ARG1} \\text{believe-01}\\to^{ARG0} girl$ 传达girl是wanted的目标。\n\n直观地说，两个节点之间的最短路径给出了它们之间最密切且可以说是最重要的关系\n\n作者使用GRU将关系序列转换为分布表示。$i$ 到 $j$ 的最短路径关系为: $sp_{i\\to j}=  [e(i,k_1), e(k1,k2),...,e(k_n,j)]$\n\n其中$e(,)$是边标签，$k_{1:n}$ 是中继节点。\n$$\n\\begin{equation}\\begin{split} \n \\overrightarrow s_t &= GRU_f(\\overrightarrow s_{t-1}, sp_t)\\\\\n \\overleftarrow s_t &= GRU_f(\\overleftarrow s_{t+1},sp_t)\n    \\end{split}\\end{equation}\n$$\nconcat最终关系表达为$r_{ij} = [\\overrightarrow s_n; \\overleftarrow s_0]$\n\n#### Bidirectionality\n\n因为应用任务常是DAG，作者给做成理论双向交互的。反转边连接与原始边相同的两个节点，但方向不同，并使用反转标签。\n\n此外作者还在每个图中引入一个额外的全局节点和自环边，该节点具有特殊标签GLOBAL与其他所有节点都有一条直接边。全局节点的最终表示$x_{global}$用作整个图表示。\n\n#### Absolute Position\n\n除了成对关系之外，一些绝对位置信息也是有益的。例如，AMR图的根作为整体焦点的粗略表示，使得到根节点的最小距离部分地反映了相应概念在整句语义中的重要性。 \n\n位置嵌入添加到编码器堆栈底部的输入embedding中。例如，第一个中的Want-01是AMR图的根节点，因此其索引应该为0。也将全局节点的索引表示为0。\n\n\n\n### Sequence Decoder\n\n和普通Transformer Decoder没什么大的区别\n\n特殊的一点，使用全局图形表示$x_{global}$来初始化每个时间步的隐藏状态。\n\n然后，通过在编码器的输出上交错多轮关注来更新每个时间步骤t处的隐藏状态 $h_t$\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["GNN&nlp"]},{"title":"Rethinking Graph Transformers with Spectral Attention","url":"/2021/07/21/Rethinking-Graph-Transformers-with-Spectral-Attention/","content":"\n# Rethinking Graph Transformers with Spectral Attention\n\n提出了*Spectral Attention Network*(SAN)，它使用学习的位置编码(LPE)，可以利用全拉普拉斯频谱来学习给定图中每个节点的位置。通过利用拉普拉斯的全谱，模型在理论上具有强大的区分图形的能力，并且可以更好地从它们的共振中检测出相似的子结构。\n\n在这项工作中，作者还是研究如何将Transformer体系结构应用于图形表示学习。开发了强大的可学习的位置编码方法，这些方法植根于谱图理论。 谱注意力网络(SAN)架构解决了先前图形转换器工作中的关键理论限制，并且明显超过了标准消息传递GNN的表达能力。\n\nSAN方法的优势对比：\n\n![](https://i.loli.net/2021/07/26/x7U849s2RSCdQau.png)\n\n- 保持注意中的局部结构\n- 使用边特征\n- 连接非相邻节点\n- 使用基于特征向量的PE进行注意\n- 使用具有结构信息的PE\n- 考虑特征值的排序\n- 特征向量的范数不变量\n- 考虑特征值的谱               (SAN独有)\n- 考虑特征向量的变量#       (SAN独有)\n- 意识到特征值的多重性    (SAN独有)\n- 对特征向量的符号不变\n\n也就是说SAN结合了稀疏和稠密GT的特性，并且还考虑了特征值的谱、征向量的变量#、意识到特征值的多重性。\n\n## 基于特征函数的绝对和相对位置编码\n\n因为不存在对节点进行排序或定义轴的规范方法。在本节中，作者将研究如何使用拉普拉斯的特征函数来定义图形中的绝对和相对PE，测量节点之间的物理相互作用，并使特定的子结构能够“听到”-类似于鼓的声音，揭示其结构。\n\n### 特征向量等价于图上的正弦函数\n\n在Transformer架构中，一个基本方面是使用正弦和余弦函数作为序列的PE。然而，对于任意图形，sinusoids正弦不能被清楚地定义，因为沿轴的位置没有清晰的概念。取而代之的是，它们的等价性由图Laplacian L的特征向量 $\\Phi$ 给出。\n\n事实上，在欧几里得空间中，拉普拉斯算子对应于梯度的散度，其特征函数是正弦/余弦函数，平方频率对应于特征值(我们有时从这里起将这两个概念互换)。因此，在图域中，图的Laplacian的特征向量与正弦函数自然等价，并且这一直觉被用于最近的多项工作中，这些工作将特征向量用作GNN(Benchmarking graph neural networks)、定向流(Directional graph networks. ICML2021)和GT的PE。\n\n在与正弦函数等价的情况下，我们很自然地发现，$\\mathcal{F}[f]$的傅里叶变换函数应用于图$\\mathcal{F}[f](\\lambda_i) = \\langle f, \\phi_i \\rangle$，其中特征值被认为是该图的傅立叶域中的一个位置。因此，最好将特征向量视为位于特征值轴上的向量，而不是矩阵的组成部分，如图所示。\n\n![](https://i.loli.net/2021/07/26/Bg3QbcITZuMRLjs.png)\n\n### 关于相对位置，特征函数告诉我们什么？(物理应用)\n\n除了模拟正弦函数外，拉普拉斯函数的特征向量还包含有关系统物理的重要信息，可以揭示距离度量。因为拉普拉斯运算符是物理学中的一个基本运算符，在麦克斯韦方程和热扩散中都有显著的应用。\n\n在电磁理论中，拉普拉斯的(伪)逆，在数学上称为拉普拉斯的格林函数，表示电荷的静电势。\n\n在图中，相同的概念使用拉普拉斯G的伪逆，并且可以通过其特征函数来计算。\n\n如下公式，$G(j_1,j_2)$ 是节点$j_1,j_2$ 之间的电势。 $\\hat \\phi_i,\\hat \\lambda_i$ 为对称Laplacian$D^{\\frac{-1}{2}}LD^{\\frac{-1}{2}}$第 $i$个特征值和特征向量。\n$$\nG(j_1,j_2) = d_{j_1}^{\\frac{1}{2}}d_{j_2}^{\\frac{-1}{2}}\\sum_{i>0}\\frac{(\\hat \\phi_{i,j_1},\\hat \\phi_{i,j_2})^2}{\\hat \\lambda_i}\n$$\n此外，傅立叶给出的热方程的原始解依赖于被称为傅立叶级数的正弦/余弦的和。由于拉普拉斯函数的特征向量是这些函数在图中的近似，我们找到了近似的解。热核与随机游走相关，我们利用两个热核之间的相互作用在下面方程中定义节点$j_1,j_2$之间的扩散距离$d_D$。类似的二次谐波距离$d_B$是一种不同的距离测量方法。这里我们使用正则拉普拉斯L的特征函数：\n$$\n\\begin{equation}\\begin{split} \n d^2_D(j_1,j_2) &= \\sum_{k>0} e^{-2t\\lambda_i}(\\phi_{i,j_1} - \\phi_{i,j_2})^2\\\\ d_B^2(j_1,j_2)&=\\sum_{i>0}\\frac{(\\phi_{i,j_1} - \\phi_{i,j_2})^2}{\\lambda_i^2}\n    \\end{split}\\end{equation}\n$$\n这个方程，首先强调了在提供有关图中相对位置的信息时将特征向量与其对应的特征值配对的重要性。其次，我们注意到特征向量的乘积与静电相互作用成正比，而减法与扩散距离和重谐距离成正比。最后，所有3个方程都有一个一致的模式：在确定节点之间的距离时，频率/特征值越小，权重越大。\n\n\n\n### 听图的形状及其子结构\n\n特征值的另一个众所周知的性质是它们如何用于区分不同的图结构和子结构，因为它们可以解释为图的共振频率。\n\n这就引出了一个著名的问题，即我们是否能从鼓的特征值中听到鼓的形状，同样的问题也适用于几何物体和3D分子。\n\n通过将特征函数用于部分功能对应、算法理解几何和样式对应。分子图的特征向量的例子如图所示。\n\n![](https://i.loli.net/2021/07/26/o4M9SwJnLWTKCsj.png)\n\n\n\n##  Laplace Eigenfunctions的规范\n\n在欧几里德空间和序列中，使用正弦波作为PE是很简单的：我们可以简单地选择一组频率，计算正弦波，并将它们添加或拼接到输入嵌入，就像在原始变压器中所做的那样。然而，在任意图中，复制这些步骤并不那么简单，因为每个图都有一组唯一的特征函数。\n\n在接下来的部分中，将介绍谱图理论中的关键原则，在为图构造PE时要考虑这些原则，这些原则大部分被以前的方法忽略了。包括正则化，特征值及其多样性的重要性，特征向量的数量是可变的，以及符号模糊性。作者的LPE架构旨在解决这些问题。\n\n\n\n**Normalization** 给定拉普拉斯的特征值，就有一个维数大于1的相关特征空间。为了在模型中利用这些信息，必须选择一个单一的特征向量。在我们的工作中，我们使用L2正则化，因为它与格林公式也就是上面的第一个公式的定义是兼容的。因此，我们将始终选择特征向量$\\phi$，使$⟨\\phi，\\phi⟩=1$。\n\n**Eigenvalues** 另一个基本方面是与每个特征向量相关联的特征值提供了有价值的信息。基于特征向量的特征值的排序在序列中起作用，因为频率是预先确定的。然而，这一假设在图中不起作用，因为它们的谱中的特征值可以改变。例如，在上图中，我们观察到排序如何忽略两个分子在 $λ = 1$ 以不同方式共振的事实。\n\n**Multiplicities** 选择特征函数的另一个重要问题是特征值高度多样的可能性，即当一个特征值多次作为特征多项式的根出现时。在这种情况下，相关联的特征空间可以具有2维或更多维，因为我们可以从具有相同特征值的任何特征向量的线性组合中生成有效的特征向量。这进一步复杂化了选择用于算法计算的特征向量的问题，并突出了拥有能够处理这种歧义的模型的重要性。\n\n**Variable number of eigenvectors** 图 $G_i$ 至多可以有 $N_i$ 个线性独立的特征向量，其中 $N_i$ 是它的节点数。最重要的是，$N_i$ 可以在数据集中的所有的 $G_i$ 都有所不同。GT选择了固定数目的k个特征向量给每个图，其中 $k≤N_i$，$∀i$。当数据集中最小的图的节点比最大的图少得多时，这就产生了一个主要的瓶颈，因为很小比例的特征向量将用于大型图。这不可避免地造成信息丢失，并激发了对构建k维固定PE的模型的需求，其中k不依赖于图中的特征向量的数目。\n\n**Sign invariance** 如前所述，特征向量存在符号歧义。由于φ的符号与它的正则化无关，在选择图的k个特征向量时，我们只剩下2k个可能的符号组合。以前的工作已经提出通过随机反转特征向量的符号来进行数据增强，虽然当k较小时可以工作，但是对于较大的k会变得困难。\n\n\n\n## Model Architecture\n\n我们提出了一种体系结构，它可以使用特征函数作为PE，同时解决上述规范中提出的问题。我们的 *Spectral Attention Network* (SAN)模型输入图的特征函数，并将其投影到固定大小的学习位置编码(LPE)中。LPE允许网络使用每个图的整个拉普拉斯频谱，学习频率如何交互，并决定哪些频率对给定任务最重要。\n\n![](https://i.loli.net/2021/07/26/8uAUjDZ5EdNQpFs.png)\n\n如图分为两步学习过程。\n\n图中的(c-d-e)描述了第一步，在每个节点的特征函数上应用一个Transformer，为每个图生成一个LPE矩阵。\n\n然后将LPE连接到节点嵌入图中(g-h)，然后将其传递给Graph Trabsformer (i)。如果任务涉及图分类或回归，则最终节点嵌入随后将传递到最终池化层。\n\n### LPE Transformer Over Nodes\n\n使用拉普拉斯编码作为节点特征在有关该主题的文献中是普遍存在的。LPE的想法受到上面第二个图的启发，其中特征向量 $\\phi$ 被表示为一个非均匀序列，特征值λ是频率轴上的位置。使用此表示法，Transformers是处理它们并生成固定大小PE的自然选择。\n\nLPE结构如图所示：\n\n![](https://i.loli.net/2021/07/26/yxhrKLAwXcvBTgD.png)\n\n学习位置编码(LPE)结构，模型通过考虑m个特征值和特征向量来学习图的拉普拉斯谱，其中允许 $m≤N$，其中N表示节点数。\n\n首先，我们通过将m个最低特征值与其关联的特征向量连接起来，为每个节点$j$ 创建一个大小为 $2×m$ 的嵌入矩阵。这里，m是要计算的特征向量的最大数目的超参数，并且类似于标准变压器的可变长度序列。对于 $m>N$ 的图，只需添加掩码填充。注意，要捕获所有图的整个谱，只需选择m，使其等于图在数据集中具有的最大节点数。然后在大小为2的维度上应用线性层以生成大小为k的新嵌入。然后，Transformer编码器对长度为m且隐藏维数为k的序列计算self-attention。最后，sum pooling将该序列简化为固定的k维节点嵌入。\n\n通过将特征值与归一化特征向量连接起来，该模型直接处理前三个规范。即将特征向量归一化，将特征向量与其特征值配对，并将特征向量的个数作为变量。此外，该模型意识到了多重性，并且有可能线性组合或忽略一些重复的特征值。\n\n然而，这种方法仍然没有解决预先计算的特征向量的符号是任意的限制。为了解决这个问题，我们像以前的工作[13，12]所采用的那样，在训练过程中随机反转预先计算的特征向量的符号，以促进符号歧义的不变性。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["GNN"]},{"title":"Heterogeneous Graph Transformer","url":"/2021/07/09/Heterogeneous-Graph-Transformer/","content":"\n# Heterogeneous Graph Transformer\n\n提出了一种用于Web规模异构图建模的异构图Transformer(HGT)体系结构。\n\n其一是设计了节点和边类型相关的参数来表征对每条边的异构attention，使得HGT能够维护不同类型的节点和边的专用表示。\n\n其二为了处理Web规模的图形数据，我们设计了异构小批量图形采样算法HG Samples，以实现高效和可扩展的训练\n\n作者使用的是OAG学术图，其存在的异构关系如下图：\n\n![](https://z3.ax1x.com/2021/07/09/RxMqUA.png)\n\n## 要解决的问题\n\nGNN以前可以处理异质图是基于元路径的方法有PathSim, methpath2vec等。GNN火起来以后也出现了好多处理异质图的工作。\n\n作者认为面临着几个问题：首先，它们大多涉及为每种类型的异构图设计元路径，需要特定的领域知识；其次，它们要么简单地假设不同类型的节点/边共享相同的特征和表示空间，要么只针对节点类型或边类型保持不同的非共享权重，使得它们不足以捕捉异构图的属性；最后，其固有的设计和实现使得它们无法对Web规模的异构图进行建模。\n\n作者的目标是：保持节点和边类型的依赖表示，避免定制的元路径，并且能够扩展到Web规模的异构图。\n\n### 做法：\n\n#### 异质处理\n\n为了处理图的异构性，引入了节点和边型依赖的注意机制。HGT中的异构相互关注度不是参数化的，而是通过基于其元关系三元组分解每条边e=(s，t)来定义的，即 <s的节点类型、s&t之间的e的边类型、t的节点类型>。上图说明了异质学术图的元关系。使用这些元关系来参数化权重矩阵，以计算每条边上的关注度。因此，允许不同类型的节点和边保持其特定的表示空间。\n\n同时，不同类型的连接节点仍然可以交互、传递和汇聚消息，而不受其分布差距的限制。由于其体系结构的本质，HGT可以通过跨层的消息传递来融合来自不同类型的高阶邻居的信息，这可以被认为是“软”元路径。也就是说，即使HGT只将其一跳边作为输入，而不需要人工设计元路径，所提出的注意机制也可以自动和隐式地学习和提取对不同下游任务重要的“元路径”。\n\n#### 异质子图采样法\n\n为了对Web规模的异构图进行建模，设计了第一个用于小批量GNN训练的异构子图采样算法HG Samples。它的主要思想是对不同类型节点比例相近的异构子图进行采样。此外，它还被设计成保持采样子图的稠密性，以最大限度地减少信息损失。有了HG-sample，所有的GNN模型都可以在任意大小的异构图上进行训练和推断。\n\n## 方法\n\n思想：利用异构图的元关系来参数化异构相互关注、消息传递和传播步骤的权重矩阵。\n\n有向图 $G = (V,E,A,R)$ ,  节点 $v \\in V$，每个边$e \\in E$ 。他们的类型映射函数为 $\\tau(v):V \\to A$ 、$\\phi(e):E\\to R$ \n\n### 元关系\n\n对于一个边 $e = (s,t)$ ，元关系定义为 $<\\tau(s),\\phi(e),\\tau(t)>$ 。$\\phi(e)^{-1}$ 是关系的反向表达。\n\n### HGT架构\n\n![](https://i.loli.net/2021/07/09/8CepfwW4dgEzsjc.png)\n\n主要的三个组件：Heterogeneous Mutual Attention、Heterogeneous Message Passin和特定于Target-Specific Aggregation。\n\n定义第$l$ 层的输出为 $H^l$, 也是第$l+1$层的输入。\n\n#### Heterogeneous Mutual Attention\n\n首先计算源节点 s 到目标节点 t 之间的 Mutual Attention。\n\n针对问题是：通过使用一个权重矩阵W来假设s和t具有相同的特征分布。这种假设对于异构图通常是不正确的，因为在异构图中，每种类型的节点都可以有自己的特征分布。\n\n给出目标节点 t ，以及它的邻居节点 $s \\in N(t)$ 它们可能属于不同的分布。通过元关系三元组 $<\\tau(s),\\phi(e),\\tau(t)>$, 计算mutual attention。\n\n将目标节点t映射为query向量，将源节点s映射为key向量，并计算它们的点积作为关注度。\n\n与Vanilla Transformer相比关键区别在于，Vanilla Transformer对所有单词使用一组投影映射，HGT的每个元关系都应该有一组不同的投影权重。\n\n为了在保持不同关系特性的同时最大限度地实现参数共享，提出将交互算子的权重矩阵参数化为源节点投影、边投影和目标节点投影。\n\n对每个边$e=(s,t)$进行h heads attention :\n$$\n\\begin{equation}\\begin{split} \n Attention_{HGT}(s,e,t) &= Softmax_{\\forall s\\in N(t)}(  \\|_{i\\in[1,h]} \\text{ATT-head}^i(s,e,t) )\\\\\n\\text {ATT-head}^i(s,e,t) &=(K^i(s) W^{ATT}_{\\phi(e)}Q^i(t)^T) \\cdot \\frac{\\mu<\\tau(s),\\phi(e),\\tau(t)>}{\\sqrt d} \\\\\nK^i(s) &= \\text{K-Linear}_{\\tau(s)}^i(H^{(l-1)}[s])\\\\\nQ^i(t) &= Q-Linear_{\\tau(t)}^i (H^{(l-1)}[t])\n    \\end{split}\\end{equation}\n$$\n$\\text{ATT-head^i(s,e,t)}$ 是第 $i$ 个注意力头。$\\text{K-Linear}^i_{\\tau{(s)}}:R^d \\to R^{\\frac{d}{h}}$ 编码了源接地那s类型$\\tau(s)$ 意味着每每个类型节点有独一无二的线性映射最大限度地对分布差异进行建模。\n\n然后计算Query和Key的相似度， 异构图的一个独特特征是在节点类型对之间可能存在不同的边类型(关系)，例如 $τ(S)$和$τ(T)$ 。因此，与直接计算查询和键向量之间的点积的Vanilla Transformer不同，我们为每个边类型$\\phi(e)$保留了一个不同的基于边的矩阵 $W^{ATT}_{\\phi(e)}\\in R^{\\frac{d}{h}\\times \\frac{d}{h}}$ 。这样，即使在相同的节点类型对之间，该模型也可以捕获不同的语义关系。\n\n此外，由于不是所有的关系对目标节点的贡献相等，我们增加了一个先验张量 $\\mu\\in R^{|A|\\times |R|\\times |A|}$ 表示每个元关系三元组的一般意义，作为对注意力的自适应缩放。\n\n最后，我们将注意力集中在一起，以获得每个节点对的attention向量。\n\n#### Heterogeneous Message Passing\n\n在计算Mutual Attention的同时，将信息从源节点传递到目标节点。\n\n与attention过程类似，希望在消息传递过程中加入边的元关系，以缓解不同类型节点和边的分布差异。\n\n对于一对节点 $e=(s,t)$，我们通过以下公式计算其多头 Message:\n$$\n\\begin{equation}\\begin{split} \n Message_{HGT(s,e,t)} &= \\|_{i\\in [1,h]} \\text{MSG-head}^i(s,e,t)\\\\\n \\text{MSG-head}^i(s,e,t) &= \\text{M-Linear}_{\\tau(s)}^i(H^{(l-1)}[s])W^{MSG}_{\\phi(e)}\n    \\end{split}\\end{equation}\n$$\n\n#### Target-Specific Aggregation\n\n$$\n\\hat H^{(l)}[t] =  \\oplus_{\\forall s\\in N(t)} (Attention_{HGT}(s,e,t) \\cdot Message_{HGT}(s,e,t))\n$$\n\n这将来自不同特征分布的所有近邻(源节点)的信息聚集到目标节点 t。\n\n最后一步是将目标节点t的向量映射回按其节点类型τ(T)索引的特定于类型的分布。为此，我们将线性投影A-线性τ(T)应用于更新后的向量H􏰅(L)[t]，随后是非线性激活和剩余连接[5]，如下所示：\n\n\n\n### HGSampling\n\n![](https://i.loli.net/2021/07/09/5yz2s4vhCZPINX9.png)\n\n\n\n\n\n\n\n","tags":["GNN"]},{"title":"Transformer的辅助","url":"/2021/07/04/Transformer的辅助/","content":"\n# Transformer的辅助\n\n转载：https://zhuanlan.zhihu.com/p/149634836\n\n## [为什么Transformer需要进行Multi-head Attention](https://www.zhihu.com/question/341222779/answer/814111138)\n\nAttention is all you need论文中讲模型分为多个头，形成多个子空间，每个头关注不同方面的信息。\n\n如果Multi-Head作用是关注句子的不同方面，那么不同的head就应该关注不同的Token；当然也有可能是关注的pattern相同，但是关注的内容不同，即V不同。\n\n但是大量的paper表明，transformer或Bert的特定层有独特的功能，底层更偏向于关注语法；顶层更偏向于关注语义。\n\n所以对Multi-head而言，同一层Transformer_block关注的方面应该整体是一致的。不同的head关注点也是一样。但是可视化同一层的head后，发现总有那么一两个头独一无二的，和其他头的关注不一样。\n\n众多研究表明Multi-Head其实不是必须的，去掉一些头效果依然有不错的效果（而且效果下降可能是因为参数量下降），这是因为在头足够的情况下，这些头已经能够有关注位置信息、关注语法信息、关注罕见词的能力了，再多一些头，无非是一种enhance或noise而已。\n\n### 相关paper \n\n- A Multiscale Visualization of Attention in the Transformer Model [https://arxiv.org/pdf/1906.05714.pdf](https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1906.05714.pdf)\n- What Does BERT Look At? An Analysis of BERT’s Attention [https://arxiv.org/pdf/1906.04341v1.pdf](https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1906.04341v1.pdf)\n- Improving Deep Transformer with Depth-Scaled Initialization and Merged Attention [https://arxiv.org/pdf/1908.11365.pdf](https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1908.11365.pdf)\n- Adaptively Sparse Transformers[https://arxiv.org/pdf/1909.00015.pdf](https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1909.00015.pdf)\n- Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned [https://arxiv.org/pdf/1905.0941](https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1905.09418.pdf)\n\n\n\n## [Transformer为什么Q和K使用不同的权重矩阵生成，为什么不能使用同一个值进行自身的点乘？（注意和第一个问题的区别）](https://www.zhihu.com/question/319339652)\n\n既然K和Q差不多（唯一区别是W_k和W_Q权值不同），直接拿K自己点乘就行了，何必再创建一个Q？创建了还要花内存去保存，浪费资源，还得更新参数。\n\n**为什么要计算Q和K的点乘？**\n\n我们知道K和Q的点乘是为了得到一个attention score 矩阵，用来对V进行提纯。K和Q使用了不同的W_k, W_Q来计算，可以理解为是在不同空间上的投影。正因为有了这种不同空间的投影，增加了表达能力，这样计算得到的attention score矩阵的泛化能力更高。这里解释下我理解的泛化能力，因为K和Q使用了不同的W_k, W_Q来计算，得到的也是两个完全不同的矩阵，所以表达能力更强。\n\n 但是如果不用Q，直接拿K和K点乘的话，你会发现attention score 矩阵是一个对称矩阵。因为是同样一个矩阵，都投影到了同样一个空间，所以泛化能力很差。这样的矩阵导致对V进行提纯的时候，效果也不会好。\n\n## [为什么在进行softmax之前需要对注意进行scaled（为什么除以dk的平方根），并使用公式推导进行讲解](https://www.zhihu.com/question/339723385/)\n\n**（**论文中解释是：向量的点积结果会很大，将softmax函数push到梯度很小的区域，scaled会缓解这种现象。怎么理解将sotfmax函数push到梯度很小区域？还有为什么scaled是维度的根号，不是其他的数？**）**\n\n以数组为例，2个长度是len，均值是0，方差是1的数组点积会生成长度是len，均值是0，方差是len的数组。而方差变大会导致softmax的输入推向正无穷或负无穷，这时的梯度会无限趋近于0，不利于训练的收敛。因此除以len的开方，可以是数组的方差重新回归到1，有利于训练的收敛。\n\n@LinT成功人士（） 以下感谢分享\n\n**1. 为什么比较大的输入会使得softmax的梯度变得很小？**\n\n对于一个输入向量$x\\in R^d$, softmax函数将其映射/归一化到一个分布$\\hat y\\in R^d$。在这个过程中softmax先用一个自然底数$e$ 将输入中的元素检举先“拉大”，然后归一化为一个分布。假设某个输入x 中最大的元素下班是k，如果输入的数量级变大(每个元素都很大)，那么$\\hat y_k$会非常接近1。\n\n举个例子$x$ 的数量级对输入最大元素对应的预测概率$\\hat y_k$的影响。假定输入 $x = [a,a,2a]^T$, 我们看看不同量级的$a$ 产生的$\\hat y_3$有什么区别。\n\n- ![[公式]](https://www.zhihu.com/equation?tex=a%3D1+) 时， ![[公式]](https://www.zhihu.com/equation?tex=%5Chat%7By%7D_3%3D0.5761168847658291) ;\n- ![[公式]](https://www.zhihu.com/equation?tex=a%3D10++) 时， ![[公式]](https://www.zhihu.com/equation?tex=%5Chat%7By%7D_3%3D0.999909208384341);\n- ![[公式]](https://www.zhihu.com/equation?tex=a%3D100++) 时， ![[公式]](https://www.zhihu.com/equation?tex=%5Chat%7By%7D_3%5Capprox+1.0) (计算机精度限制)。\n\n可以看出，第三个元素里的值随着数量级的增加而接近于1。而我们知道softmax层后的每个元素之后为1。也就是说，向量里最大值索引的元素基本上占据所有的概率了。为了理解方便，可视化如下。可以看出，随着向量里最大元素的数量级的增大，它就越近于1，相当于整个输出变成了one-hot编码了[y = [0,0,1\\]](#)\n\n```python\nimport numpy as np\nimport matplotlib.pyplot as plt\nx  = np.linspace(0,100,100)\nf = lambda x: np.exp(x * 2) / (np.exp(x) + np.exp(x) + np.exp(2 * x))\ny = [f(temp) for temp in x]\nplt.plot(x,y)\n```\n\n![](https://i.loli.net/2021/07/05/25qZGxyD17w9UgM.png)\n\n![](https://i.loli.net/2021/07/05/NZpiYSf8y7vVWEL.png)\n\n**2. 维度与点积大小的关系是怎么样的，为什么使用维度的根号来放缩？**\n\n![v2-493286fbea075e160bf3bac214d2ac60_720w](https://pic1.zhimg.com/80/v2-493286fbea075e160bf3bac214d2ac60_720w.jpg)\n\n![](https://i.loli.net/2021/07/05/5BnlfzVdOjh14EA.png)\n\n----\n\n## **在计算注意力分数的时候如何对padding做mask操作？**\n\nmask是将一些不要用的值掩盖掉，使其不产生作用。有两种mask，第一种是**padding mask**，在所有scaled dot-product attention都用到；第二种是**sequence mask，**在decoder的self-attention里面用到。\n\n**padding mask：**因为一个批量输入中，所有序列的长度使不同的。为了符合模型的输入方式，会用padding的方式来填充（比如填0），使所有序列的长度一致。但填充部分是没有意义的，所以在计算注意力的时候，不需要也不应该有注意力分配到这些填充的值上面。所以解决方式就是在填充的位置赋予一个**很小的负值/负无穷（-np.inf）**的值，**经过softmax后的得分为0**，即没有注意力分配到这个上面。\n\n```python\ndef padding_mask(seq_k, seq_q):\n  # shape(seq_k)=(B,L_k) , shape(seq_q) = (B, L_q)\n  # 因为要计算seq_k和seq_q的相似程度，来表示注意力的得分\n  # padding mask要作用在 QK^T上，所以padding mask是跟seq_k和seq_q序列长度相关的矩阵\n  # shape(padding mask) = (B, L_q, L_k)\n  len_q = seq_q.size(1)\n  # PAD is 0 这里要计算seq_k序列中，padding为0的地方，并将相应位置变为True，方便后续处理\n  pad_mask = seq_k.eq(0)\n  # 将每个seq_k序列扩展len_q次，shape[B, L_q, L_k]\n  pad_mask = pad_mask.unsqueeze(1).expand(-1, len_q, -1)\n  return pad_mask\n  \n```\n\n以上方法为大部分padding mask的计算形式，但实际上，这里做了seq_q全部有效的假设（没有padding），并不够精确 。自己的看法：上述代码expand操作，只是将seq_k中padding的部分重复了L_q次，并没有注意到，seq_q也有padding的部分。即在一个(L_q,L_k)矩阵中，只有最后几列需要掩码，实际矩阵的最后几行也需要掩码。（以后上图更形象）\n\n**sequence mask：**在decoder部分，因为不能见到下文信息（防止泄漏），所以用mask的方式掩盖掉当前时刻t及之后的下文信息。具体，可产生一个对角线为0的上三角矩阵，将其作用到每个decoder的输入列上。代码如下：\n\n```python\ndef sequence_mask(seq):\n    batch_size, seq_len = seq.size()\n    mask = torch.triu(torch.ones((seq_len, seq_len), dtype=torch.uint8),\n                    diagonal=1)\n    mask = mask.unsqueeze(0).expand(batch_size, -1, -1)  # [B, L, L]\n    # 三角矩阵中，为1的部分是需要被掩码掉的\n    return mask\n```\n\ndecoder-block有两个multi-head attention，下面的multi-head attention是目标输入的self-attention，需要用到1.padding mask：去除padding位置的影响；2.sequence mask：去掉下文穿越的影响。上面的multi-head attention只需要padding mask，因为下面的多头注意力已经磨平了下文信息。当**encoder和decoder的输入序列长度一样时**，可以通过padding mask+sequence mask作为scaled dot-product attention的attn_mask来实现。\n\n其他情况的attn_mask（代码中的表达）等于padding mask\n\n\n\n## [为什么在进行多头关注的时候需要对每个head进行切割？](https://www.zhihu.com/question/350369171)\n\n@何妨吟啸且徐行 感谢回答\n\nTransformer的多头注意力看上去是借鉴了CNN中同一卷积层内使用多个卷积核的思想，原文中使用了 8 个“scaled dot-product attention”，在同一“multi-head attention”层中，输入均为“KQV”，**同时**进行注意力的计算，彼此之前**参数不共享**，最终将结果**拼接**起来，这样可以允许模型在**不同的表示子空间里学习到相关的信息**，在此之前的 [A Structured Self-attentive Sentence Embedding](https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1703.03130) 也有着类似的思想。简而言之，就是希望每个注意力头，只关注最终输出序列中一个子空间，互相**独立**。其核心思想在于，抽取到更加丰富的**特征信息**。\n回到题主的问题上来，如果只使用 one head 并且维度为 ![[公式]](https://www.zhihu.com/equation?tex=d_%7Bmodel%7D) ，相较于 8 head 并且维度为 ![[公式]](https://www.zhihu.com/equation?tex=d_%7Bmodel%7D+%2F+8)。首先存在计算量极大的问题，并且高维空间下的学习难度也会相应提升，这就难免文中实验出现的参数量大且效果不佳的情况，于是将原有的高维空间转化为多个低维空间并再最后进行拼接，形成同样维度的输出，借此丰富特性信息，降低了计算量，而且取得了更好的效果，十分巧妙。\n\n## **为何在获取输入词向量之后需要对矩阵乘以embeddding size的开方？意义是什么？**\n\nembedding matrix的初始化方式是xavier init，这种方式的方差是1/embedding size，因此乘以embedding size的开方使得embedding matrix的方差是1，在这个scale下可能更有利于embedding matrix的收敛。\n\n## **你还了解些关于位置编码的技术，各自的优缺点是什么？**\n\nhttps://zhuanlan.zhihu.com/p/105001610\n\n## [Transformer 为什么使用 layer normalization，而不是其他的归一化方法？](https://www.zhihu.com/question/395811291)\n\nhttps://www.zhihu.com/question/395811291/answer/1251829041\n\n\n\n\n\n## **Transformer如何并行化的？**解码器端可以做并行化吗？\n\nTransformer的并行化主要体现在self-attention模块，在Encoder端Transformer可以并行处理整个序列，并得到整个输入序列经过Encoder端的输出，在self-attention模块，对于某个序列![[公式]](https://www.zhihu.com/equation?tex=x_%7B1%7D%2C+x_%7B2%7D%2C+%5Cdots%2C+x_%7Bn%7D)，self-attention模块可以直接计算![[公式]](https://www.zhihu.com/equation?tex=x_%7Bi%7D%2C+x_%7Bj%7D)的点乘结果，而RNN系列的模型就必须按照顺序从![[公式]](https://www.zhihu.com/equation?tex=x_%7B1%7D)计算到![[公式]](https://www.zhihu.com/equation?tex=x_%7Bn%7D)。\n\n\n\n\n\n## **简单描述一下wordpiece model和字节对编码？**\n\nhttps://zhuanlan.zhihu.com/p/86965595\n\n\n\n\n\n## **Transformer训练的时候学习率是如何设定的？**\n\n![](https://i.loli.net/2021/07/05/FDESyq27uWr1lvJ.png)\n\n\n\n## [Transformer中multi-head机制是如何实现每个head提取的信息空间互斥的？](https://www.zhihu.com/question/357565475)\n\nTransformer的多头注意力看上去是借鉴了CNN中同一卷积层内使用多个卷积核的思想，原文中使用了 8 个“scaled dot-product attention”，在同一“multi-head attention”层中，输入均为“KQV”，**同时**进行注意力的计算，彼此之前**参数不共享**，最终将结果**拼接**起来，这样可以允许模型在**不同的表示子空间里学习到相关的信息**。简而言之，就是希望每个注意力头，只关注最终输出序列中一个子空间，互相**独立**。其核心思想在于，抽取到更加丰富的**特征信息**。\n\n\n\n## **Transformer的细节到底是怎么样的？**\n\nhttps://www.zhihu.com/question/362131975/answer/945357471\n\n\n\n## **[为什么Bert的三个Embedding可以进行相加？](https://www.zhihu.com/question/374835153/answer/1040767499)**\n\n(Token Embedding、Segment Embedding、Position Embedding三个向量为什么可以相加呢？相加后向量的大小和方向就变了，语义不就变了吗？) 深度神经网络里变得非常复杂，本质上神经网络中每个神经元收到的信号也是“权重”相加得来。这三个向量为什么可以相加呢？因为三个embedding相加等价于三个原始one-hot的拼接再经过一个全连接网络。 相加后向量的大小和方向就变了，语义不就变了吗？这里不是语义变了，而是在训练的时候就是这几个向量相加进行训练的，训练完之后，将lookup后的向量进行相加，就能得到比较好的表示了。 从梯度的角度解释：\n$$\n(f+g+h)' = f'+g'+h'\n$$\n\n## **[为什么BERT输入的最大长度要限制为512？](https://www.zhihu.com/question/395903256)**\n\n个人推断是考虑了计算与运行效率综合做出的限制。\n\nBERT输入的最大长度限制为512, 其中还需要包括[CLS]和[SEP]. 那么实际可用的长度仅为510.**但是别忘了,**每个单词tokenizer之后也有可能被分成好几部分. 所以实际可输入的句子长度远不足510.\n\nBERT由于position-embedding的限制只能处理最长512个词的句子。如果文本长度超过512，有以下几种方式进行处理：\n\n**a）直接截断：**从长文本中截取一部分，具体截取哪些片段需要观察数据，如新闻数据一般第一段比较重要就可以截取前边部分；\n\n**b）抽取重要片段：**抽取长文本的关键句子作为摘要，然后进入BERT；\n\n**c）分段：**把长文本分成几段，每段经过BERT之后再进行拼接或求平均或者接入其他网络如lstm。\n\n另外transformer-xl 、[LongFormer：用稀疏自注意力拓展模型文本容纳量](https://zhuanlan.zhihu.com/p/133491514)等优秀设计也可以解决长文本。\n\n\n\n## **为什么BERT选择mask掉15%这个比例的词，可以是其他的比例吗？**\n\n来自@海晨威的算法屋\n\nBERT采用的Masked LM，会选取语料中所有词的15%进行随机mask，论文中表示是受到完形填空任务的启发，但其实**与CBOW也有异曲同工之妙**。\n\n从CBOW的角度，这里 ![[公式]](https://www.zhihu.com/equation?tex=p%3D15%5C%25) 有一个比较好的解释是：在一个大小为 ![[公式]](https://www.zhihu.com/equation?tex=1%2Fp%3D100%2F15%5Capprox7) 的窗口中随机选一个词，类似CBOW中滑动窗口的中心词，区别是这里的滑动窗口是非重叠的。\n\n那从CBOW的滑动窗口角度，10%~20%都是还ok的比例。\n\n上述非官方解释，是来自我的一位朋友提供的一个理解切入的角度，供参考。\n\n来自@Serendipity\n\n15%的概率是通过实验得到的最好的概率，xlnet也是在这个概率附近，说明在这个概率下，既能有充分的mask样本可以学习，又不至于让segment的信息损失太多，以至于影响mask样本上下文信息的表达。然而因为在下游任务中不会出现token“<mask>”，所以预训练和fine-tune出现了不一致，为了减弱不一致性给模型带来的影响，被mask的token有80%的概率用“<mask>”表示，有10%的概率随机替换成某一个token，有10%的概率保留原来的token，这3个百分比也是多次实验得到的最佳组合，在这3个百分比的情况下，下游任务的fine-tune可以达到最佳的实验结果。\n\n## **为什么BERT在第一句前会加一个[CLS]标志?**\n\nbert在token序列之前加了一个特定的token“[cls]”，这个token对应的向量后续会用在分类任务上；如果是句子对的任务，那么两个句子间使用特定的token“[seq]”来分割。\n\n为什么选它呢，因为与文本中已有的其它词相比，这个无明显语义信息的符号会**更“公平”地融合文本中各个词的语义信息**，从而更好的表示整句话的语义。\n\n这里补充一下bert的输出，有两种：\n\n一种是get_pooled_out()，就是上述[CLS]的表示，输出shape是[batch size,hidden size]。\n\n一种是get_sequence_out()，获取的是整个句子每一个token的向量表示，输出shape是[batch_size, seq_length, hidden_size]，这里也包括[CLS]，因此在做token级别的任务时要注意它。\n\n\n\n## **Bert和Transformer在loss上的差异**\n\ntransformer的loss是在decoder阶段计算的。bert预训练的loss由2部分构成，一部分是NSP的loss，就是token“[cls]”经过1层Dense，然后接一个二分类的loss，其中0表示segment B是segment A的下一句，1表示segment A和segment B来自2篇不同的文本；另一部分是MLM的loss，segment中每个token都有15%的概率被mask，而被mask的token有80%的概率用“<mask>”表示，有10%的概率随机替换成某一个token，有10%的概率保留原来的token，被mask的token经过encoder后乘以embedding matrix的转置会生成在vocab上的分布，然后计算分布和真实的token的one-hot形式的cross entropy，最后sum起来当作loss。这两部分loss相加起来当作total loss，利用adam进行训练。bert fine-tune的loss会根据任务性质来设计，例如分类任务中就是token“[cls]”经过1层Dense，然后接了一个二分类的loss；例如问题回答任务中会在paragraph上的token中预测一个起始位置，一个终止位置，然后以起始位置和终止位置的预测分布和真实分布为基础设计loss；例如序列标注，预测每一个token的词性，然后以每一个token在词性的预测分布和真实分布为基础设计loss。\n\nbert在encoder之后，在计算NSP和MLM的loss之前，分别对NSP和MLM的输入加了一个Dense操作，这部分参数只对预训练有用，对fine-tune没用。而transformer在decoder之后就直接计算loss了，中间没有Dense操作。\n\n\n\n## **为什么bert需要额外的segment embedding?**\n\n\n\n因为bert预训练的其中一个任务是判断segment A和segment B之间的关系，这就需要embedding中能包含当前token属于哪个segment的信息，然而无论是token embedding，还是position embedding都无法表示出这种信息，因此额外创建一个segment embedding matrix用来表示当前token属于哪个segment的信息，segment vocab size就是2，其中index=0表示token属于segment A，index=1表示token属于segment B。\n\n\n\n## **为什么transformer的embedding后面接了一个dropout，而bert是先接了一个layer normalization，再接dropout?**\n\nLN是为了解决梯度消失的问题，dropout是为了解决过拟合的问题。在embedding后面加LN有利于embedding matrix的收敛。\n\n\n\n## **BERT模型有什么调参技巧?**\n\nhttps://www.zhihu.com/question/373856698/answer/1034691809\n\n## **Transformer中warm-up和LayerNorm的重要性？**\n\nhttps://zhuanlan.zhihu.com/p/84614490\n\n\n\n## [Bert的mask为何不学习transformer在attention处进行屏蔽score的技巧？](https://www.zhihu.com/question/318355038)\n\n\n\nhttps://www.zhihu.com/question/318355038\n\n\n\n","tags":["nlp"]},{"title":"A Generalization of Transformer Networks to Graphs","url":"/2021/06/29/A-Generalization-of-Transformer-Networks-to-Graphs/","content":"\n# A Generalization of Transformer Networks to Graphs\n\n作者提出了一种适用于任意图的Transformer结构的。 \n\n## 针对问题:\n\n最初的Transformer相当于一个在所有单词之间都有连接的全连通图上操作，但这样的体系结构没有利用图的连通感应偏差，并且当图拓扑结构重要时，没有被编码到节点特征汇总，性能不好。\n\n## 解决方案\n\n作者提出四个新特性：\n\n- 首先，注意机制是图中每个节点的邻域连通性的函数。\n- 其次，位置编码由Laplacian特征向量来表示，用在了原始Transformer在NLP中常用的正弦位置编码。\n- 第三，用batch normalization层代替layer normalization，提供了更快的训练速度和更好的泛化性能。\n- 最后，将对任务至关重要的边缘特征表示，加入到该graph-transformer结构中。\n\n## 相关工作\n\n### Graph Transformer-2019\n\n首先作者提出在2019年Graph Transformer那篇文章，为了捕捉全局信息将attention应用在全图节点上替代了局部邻居。\n\n但作者认为这样限制了稀疏性的有效利用，这是在图数据上学习比较重要的ductive bias。 为了获取全局信息的目的，作者认为还有其他方法可以合并相同的信息，而不是放弃稀疏性和局部上下文。\n\n> 例如，使用特定于图形的位置特征(Zhang et al.2020)，或节点拉普拉斯位置特征向量(Belkin和Niyoi 2003；Dwivedi等人)。2020)或相对可学习的位置信息(You、Ying和Leskovec 2019)、虚拟节点 (Li et al. 2015)等。\n\n### Graph-BERT-2020\n\n其次作者在相关工作中评价了Graph-Bert那篇文章，其强调预先训练和并行化学习，使用一种子图批处理方案，创建固定大小的无链接子图，将其传递给模型，而不是原始图。\n\nGraph-BERT采用几种位置编码方案的组合来捕获绝对节点结构和相对节点位置信息。由于原始图不直接用于Graph-BERT，并且子图在节点之间没有边(即，无链接)，所提出的位置编码的组合试图在节点中保留原始图的结构信息。\n\n### HGT-2020、GTN-2019\n\nGraph Transformer Networks(GTN)学习异构图，目标是将给定的异构图转换为基于元路径的图，然后执行卷积。\n\n他们使用attention背后的重点是为了预置生成的meta-paths，除了能够处理任意数目的节点和边类型外，HGT还以基于中心节点和消息传递节点的时间戳差异的相对时间位置编码的形式捕获了异质图中信息流的动态变化。\n\n\n\n### 本文贡献\n\n提出稀疏性和位置编码是图变形器开发中的两个关键方面。与为特定的图形任务设计一个性能最佳的模型相反，这篇的工作是尝试一个通用的graph-Transformer模型。\n\n- 提出了一种将Transformer网络可以用于任意结构同质图的方法，即Graph Transformer，并提出了一种具有边特征的扩展Graph Transformer，它允许使用显式的域信息作为边特征。\n- 利用图数据集的拉普拉斯特征向量来融合节点位置特征， 与文献的比较表明，对于任意同质图，拉普拉斯特征向量比任何现有的编码节点位置信息的方法都要好。\n- 实验证明其好于传统GNN\n\n\n\n## 方法\n\n### 图的稀疏性\n\n在NLP Transformer中，句子被视为完全连通的图形，这种选择有两个原因：\n\n- 很难在句子中的单词之间找到有意义的稀疏交互或联系。例如，句子中的一个词对另一个词的依赖性可以随上下文、用户的视角和特定应用而变化。一个句子中的词之间可能存在许多似是而非的基本事实连接，因此，句子的文本数据集没有显式的词交互可用。因此，让一个句子中的每个单词相互关注其他单词是有意义的，就像Transformer架构所遵循的那样。\n- 在NLP Transformer中考虑的所谓的图通常具有少于数十或数百个节点。这在计算上是可行的，大型变压器模型可以在这种完全连通的文字图上进行训练。\n\n在高达数百万或数十亿的节点大小。可用的结构为我们提供了丰富的信息源，可以作为神经网络中的归纳偏差加以利用，而节点大小实际上使得这样的数据集不可能有一个完全连通的图。\n\n### 图的位置编码\n\n在NLP中，大多数情况下，基于Transformer的模型由每个字的位置编码补充。这对于确保每个单词的唯一表示以及甚至保留距离信息是至关重要的。\n\n> 对于图，唯一节点位置的设计是具有挑战性的，**因为存在防止规范节点位置信息的对称** 。事实上，大多数GNN学习的是节点位置不变的structural node信息。\n>\n> 这就是为什么简单的基于注意力的模型，如GAT，其中attention是局部邻域连通性的函数，而不是全图连通性。\n\n为了更好地对距离感知信息进行编码，(附近节点具有相似的位置特征，而较远的节点具有不同的位置特征)使用拉普拉斯特征向量作为图变换中的PE。\n\n 作者在训练过程中随机反转特征向量的符号，遵循 Benchmarking graph neural networks 的做法 。预先计算了数据集中所有图的拉普拉斯特征向量。通过对图的拉普拉斯矩阵进行因式分解来定义特征向量；\n$$\n\\Delta = I - D^{-1/2}AD^{-1/2}=U^T\\Lambda U\n$$\n使用节点的k个最小特征向量作为其位置编码，并对节点 $i$用 $λ_i$表示。\n\n### Graph Transformer Architecture\n\n![](https://z3.ax1x.com/2021/06/29/RwVhq0.png)\n\n左边的模型是为没有明确边属性的图设计的，右边的模型维护一个指定的边特征，以结合可用的边信息并在每一层维护它们的抽象表示。\n\n#### 输入\n\n图 $G$ 的节点特征 $\\alpha_i \\in R^{d_n \\times 1}$ ，节点$i,j$ 对应的边特征$\\beta_{ij}\\in R^{d_e \\times 1}$\n\n$\\alpha_i, \\beta_{ij}$  通过线性映射成为$d$ 维隐层特征 $h_i^0 , e_{ij}^0$ :\n$$\n\\hat h_i^0 = A^0\\alpha_i + a^0 ; e_{ij}^0 = B^0\\beta_{ij}+b^0\n$$\n其中，$A^0\\in R^{d\\times d_n}, B^0\\in R^{d\\times d_e}, a,b\\in R^d$\n\n将位置编码线性映射后加入节点特征:\n$$\n\\lambda_i^0 = C^0\\lambda_i +c^0; h_i^0 = \\hat h_i^0 + \\lambda_i^0\n$$\n其中，$C^0\\in R^{d\\times k}, c^0 \\in R^d$ . 请注意，拉普拉斯位置编码仅添加到输入层的节点特征，而不是在中间层。\n\n#### Graph Transformer Layer\n\n第 $l$ 层节点更新:\n$$\n\\begin{equation}\\begin{split} \n \\hat h_i^{l+1} &= O^l_h \\parallel_{k=1}^H \\left ( \\sum_{j\\in N_i} w_{ij}^{k,l} V^{k,l} h^l_j \\right )\\\\\n where, w_{i,j}^{k,l} &= softmax_j(\\frac{Q^{k,l} \\cdot K^{k,l}h_j^l}{\\sqrt{d_k}})\n    \\end{split}\\end{equation}\n$$\n其中，$Q^{k,l}, K^{k,l}, V^{k,l} \\in R^{d_k \\times d}, O^{l}_h\\in R^{d\\times d}$ ，$k$ 注意力haed数。\n\n为了数值稳定性，在取softmax 的输出被限制介于−5到+5之间。\n\n然后，将attention输出$h^{l+1}$传递给FFN，然后是残差和归一化层，如下所示：\n$$\n\\begin{equation}\\begin{split} \n \\hat{\\hat {h}}_i ^{l+1} &= Norm(h_i^l + \\hat h^{l+1}_i) \\\\\n \\hat{\\hat{\\hat{h_i}}}^{l+1} &= W_2^l ReLU(W_1^l \\hat{\\hat {h}}_i ^{l+1}) \\\\\n h^{l+1}_i &= Norm(\\hat{\\hat {h}}_i ^{l+1}+\\hat{\\hat{\\hat{h_i}}}^{l+1})\n    \\end{split}\\end{equation}\n$$\n其中 $W_1^l\\in R^{2d \\times d}, W_2^l \\in R^{d\\times 2d}$ 为了说明清楚，省略了偏执项。\n\n\n\n#### Graph Transformer Layer with edge features\n\n旨在更好地利用图数据集中以边属性形式提供的丰富特征信息。\n\n![](https://z3.ax1x.com/2021/06/30/RwzFXD.png)\n\n\n\n这些边特征是对应于节点对的相关分数，所以将这些可用的边特征与通过 pairwise attention计算的隐含边分数联系起来。换言之，假设在query 和 key 特征投影相乘之后，当节点 $i$ 关注节点 $j$ 时，计算在softmax注意分数 $\\hat w_{ij}$， 将该分数  $\\hat w_{ij}$ 视为关于边 $<i，j>$的隐含信息。\n\n利用边特征改进已经计算的隐式注意分数 $\\hat w_{ij}$ 。通过简单地将两个值 $\\hat w_{ij}$ 和 $e_{ij}$ 相乘来实现的\n\n指定的节点对称的边特征表示管道，用于将边属性从一层传播到另一层：\n$$\n\\begin{equation}\\begin{split} \n  \\hat h_i^{l+1} &= O^l_h \\parallel_{k=1}^H \\left ( \\sum_{j\\in N_i} w_{ij}^{k,l} V^{k,l} h^l_j \\right )\\\\ \\\\\n  \\hat e^{l+1}_{ij} &= O^l_e \\parallel_{k=1}^H(\\hat w_{ij}^{k,l}),\\\\  \\\\\n  where, w_{ij}^{k,l} &= softmax_j(\\hat w_{ij}^{k,l}) ,\\\\ \\\\\n  \\hat w_{ij}^{k,l} &= \\left(\\frac{Q^{k,l} \\cdot K^{k,l}h_j^l}{\\sqrt{d_k}} \\cdot E^{k,l}e^{l}_{ij} \\right)\n  \n    \\end{split}\\end{equation}\n$$\n其中 $Q^{k,l}, K^{k,l}, V^{k,l} ,E^{k,l} \\in R^{d_k\\times d} , O^l_h,O^l_e\\in R^{d\\times d}$\n\n其余d 也是要经过Transformer架构中的其他成分。\n\n\n\n## 实验\n\n![](https://z3.ax1x.com/2021/06/30/R0NJln.png)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["GNN&nlp"]},{"title":"Do Transformers Really Perform Bad for Graph Representation?","url":"/2021/06/23/Do-Transformers-Really-Perform-Bad-for-Graph-Representation/","content":"\n# Do Transformers Really Perform Bad for Graph Representation?\n\n作者提出了一个建立在Transformer体系结构上可以对图进行出色表征的模型——Graphormer。\n\n近来Transformer和Graph进行结合尝试的文章有：\n\n- Graph transformer for graph-to-sequence learning. AAAI 2020.\n- A generalization of transformer networks to graphs. AAAI 2021. (GT)\n- Heterogeneous graph transformer.  2020.\n- Re-thinking graph transformers with spectral attention.   2021.  (>GT)\n- Graph transformer.  2019.\n- Direct multi-hop attention based graph neural network. 2020\n- Graph transformer networks.   2019.\n- Transformers are Graph Neaurl Networks. 2020\n- Graph-bert: Only attention is needed for learning graph representations. 2020\n\n虽然有很多利用Transformer进入图形领域的尝试，但唯一有效的方法是用Softmax attention 取代经典GNN变体中的一些关键模块(例如，特征聚合)。因此，Transformer体系结构是否适合于对图进行建模，以及如何使其在图表示学习中发挥作用，仍然是一个悬而未决的问题。\n\n## 本文方法\n\nHow Transformers could perform well for graph representation learning?\n\n作者解决办法：关键是要正确地将图的结构信息融入到模型中。\n\n1.  *Centrality Encoding*：捕捉节点在图中的重要性。在图中，不同的节点可以具有不同的重要性，例如，名人被认为比社交网络中的大多数网络用户更有影响力。然而，这种信息没有反映在self-attention模块中，因为它主要使用节点语义特征来计算相似度。\n\n   1.1. *degree centrality* ：利用度中心性进行Centrality Encoding，其中根据每个节点的度将可学习向量分配给每个节点，并将其添加到输入层中的节点特征。\n\n2. *Spatial Encoding* ：提出了一种新的空间编码来捕捉节点之间的结构关系。将图形结构化数据与其他结构化数据(例如语言、图像)区分开来的一个值得注意的几何属性是不存在用于嵌入图形的规范网格，结点只能位于非欧几里德空间中，并且由边连接。作者使用任意两个节点之间的**最短路径距离**作为示例，将其编码为Softmax关注度中的偏置项，以帮助模型准确地捕捉图中的空间相关性。\n\n   2.1. 此外，有时edge特征中还包含额外的空间信息，例如分子图中两个原子之间的键类型。设计了一种新的Edge Encoding方法，将这种信号进一步带入Transformer layers。\n\n\n\n## Graphormer\n\n### Structural Encodings in Graphormer\n\n三种有效的Graphormer编码：Centrality Encoding、Spatial Encoding、Edge Encoding in the Attention\n\n![](https://i.loli.net/2021/06/24/CoMykaSRbVxvtUc.png)\n\n#### 特征层面 Centrality Encoding\n\n普通的attention机制是基于节点之间的语义相关性来计算注意力分布的，节点的中心性可以衡量节点在图中的重要性，但这种信息在目前的attention计算中被忽略了。(attention不是也可以计算出什么比较重要吗，这里有点疑问)\n\n在Graphormer中，作者使用了degree中心性，作为节点中心性的度量。根据每个节点的入度和出度为每个节点分配两个实值embedding向量。对每个节点都应用中心性编码，因此需将其作为输入添加到节点特征中。\n$$\nh_i^{(0)} = x_i + z_{deg^{-}(v_i)}^- + z^+_{deg^+(v_i)}\n$$\n通过在输入中使用中心性编码，Softmax注意力既可以捕捉到查询和关键字中的节点重要性信号，又能捕捉到节点的重要性。\n\n```python\nself.in_degree_encoder = nn.Embedding(512, hidden_dim, padding_idx=0)\nself.out_degree_encoder = nn.Embedding(512, hidden_dim, padding_idx=0)\nnode_feature = node_feature + self.in_degree_encoder(in_degree) + self.out_degree_encoder(out_degree)\n```\n\n\n\n#### 注意力层面 Spatial Encoding\n\noriginal的transformer的注意力机制使得它具有全局的感受野，前提是对于每一个token需要指定一个位置，比如一个句子中不同词的位置可以用 $1,2,3,4......$ 来代表序列中不同位置的编码。对于图来说并不存在序列这样的位置特性，那么应该如何考虑不同节点的位置信息呢？\n\n图结构通常是在非欧空间下的，两个节点的位置关系可以用节点之间的最短路径 $\\phi(v_i,v_j):V \\times V \\to R$ 来表示(无关联的两个节点之间的最短路径为-1)。 函数 $\\phi$ 可以由图中节点之间的连通性来定义。在这篇文章中作者选用的是最短路径长度SPD。并进行可学习参数映射为 $b_{\\phi(v_i,v_j)}$  ，在所有层之间共享。\n\n将这一特征融入注意力矩阵，使得注意力系数也包含了图中节点的相对位置（连接关系）信息：\n$$\nA_{ij} = \\frac{(h_iW_Q)(h_jW_K)^T}{\\sqrt{d}} + b_{\\phi}(v_i,v_j)\n$$\n\n\n这样做的好处：\n\n- 首先，与传统GNN相比，其中接受场仅限于邻居，可以在公式中看到这一点。transformer层提供了全局信息，每个节点都可以关注图中的所有其他节点。\n- 其次，通过使用 $b_{\\phi(v_i,v_j)}$，单个transformer层中的每个节点可以根据图的结构信息自适应地关注所有其他节点。比如学到的b是个单调减函数，那就表达了**最短路径越大的节点之间的关系越小**，这也是图神经网络中的基本思想：**越近的邻居的信息越重要**。\n\n\n\n#### 注意力层面 Edge Encoding in the Attention\n\n此外，graph相关的任务中通常还有边的信息，这些特征对于图形表示很重要。\n\n以前工作中的有两种编码方式：\n\n- 在第一种方法，边缘特征被添加到关联节点的特征。\n- 在第二种方法，对于每个节点，其关联边的特征将与节点特征一起aggregation使用。\n\n但这种使用边特征的方法只将边信息传播到其关联的节点，这可能不是利用边信息来表示整个图的有效方式。\n\n作者提出了一个新的edge编码方式，\n\n注意机制需要估计每个节点对 $(v_i，v_j)$ 的相关性，作者认为应该在相关性中考虑连接它们的边 (像多跳图网络那样)。对于每个有序节点对 $(v_i，v_j)$，从 $v_i$ 到 $v_j$ 的最短路径为 $SP_{ij}=(e_1，e_2，...，e_n)$，则可以用路径的加权平均得到两个节点之间边的相关信息：\n$$\ne_{ij} = \\frac{1}{N} \\sum_{n=1}^N x_{e_n} (w_n^E)^T\n$$\n其中 $x_{e_n}$ 是第n个边 $e_n$ 的特征，$w_n^E \\in R^{d_E}$ 是第n个权重embedding，$d_E$ 是边特征的维度。\n\n将这个信息也一起融入到注意力机制中：\n$$\nA_{ij} = \\frac{(h_iW_Q)(h_jW_K)^T}{\\sqrt{d}} + b_{\\phi}(v_i,v_j) + e_{ij}\n$$\n\n```python\n# Scaled Dot-Product Attention.\n# Attention(Q, K, V) = softmax((QK^T)/sqrt(d_k))V\nq = q * self.scale\nx = torch.matmul(q, k)  # [b, h, q_len, k_len]\nx = x + attn_bias\nx = torch.softmax(x, dim=3)\nx = self.att_dropout(x)\nx = x.matmul(v)  # [b, h, q_len, attn]\n```\n\n> 把 $A_{ij}$  的三部分进行拆分，三个分支的网络分别学习不同层面的信息，然后再后面再对三个分支的网络输出进行concat或者attention是否有帮助？\n\n\n\n### 图池化的一个细节\n\n想要表示图级别的embedding，Graphormer采用了一个额外写的特殊节点 $[VNode]$ , 让它和图中每个节点都链接。\n\n有点像bert中的CLS一样，整个图$h_G$的表示将是最终层中的 $[VNode]$ 的节点特征\n\n\n\n\n\n## *Do these modifications make Graphormer more powerful than other GNN variants?* \n\n### Fact 1.\n\n通过选择合适的权值和距离函数 $\\phi$，Graphormer layer可以表示GIN、GCN、GraphSAGE等流行的广义网络模型的AGGREGATE和 COMBINE 步骤。\n\n1. Spatial encoding 使得 self-attention 模块能够区分节点 $v_i$ 的邻居集合 $N(v_i)$，从而SoftMax函数可以计算 $N(v_i)$ 上的平均统计量\n2. 通过了解节点的度，平均邻域可以转化为邻域之和\n3. 利用多头注意力和FFN，可以分别处理 $v_i$ 和 $N(v_i)$ 的表示，并且将其组合在一起。 \n\n### 证明1  \n\n#### 采用空间编码的自我注意模块可以表示均值聚合\n\n$$\nA_{ij} = \\frac{(h_iW_Q)(h_jW_K)^T}{\\sqrt{d}} + b_{\\phi}(v_i,v_j)\n$$\n\n\n\n如果 $\\phi=1$ ，则设置 $b_{\\phi}=0$ ，否则设置 $b_{\\phi}=−∞$，其中 $\\phi$ 是 SPD。意思是如果直接相连就考虑其原本的注意力分数，如果不是直接相连注意力分数就为负无穷，就和普通的GNN一样的了。\n\n设置 $W_Q=W_K=0$ 且 $W_V$ 为单位矩阵，$softmax(A)V$ 表示邻居表示的平均值。\n\n\n\n\n\n## 实验\n\n OGB-LSC quantum chemistry regression (i.e., PCQM4M-LSC) challenge\n\n这是目前最大的图形级预测数据集，总共包含超过380万个图表\n\n还有其他三个任务：ogbg- molhiv, ogbg-molpcba and ZINC\n\n主要有两种模型大小：\n\nGraphormer (L = 12, d = 768) ， $Graphormer_{SMALL}$ (L = 6,d = 512).\n\n\n\n![](https://i.loli.net/2021/06/25/QJ9CO7jATVIXzxE.png)\n\n\n\n![](https://i.loli.net/2021/06/25/h3dgUJ65qlzEAuX.png)\n\n\n\n### 消融实验\n\n将以前使用的位置编码(PE)与作者提出的空间编码进行了比较，这两种编码的目的都是对变压器的不同节点关系信息进行编码。\n\n以前的基于变压器的GNN采用了各种PE，例如Weisfeiler-Lehman-PE(WL-PE)和Laplacian PE。采用的是Laplacian ，有文章证明一系列PE相比，它的性能很好。\n\n采用空间编码的transformer体系结构的性能优于基于位置编码的transformer体系结构，说明了利用空间编码捕获节点空间信息的有效性。\n\n![](https://i.loli.net/2021/06/25/5INfs8M9XHSmqDK.png)\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["GNN&nlp"]},{"title":"Avoiding Reasoning Shortcuts- Adversarial Evaluation, Training, and Model Development for Multi-Hop QA","url":"/2021/06/13/Avoiding-Reasoning-Shortcuts-Adversarial-Evaluation-Training-and-Model-Development-for-Multi-Hop-QA/","content":"\n# Avoiding Reasoning Shortcuts- Adversarial Evaluation, Training, and Model Development for Multi-Hop QA\n\n这篇文章作者发现在HotpotQA中经常包含Reasoning Shortcuts。也就是说模型没有真正的理解文章并进行推理，而是通过将问题与上下文中的句子进行词匹配来直接定位答案。\n\n作者主要做了两件事：\n\n- 构建干扰文档数据，证明了存在推理shortcut现象。\n- 设计一个新模型来缓解这个问题\n\n\n\n## 对抗验证\n\n![](https://z3.ax1x.com/2021/06/14/27n5O1.png)\n\n\n\n问题是What was the father of Kasper Schmeichel voted to be by the IFFHS in 1992? （卡斯珀·舒梅切尔的父亲1992年被IFFHS投票选为什么？）\n\n模型需要从两个文档中考虑信息，找出隐含的推理链条。\n\nKasper Schmeichel $\\rightarrow^{son}$  Peter Schemeichel $\\rightarrow^{voted}$ World’s Best Goalkeeper\n\nKasper Schmeichel是Peter Schemeicher, Peter Schemeicher 被投票为 World’s Best Goalkeeper 世界最佳守门员。\n\n在该示例中，也可以通过将问题中的几个关键字(“voted to be by the IFFHS in 1992——1992年投票的IFFHS”)与上下文中的相应事实相匹配来得到正确的回答，而无需通过第一跳推理来找到“Kasper Schmeichel的父亲”，因为两个distractor文档都不包含足够分散注意力的信息。 \n\n因此，一个在现有评估上表现良好的模型并不一定表明它具有很强的复合推理能力。\n\n随着对抗扰动文本被添加到上下文中，使用单跳shotcut方式不再可能找到正确的答案，这现在导致了两个可能的答案(“世界最佳守门员”和“世界最佳防守人”)。\n\n添加干扰后模型预测答案为 IFFHS World's Best Defender 最佳防守人。\n\n\n\n## 如何构建对抗数据\n\n**要构建这种对抗的需求**\n\n> 作者指出HotpotQA从维基百科中选择距离目标问题最短的bigram TF-IDF的前8个文档作为干扰项，形成总共10个文档的上下文。由于在生成问题时没有向群组工作人员提供导向文档，因此不能保证在给定整个上下文的情况下，两个支持文档都是必要的来推断答案。\n>\n> 多跳假设可以通过两种方式由不完整的分心文档来实现。\n>\n> 1. 其中一个选定的干扰项可能包含推断答案所需的所有证据，从经验上讲，在HotpotQA中没有发现这样的情况，因为关于一个主题的Wiki文章很少讨论另一个主题的细节\n>\n> 2. 整个分散注意力的文档池可能不包含真正分散读者/模型注意力的信息。\n\n作者把绕过推理回答问题这种方式，叫做shortcut 。其经常出现在HotpotQA中的桥接问题中，比较问题一般不能匹配而得出。作者采样了50个桥接问题，发现其中26个有这种问题。\n\n-----\n\n设原内容、问题答案为 $(C,q,a)$ 是可能包含shortcut问题的数据，作者是想将其变为$(C',q,a)$ \n\n$q,a$ 不变，$C'$ 变成接近 $C$ 的文章。在HotpotQA中是提供两个支持文档$P$的， 其中$P\\subset C$ 。\n\n 在构建对抗文本时也就是ADDDoc。就是利用新的 $P'$ ，混合$(C,P')$ 构成新的数据集。\n\n**那么 $P'$ 如何来的？**\n\n假设 $p2\\in P$ 是包含答案的支持文档，$p1\\in P$ 是包含线索的文档。\n\nADDDoc是利用词或短语级别的干扰，将 $p2$ 替换成$p'2$ ，其包含满足推理快捷方式但不与整个问题的答案相矛盾的假答案。\n\n**那么词语是如何替换的？**\n\n首先，对于答案中的每个非停用词，都会在GloVe100维向量空间中找到最接近的10个替代词，它的子串与原始答案的重叠子串长度不超过3个。如(Mumbai → Delhi, Goalkeeper → Defender)。如果这个过程失败，就从HotpotQA dev集合的整个答案池中随机抽样一个候选者 。 \n\n如果原始答案有多个单词，我们将答案中的一个非停用词与相应的抽样答案单词替换，以创建假答案(“World’s Best Goalkeeper → World’s Best Defender”)。\n\n![27EFfA.png](https://z3.ax1x.com/2021/06/14/27EFfA.png)\n\n问：Sachin Wamer作为软件工程师所在的公司的总部在哪里？\n\n由此产生的段落 $p'2$ 提供了一个满足推理捷径的答案，但也与整个问题的真实答案相矛盾，因为它形成了另一个有效的推理链，将问题与假答案连接起来 (Sachin Warrier $\\rightarrow^{work}$ TCS $\\rightarrow^{at}$ Delhi)。\n\n为了打破这个矛盾的推理链，我们需要用另一个实体替换连接两个证据的桥梁实体（在这种情况下为“Tata Consultancy Services”），这样生成的答案就不再作为有效答案 。\n\n用从 HotpotQA 开发集中所有文档标题中随机采样的候选者替换 $p'2$ 的标题。 如果 $p1$ 的标题出现在$p'2$ 中，我们也将其替换为另一个采样标题，以彻底消除 $p'2$ 和 $p1$ 之间的联系。\n\n如上图将 Tata Consultancy Services  替换为  Valencia Street Circuit \n\n\n\n## 模型方法\n\n\n\n### Encoding\n\n对于cotnext 和question 使用v 维Highway Network 合并 字符嵌入和GloVe词嵌入。\n\n得到 $x\\in R^{J\\times v}$ 和 $q\\in R^{S\\times v}$ 其中 J 是文章长度 S 为问题长度\n\n整体结构和BiDAF那个文章相似。\n\n[![27xDFP.png](https://z3.ax1x.com/2021/06/14/27xDFP.png)](https://imgtu.com/i/27xDFP)\n\n\n\n### Single-Hop Baseline\n\n使用bi-attention + self-attention ，给定上下文和问题encoding  $h,u$ 经过 context-to-query $BiAttn(h,u)$ 计算得到一个相似矩阵 $M^{S\\times J}$ :\n$$\n\\begin{equation}\\begin{split} \n M_{s,j} &= W_1u_s +W_2h_j + W_3(u_s\\odot h_j) \\\\\n p_{s,j} &= \\frac {exp(M_{s,j})}{\\sum_{s=1}^S exp(M_{s,j})}\\\\\n c_{q_j} &= \\sum_{s=1}^S p_{s,j} u_s\n    \\end{split}\\end{equation}\n$$\n$\\odot$ 对应元素相乘。\n\n然后query-to-context 注意力：\n$$\n\\begin{equation}\\begin{split} \nm_j &= max_{1\\le s\\le S} M_{s,j} \\\\\n p_{s,j} &= \\frac {exp(m_{j})}{\\sum_{j=1}^J exp(m_{j})}\\\\\n q_c &= \\sum_{j=1}^J p_{j} h_j\\\\\n h'_j &= [h_j ;c_{q_j}; h_j\\odot c_{q_j}; c_{q_j} \\odot q_c]\\\\\n h^1 &= BiLSTM(h')\n    \\end{split}\\end{equation}\n$$\n\n\n\n\n\n## 实验\n\n![](https://i.loli.net/2021/06/23/mPiX5Rkz1o9tCSl.png)\n\n\n\n\n\n![](https://i.loli.net/2021/06/23/yQODEbgUcaeZApK.png)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["nlp"]},{"title":"TRANSFORMER-XH: MULTI-EVIDENCE REASONING WITH EXTRA HOP ATTENTION","url":"/2021/06/10/TRANSFORMER-XH-MULTI-EVIDENCE-REASONING-WITH-EXTRA-HOP-ATTENTION/","content":"\n# TRANSFORMER-XH: MULTI-EVIDENCE REASONING WITH EXTRA HOP ATTENTION\n\n## 摘要\n\n提出Transformer-XH配有eXtra Hop attention以完全数据驱动的方式实现了结构化文本的内在建模。\n\n完全数据驱动应该是指不仅可以处理序列结构的数据，还可以处理图结构。\n\neXtra Hop attention 除了关注每个序列内的记号外，还可以连接的文本序列之间跳跃\n\n因此文档之间传播信息和构建全局上下文表示来更好地进行联合多证据推理。\n\neXtra Hop attention的作用：\n\n- 当每段文本与其他证据相关时能够更全局地表示每段文本所贡献的证据\n- 以一种自然的方式，通过必要的边信息传递对证据图联合推理\n\n## 方法\n\n面临的第一个挑战就是由于transformer的softmax计算在所有token对上，很难处理长文本。\n\n Transform-XL(eXtra Long) 通过将更长的文本(多段落文档) 分解成文本段序列  $\\lbrace X_1,...,X_r,...,X_{\\zeta} \\rbrace$ 来解决。\n\n使用如下的公式计算在相邻文本段之间传播信息：\n$$\n\\hat H_r^{l-1} = [cat(Freeze(H_{r-1}^{l-1}) ,H_r^{l-1})]\n$$\n其中 $H_r^{l-1}$ 表示第 r 个文本段的第 $l-1$ 层Transformer表达。\n\n新注意力机制中的 $Q,K,V$ 就表达为：\n$$\n\\hat Q^T; \\hat K^T; \\hat V^T =  W^q\\cdot \\hat H^{l-1}_r; W^k\\cdot \\hat H^{l-1}_r; W^v \\cdot \\hat H^{l-1}_r\n$$\n之后就还是送到缩放点积中。这一点处理长文本可能是参考了TransformerXL。\n\n> Transformer-XL 的重要组件之一，**Segment Recurrence Mechanism（段循环机制）**想做的就是，能不能在前一段计算完后，将它计算出的隐状态都保存下来，存到一个 Memeory 中，之后在计算当前段的时候，**将之前存下来的隐状态和当前段的隐状态拼起来，作为 Attention 机制的 K 和 V，从而获得更长的上下文信息**\n\n![](https://i.loli.net/2021/06/10/5zH2Avr7IiXOl6d.png)\n\n然而，在许多情况下，文本段被组织在线性序列之外的结构中。例如，文档由图形结构中的超链接连接，这种图形结构不容易简化为形成线性序列，从而禁止了Transformer-XL的递归方法。\n\n\n\n下面将引出eXtra Hop attention 如下图\n\n![](https://i.loli.net/2021/06/10/lZicWgnPv4L1dz9.png)\n\n\n\n图a 表示 三个链接的文档 $d_2,d_1,d_3$ . Transform-XH使用eXtra Hop attention沿图形边缘传播信息，从而在连接的文本序列之间实现信息共享。\n\n结构化文本包含一些列节点 $ X =\\lbrace X_1,...,X_r,...X_{\\zeta} \\rbrace$ , 对应于一个文本序列。 \n\n目标是生产表达 $X =\\lbrace \\hat H_1,...,\\hat H_r,...\\hat H_{\\zeta} \\rbrace$  ，其不仅合并了每个序列 $X$ 中的本地信息，而且还合并了关于整个结构化文本 ${X，E}$的全局上下文。\n\nTransform-XH通过两种注意机制来实现这一点：in-sequence attention 和 eXtra Hop attention。\n\nin-sequence attention 和 Transformer一样， 在 $l$ 层，第 $i$ 个token 收集从同一文本段τ内的其他 token 的信息：\n$$\nh_{r,i}^l = \\sum_j softmax_j (\\frac {q_{r,i}^T \\cdot k_{r,j}}{ \\sqrt d_k}) \\cdot v_{r,j}\n$$\neXtra Hop attention, 使用第 CLS token 作为 attention hub ，在 $l$ 层，第 $\\tau$ 个文本序列，如果 $τ$ 文本序列与另一个文本序列η之间存在边( $e_{τη}=1 $) :\n$$\n\\hat h_{r,0}^l = \\sum_{\\eta ; e_{r\\eta}=1} softmax_{\\eta} (\\frac {\\hat q_{r,0}^T \\cdot \\hat k_{\\eta,0}}{\\sqrt d_k}) \\cdot \\hat v_{\\eta,0}\n$$\n节点 $τ$  使用hop query $\\hat q_{r,0}$ 和 key $\\hat k_{\\eta, 0}$ 计算其邻居 $η$ 上的关注度权重，然后乘以邻居的value $\\hat v_{\\eta,0}$ ，最后将两个注意力机制聚合起来得到新的 $l$ 层的表达:\n\n\n$$\n\\begin{equation}\\begin{split} \n \\hat h_{r,0}^l &= Linear(cat[h_{r,0}^l, \\hat h_{r,0}^l ])\\\\\n \\hat h_{r,i}^l &= h^l_{r,i} ; \\forall i \\ne 0\n    \\end{split}\\end{equation}\n$$\n$ i \\ne 0$ 是 non-hub tokens \n\n一层 eXtra Hop attention 可视为沿着边 E 信息传递的 single-step \n\n例如，在图a中，文档节点 $d_3$ 通过使用hop attention ,  $d_1→d_3$ 从其邻居d1收集信息来更新其表示。当多个Transformer-xh层被堆叠时，$d_1$ 中的该信息包括来自其in-sequence attention 的 $d_1$的本地上下文，以及来自 $ l-1$ 层的 hop attention ，$d_2−d_1$ 的交叉序列信息。因此，L 层 Transformer-XH可以处理最多 L 跳以外的信息。\n\n总之 Transformer-XH共有三个主要属性，可对原始结构化文本数据进行有效建模：\n\n- 信息沿边的传播\n- 信息的重要性 (hop attention)\n- 序列内和跨序列信息的平衡 (attention combination)\n\n在 $H$ 中学习的表示可以天生地表达结构化文本中的细微差别，这些细微差别是复杂的推理任务(如多跳QA和自然语言推理)所需的。\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["GNN&nlp"]},{"title":"旋转数组的最小数字&搜索旋转排序数组","url":"/2021/06/07/旋转数组的最小数字-搜索旋转排序数组/","content":"\n# 旋转数组的最小数字&搜索旋转排序数组\n\n\n\n## 旋转数组最小数字\n\n### 题目\n\n把一个数组最开始的若干个元素搬到数组的末尾，我们称之为数组的旋转。\n\n输入一个升序的数组的一个旋转，输出旋转数组的最小元素。\n\n例如数组 {3,4,5,1,2}{3,4,5,1,2} 为 {1,2,3,4,5}{1,2,3,4,5} 的一个旋转，该数组的最小值为 11。\n\n数组可能包含重复项。\n\n**注意**：数组内所含元素非负，若数组大小为 00，请返回 −1−1。\n\n样例\n\n```\n输入：nums = [2, 2, 2, 0, 1]\n\n输出：0\n```\n\n### 解法：二分查找\n\n题目中有排序两字，自然较优的解是涉及到二分法的\n\n假设我们用下图表示数组，水平线代表数字相同，横坐标代表数字下标\n\n![](https://i.loli.net/2021/06/07/iFZJBWC4teHIxKR.png)\n\n我们发现除了最后水平的一段（黑色水平那段）之外，其余部分满足二分性质：\n\n竖直虚线左边的数满足 $numbers[i] ≥ numbers[0]$ ；\n\n而竖直虚线右边的数不满足这个条件。\n\n我们要找的便是不满足上诉性质的那段中的最小值。\n\n所以我们先将最后水平的一段删除 , 使得右半段不满足 $numbers[i] ≥ numbers[0]$ ，而是严格满足 $numbers[i] < numbers[0]$。\n\n另外，如果处理数组完全单调的情况：\n\n当删除最后一段后，如果剩下的最后一个大于等一第一个数，说明数组完全单调。\n\n```java\nclass Solution {\n    public int findMin(int[] numbers) {\n        if(numbers == null || numbers.length==0) return -1;\n        int left=0;\n        int right = numbers.length-1;\n        // 去除第二段有序数组中最后的和第一段第一个数相同的数\n        // 使得第二段有序数组严格满足numbers[i]<numbers[0]\n        while(right>0 && numbers[right]==numbers[0]){\n            right--;\n        }\n        // 如果此时整个数组都有序了，那么numbers[0]就是最小值\n        if(numbers[0] < numbers[right]){\n            return numbers[0];\n        }\n        \n        while(left<right){\n            int mid = left+right>>1;\n            if(numbers[mid] < numbers[0]){ // 说明mid落在了右半段，最小值在[left,mid]里\n                right = mid;\n            }else{\n                left = mid +1;\n            }\n        }\n        return numbers[left];\n    }\n}\n```\n\n## 搜索旋转数组\n\n![](https://i.loli.net/2021/06/07/wMJ9hGK68eZspRy.png)\n\n数组旋转后可画出如下图：\n\n![](https://i.loli.net/2021/06/07/zudQlKM7UBmpbhq.png)\n\n橙色线表示的就是旋转后数组的左右两个部分。不难发现，如果下标落在右半部分，则一定有 $nums[mid] <= nums[nums.length-1]$\n\n判断 $nums[mid] <= nums[nums.length-1]$ 是否成立\n\n- 成立：说明当前mid落在了数组的右半部分，而我们要找的最小值其实就是右半部分的开头，故更新区间为 $[l,mid]$ 。\n- 否则：说明mid落在了旋转数组的左半部分，那么右半部分的起点则在 $[mid+1, r]$\n\n总之，要找满足 $nums[mid] <= nums[nums.length-1]$ 的最小值\n\n\n\n第二阶段\n\n找到最小值后，假如最小值的下标是 min ，数组便可以分为有序的两半 $[l, min-1]$  和 $[min, r]$  此时判断 $target<=nums[nums.length-1]$  。\n\n若成立，可以再右半部分中找target，因为target如果在右半部分的话，一定大于 $nums[nums.length-1]$， 那么久应该去左半边 $[l, min-1]$ 中找 target\n\n```java\nclass Solution {\n    public int search(int[] nums, int target) {\n        if(nums==null || nums.length==0) return -1;\n        //1,找出数组中的最小值,即左右两边的分界点，便可以将数组分为有序的左右两边\n        //2,判断target <= nums[nums.length - 1]是否成立\n        //  成立：target在旋转后的右半边\n        //  不成立：target在旋转数组的左半边\n        int l =0 ;\n        int r = nums.length-1;\n        while(r>0 && nums[r]==nums[0]){\n            r--;\n        }\n\n        while(l<r){\n            int mid = l+r >>1;\n            if(nums[mid] <= nums[nums.length-1]){\n                r=mid;\n            }else{\n                l=mid+1;\n            }\n        }\n        //上面while结束后，l = r，都指向旋转数组中的最小值\n        if(target<=nums[nums.length-1]){\n            // target在右边， l本身就是指向右边起点的，不用更新，更新r为右边终点。\n            r = nums.length-1;\n        }else{\n            //target在左半边\n            l = 0;//左半边的起点\n            r--;//让r指向最小值的前一个位置，即左半边的终点\n        }\n        //定好了区间[l,r]后，可以在里面找target了\n        //使用二分模板即可，找满足nums[mid] >= target的最小值\n        while(l<r){\n            int mid = l+r>>1;\n            if(nums[mid] >= target){\n                r=mid;\n            }else{\n                l=mid+1;\n            }\n        }\n        // 判断最终找到的num[l]是否等于target\n        if(nums[l] == target) return l;\n        return -1;\n\n\n    }\n}\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["刷题"]},{"title":"GRAPH-BERT: Only Attention is Needed for Learning Graph Representations","url":"/2021/06/04/GRAPH-BERT-Only-Attention-is-Needed-for-Learning-Graph-Representations/","content":"\n# GRAPH-BERT: Only Attention is Needed for Learning Graph Representations\n\n当前GNNs的主要方法是过度依赖图中的连接关系，这样造成了三大问题。\n\n1. 模型假死 (*suspended animation problem*) : 随着神经网络层数的不断加深，模型对于输入的数据开始不进行反应。这个问题的原因论文没写，个人理解是由于层之间的非线性使得数据分布变换导致梯度消失。\n2. 过平滑 (*over-smoothing problem*) : 由于GNN大多依靠聚合操作 (mean,max,sum) 的信息更新方式，这样随着层的不断堆叠，每个节点都会大量收到其他信息节点的影响，从而使得每个节点的embedding预测趋同。\n3. 难以并行计算：由于内存的限制，尤其是在大型图里面，图中的关联关系难以并行计算。\n\n根据以上问题作者提出了一种新的图神经网络，即Graph-Based BERT，它完全基于注意力机制，不需要任何图卷积或聚集操作。\n\n在模型输入部分，不会把一整个大图输入给模型，而是先采样得到大图的一些无边子图，只是抽取子节点，而不考虑这些节点之间的边关系。这样就解决了GNN不能并行的问题。\n\n传统GNN由于图的结构多样性，不能进行跨任务的预训练工作，但Graph-Bert不考虑边之间的联系，因此并不受限于图结构，可以很好地进行预训练和迁移学习。\n\n$$\ne_j^{(r)} = \\left[ sin(\\frac {WL(v_j)}{10000^{\\frac{2l}{d_h}}}) , cos(\\frac {WL(v_j)}{10000^{\\frac{2l+1}{d_h}}}) \\right]_{l=0}^{[\\frac {d_h}{2}]}\n$$\n\n$$\n\\begin{equation}\\begin{split} \nH^{(l)} &=  \\mathrm{G\\text{-}Transformer}(H^{(l-1)})\\\\ \n&=\\mathrm{softmax}(\\frac{QK^T}{\\sqrt d_h})V + \\mathrm{G\\text{-}Res}(H^{(l-1)},X_i)+ \\mathrm{features...}\n    \\end{split}\\end{equation}\n$$\n\n$$\n\\begin{equation}\\begin{split} \n H^{(l)} &=  \\mathrm{G\\text{-}Transformer}(H^{(l-1)})\\\\ \n&=\\mathrm{softmax}(\\frac{QK^T}{\\sqrt d_h})V + \\mathrm{features...}\n    \\end{split}\\end{equation}\n$$\n\n## Method\n\n### 符号定义\n\n\n\n\n\n![](https://i.loli.net/2021/06/04/lRKbH2Aa71m3peP.png)\n\n### 无边子图采样\n\n\n\n\n\n### 输入节点向量Embedding\n\n\n\n\n\n#### 原始特征embedding\n\n\n\n#### Weisfeiler-Lehman 绝对角色 Embedding\n\n\n\n#### 基于亲密度的相对位置Embedding\n\n\n\n#### 基于相对距离的Hop Embedding\n\n\n\n### Graph Transformer Encoder\n\n\n\n### 预训练任务\n\n\n\n#### 节点原始属性重构\n\n\n\n\n#### 图结构恢复\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["GNN&nlp"]},{"title":"Attention","url":"/2021/05/31/Attention/","content":"\n# 从RNN到LSTM到Transformer再到GNN\n\n\n\n## RNN\n\n\n\n\n\n\n\n## LSTM\n\n\n\n\n\n\n\n## Attention\n\n### 单头注意力\n\n![](https://i.loli.net/2021/05/31/PkepyKTAUWOI3wB.png)\n\n将句子 $S$ 中第 $i$ 个词的隐藏特征 $h$ 从 $l$ 层更新到 $l+1$ 层 :\n$$\n\\begin{equation}\\begin{split} \n h^{l+1}_i &= Attention(Q^lh_i^l, K^lh_j^l, V^lh_j^l)\\\\\n i.e., \\ h_i^{l+1} &= \\sum_{j\\in S} softmax_j(Q^lh^l_i,K^lh_j^l)\n    \\end{split}\\end{equation}\n$$\n$Q^l, K^l , V^l$ 是可学习的线性权重（分别表示注意力计算中的Query，Key，Value）。句子中的每个单词并行执行注意力机制，从而可以一次性获得他们已更新的特征——这是Transformer相对RNNs的另一个加分点，它使得模型能够逐字更新特征。\n\n![](https://i.loli.net/2021/05/31/vx6helFfAStIKj4.png)\n\n### 多头注意力\n\n事实证明，要让这种点积注意力机制起作用是很难的——如果随机初始化处理得不好会使得整个学习过程失去稳定性。我们可以通过并行执行多个注意力“头”并将结果连接起来（现在每个注意力头都有单独的可学习权重）来克服这个问题：\n$$\n\\begin{equation}\\begin{split} \n h^{l+1}_i &= Concat(head_1,...,head_K) O^l\\\\\n head_k &= Attention(Q^{k,l} h_i^l, \\ K^{k,l} h_j^l, \\ V^{k,l}h_j^l)\n    \\end{split}\\end{equation}\n$$\n其中， $Q^{k,l} ,K^{k,l}, V^{k,l}$ 是第 $k$ 个注意力投的可学习权重，而 $O^l$ 是一个向下的投影，可以用以匹配跨层的 $h_i^{l+1}$ 和 $h^l_i$ 的尺寸。此外多头注意力形成多个子空间，可以让模型去关注不同方面的信息。\n\n## Transformer架构\n\n![](https://i.loli.net/2021/05/31/F8obteYNsUVGpPZ.png)\n\n\n\n下面是上文的多头Attention结构，但为什么Transformer的结构为什么是这样的？\n\n注意力机制之后的词的特征可能在不同尺度或重要性上:\n\n1. 这可能是由于某些词在将其他词的特征累加时具有非常集中或非常分散的注意力权重 $w_{ij}$\n\n2. 在单个特征/向量输入级别，跨多个注意力头 (每个可能会以不同的比例输出值) 进行级联可以导致最终向量 $h_i^{l+1}$ 的输入具有一个大范围的值。遵循传统的机器学习思路，在上述流程中增加一个归一化层似乎是合理的选择。\n\n对于上面的两个问题，Transformer用LayerNorm客服了问题2，LayerNorm在特征层级上进行归一化并学习一种仿射变换。  [batchNormalization与layerNormalization的区别](https://zhuanlan.zhihu.com/p/113233908)\n\n对于问题1，通过求特征维度的平方根，来做缩放点积。\n\n在LayerNorm之后，是FF-MLP\n\n是一个控制尺度问题的技巧，具有特殊结构的考虑位置的双层MLP，在多头注意力之后，他们通过一个可学习的权重将 $h_i^{l+1}$  投影到一个更高的维度，在该维度中， $h_i^{l+1}$ 经过ReLU 非线性变换，然后投影回其原始维度，然后再进行另一个归一化操作。\n$$\nh^{l+1}_i = LN (MLP(LN(h_l^{l+1})))\n$$\n不确定超参数化前馈子层背后的确切理由是什么，似乎也没有人对此提出疑问！我认为LayerNorm和缩放的点积不能完全解决突出的问题，因此大型MLP是一种可以相互独立地重新缩放特征向量的手段。\n\nTransformer架构也非常适合非常深的网络，使NLP界能够在模型参数和扩展数据这两方面进行延伸。每个多头注意力子层和前馈子层的输入和输出之间的残差连接是堆叠Transformer层的关键（但为了清楚起见，在上图中省略了）。\n\n\n\n\n\n## GNN\n\n图神经网络（GNNs）或图卷积网络（GCNs）在图数据中建立节点和边的表示。它们是通过邻域聚合（或消息传递）来实现的，在邻域聚合中，每个节点从其邻域收集特征，以更新其周围的局部图结构表示。通过堆叠多个GNN层使得该模型可以将每个节点的特征传播到整个图中，从其邻居传播到邻居的邻居，依此类推。\n\n![](https://i.loli.net/2021/05/31/VgT8NGlDXIxLB3H.png)\n\n以这个表情符号社交网络为例：由GNN产生的节点特征可用于预测性任务，例如识别最有影响力的成员或提出潜在的联系。\n\n在他们最基本的形式中，GNNs通过以下方法来更新节点 $i$ 在 $l$ 层的隐藏层特征 $h$ 。\n\n也就是先将节点自身特征 $h_i^{l}$ 和每个邻居节点 $j \\ \\ (j\\in N(i))$  特征 $h_j^{l}$ 的聚合相加，然后在整体做一个非线性变换， 如下:\n$$\nh_i^{l+1} = \\sigma (U^{l} h_i^l + \\sum_{j\\in N(j)}(V^l h_j^l))\n$$\n其中， $U^l, V^l$ 是GNN 层的可学习权重矩阵。\n\n邻居节点 $j\\in N(i)$ 上的求和可以被其他输入大小不变的聚合函数代替，例如简单的 均值/最大值函数或其他更强大的函数（如通过注意机制的加权和）。\n\n如果是GAT的话其实就变成了Transformer了\n\n![](https://i.loli.net/2021/05/31/YRcsK5h38HoS4On.png)\n\n如果我们要执行多个并行的邻域聚合头，并且用注意力机制（即加权和）替换领域 上的求和 ，我们将获得图注意力网络（GAT）。加上归一化和前馈MLP，瞧，我们就有了Graph Transformer！\n\n\n\n### 在NLP中，句子就是由词全连接而成的图\n\n为了使连接更加清晰，可以将一个句子看作一个完全连接的图，其中每个单词都连接到其他每个单词。现在，我们可以使用GNN来为图（句子）中的每个节点（单词）构建特征，然后我们可以使用它来执行NLP任务。\n\n![](https://i.loli.net/2021/05/31/eV8aQgnZ64rsNyv.png)\n\n广义上来讲，这就是Transformers正在做的事情：Transformers是以多头注意力作为邻聚合函数的GNNs。标准GNNs从其局部邻域节点 $j\\in N(i)$ 聚合特征，而NLP的Transfors 将整个句子视为局部邻域，在每个层聚合来自每个单词 $j\\in S$的特征。 而NLP的Transformers将整个句子视为局部邻域，在每个层聚合来自每个单词 $j\\in S$ 的特征。\n\n重要的是，各种特定于问题的技巧（如位置编码、因果/掩码聚合、学习率表和大量的预训练）对于Transformers的成功至关重要，但在GNN界中却很少出现。同时，从GNN的角度看Transformers可以启发我们摆脱模型结构中的许多花哨的玩意。\n\n\n\n### 全连接图是NLP的最佳输入格式吗？\n\n在统计NLP和ML之前，Noam Chomsky等语言学家致力于发展语言结构的最新理论，如语法树/图。Tree LSTMs已经尝试过这一点，但是也许Transformers/GNNs是可以让语言理论和统计NLP的领域结合得更加紧密的更好的架构？\n\n\n\n###  **如何学习到长期依赖？**\n\n完全连通图使得学习词与词之间非常长期的依赖关系变得非常困难，这是完全连通图的另一个问题。这仅仅是因为图中的边数与节点数成二次方关系，即在n个单词的句子中，Transformer/GNN 将在 $n^2$ 上对单词进行计算，如果n很大，那将会是一个非常棘手的问题。\n\nNLP界对长序列和依赖性问题的看法很有意思，例如，使用注意力机制在输入大小方面稀疏或自适应，在每一层中添加递归或压缩，以及使用对局部性敏感的哈希法进行有效的注意，这些都是 优化Transformers 有希望的想法。\n\n有趣的是，还可以看到一些GNN界的想法被混入其中，例如使用句子图稀疏化的二进制分区似乎是另一种令人兴奋的方法。\n\n![](https://i.loli.net/2021/05/31/k1XmCxvfYMwuNIt.png)\n\n\n\n### Transformers在学习神经网络的句法吗？\n\nNLP界有几篇关于Transformers可能学到什么的有趣论文。其基本前提是，对句子中的所有词对使用注意力机制（目的是确定哪些词对最有趣），可以让Transformers学习特定任务句法之类的东西。\n\n多头注意力中的不同头也可能“关注”不同的句法属性。\n\n从图的角度来看，通过在完全图上使用GNN，我们能否从GNN在每一层执行邻域聚合的方法中恢复最重要的边线及其可能带来的影响？我还不太相信这种观点。\n\n\n\n### **为什么要用多头注意力？为什么要用注意力机制？**\n\n\n\n我更赞同多头机制的优化观点——拥有多个注意力可以改进学习，克服不好的随机初始化。例如，这些论文表明，Transformers头可以在训练后“修剪”或“删除”，并且不会产生重大的性能影响。\n\n\n\n多头邻聚合机制在GNNs中也被证明是有效的，例如在GAT使用相同的多头注意力，MoNet使用多个高斯核来聚合特征。虽然多头技巧是为了稳定注意力机制而发明的，但它能否成为提炼出额外模型性能的标准？\n\n\n\n相反，具有简单聚合函数（如sum或max）的GNNs不需要多个聚合头来维持稳定的训练。如果我们不需要计算句子中每个词对之间的成对兼容性，对Transformers来说不是很好吗？\n\n\n\nTransformers能从抛弃注意力中获益吗？Yann Dauphin和合作者最近的工作提出了另一种ConvNet架构。Transformers也可能最终会做一些类似于ConvNets的事情。\n\n![](https://i.loli.net/2021/05/31/6nlhQ2GLpBSeudq.png)\n\n\n\n### **为什么Transformers这么难训练？**\n\n阅读新的Transformer论文让我觉得，在确定最佳学习率表、预热策略和衰减设置时，训练这些模型需要一些类似于黑魔法的东西。这可能仅仅是因为模型太大，而且所研究的NLP任务非常具有挑战性。\n\n但是最近的结果表明，这也可能是由于结构中归一化和残差连接的特定组合导致的。\n\n在这一点上我很在意，但是也让我感到怀疑：我们真的需要代价昂贵的成对的多头注意力结构，超参数化的MLP子层以及复杂的学习计划吗？\n\n我们真的需要具有大量碳足迹的（译者注：有人提出现在训练一个模型相当于5辆汽车一天的排碳量）大规模模型吗？\n\n具有良好归纳偏差的架构难道不容易训练吗？\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## 参考文献\n\n[为什么说Transformer就是图神经网络？](https://zhuanlan.zhihu.com/p/110805093)\n\n\n\n","tags":["nlp"]},{"title":"Do Multi-Hop Question Answering Systems Know How to Answer the Single-Hop Sub-Questions?","url":"/2021/05/31/Do-Multi-Hop-Question-Answering-Systems-Know-How-to-Answer-the-Single-Hop-Sub-Questions/","content":"\n# Do Multi-Hop Question Answering Systems Know How to Answer the Single-Hop Sub-Questions?\n\n这是一篇比较有意思的工作，但是出发点是多跳阅读理解的本质问题。\n\n多跳QA需要一个模型来检索和整合来自多个段落的信息来回答问题，作者认为现有的评估标准，EM和F1并不能证明在多大程度上学会了多跳推理能力。\n\n所以作者根据多跳QA中的桥接实体生成了一千个相关的子问题，来测试模型的能力，并期望这样能说明一些问题。\n\n## 做法\n\n当设计一个多跳问题时，我们要求模型去检索一系列句子作为证据，然后对他们进行推理来回答问题。作者设计了一个HotpotQA干扰项集，的子问题集，期望模型如果具有了多跳的推理能力，多跳的问题可以回答的话，那么单跳问题也可以回答。但是这个单跳问题不是凭空出现的和原问题不相关的问题。如下图所示：\n\n![](https://i.loli.net/2021/05/31/YEQ2HtyLSrqU1FD.png)\n\n这是一个典型的桥接问题，问题是：罗斯为阿诺德·施瓦辛格饰演的前纽约警探主演的一部电影做宣传是在哪一年？\n\n想要回答问题，我们就必须先知道施瓦辛格在哪个电影里扮演了纽约警探，也就是必须找到桥梁实体 Gold Para2 中的电影《End of Days》才能回答。\n\n那么子问题的建立就很自然的可以分为，\n\n1、施瓦辛格正在哪个电影里扮演了纽约警探？\n\n2、罗斯在那一年为电影《End of Days》做了宣传？\n\n第一个问题的答案正好是桥梁实体，第二个问题的答案是最终答案。\n\n作者认为只有模型能够完整的回答这些问题，说明模型就具备了多跳推理能力。\n\n生成方法是半自动的：\n\n- 首先，我们通过预测断点将每个源问题分解成若干子串\n- 其次，进行post processed，生成两个子问题。使用一些启发式方法从段落中提取子问题的答案。\n- 最后，将生成的候选评价实例发送给人工验证。\n\n## 实验\n\n作者认为有些预测答案，虽然部分匹配EM=0但是语义上是正确的，也应该被算作预测正确。如下这种：\n\n![](https://i.loli.net/2021/05/31/8xBnLoPbdfKmDiI.png)\n\n新的评估标准：给定黄金答案文本跨度 $a_g$ 和预测答案文本 $a_p$，如果满足以下两个要求之一，则它们部分匹配：\n$$\nf1 > 0.8\\\\\nf1>0.6 \\land \\{(a_g\\ contains\\ a_{p} ) \\lor (a_p \\ contains \\ a_g) \\}\n$$\n$f1$ 值大于0.8，直接认为符合要求， 或者，$f1$ 大于0.6 ，且标准答案文本跨度包含了预测文本的答案或预测答案包含了标准答案。\n\n\n\nBaseline 选用开源的CogQA、DFGN、DecompRC\n\n![](https://i.loli.net/2021/05/31/FI9gEo7fLJ3UjBO.png)\n\n实验结果发现CogQA稍微好一些\n\n\n\n![](https://i.loli.net/2021/05/31/jq1aPVeZrJYBEQu.png)\n\n模型有很高的概率没有答对其中一个问题。\n\n作者将这些示例称为模型故障案例：模型故障案例在所有正确回答的多跳问题中所占的百分比被定义为模型故障率。\n\nCogQA PM下的故障率: $(6.1+16.5+3.4)/(40.9+6.1+16.5+3.4) \\times100\\% = 38.86\\%$ \n\n![](https://i.loli.net/2021/05/31/TfhW2lJBSLtbRP3.png)\n\n所评估的所有三个模型都有很高的模型失败率，这表明这些模型学会了回答复杂的问题，而没有探索推理过程的多个步骤。当使用EM和PM分数进行评估时，也会出现同样的现象。\n\n> After analyzing the model failure cases, we ob- serve a common phenomenon that there is a high similarity between the words in the second sub- question and the words near the answer in the con- text. The model has learned to answer multi-hop question by local pattern matching, instead of going through the multiple reasoning steps. For the ex- ample presented in Figure 1, the model may locate the answer “*1999*” for the multi-hop question by matching the surrounding words “ *Guns N Roses*” in the second sub-question. Despite answering the multi-hop question correctly, the model fails to identify the answer of the first sub-question which it is expected to retrieve as a multi-hop QA system.\n\n\n\n\n\n\n\n\n\n\n\n","tags":["GNN&nlp"]},{"title":"Pytorch RNN之pack_padded_sequence()和pad_packed_sequence()","url":"/2021/05/29/Pytorch-RNN之pack-padded-sequence-和pad-packed-sequence/","content":"\n# Pytorch RNN之pack_padded_sequence()和pad_packed_sequence()\n\n\n\n## 为什么有pad和pack操作？\n\n先看一个例子，这个batch中有5个sample\n\n![](https://i.loli.net/2021/05/29/AZFV4WzLUKsgpfa.png)\n\n如果不用pack和pad操作会有一个问题，什么问题呢？\n\n比如上图，句子“Yes”只有一个单词，但是padding了多余的pad符号，这样会导致LSTM对它的表示通过了非常多无用的字符，这样得到的句子表示就会有误差，更直观的如下图：\n\n![](https://i.loli.net/2021/05/29/hT5ab7rQgunimtB.png)\n\n\n\n那么我们正确的做法应该是怎么样呢？\n\n在上面这个例子，我们想要得到的表示仅仅是LSTM过完单词\"Yes\"之后的表示，而不是通过了多个无用的“Pad”得到的表示：如下图：\n\n![](https://i.loli.net/2021/05/29/9efQa4sVrN8ulFd.png)\n\n\n\n\n\n## torch.nn.utils.rnn.pack_padded_sequence()\n\n这里的`pack`，理解成压紧比较好。 将一个 填充过的变长序列 压紧。（填充时候，会有冗余，所以压紧一下）\n\n其中pack的过程为：（注意pack的形式，不是按行压，而是按列压）\n\n![](https://i.loli.net/2021/05/29/KTaQHmkbOIC3h8x.png)\n\n​                                      （下面方框内为`PackedSequence`对象，由data和batch_sizes组成）\n\npack之后，原来填充的 PAD（一般初始化为0）占位符被删掉了。\n\n输入的形状可以是(T×B×* )。`T`是最长序列长度，`B`是`batch size`，`*`代表任意维度(可以是0)。如果`batch_first=True`的话，那么相应的 `input size` 就是 `(B×T×*)`。\n\n`Variable`中保存的序列，应该按序列长度的长短排序，长的在前，短的在后。即`input[:,0]`代表的是最长的序列，`input[:, B-1]`保存的是最短的序列。\n\n> `NOTE：` 只要是维度大于等于2的`input`都可以作为这个函数的参数。你可以用它来打包`labels`，然后用`RNN`的输出和打包后的`labels`来计算`loss`。通过`PackedSequence`对象的`.data`属性可以获取 `Variable`。\n\n参数说明:\n\n- input (Variable) – 变长序列 被填充后的 batch\n- lengths (list[int]) – `Variable` 中 每个序列的长度。\n- batch_first (bool, optional) – 如果是`True`，input的形状应该是`B*T*size`。\n\n返回值:\n\n一个`PackedSequence` 对象。\n\n## torch.nn.utils.rnn.pad_packed_sequence()\n\n填充`packed_sequence`。\n\n上面提到的函数的功能是将一个填充后的变长序列压紧。 这个操作和pack_padded_sequence()是相反的。把压紧的序列再填充回来。填充时会初始化为0。\n\n返回的Varaible的值的`size`是 `T×B×*`, `T` 是最长序列的长度，`B` 是 batch_size,如果 `batch_first=True`,那么返回值是`B×T×*`。\n\nBatch中的元素将会以它们长度的逆序排列。\n\n参数说明:\n\n- sequence (PackedSequence) – 将要被填充的 batch\n- batch_first (bool, optional) – 如果为True，返回的数据的格式为 `B×T×*`。\n\n返回值: 一个tuple，包含被填充后的序列，和batch中序列的长度列表\n\n## 例子\n\n![](https://i.loli.net/2021/05/29/ok9UMKLO5RYAlWP.png)\n\n![](https://i.loli.net/2021/05/29/rkuqZlphAoPFyi7.png)\n\n此时PackedSequence对象输入RNN后，输出RNN的还是PackedSequence对象 \n\n## 参考\n\nhttps://www.cnblogs.com/lindaxin/p/8052043.html\n\nhttps://pytorch.org/docs/stable/nn.html?highlight=pack_padded_sequence#torch.nn.utils.rnn.pack_padded_sequence\n\nhttps://zhuanlan.zhihu.com/p/34418001?edition=yidianzixun&utm_source=yidianzixun&yidian_docid=0IVwLf60\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["pytorch"]},{"title":"Multi-hop Attention Graph Neural Networks","url":"/2021/05/27/Multi-hop-Attention-Graph-Neural-Networks/","content":"\n# Multi-hop Attention Graph Neural Networks\n\nGAT中的attention运算只能关注节点相连节点表达，这种机制不考虑不直接相连但又有很重要信息的节点表达。\n\n所以提出了多跳注意力图神经网络(MAGNA)，这是一种将多跳上下文信息融入到注意力计算的每一层的方法。\n\n其将注意力分数分散到整个网络，相当于增加了每一层的GNN的“感受野”。\n\n![](https://i.loli.net/2021/05/27/xCrtn9LhXwiZ7sK.png)\n\n如左图，考虑A和D节点，普通的attention层只计算直接相连节点的注意力分数，如 $ \\alpha_{A,D} $   , 但如果C的信息很重要，   $ \\alpha_{C,D}=0 $  关注度却为0。并且，单个GAT层中A和D节点之间的运算只依赖于自己的表达，而不依赖于它们的图邻域上下文。其相当于每一层只关注了一阶邻居范围的感受野，虽然堆叠多层GNN可以扩大这个范围，但GNN层数一多就会有过平滑的问题。\n\n再看右图，MAGNA 层的改进方法是\n\n- 通过扩散多跳注意力捕捉  $ \\alpha_{D,C}' $  表达为  $ \\alpha_{D,C}' = f([\\alpha_{B,C},\\alpha_{D,B}]) $\n- 基于图邻接矩阵的权值，通过分散注意力来考虑节点之间的所有路径，从而增强图结构学习。MAGNA利用D的节点特征进行A和B之间的注意力计算，这意味着MAGNA中的两跳注意力是基于上下文的。\n\n总之，GAT中的一跳注意机制限制了探索更广泛的图形结构与注意权重之间关系的能力。\n\n\n\n本文提出了多跳注意图神经网络(MAGNA)，这是一种针对图结构数据的有效的多跳自注意机制。Magna使用了一种新颖的图形注意力扩散层(图1)，其中我们首先计算边上的注意力权重(用实心箭头表示)，然后使用边上的注意力权重通过注意力扩散过程计算断开的节点对之间的自我注意力权重(虚线箭头)。\n\n## 方法\n\n\n\n### 参数定义\n\n图 $G =(V,E)$ , $E\\in V\\times V$ ,  V 节点集有 $N_n$ 个 ，E 边集有 $N_e$ 个\n\n节点 v 到其类型的映射为 $ \\phi: V \\rightarrow \\Tau $ , 边e 到其关系类型的映射 $\\psi : E \\rightarrow R$\n\n节点的embedding : $X \\in \\mathbb{R}^{N_n\\times d_n}$ , 边的embedding: $R\\in \\mathbb{R}^{N_r\\times d_r}$\n\n其中 $N_n = |V|, N_r=|R|$ , $d_n,d_r$ 是节点和边类型的embedding维度。\n\nEmbedding 的每行 $x_i = X[i:]$ 表示节点 $v_i (1\\le i\\le N_n)$ 的embedding ， $r_j=R[j:] ,  r_j(1\\le j\\le N_r)$  \n\n首先看一下MAGNA 模块的整体结构\n\n![](https://i.loli.net/2021/05/27/sd32RDYOLyvK64l.png)\n\n有点像Transformer block，现在GNN的包装越来越往Transformer based模型上靠了。\n\n他传入节点和关系embedding，会首先经历一个对于每个节点的多头注意力层（这里和GAT一样），然后是注意力扩散、 Layer Norm、前向传播层和两个残差链接。\n\n \n\n\n\n### Multi-hop Attention Diffusion\n\nAttention diffusion是每一层中用于计算MAGNA‘s的attention分数。首先第一阶段，计算每一条边上的attention分数。第二阶段，用扩散注意力计算多条邻居的注意力。\n\n#### Edge Attention Computation.\n\n在每一层 $l$ 处，为每个三元组 $(v_i，r_k，v_j)$ 计算矢量消息。 为了计算在 $l+1$ 层的表示，将关联的三元组的所有消息聚合成一条消息，然后使用该消息更新 $v_j^{l+1}$。\n\n在第一阶段， 一个边 $(v_i,r_k,v_j)$ 的注意力分数是由以下计算而来：\n$$\ns_{i,k,j}^{(l)} = LeakyRelu(v_a^{(l)} tanh(W_h^{(l)} h_i^{(l)} || W_t^{(l)}h_j^{(l)} || W_r^{(l)}r_k))\n$$\n$ W_h^{(l)} , W_t^{(l)}\\in \\mathbb{R}^{d^{(l)}\\times d^{(l)}} , W_r^{(l)}\\in \\mathbb{R}^{d^{(l)}\\times d_r} , v_a^{(l)}\\in \\mathbb{R }^{1\\times 3d^{(l)}}$   可共享的可训练参数。\n\n$h_i^{(l)}\\in \\mathbb{R}^{d^{(l)}}$ 是第 $l$ 层第 $i$ 个节点的embedding。 $h_i^{(0)} = x_i$\n\n$r_k (1\\le k \\le N_r)$ 是可训练的第 $k$ 个关系类型的embedding\n\n将上式应用到graph中的每一条边后，得到 attention score matrix $ S^{(l)}$:\n$$\nS^{(l)}_{i,j} =\n\\begin{cases}\ns_{i,j,k}^{(l)}, &\\ (v_i,r_k,v_j)\\ appears\\ in\\ G\\\\\n\\infty, &otherwise\n\\end{cases}\n$$\n随后，我们通过对得分矩阵 $S^{(l)}$ 执行逐行Softmax来获得注意力矩阵 $A^{(l)}_{i,j} = Softamax(S^{(l)})$\n\n$A^{(l)}_{i,j}$ 就定义为在第 $l$ 层中当 从节点 $j$ 和 节点 $i$ 聚合消息时的关注值。\n\n这里其实和GAT差不多 只是多了不同种边和节点。 \n\n#### Attention Diffusion for Multi-hop Neighbors\n\n通过以下注意力扩散过程，在网络中将计算不直接连接的节点之间的注意力。\n\n该过程基于1-hop 注意力矩阵A的幂 为：\n$$\nA = \\sum^{\\infty}_{i=0}\\theta_iA^i \\ \\ \\ \nwhere \\sum_{i=0}^{\\infty}\\theta_i = 1 \\ and \\ \\theta_i \\gt 0\n$$\n其中 $\\theta_i$ 是 attention decay factor 并且 $\\theta_i \\gt \\theta_{i+1}$ ，\n\n注意矩阵的幂 $A^i$ 给出了从节点 $h$ 到节点 $t$ 的长度为 $i$ 的关系路径的数量，从而增加了注意的感受野。\n\n重要的是，该机制允许两个节点之间的注意力不仅取决于它们之前的层表示，而且还考虑到节点之间的路径，从而有效地在不直接连接的节点之间创建 attention shotcuts\n\n在实现过程中，作者使用几何分布 (geometric distribution)    $θ_i=α(1−α)^i$，其中 $α∈(0，1]$  。\n\n该选择基于the inductive bias ，即较远的节点在消息聚合中应该被较小的权重，并且具有到目标节点的不同关系路径长度的节点以独立的方式被顺序加权。\n\n此外，请注意，如果定义$θ_0=α∈(0，1] ，A_0=I$ ，则上面的公式。利用关注矩阵A和移动概率 $α$ ，给出了图上的[Personal Page Rank](https://blog.csdn.net/likeyou1314918273/article/details/106895794/)。因此，扩散注意力权重 $A_{i,j}$ 可以看作是节点 $j$ 对节点 $i$ 的影响。 \n\n同时对与目标节点关系路径长度不同的节点权重应该相互独立。因此，本文定义了基于特征聚合的graph attention diffusion：\n$$\nAttDiff(G,H^{(l)}, \\Theta) = A H^{(l)}\n$$\n 其中 $\\Theta$ 为注意力参数集合。 \n\n#### Approximate Computation for Attention Diffusio\n\n对于大图，公式（3）的计算开销巨大，而DAGCN需要通过 $AH^l$进行信息聚合，本文通过定义一个数列 $Z^K$, 当 $K \\rightarrow \\infty$时，该数列能收敛到$AH^l$的值：\n$$\nZ^0 = H^L, Z^{k+1} = (1-\\alpha)AZ^{(k)} + \\alpha Z^0 \\\\\nlim_{K\\rightarrow \\infty} Z^{K} = AH^{l}\n$$\n证明请参考原文。上述的近似使得attention的复杂度保持在$O(|E|)$。很多真实世界网络具有小世界（small-world ）特征，在这种情况下，较小的K值就足够。对于具有较大直径的图，选择较大的K和较小 $\\alpha$ 。\n\n\n\n### Multi-hop Attention based GNN Architecture\n\n图2提供了可多次堆叠的MAGNA block 的架构概览。\n\n#### Multi-head Graph Attention Diffusion Layer\n\n在不同的视角联合关注来自不同表示子空间的信息。\n$$\n\\begin{equation}\\begin{split} \n \\hat H^{(l)} &= MultiHead(G, \\hat H^{(l)}) =(||_{i=1}^M head_i) W_o \\\\\nhead_i &=  AttDiff(G, \\hat H^{(l)}, \\Theta_i) \\\\\n\\hat H^{(l)} &= LayerNorm(H^{(l)})\n    \\end{split}\\end{equation}\n$$\n方程中以递归的方式计算注意力扩散。增加了层归一化，有助于稳定递归计算过程。\n\n#### Deep Aggregation\n\n此外，还包含一个完全连接的前馈子层，它由两层前馈网络组成。我们还在两个子层中添加了层标准化和残差连接，从而为每个block提供了更具表现力的聚合步骤\n$$\n\\begin{equation}\\begin{split} \n \\hat H^{(l+1)} &= \\hat H^{(l)} + H^{(l)} \\\\\n H^{(l+1)} &= W_2^{(l)} ReLU(W_1^{(l)} LayerNorm(\\hat H^{(l+1)})) + \\hat H^{(l+1)}\n    \\end{split}\\end{equation}\n$$\n\n\n## 实验\n\n![](https://i.loli.net/2021/05/28/rVp3kq5IsGweYgR.png)\n\n\n\n![](https://i.loli.net/2021/05/28/ZzVJehsHGlPoFiY.png)\n\n\n\n## Reviewer\n\n> The central question of the reviewers' discussion was whether the contribution of this paper was significant enough or too incremental. The discussion emphasized relevant literature which already considers multi-hop attention (e.g. https://openreview.net/forum?id=rkKvBAiiz [Cucurull et al.], https://ieeexplore.ieee.org/document/8683050 [Feng et al.], https://arxiv.org/abs/2001.07620 [Isufi et al.]), and which should have served as baseline. In particular, the experiment suggested by R3 was in line with some of these previous works, which consider \"a multi-hop adjacency matrix \" as a way to increase the GAT's receptive field. This was as opposed to preserving the 1-hop adjacency matrix used in the original GAT and stacking multiple layers to enlarge the receptive field, which as noted by the authors, may result in over-smoothed node features. The reviewers acknowledged that there is indeed as slight difference between the formulation proposed in the paper and the one in e.g. [Cucurull et al.]. The difference consists in calculating attention and then computing the powers with a decay factor vs. increasing the receptive field first by using powers of the adjacency matrix and then computing attention. Still, the multi-hop GAT baseline of [Cucurull et al.] could be extended to use a multi-hop adjacency matrix computed with the diffusion process from [Klicpera 2019], as suggested by R3. In light of these works and the above-mentioned missing baselines, the reviewers agreed that the contribution may be viewed as rather incremental (combining multi-hop graph attention with graph diffusion). The discussion also highlighted the potential of the presented spectral analysis, which could be strengthened by developing new insights in order to become a stronger contribution (see R2's suggestions).\n\n>Proposed methodology being more powerful than GAT is arguable:\n>When the attention scores for indirectly connected neighbors are still computed based on the immediate neighbors' attention scores, it is not convincing enough to be argued as more powerful than GAT, which learns attention scores over contextualized immediate neighbors.Also, the approximate realization of the model described in Eqn: 5 follows a message-passing style to propagate attention scores. Suppose it is to be argued that standard message-passing-based diffusion is not powerful enough to get a good immediate neighbor representation that encodes neighbors' information from far away. In that case, it is not immediately clear how a similar diffusion, when used for propagating attention scores from immediate neighbors to neighbors multiple hops away, will be more powerful. \n\n\n\n","tags":["GNN"]},{"title":"GCC: Graph Contrastive Coding for Graph Neural Network Pre-Training","url":"/2021/05/24/GCC-Graph-Contrastive-Coding-for-Graph-Neural-Network-Pre-Training/","content":"\n# GCC: Graph Contrastive Coding for Graph Neural Network Pre-Training\n\n一个自监督的利用对比学习来学习GNN内在可迁移的先验知识的预训练框架，目的是想得到一个可迁移性强，迁移领域广的，通用的表达。为了捕捉跨多个网络的通用网络拓扑特性，预训练任务为，跨网络子图实例判别。所以预训练的重点在结构相似性层面上，并且不带节点属性。\n\n\n\n## 基本思想\n\n基本思想是对输入图中的实例进行采样，将每个实例视为自己的一个不同的类，并学习对这些实例进行编码和区分。\n\n具体地说，作者认为GCC需要回答三个问题，才能学习到可转移性好的结构模式：\n\n- 实例是什么？\n- 分辨规则是什么？\n- 如何对实例进行编码？\n\n对于者三个问题作者展开研究。\n\n## 预训练任务——子图实例判别\n\n任务的目标是根据顶点的局部结构来区分它们。\n\n![](https://i.loli.net/2021/05/24/vH3s8Rm45liJPxh.png)\n\n对于每个顶点，从它的多跳ego网络中抽取子图作为实例。\n\nGCC的目的是区分从某个顶点采样的子图和从其他顶点采样的子图。并且不假设顶点和子图来自同一个图，所以图编码器被迫捕获不同输入图的通用模式。\n\n\n\n### 定义子图实例\n\n对比学习框架的成功很大程度上取决于数据实例的定义。CV和NLP任务可以直接将实例定义为图像或句子。\n\n 但是，这些想法不能直接扩展到图形数据，因为图形中的实例没有明确定义。\n\n因为节点是无属性的节点，所以要表示一个节点，就要采用以他为中心的局部结构。\n\n具体地说，对于某个顶点v，定义一个实例为它的r-ego网络：\n\n对于一个 r-ego 网络 $G = (V,E)$ ，$V$ 是节点集并且 $E \\subseteq V\\times V$\n\n对于其中心点v， 他的 r-neighbors 定义为 $S_v=\\{u:d(u,v)\\le r\\}$ , 其中 $d(u,v)$ 为邻居u节点到v节点的最短路径。\n\n顶点v的r-ego图，记为 $G_v$，是由 $S_v$ 引出的子图。 下图就是一个2-ege图，右边是预训练过程。\n\n![](https://i.loli.net/2021/05/25/Epkna1vfKVIU4hG.png)\n\n### 定义实例相似性判别准则\n\n在cv中，同一图像的两个随机数据增加(例如，随机裁剪、随机调整大小、随机颜色抖动、随机翻转等)被视为相似的实例对。\n\n在GCC中将同一r-ego网络的两个随机数据扩充看作一个相似实例对，并将数据扩充定义为图采样。\n\nGCC的图采样遵循三个步骤\n\n- 重新启动的随机行走(RWR) ：从ego图的节点v出发，随机采样子图结构，并以一定概率返回到v节点。得到的采样子图可以被认为是一种数据扩增，像cv那样。\n- 子图归纳：导出子图随机游走抽样(ISRW)。\n- 匿名化：匿名化被采样的子图 $\\hat G_v$ ,并重新排序。\n\n\n\n### 定义图编码器\n\n给定两个采样子图 $x^q$ 和 $x^k$，GCC分别通过两个图神经网络编码器 $f_q$ 和 $f_k$ 对其进行编码。从技术上讲，任何图神经网络都可以作为这里的编码器，而GCC模型对不同的选择并不敏感。因为不考虑节点属性，而大多数GNN模型需要把节点特征/属性作为输入。为了弥补这一差距，作者建议利用每个采样子图的图结构来初始化顶点特征。\n\n目标Loss采用对比学习经典的InfoNCE:\n$$\nL = -log \\frac{exp(q^Tk_+/\\tau)}{\\sum_{i=0}^K exp(q^Tk_i/\\tau)}\n$$\n其中 $q = f_q(x^q) , k=f_k(x^k)$ ，$q$ 是query 对应的目录为 $K+1$ 个编码的keys: $\\{k_0,...,k_K\\}$\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["GNN"]},{"title":"Leetcode63_DP走方格","url":"/2021/05/23/Leetcode63-DP走方格/","content":"\n# Leetcode63_DP走方格\n\n题目：https://leetcode-cn.com/problems/unique-paths-ii/\n\n## 状态定义\n\n$dp[i][j]$ 表示走到格子 $(i,j)$ 的路径数\n\n## 状态计算\n\n如果网格 $(i,j)$ 上有障碍物，则 $dp[i][j]$ 值为0，走到这个格子的方法数为0\n\n否则网格 $(i,j)$ 可以从网格 $(i-1,j)$ 或者网格 $(i,j-1)$ 走过来，因此走到该格子的方法数为走到网格 $\n(i-1,j)$ 和网格$(i,j-1)$ 的方法数之和，即: $dp[i,j] = dp[i-1,j] + dp[i,j-1]$\n$$\ndp[i][j] = \n\\begin{cases}\ndp[i-1,j] + dp[i,j-1], & \\text{(i,j) 上无障碍物}  \\\\\n0, & \\text{(i,j)上有障碍物}\n\\end{cases}\n$$\n\n## 初始条件\n\n第 1 列的格子只有从其上边格子走过去这一种走法，因此初始化 $dp[i][0]$ 值为 1，存在障碍物时为 0；\n\n第一行的格子只有从其左边格子走过去这一种走法，因此初始化$dp[0][j]$ 值为1，存在障碍物事为0；\n\n```java\nint[][] dp = new int[m][n];\nfor (int i = 0; i < m && obstacleGrid[i][0] == 0; i++) {\n    dp[i][0] = 1;\n}\nfor (int j = 0; j < n && obstacleGrid[0][j] == 0; j++) {\n    dp[0][j] = 1;\n}\n\n```\n\n## 具体实现\n\n```java\npublic int uniquePathWithObstacles(int[][] grid){\n  \tif (obstacleGrid == null || obstacleGrid.length == 0) {\n       return 0;\n    }\n\t\tint m=grid.length;\n  \tint n=grid[0].length;\n  \t\n  \tint[][] dp=new int[m][n];\n  \tfor(int i=0;i<m && grid==0;i++){\n       dp[i][0] = 1;\n    }\n  \tfor(int i=0;i<n && grid==0;i++){\n      \tdp[0][j] = 1;\n    }\n  \n  \tfor(int i=1;i<m;i++){\n      \tfor(int j=1;j<n;j++){\n          if(grid[i][j]==0){\n            dp[i][j] = dp[i-1][j] + dp[i][j-1];\n          }\n        }\n    }\n  return dp[m-1][n-1];\n}\n```\n\n同理没有障碍物就删掉判断条件。\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["DP"]},{"title":"Dynamically Fused Graph Network for Multi-hop Reasoning","url":"/2021/05/22/Dynamically-Fused-Graph-Network-for-Multi-hop-Reasoning/","content":"\n# Dynamically Fused Graph Network for Multi-hop Reasoning\n\n受人类分步推理行为的启发，提出了动态融合图网络(DFGN)，回答那些需要多个分散证据并在这些证据上进行推理的问题。不依赖于任何额外的预定义知识基础，能回答开放领域中的问题。\n\n## 大体过程\n\n![](https://i.loli.net/2021/05/22/OzWcZmVIGBq9yut.png)\n\n给出了一个问题和三个段落。DFGN通过从多个段落构造实体图，预测动态掩码选择子图，沿着图传播信息，最后将图中的信息传回文本来定位答案，从而对事实进行多步推理。节点是实体引用，带颜色节点表示潜在实体。边由共现关系构造而成，每一步都由DFGN选择灰色圆圈内的子图来处理。\n\n## 挑战\n\n1. 由于并不是每个文档都包含相关信息，基于多跳文本的问答需要从多个段落中滤除噪声并提取有用信息。\n\n> 作者思路: 通过DFGN这种多轮迭代的动态实体图来解决，如上图DFGN每一轮都通过掩码预测模块在动态图上生成和推理，其中不相关的实体被屏蔽，只有推理远被保留也就是灰色圆圈内的子图，这种做法缓解了误差的传播问题。\n>\n> 此外，DFGN的预测mask的过程可隐含地导出推理链，可以解释推理结果。针对开放域语料库基本真值推理链难以定义和标注的问题，提出了一种可行的弱监督掩码学习方法。提出了一种新的度量来评估预测推理链和构建的实体图的质量。\n\n但这样做有用的信息被mask了怎么办？怎么确定的mask范围？其实是用了注意力机制计算实体的权重，后文写。\n\n2. 不能直接从实体图中提取出答案，现实中，答案可能不在所提取的实体图的实体中。\n\n> 作者思路：在DFGN中设计了一个fusion处理模块，不仅将信息从文档聚合到实体图(Doc2graph)，还将实体图的信息传播回文档表示(Raph2doc)。通过文档token和实体在每一跳迭代地执行融合过程，然后从文档令牌获得最终结果答案。Doc2graph和Graph2doc的融合过程以及动态实体图共同改善了文档信息和实体图之间的交互性，从而减少了噪声，从而提高了答案的准确性。\n\n相当于在tokens的表达中加入了推理图中的推理信息，这个思想还是挺不错的。\n\n## 具体过程\n\n模仿人类对QA的推理过程。从查询感兴趣的实体开始，聚焦于开始实体周围的单词，连接到在邻居中发现的或由相同表面信息链接的某些相关实体，重复该步骤以形成推理链，并且落在可能是答案的某个实体或片段上。\n\nDFGN包含五个组件：\n\n![](https://i.loli.net/2021/05/22/DMpXHmNs6PYVbad.png)\n\n- 段落选择子网络\n- 实体图构建模块\n- 编码层\n- 用于多跳推理的融合模块\n- 最终预测层\n\n\n\n### Fusion Block\n\n这里只着重写一下Fusion Block\n\n在为查询Q和上下文C计算嵌入后，剩下的挑战是如何识别支持实体和潜在答案的文本跨度。\n\nFusion Block从 $Q_0$和 $C_0$ 开始，寻找一步支持实体。\n\n1. 通过计算实体嵌入从tokens将信息传递到实体(Doc2Graph Flow)\n2. 在实体图上进行信息传递\n3. 传递信息从实体图到文本tokens(Graph2Doc flow)\n\n![](https://i.loli.net/2021/05/22/zlremMsBCHVwILJ.png)\n\n#### Doc2Graph Flow\n\n由于通过NER工具识别每个实体，因此利用与实体相关联的文本跨度来计算实体嵌入(Doc2Graph)。\n\n为此，作者定义了一个 M 是01矩阵，$M_{i,j}$ 的值意思是，如果第 $i$ 个token在第j个实体的范围内，则 $M_{i,j}=1$\n\n这个 M 用于选择与实体相关联的文本范围。这其实是一个池化操作，将上下文C 的嵌入变成了实体E的嵌入 。\n\n$E_{t-1} = [e_{t-1,1},...,e_{t-1,N}] \\in R^{2d_2\\times N}$  这个模块作者定位 Tok2Ent，就是上图的左边部分。\n\n\n\n#### Dynamic Graph Attention\n\n然后是图中的中间部分，动态图注意力部分。\n\n在从输入上下文Ct−1获得实体嵌入后，我们应用图神经网络将节点信息传播给它们的邻居。我们提出了一种动态图注意机制来模仿人类的循序渐进的探索和推理行为。与q越相关，邻居节点从附近接收的信息越多。\n\n首先通过在实体上创建 Soft Mask 来识别与查询相关的节点。它充当信息看门人，即只允许与查询有关的那些实体节点传播信息。\n\n使用查询嵌入和实体嵌入之间的注意力网络来预测 Soft Mask $m_t$，其目的是表示第 t 个推理步骤中的开始实体：\n$$\n\\begin{equation}\\begin{split} \n \\hat q^{(t-1)} &= MeanPooling(Q^{t-1}) \\\\\n \\gamma^{(t)}_i &= \\frac {\\hat q^{(t-1)} V^{(t)} e_i^{(t-1)} }{\\sqrt{d_2}}\\\\\n m^{(t)} &= \\sigma([\\gamma^{(t)}_1,...,\\gamma_{N}^{(t)}]) \\\\\n \\hat E^{(t-1)} &= [m_1^{(t)}e_1^{(t-1)} ,..., m^{(t)}_N e_{N}^{(t-1)}]\n    \\end{split}\\end{equation}\n$$\n其实就是用注意力机制计算每个实体嵌入的权重。$V_t$ 是线性映射矩阵。\n\n总之就是通过Soft Mask，得到想要的开始推理的实体，并将它送入图中初始化。噪声信息不放入图中，相当于过滤掉。\n\n> 此外，作者引入一个弱监督信号来诱导每个 Fusion Block 处的软掩码来匹配启发式掩码。对于每个训练案例，启发式掩码包含从查询中检测到的开始掩码，并且通过对相邻矩阵应用广度优先搜索(BFS)获得的附加BFS掩码给出开始掩码。然后，将预测的软掩码和启发式之间的二进制交叉熵损失添加到目标。（跳过那些无法从查询中检测到起始掩码的情况）。\n\n在送入图后的信息聚合方式是使用的GAT，但有一点作者和以前的GAT不同，\n\n在Dynamic Graph Attention中，每个节点隐层的列进行求和，形成一个新的实体状态，其中包含它从邻居收到的全部信息：\n$$\ne_i^{(t)} =ReLU(\\sum_{j\\in B_i} \\alpha_{j,i}^{(t)} h_j^{(t)}) \n$$\n其中 $B_i$ 是邻居实体集合中的第 i 个实体，所以一次更新后的实体表达为 $E^{(t)} =[e_1^{(t)},...,e_N^{(t)}] $\n\n#### Updating Query\n\n一条推理链包含多个步骤，每一步新访问的实体就是下一步的起始实体。\n\n为了预测下一步期望的起始实体，引入了一种Updating Query机制，通过当前步骤的实体嵌入来更新查询嵌入。\n$$\nQ^{(t)} = Bi-Attention(Q^{(t-1)},E^{(t)})\n$$\n\n#### Graph to Document Flow\n\n利用Tok2Ent和动态图关注度，实现了实体级的推理步骤。然而，不受限制的答案仍然无法追溯。\n\n为了解决这个问题，开发了一个Graph2Doc模块来保持信息从实体回流到上下文中的tokens。因此，与答案有关的文本跨度可以在上下文中本地化。\n\n使用Doc2Graph Flow中一样的M矩阵，将$C_{t-1}$ 中的先前tokens嵌入和 对应于该令牌的关联实体嵌入对应回来。\n\nM中的每一行对应一个令牌，因此如果该令牌出现在实体的提及中，就使用它从 $E_t$ 中选择一个实体的嵌入。利用LSTM层进一步处理该信息，以产生下一级上下文表示： $C^{(t)} = LSTM([C^{(t-1)}, ME^{(t)T}])$\n\n\n\n\n\n### Prediction\n\n有四个输出维度，1.支持句，2.答案的开始位置，3.答案的结束位置，4.答案的类型。\n\n使用四个同构的LSTM $F_i$ 是逐层堆叠的。最后Fusion Block的上下文表示被发送到第一个LSTM $F_0$。每个$F_i$输出的logits为$  O∈R^{m×d2}$   ，并计算这些logit上的交叉熵损失。\n\n![](https://i.loli.net/2021/05/22/6ov3shgtbaNZWDP.png)\n\n\n\n## 实验\n\n![](https://i.loli.net/2021/05/22/udk43YL7pFQDCZX.png)\n\n\n\n### 作者提出的推理链质量的衡量标准\n\nESP(实体级支持)分数\n\n> 推理链是实体图上的一条有向路径，因此高质量的实体图是良好推理的基础。由于NER模型的精度有限和图结构的不完备性，31.3%的发展集中的情况不能进行完整的推理过程，其中至少有一个支持语句不能通过实体图到达，即在这个句子中没有实体被NER模型识别。我们将这类情况命名为“缺失支撑实体”，这种情况的比率可以用来评价图的构造质量。\n> 下面，在给出ESP(实体级支持)分数之前，我们首先给出几个定义。\n\n![](https://i.loli.net/2021/05/22/Eft6vqQFXSKu7ek.png)\n\n\n\n### 案例分析\n\n![](https://i.loli.net/2021/05/22/ryUW4c5s7VbQwKx.png)\n\n\n\n\n\n\n\n\n\n\n\n","tags":["GNN&nlp"]},{"title":"120三角形最小路径和","url":"/2021/05/22/120三角形最小路径和/","content":"\n# 120三角形最小路径和\n\n## 题目描述\n\n```\n给定一个三角形，找出自顶向下的最小路径和。\n每一步只能移动到下一行中相邻的结点上。\n\n相邻的结点 \n在这里指的是 下标 与 上一层结点下标 相同或者等于 上一层结点下标 + 1 的两个结点。\n\n \n\n例如，给定三角形：\n\n[\n     [2],\n    [3,4],\n   [6,5,7],\n  [4,1,8,3]\n]\n自顶向下的最小路径和为 11（即，2 + 3 + 5 + 1 = 11）。\n\n \n\n说明：\n\n如果你可以只使用 O(n) 的额外空间（n 为三角形的总行数）来解决这个问题，\n```\n\n## 分析\n\n若定义 f(i,j) 为 (i, j)点到底边的最小路径和，则递归求解式为：\n$$\nf(i,j) = mian(f(i+1,j) , f(i+1,j+1)) + triangle[i][j]\n$$\n由此，将任一点到底边的最小路径和，转化为了与该点相邻两点到底边的最小路径和中的较小值，再加上该点本身的值。\n\n得出(解一) 递归解法。\n\n### 解一（递归）\n\n```java\npublic int minimumTotal(List<List<Integer>> tri){\n  return dfs(tri,0,0);\n}\nprivate int dfs(List<List<Integer>> tri, int i, int j){\n  if (i==tri.size()) return 0;\n  return Math.min(dfs(tri,i+1,j), dfs(tri,i+1, j+1)) + tri.get(i).get(j);\n}\n```\n\n缺点：暴力搜索会有大量重复计算，引出解法二，结合记忆化数组进行优化。\n\n### 解法二：(递归+记忆化)\n\n定义一个二位数组用来记忆化\n\n```java\nInteger[][] memo;\n\npublic int minimumTotal(List<List<Integer>> tri){\n  memo = new Integer[tri.size()][tri.size()];\n  return dfs(tri,0,0);\n}\nprivate int dfs(List<List<Integer>> tri, int i, int j){\n  if(i==tri.size()) return 0;\n  if(memo[i][j]!=null) return memo[i][j];\n  return memo[i][j] = Math.min(dfs(tri, i+1, j), dfs(tri, i+1, j+1)) + tri.get(i).get(j);\n}\n```\n\n时间复杂度：$O(N^2)$，N为三角形的行数。\n空间复杂度：$O(N^2)$，N为三角形的行数。\n\n### 动态规划\n\n定义二维 dp 数组，将解法二中「自顶向下的递归」改为「自底向上的递推」。\n\n状态表示：$dp[i][j]$ 表示从点 $(i,j)$ 到底边的最小路径和\n\n状态计算：$dp[i][j] = min(dp[i+1][j] , dp[i+1][j+1]]) + tri[i][j]$\n\n```java\npublic int minmumTotal(List<List<Integer>> tri){\n  int n = tri.size();\n  // dp[i][j] 表示从点(i,j)到底边的最小路径和\n  int[][] dp = new int[n+1][n+1];\n  // 从三角形的最后一行开始递推\n  for(int i=n-1;i>=0;i++){\n    for(int j=0;j<=i;j++){\n      dp[i][j]=Math.min(dp[i+1][j], dp[i+1][j+1]) + tri.get(i).get(j);\n    }\n  }\n  return dp[0][0];\n}\n```\n\n时间复杂度：$O(N^2)$，N为三角形的行数。\n空间复杂度：$O(N^2)$，N为三角形的行数。\n\n\n\n### 空间优化\n\n上一个解定义了一个N行N列的 dp数组\n\n但实际递推中发现，计算 $dp[i][j]$ 时，只用到了下一行的 $dp[i+1][j]  和 dp[i+1][j+1]$\n\n因此dp 数组不需要定义N行，只需定义1行\n\n把 $i$ 所在维度去掉，将就可以将 $O(N^2)$ 的空间复杂度优化成$ O(N)$\n\n```java\npublic int minimumTotal(List<List<Integer>> tri) {\n \tint n = tri.size();\n  int[] dp = new int[n+1];\n  for(int i=n-1; j>=0; i--){\n    for(int j=0;j<=i; j++){\n      dp[j] = Math.min(dp[j], dp[j+1]) + tri.get(i).get(j);\n    }\n  }\n  return dp[0];\n}\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["DP"]},{"title":"Unsupervised Multi-hop Question Answering by Question Generation","url":"/2021/05/21/Unsupervised-Multi-hop-Question-Answering-by-Question-Generation/","content":"\n#  Unsupervised Multi-hop Question Answering by Question Generation\n\n第一个研究无监督多跳QA的。\n\nMQA-QG致力于探索在不参考任何人工标记的多跳问答对的情况下训练性能良好的多跳QA模型的可能性。\n\n无标签数据源分为同构和异构，即作者考虑了两种数据源，一种是结构化的表格文本数据，一种是纯文本数据。\n\n如果推理链中只有一种数据源的叫同构，两种数据源的叫异构。\n\n仅使用生成的训练数据，和有监督的性能做对比，对于Hybridge QA和HotpotQA数据集分别有61%和83%的有监督学习性能。其中hotpotQA(同构数据)，Hybridge QA(异构数据)。\n\n## 大体过程\n\n从每个数据源中选择或生成相关信息，将多个信息整合成一个问题。\n\n- 首先定义一系列operators去检索或生成相关信息。\n\n- 然后定义六个推理图每个对应于一种类型的多跳问题，且是建立在operators之上的计算图。\n\n![](https://i.loli.net/2021/05/21/dz9iH1rRSjg68ox.png)\n\n如上图，是生成table2text的问题。给出输入$(table, text)$ ，桥梁实体Jenson Button被operators找出来，他链接了文本数据和表格数据。\n\n然后再用一个叫 (QGwithEnt operator)的操作生成了右边的一个简单的问题：简森巴顿是什么时候出生？\n\n左边被 (DescribeEnt operator) 生成了一个描述桥梁实体的句子：简森巴顿是2004年美国大奖赛排名第4位的车手。\n\n最后再由 BridgeBlend operator 混合成一个多跳问题：2004年美国大奖赛排名第四的车手是什么时候出生的？\n\n\n\n## 具体方法\n\n给一个问题 q 和一系列文本 $C = \\{C_1,...,C_n\\}$ 其中 $C_i$ 可能是文章、table，如果推广到多模态还可能是image。\n\nQA model 表示为 $p_{\\theta}(a|q,C)$\n\n在本文中，作者只考虑两跳问题，并将所需的上下文表示为 $C_i$ 和 $C_j$。\n\n主要有三个成分分别是 \n\n- operators：由规则或现成的预训练模型实现的原子操作，用于从输入上下文 $(C_i、C_j)$ 检索、生成或融合相关信息。\n- reasoning graphs：不同的推理图定义了不同类型的以operators构建的多跳QA推理链。通过执行推理图生成训练 (q，a) 对。\n- question filtration：去除不相关和不自然的(q，a)对，给出多跳问答的最终训练集D。\n\n![](https://i.loli.net/2021/05/21/zQhscxV4MLRoWwn.png)\n\n\n\n### Operators\n\n定义了8个基本operator ，分为三种类型：\n\n- 选择：从单个上下文中检索相关信息\n- 生成：从单个上下文中生成信息\n- 融合：将多个检索或生成的信息进行融合，以构造多跳问题。\n\n#### FindBridge\n\n大多数多跳问题依赖于连接不同输入上下文的实体整合多条信息，即桥梁实体。\n\nFindBridge将两个上下文 $(C_i、C_j)$ 作为输入，并提取出现在 $C_i$ 和 $C_j$ 中的实体作为桥实体。如在第一个图中，提取“Jenson Button”作为桥实体。\n\n\n\n### FindComEnt\n\n在生成比较类型的多跳问题时，我们需要决定为桥实体比较什么属性。\n\nFind-Coment提取潜在的可比性，从文本中提取具有NER类型的实体作为比较属性(国籍、位置、日期时间和数字)。\n\n![](https://i.loli.net/2021/05/21/desLTyfBGOnzgqR.png)\n\n如上图的 #1 步骤\n\n\n\n#### QGwithAns和QGwithEnt\n\n这两个都是生成简单的单跳问题的， 随后会被用来合成多跳问题。\n\n作者使用预培训好的Google T5模型微调在SQuAD来实现这两个操作员。给定上下文-问题-答案三元组训练集D={(c，q，a)}，我们在两个任务上联合微调模型。给定上下文-问题-答案三元组训练集 $D={(c，q，a)}$ ，在两个任务上联合微调模型。\n\n- QGwithAns的目标是生成一个问题Q，其中a为答案，给定(c，a)为输入。\n- QGwithEnt旨在生成包含特定实体e的问题Q，给定(c，e)作为输入。\n\n![](https://i.loli.net/2021/05/21/IR6M35PrYKt91ba.png)\n\n#### CompBlend\n\n基于两个单跳问题Q1和Q2组成比较型多跳问题。这两个问题询问两个不同实体e1和e2的相同比较属性p。我们通过将p、e1和e2填入预定义模板来形成多跳问题。\n\n![](https://i.loli.net/2021/05/21/yiafYuGkUSeWl4B.png)\n\n\n\n#### DescribeEnt\n\n给定table $T$ 和表中的目标实体 e，DescribeEnt operator 基于T中的信息生成描述实体 e 的语句。使用GPT-TabGen模型，该模型首先使用模板将T 变成文档 $P_T$，然后将 $P_T$ 送到GPT-2生成输出句子 Y\n\n![](https://i.loli.net/2021/05/22/W9gHwV2PKpRtulr.png)\n\n为了避免 $P_T$中存在不相关信息，应用了一个仅描述目标实体所在行的模板。然后，在 ToTTo 数据集上通过最大化 $p(Y|P_T;β)$ 的来微调模型，β表示模型参数。ToTTo 数据集是一种受控的表格到文本生成的大规模数据集。\n\n\n\n#### QuesToSent\n\n通过应用《Transforming question answering datasets into natural language inference datasets》定义的语言规则将问题Q转换成其陈述形式s。\n\n\n\n#### BridgeBlend\n\n基于1)桥接实体e。2)包含e的单跳问题q。3)描述e的句子s。组成桥接型多跳问题。\n\n![](https://i.loli.net/2021/05/22/Rqj6PJW5kCOnS7x.png)\n\n作者通过应用简单但有效的规则来实现这一点，该规则将 Q中的桥接实体 e替换为 “the [MASK] that s”，并采用预训练的Bert-Large来填充[MASK]。\n\n\n\n### Reasoning Graphs\n\n基于以上的operators ，作者定义了6种类型的推理图，生成不同类型的问题。\n\n 每个问题都是有向无环图 G，每个G对应一个operator。\n\n一共有四类：\n\n- Table-to-Text：表格和文本之间的桥接式问题，答案来自文本。\n- Text-to-Table ：表格和文本之间的桥接式问题，答案来自表格。\n- Text-to-Text : 桥接类型，两边都是文本。\n- Comparison：基于两篇文章的比较型问题。\n\n通过执行每个推理图来生成QA对。通过定义新的算子和推理图，可以很容易地扩展到其他模态和推理链。\n\n![](https://i.loli.net/2021/05/22/9fWtj7U2vu4lbIi.png)\n\n![](https://i.loli.net/2021/05/22/aAs6NjF2TlPYiQd.png)\n\n![](https://i.loli.net/2021/05/22/mnT1JuCsK25ZrVx.png)\n\n\n\n### Question Filtration\n\n使用了两种方法来提炼生成的QA对的质量\n\n- Filtration：使用预先训练的gpt-2模型来过滤解决那些不流利或不自然的问题。选择困惑度最低的前N个样本作为生成的数据集来训练多跳QA模型。\n- Paraphrasing：基于BART模型训练一个问题解释模型来解释每个生成的问题。\n\n实验表明，过滤给QA模型带来了明显的改进。然而，在实验中展示了释义产生了更多类似人类的问题，但是引入了语义漂移问题，从而损害了QA性能。\n\n为了生成更自然的问题，我们试图训练一个基于BART的问题释义模型，以对每个生成的问题进行语法分析。观察到，通过将原问题的冗余部分改写成更简洁的表达，释义确实产生了更多的流行性问题。然而，释义引入了“语义漂移”问题，即释义后的疑问句改变了原疑问句的语义。我们认为这会影响QA性能，因为它会产生问答不一致的嘈杂样本。\n\n作者认为在无监督多跳问答中，对于生成的问题，语义的忠实性比流利性更重要。这就解释了为什么设计手工制作的推理图来保证语义的忠实性。然而，如何在保持语义忠实性的同时生成流畅的类人问题是未来的一个重要方向。\n\n\n\n## 实验\n\n对于Hybridge QA，问题按其答案是来自表格(56%)还是来自段落(44%)进行划分。大约80%的Hybridge QA问题需要桥接式推理。\n\n![](https://i.loli.net/2021/05/22/TpgkmquVjYtrPMf.png)\n\n\n\n在Hybridge QA和HotpotQA上的QA性能。\n\n![](https://i.loli.net/2021/05/22/IUMvlYxrGH4j8WC.png)\n\n\n\n![](https://i.loli.net/2021/05/22/AKh2cWJMs9UYrn3.png)\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["GNN&nlp"]},{"title":"Is Graph Structure Necessary for Multi-hop Question Answering?","url":"/2021/05/19/Is-Graph-Structure-Necessary-for-Multi-hop-Question-Answering/","content":"\n# Is Graph Structure Necessary for Multi-hop Question Answering?\n\n图结构对多跳问答有多大贡献？\n\n这是一篇只有6页的类似实验报告的论文。是在作者在做实验时发现，图结构和邻接矩阵都是与任务相关的先验知识，graph-attention可以看作是self-attention的特例。实验和可视化分析表明，self-attention和transformer可以代替graph-attention或整个图形结构，并且效果无明显变化，从而对图网络在自然语言处理任务上的应用能力提出了质疑。并希望未来引入图结构纳入自然语言处理任务的工作，应说明其必要性和优越性。\n\n作者使用 **Dynamically Fused Graph Network ** 那篇文章作为baseline开展了研究。\n\n## Baseline\n\n首先描述baseline模型，证明了只有当预先训练的模型以feature-based的方式使用时，图结构才能发挥重要作用。虽然在fine-tuning方法中使用预先训练的模型，但图结构可能没有帮助。\n\n作者复现了DFGN，并修改了预训练模型的使用。该模型首先利用检索器从候选集合中选择相关段落，并将其提供给基于图形的阅读器。实体图中的所有实体都由独立的NER模型抽取而来。\n\n- 检索器：在HotpotQA任务中使用Roberta Large模型来计算查询与每个候选段落之间的相关得分。我们对得分小于0.1%的段落进行过滤，最大入选段落数为3，入选段落拼接为Context C\n\n- 编码层：我们将查询Q和上下文C连接起来，并将序列提供给另一个Roberta，结果被进一步送到Bi-attention layer 以从编码层获得表示。\n\n- 图形融合块：给定第 t-1 跳的上下文表达 $C_{t-1}$ , 将token送入到mean-max pooling得到实体图$H_{t-1}\\in R^{2d\\times N}$, 其中N是实体的数量。之后采用的是图注意力层更新节点表达:\n  $$\n  \\begin{equation}\\begin{split} \n   \\beta_{i,j}^{(t)} &= LeakyReLU(W_t^T[h_i^{(t-1)},h_j^{(t-1)}])\\\\\n   \\alpha_{i,j}^{(t)} &= \\frac {exp(\\beta^{(t)}_{i,j})}{\\sum_{k\\in N_i}\\alpha^{(t)}_{i,k}h_k^{(t-1)}}\\\\\n   h_i^{(t)} &= ReLU(\\sum_{k\\in N_i} \\alpha^{(t)}_{i,k}h_k^{(t-1)})\n      \\end{split}\\end{equation}\n  $$\n  还有查询实体关注、查询更新机制、弱监督等模块。\n\n- 构建实体图：上下文中具有相同提及文本的实体被连接、同一句中出现的实体是相连的。\n\n- 最终预测层\n\n作者将将预训练语言模型的输出直接送到预测层，由于基线模型与DFGN的主要区别在于我们在fine-tuning方法中使用了large的预训练模型，而不是基于feature-based的方法，因此在两种不同的设置下进行了实验。在HotpotQA上提交的结果，并进行了消融实验对比如下：\n\n![](https://i.loli.net/2021/05/19/Kmq726TuL9aU1wF.png)\n\n结果表明在fine-tuning下有没有图结构效果不明显，在feature-based下图结构是有明显作用的。\n\n\n\n## graph-attention是self-attention的一种特例\n\n基于人工定义的规则和图结构的邻接矩阵可以看作是先验知识边，可以通过self-attention或Transformers来学习\n\n基于以上的实验结果表明，自我注意或变形金刚在多跳问题回答中可能具有优势。\n\n> 解决多跳问题的关键是通过查询在原文中找到对应的实体。然后，构建从这些起始实体到其他相同或共现实体的一条或多条推理路径。如图1所示，以前的工作通常从多个段落中提取实体，并将这些实体建模为实体图。邻接矩阵是由人工定义的规则构建的，这些规则通常是实体之间的共现关系。从这个角度看，图的结构和邻接矩阵都可以看作是与任务相关的先验知识。实体图结构限制了模型只能基于实体进行推理，邻接矩阵辅助模型忽略一跳中的非相邻节点。然而，可能是在没有任何先验知识的情况下，模型仍然可以学习实体到实体的注意模式。\n\n> 此外从上文图注意力的公式来看，不难发现图注意力与自我注意具有相似的形式。在前向传播中，实体图中的每个节点都会计算与其他连接节点的关注度得分。如图1所示，当图中的节点完全连接时，图注意力将退化为普通的自我关注层。因此，图形注意可以看作是自我注意的一种特例。\n\n基于以上的想法，作者将图结构做成全连接的实体和self-attention做了一次实验比较，为了验证整个图结构能否被transformer取代。\n\n![](https://i.loli.net/2021/05/19/TAMlO8FU5KeLpma.png)\n\n实验结果如图，与自我注意相比，图形注意并没有显示出明显的优势。\n\n![](https://i.loli.net/2021/05/19/RGcaHXL1o9QOUzI.png)\n\n对于图形注意和自我注意在不同密度区间的结果。尽管邻接矩阵的密度不同，但图形注意与自我注意的结果是一致的。这意味着自我关注可以学会忽略不相关的实体。\n\n此外，transformer显示出强大的推理能力。只有叠加两层变压器才能获得与DFGN相当的效果。\n\n\n\n并且作者分布从Entity2Entity、Attribute2Entity、Coreference2Entity、Entity2Sentence角度可实话了注意力权重在预训练语言模型中效果：\n\n![](https://i.loli.net/2021/05/19/sDHM6uNOE4tIX5S.png)\n\n认为基于实体的图网络忽略了后三种链接的信息，我认为可能异质图更多的解决这个问题。\n\n\n\n\n\n\n\n\n\n","tags":["GNN&nlp"]},{"title":"Navicat配置远程连接sqlite","url":"/2021/05/19/Navicat配置远程连接sqlite/","content":"\n# Navicat配置远程连接sqlite\n\n\n\n![](https://i.loli.net/2021/05/20/qdk2IJAea8BhGxf.png)\n\n远程sqlite其实是需要php环境的\n\n因为配置远程需要一个php文件当做通道，而且要能在浏览器上可访问这个文件\n\n所以首先找到这个文件，这个文件一般在Navicat的目录下，把它放在db的同目录下\n\n![](https://i.loli.net/2021/05/19/YCiGenoyAQvwIDE.png)\n\n然后就是安装apache2 和php\n\nhttps://blog.csdn.net/qq_37264323/article/details/90586239\n\n我是按这个装的很简单\n\n按步骤按完 apache2和php就可以了其余的不用装\n\n然后就是配置可访问，先打开80端口的访问网址看看Apache启动成功否\n\n之后就是配置虚拟路径，因为一般我们的db都不是放在Apache默认的www目录下\n\n我的服务器系统是ubantu\n\nApache安装目录在：/etc/apache2\n\n我要配置的位置是 :vim /etc/apache2/sites-available/000-default.conf  \n\n![](https://i.loli.net/2021/05/19/PsukcIXBlH6U9pS.png)\n\n在virtualhost内放置上面 alias 和directory 配置好路径\n\nservice apache2 restart\n\n但是访问http://10.12.1.150/data1/ntunnel_sqlite.php \n\n会出现forbidden\n\n我是参考这个解决的 \n\n![](https://i.loli.net/2021/05/19/vMgWrR8ayShqTHu.png)\n\nhttps://www.cnblogs.com/starof/p/4685999.html\n\n最终可访问：\n\n![](https://i.loli.net/2021/05/19/MHCveaGhg59qc3y.png)\n\n但目前存在一个问题 SQLite3 class available No 链接不成功\n\n![](https://i.loli.net/2021/05/19/DrnsE9yZ8PT6jvC.png)\n\n我怀疑是php对sqlite3的某个配置没有配好\n\nvim /etc/php/7.2/apache2/php.ini\n\n![](https://i.loli.net/2021/05/20/bci5VXT3GdEpmZW.png)\n\n找到这两个地方把注释去掉 \n\n> apt-get install php7.2-sqlite3\n\n![](https://i.loli.net/2021/05/20/ISnMmaUVirpyYG8.png)\n\n\n\n![](https://i.loli.net/2021/05/20/FKb1XUYksjNRinw.png)\n\n![](https://i.loli.net/2021/05/20/BCE6i4lpxnStk8I.png)\n\n\n\n另参考：[Navicat使用HTTP通道远程连接SQLite](https://ya2.top/articles/navicat%E4%BD%BF%E7%94%A8http%E9%80%9A%E9%81%93%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5sqlite/)\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["配置记录"]},{"title":"从01背包问题一维优化到多重背包问题二进制、单调队列优化总结","url":"/2021/05/17/从01背包问题一维优化到多重背包问题二进制、单调队列优化总结/","content":"\n# 从01背包问题一维优化到多重背包问题二进制、单调队列优化总结\n\n\n\n背包问题很经典，但从来都没有从头到尾总结过。\n\n01背包问题，是给一个容量大小为V的背包和N件物品，每件物品有各自的价值w，且每个物品只能被选择1次。要求在有限的背包容量下，装入物品总价值最大。\n\n多重背包问题的变动是，每个物品不止可以选择1次了，但要求还是在有限容量下装入最大的价值。\n\n相当于问题除了给出背包容量V，每种物品的价值W，之外，还给了每种物品的可选数量S\n\n多重背包问题的做法有\n\n- 将多重背包问题拆分为01背包问题，每种物品的每个我都选择一下0或1选与不选，这种做法时间复杂度较高。\n\n  适用数据范围为：\n\n  $0<N,V≤1000$\n  $0<v_i,w_i≤1000$ (因为题目一般的可解计算量为$10^7$ )\n\n- 范围超了有，二进制优化方法\n\n  适用数据范围为：\n\n  $0<N \\le 1000$\n\n  $0<V \\le 2000$\n\n  $0<v_i,w_i,s_i≤2000$\n\n- 再大还有单调队列优化方法\n\n  适用数据范围为：\n\n  $0<N \\le 1000$\n\n  $0<V \\le 20000$\n\n  $0<v_i,w_i,s_i≤20000$\n\n\n\n## 01背包问题\n\n题目：https://www.acwing.com/problem/content/2/\n\n不断对第i个物品做出决策，[0-1] 代表选与不选两种抉择\n\n![](https://i.loli.net/2021/05/17/xM8coeUv3Guh1LX.png)\n\n将状态$f[i][j]$优化到一维$f[j]$，实际上只需要做一个等价变形。\n\n为什么可以这样变形呢？我们定义的状态$f[i][j]$可以求得任意合法的 $i$ 与 $j$ 最优解，但题目只需要求得最终状态$f[n][m]$，因此我们只需要一维的空间来更新状态。\n\n1. 状态$f[j]$ 定义：N件物品，背包容量 $j$ 下的最优解\n2. 注意枚举背包容量 $j$ 必须从 $V$ 开始\n3. 为什么一维情况下枚举背包容量需要逆序？ 在2维情况下，状态 $f[i][j]$ 是由上一轮 $i-1$ 的状态得来的， $f[i][j]$ 与 $f[i-1][j]$ 是相互独立的。而优化到1维后，如果还是正序遍历，则有 $f[较小体积]$ 更新到 $f[较大体积]$， 则有可能本应该用第 $i-1$ 轮的状态却用的是第 $i$ 轮的状态\n4. 例如，一维状态第$i$ 轮对体积为3的物品进行决策，则$f[7]$ 由 $f[4]$ 更新而来，这里的$f[4]$ 正确应该是 $f[i-1][4]$，但从后小岛大枚举 $j$ 这里的 $f[4]$ 在第 $i$ 轮却成了 $f[i][4]$。 当逆序枚举背包容量 $j$ 时， 我们求$f[7]$ 同样由 $f[4]$ 更新。这里的 $f[4]$ 还没有在第 $i$ 轮计算，所以实际计算的 $f[4]$ 仍是 $f[i-1][4]$\n5. 简单来说，一维情况下正序更新状态 $f[j]$ 需要用到前面计算的状态已经被污染，逆序则不会有这样的问题\n6. 状态转移方程为 $f[j] = max(f[j], f[j-v[i]]+ w[i])$\n\n```java\npublic class Main{\n    \n    public static void main(String[] args) {\n        Scanner sc = new Scanner(System.in);\n        int N = sc.nextInt();\n        int V = sc.nextInt();\n        \n        int[] v=new int[N+1];\n        int[] w=new int[N+1];\n        \n        for(int i=1;i<=N;i++){\n            v[i] = sc.nextInt();\n            w[i] = sc.nextInt();\n        }\n        \n         //dp1(v,w, N, V);// 无优化数组\n      \t dp2(v,w, N, V);// 优化为1维数组\n    }\n    \n    public static void dp1(int[] v,int [] w, int N, int V){\n        int[][] dp = new int[N+1][V+1];\n        dp[0][0]= 0;\n        for(int i=1;i<=N;i++){\n            for(int j=1;j<=V;j++){\n                if(j<v[i]) dp[i][j]=dp[i-1][j];\n                else{\n                    dp[i][j] = Math.max(dp[i-1][j], dp[i-1][j-v[i]]+w[i]);\n                }\n            }\n        }\n        System.out.println(dp[N][V]);\n    }\n  \n    public static void dp2(int[] v,int [] w, int N, int V){\n          int[] dp = new int[V+1];\n          dp[0]= 0;\n          for(int i=1;i<=N;i++){\n              for(int j=V;j>=v[i];j--){\n                  // if(j<v[i]) dp[j]=dp[j];\n                  // else{\n                  dp[j] = Math.max(dp[j], dp[j-v[i]]+w[i]);\n                  // }\n              }\n          }\n          System.out.println(dp[V]);\n      }\n\n}\n```\n\n\n\n还可以优化输入\n\n处理数据时，我们是一个物品一个物品，一个体积一个体积的去枚举\n\n因此可以不必开两个数组去记录体积和价值，而是边输入边处理。\n\n```java\npublic class Main{\n    \n    public static void main(String[] args) {\n        Scanner sc = new Scanner(System.in);\n        int N = sc.nextInt();\n        int V = sc.nextInt();\n        int[] f=new int[V+1];\n        \n        for(int i=1;i<=N;i++){\n            int v = sc.nextInt();\n            int w = sc.nextInt();\n            for(int j = V;j >= v;j--){\n                f[j] = Math.max(f[j], f[j-v]+w);\n            }\n        }\n        System.out.println(f[V]);\n    }\n}\n```\n\n\n\n## 多重背包问题1\n\n题目：https://www.acwing.com/problem/content/4/\n\n多重背包问题，在给出每个物品的体积V和价值W的基础上，让每个物品不只可选1次\n\n完全背包和01背包的区别是完全背包中每个物品可以用无限次，而多重背包不是无限次用。\n\n最直接也最耗时的思路是，所有的可选的物品种类和次数都询问一次选或不选，也就是当成01背包问题来做。\n\n但也比01背包问题多了一个数量级, 相对暴力\n\n![](https://i.loli.net/2021/05/18/UWfLp2TGBw4jPvn.png)\n\n```java\nimport java.util.Scanner;\n\npublic class Main{\n    public static void main(String[] args) {\n        Scanner scanner = new Scanner(System.in);\n        int N = scanner.nextInt();\n        int V = scanner.nextInt();\n\n        int[] f = new int[110];\n\n        for (int i = 0; i < N; i++) {\n            int v = scanner.nextInt();\n            int w = scanner.nextInt();\n            int s = scanner.nextInt();\n            for (int j = V; j >= 0; j--) {\n                for (int k = 1; k <= s && k * v <= j; k++) {\n                    f[j] = Math.max(f[j], f[j - k * v] + k * w);\n                }\n            }\n        }\n\n        System.out.println(f[V]);\n    }\n}\n```\n\n\n\n## 多重背包问题2\n\n题目：https://www.acwing.com/problem/content/5/\n\n这道题和多重背包问题1其实是一样的，只不过数量级有变化，要求你用二进制优化的方法来解。\n\n那么什么是二进制优化法？\n\n上一道题是将每种物品拆成单份的01背包去求解的\n\n```text\n 即 v,w,s = v,w,7 时：\n 正常拆分：-> (v,w)，(v,w)，(v,w)，(v,w)，(v,w)，(v,w)，(v,w)\n 二进制拆分：-> (v,w),(v<<1,w<<1),(v<<2,w<<2)\n\n 7 : 1 ,2, 4\n 0\n 1\n 2\n 3 = 1+2\n 4\n 5= 1+4\n 6 =2+4\n 7=1+2+4\n <p>\n s - 1 -2 - 4 - 8  ....\n 减 2的幂  减到不能减为止 用s - (1+2+4+8...)\n 就可以把物品分成log(s)份 而不是s份\n <p>\n log(2000)=11\n 1000*11*2000 = 2*10^7\n 所以将每个物品拆成log份\n \n 模拟\n1 2 4 8 16 32 64 128 256 512 1024\n这十一个数可以拼凑出0-2047间的所有整数\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16................\n1 2 1+2 4 4+1 4+2 4+2+1 8 8+1 8+2 8+2+1 8+4 8+4+1 8+4+2 8+4+2+1 16................\n所以在使用二进制将si个i物品拆包组装成一个个大包之后我们总归可以通过01背包的枚举方式来得到一个正确的i物品选用数量，比如说应该选67件i物品，那么体现成我们选取了 价值为64w的物品一件 + 价值为2w的物品一件 + 价值为1*w的物品一件\n\n```\n\n为什么这么拆有用？\n\n上一题的状态转移方程是\n$$\n\\begin{equation}\\begin{split} \n f[j] &= max(f[j-1], f[j-v[i]]+w[i], f[j-2*v[i]]+2*w[i],... ) \\\\\n    \\end{split}\\end{equation}\n$$\n我们首先确认三点：\n\n（1）我们知道转化成01背包的基本思路就是：判断每件物品我是取了你好呢还是不取你好。\n\n（2）我们知道任意一个实数可以由二进制数来表示，也就是$2^0 - 2^k$其中一项或几项的和。\n\n（3）这里多重背包问的就是每件物品取多少件可以获得最大价值。\n\n如果仍然不是很能理解的话，取这样一个例子:要求在一堆苹果选出n个苹果。我们传统的思维是一个一个地去选，选够n个苹果就停止。这样选择的次数就是n次\n\n二进制优化思维就是：现在给出一堆苹果和10个箱子，选出n个苹果。将这一堆苹果分别按照1,2,4,8,16,.....512分到10个箱子里，那么由于任何一个数字x ∈[1,1024]\n都可以从这10个箱子里的苹果数量表示出来，但是这样选择的次数就是 ≤10次 。\n\n这样利用二进制优化，时间复杂度就从$O(n^3)降到O(n^2logS)$,从$4*10^9$降到了$2*10^7$。\n\n```java\nimport java.util.Scanner;\n\npublic class Main{\n   \tScanner scanner = new Scanner(System.in);\n    \n    void run1(){\n        int N = scanner.nextInt();\n        int V = scanner.nextInt();\n        \n        int[] v_arr = new int[12010];\n        int[] w_arr = new int[12010];\n        \n        int cnt = 0; // 分组的组别\n        for(int i=1;i<=N;i++){\n            int v = scanner.nextInt();\n            int w = scanner.nextInt();\n            int s = scanner.nextInt();\n            int k =1; //组别里的类别个数\n            while(k<=s){\n                cnt++; //组别先增加\n                v_arr[cnt] = v*k; //整体体积\n                w_arr[cnt] = w*k; //整体价值\n                s-=k;   \n                k*=2;\n            }\n            //剩余一组\n            if(s>0){\n                cnt++;\n                v_arr[cnt]= v*s;\n                w_arr[cnt]= w*s;\n            }\n        }\n        \n        int[] f = new int[V+1];\n        N = cnt;\n        // 01背包\n        for(int i=1;i<=N;i++){\n            for(int j=V;j>=v_arr[i];j--){\n                f[j] = Math.max(f[j] , f[j-v_arr[i]]+w_arr[i]);\n            }\n        }\n        System.out.println(f[V]);\n    }\n\n    public static void main(String[] args) {\n        new Main().run1();\n    }\n}\n```\n\n\n\n\n\n## 多重背包问题3\n\n题目：https://www.acwing.com/problem/content/description/6/\n\n$0<N \\le 1000$\n\n$0<V \\le 20000$\n\n$0<v_i,w_i,s_i≤20000$\n\n如果还以上面的二进制优化来做，复杂度为 $1000 * log(20000) * 20000 = 3*10^8$  会超时。\n$$\n\\begin{equation}\\begin{split} \n 原: f[j]=max(f[j],f[[j-kv[i]]+kw[i]);\\\\\n    \\end{split}\\end{equation}\n$$\n\n\n```java\nfor(int i=1;i<=N;i++)  //第一重循环\n        for(int j=0;j<=V;j++)  //第二重循环\n            for (int k = 0; k <= s[i] && k * v[i] <= j; k ++ )  //第三重循环\n```\n\n考虑到对于每次层 $i，j$  只与 j % v+kv 有关，k 的范围 $[0,s]$\n\n优化二三重循环,将每一层 j 按 j%v 分成v组，节省了第二重循环中 $ j+v…j+kv$ 的时间，将两重循环优化为遍历一次 m；\n\n$f[i][j]=max(f[i][j],f[i-1][j-kv[i]]+k*w[i]) $相当于求每一组在s个范围内的最大值，单调队列O（1）时间即可；\n\n时间复杂度应该是O(NV)\n\n\n\n```java\nimport java.util.Scanner;\n\npublic class Main{\n   \tScanner scanner = new Scanner(System.in);\n    \n    void run1(){\n        int N = scanner.nextInt();\n        int V = scanner.nextInt();\n        \n        int[] v_arr = new int[V+1];\n        int[] w_arr = new int[V+1];\n        \n        int[] f = new int[V+1];\n        int[] g = new int[V+1];\n        int[] q = new int[V+1];\n        \n        for(int i=1;i<=N;i++){\n            int v = scanner.nextInt();\n            int w = scanner.nextInt();\n            int s = scanner.nextInt();\n            for(int j=0;j<v;j++){\n                int hh,tt;\n                hh=0,tt=-1;\n                for(int k=j;k<=m;k+=vi){\n                    g[k] = f[k];//每次f[k]都可能会更新， 预先保存f[i-1, k]的值 \n                    if(hh<=tt&&(k-q[hh])/vi>si) hh++;//保证保证不超前si个\n                    while(hh<=tt&&g[q[tt]]+(k-q[tt])/vi*wi <f[k]) tt--;//单调队列入队方法\n                    q[++tt] = k;\n                    f[k] = g[q[hh]]+(k-q[hh])/vi*wi;\n                }\n            }\n        }\n        \n    }\n\n    public static void main(String[] args) {\n        new Main().run1();\n    }\n}\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["DP"]},{"title":"Adam & AdamW 原论文","url":"/2021/05/16/Adam-AdamW-原论文/","content":"\n# Adam & AdamW 原论文\n\n---\n\n# Adam\n\n一种基于低阶矩估计的随机目标函数一阶梯度优化算法。该方法也适用于非平稳目标和具有非常强噪声和/或稀疏梯度的问题。特点有：实现简单、计算高效、低内存要求、对梯度的对角重新缩放不变，并且很适合于数据和/或参数较大的问题。\n\n","tags":["ML&DL"]},{"title":"GPT-GNN: Generative Pre-Training of Graph Neural Networks","url":"/2021/05/15/GPT-GNN-Generative-Pre-Training-of-Graph-Neural-Networks/","content":"\n# GPT-GNN: Generative Pre-Training of Graph Neural Networks\n\nSelf-Supervised Learning分成两种方法:一种是生成式模型，一种是判别式模型(对比学习)。\n\n以输入图片信号为例，生成式模型，输入一张图片，通过Encoder编码和Decoder解码还原输入图片信息，监督信号是输入输出尽可能相似。判别式模型，输入两张图片，通过Encoder编码，监督信号是判断两张图是否相似(例如，输入同一个人的两张照片，判断输入相似，输出1；输入两个人的照片，判断输入不相似，输出0)。\n\n## 文章贡献\n\n继上一文 [Strategies for Pre-training Graph Neural Networks](https://coding-zuo.github.io/2021/05/12/Strategies-for-Pre-training-Graph-Neural-Networks/) 对预训练GNN做了大规模的实验，并提出提出了一种结合节点级和图级表示的预训练方法，优化了单单使用一种级别做预训练后产生的负迁移效果。\n\n又以生成式自监督的方式，来在预训练阶段捕捉图数据的结构信息和语义信息。分别是边生成任务和属性生成任务。\n\n它们联合优化等价于最大化整个属性图的概率似然，这样预训练模型可以捕捉到节点属性与图结构之间的内在依赖关系。\n\n预训练的GNN网络目标主要是异质单个(大规模)图上预训练，并进行节点级迁移。\n\n然后优化了预训练模型可以让其处理大规模的图采样子图，采用的是通过自适应的嵌入队列，减轻负采样带来的不准确损失。\n\n接下来主要介绍两种自监督任务和这个优化方法。\n\n\n\n## 行文逻辑\n\n通过行文逻辑，学习怎么写论文。\n\n首先作者先是说GNN有用，预训练GNN刚刚被证明有用！接下来从充分利用无标签数据做无监督任务说，大规模的图数据标记成本昂贵。NLP的数据也一样标注昂贵，所以有了bert那样的预训练语言模型，并且提高了下游任务性能。同样在cv领域也是。\n\n列举了GAE、GraphRNN、半监督GCN等图生成技术，但他们不适合用于预训练GNN。因为：首先，它们大多只关注于生成无属性的图结构，而没有定义节点属性与图结构之间的底层模式，图结构是GNNs中卷积聚合的核心。其次，它们被设计用来处理迄今为止的小图形，限制了它们在大规模图形上进行预训练的潜力。\n\n然后介绍了下预训练和finetuning的流程，就不多说了。\n\n然后切入正题介绍他的贡献，上文介绍过。\n\n----\n\n然后是准备工作和相关工作，介绍GNN的传统机制，信息传递和信息聚合的基本原理，不多介绍。\n\n和GNN发展历史，其中有一个Graph Infomax 最近可能要学习一下，最大化了从GNNs获得的节点表示和图pooling表示之间的互信息，也就是节点级和图级。作者认为其，在纯监督学习环境下表现出改进，但学习任务通过强迫附近节点具有相似的嵌入来实现，而忽略了图的丰富语义和高阶结构。\n\n介绍预训练在cv和nlp的成功。不过我最近听说cv圈有一篇文章，最近2021的有一篇预训练CNN其效果并不比基于transformer的模型差。\n\n介绍生成预训练任务的数学定义，之后是具体细节和模型方法，再到实验结论等等。\n\n\n\n## 关于生成式预训练任务的框架流程\n\n形式上给出图数据 $G = (V,E,X)$  和GNN模型 $f_{\\theta}$\n\n我们通过这个GNN将此图上的可能性建模为 $p(G;θ)$ -----表示G中的节点是如何属性化和连接其他节点的(可以理解为先验知识)。\n\n其目的是通过最大化图的似然，得到参数 $θ^∗=max_{θ}p(G;θ)$ 来预先训练广义神经网络模型。\n\n那么问题变成了如何对 $p(G;\\theta)$ 进行适当的建模。\n\n现在大多的现有图生成方法都是遵循自回归方式来分解目标概率分布，也就是图中的节点是按顺序来的，并且边是通过将每个新到达的节点连接到现有节点来生成的。什么是自回归？\n$$\nX_t = c+\\sum_{i=1}^p\\phi_iX_{t-i}+\\epsilon_t\n$$\n如上式，c 为常数项，$\\epsilon$ 为随机误差，概况来说就是X的当前期值等于一个或数个前期值的线性组合加常数项和睡觉误差。\n\n\n\n类似的作者也通过一个排列向量 $\\pi$ 来确定节点顺序，其中 $i^{\\pi}$ 表示向量中第i个位置的节点id。因此，图的分布$p(G;\\theta)$ 等价于所有可能排列上的期望似然：\n$$\np(G;\\theta) = \\mathbb{E}_{\\pi} [p_{\\theta}(X^{\\pi},E^{\\pi})]\n$$\n其中$X^{\\pi} \\in R^{|V|\\times d}$ ，$E$ 是边集 ，$E_{i}^{\\pi}$ 表示所有连接节点$i^{\\pi}$ 的边。\n\n为简单起见，假设观察到任何节点排序 $π$ 的概率相等，并且在下面的章节中说明一个排列的生成过程时也省略了下标 $π$。给定一个排列顺序，我们可以将对数似然率自动回归分解-每次迭代生成一个节点，如下所示：\n$$\nlogp_{\\theta}(X,E) = \\sum_{i=1}^{|V|}logp_{\\theta}(X_i,E_i|X_{\\lt i},E_{\\lt i})\n$$\n在第i步，使用所有 i 之前已生成的节点，他们的属性和边分别是 $X_{\\lt i}$ ，$E_{\\lt i}$ ，给定 $X_{\\lt i}$ $E_{\\lt i}$ 生成节点 i 的概率log加和。\n\n从本质上讲，等式中的目标。描述了属性图的自回归生成过程。问题变成：如何对条件概率 $p_θ(X_i，E_i|X_{<i}，E_{<i})$ 建模？\n\n### 因式分解属性图生成\n\n为了计算 $p_{\\theta}(X_i,E_i|X_{\\lt i},E_{\\lt i})$ ，一种天真的解决方案可以是简单地假设 $X_i$ 和 $E_i$是独立的，即 :\n$$\np_{\\theta}(X_i,E_i|X_{\\lt i},E_{\\lt i}) = p_{\\theta}(X_i|X_{\\lt i},E_{\\lt i}) \\cdot p_{\\theta}(E_i|X_{\\lt i},E_{\\lt i})\n$$\n然而通过这样的分解，对于每个节点，其属性和连接之间的依赖性被完全忽略。\n\n然而，被忽略的依赖性是属性图的核心性质，也是GNNs中卷积聚集的基础。因此，这种天真的分解不能为训练前的GNN提供信息指导。\n\n就比如，物以类聚人以群分，我和相似的人右边是因为我们有相似的属性。\n\n为了解决这个问题，作者提出了属性图生成过程的依赖感知分解机制。具体地说，当估计一个新节点的属性时，我们会得到它的结构信息，反之当估计一个新的结构边信息时，我们会考虑到它的属性信息。在该过程中，可以将生成分解为两个耦合部分：\n\n- 1.给出观测边的边，生成节点属性\n- 2.给出观测边和1中已经生成的节点属性，生成剩余的边\n\n通过这种方式，模型可以捕获每个节点的属性和结构之间的依赖关系。\n\n正式的定义如何建模，定义一个变量 $o$ , 表示$E_i$内所有观测边的索引向量。\n\n$E_{i,o}$ 是已观测的边，$\\lnot o$表示要生成的所有mask边的索引。通过所有的已观测边来重写条件概率作为一个期望似然如下：\n\n![](https://i.loli.net/2021/05/16/qIjAo2HyNkF5WcS.png)\n\n这里的理解非常重要，第一个等式中，把 $E_i$ 拆成了$E_{i,¬o}$和 $E_{i,o}$ ，也就是说指定了哪些边是观测边，哪些边是masked边。需要注意的是，当o确定下来了，$\\lnot o$ 也是确定的。因此等式外面加上了对o的累加，这里可以理解为类似于全概率公司去对所有可能的o求和。\n\n此外，这里要注意  $E_i, E_{<i},E_{i,o},E_{i,\\lnot o}$  四个符号分别表示什么：\n\n- 现在位于step i，$E_{<i}$ 是指在step i 之前生成的边\n- $E_i$ 指在step i 将会生成的边 (与节点i 相连，有好多边)\n- 将 $E_i$ 的边生成过程拆分成一件生成的和将要生成的两部分，即 $E_{i,o},E_{i,\\lnot o}$\n\n在第二个等式中，把p 看成是概率分布，写作对于o 期望的形式。\n\n最后把 $X_i$ 和 $E_{i,\\lnot o}$ 看做独立的过程，拆成两个概率分布。\n\n这种分解的优势在于，没有忽略 $X_i$ 和 $E_{i,o}$ 的联系。第一项表示given观测边，聚合目标节点i的邻居信息来生成其属性$X_i$ 。第二项表示given观测边和刚生成的属性$X_i$，预测$E_{i,¬o}$中的边是否存在。\n\n![](https://i.loli.net/2021/05/16/hTuqivsBcRC1fon.png)\n\n如上图所示，给出一个例子。对于academic图，我们要去生成一个paper node，它的属性为title。我们要去生成一个paper node，它的属性为title，并且其和author，publish venue，reference相连。上图中的实线部分为已经观测到的边，首先生成节点的属性，即title。然后基于author1，author2，author3和刚生成的节点属性title，预测剩下的边，即虚线部分。\n\n### 高效的属性和边生成 \n\n出于效率考虑希望：\n\n- 对于输入图只跑一次GNN就能计算节点属性生成和边生成过程的loss\n- 希望节点属性生成和边生成能同时运行\n\n然而边生成需要用到节点属性信息，如果两个生成过程同时进行，会导致信息泄露。为避免这个问题，将节点分成两种类型：\n\n- 属性生成节点，mask住这些节点的属性，用一个公用的dummy token，并学习一个共享向量$X^{init}$来代替 和$X_i$ 维度相同。\n- 边生成节点，对于这些节点，保留他们的属性。\n\n需要注意的是，同一个节点在不同阶段扮演不同的角色，可能是属性生成节点也可能是边生成节点。只在某一阶段，一个节点有一个确定的角色。\n\n在graph上训练GNN 来生成各个节点的embedding，用$h_{attr}$ 和 $h_{edge}$ 来分别表示属性生成节点和边生成节点的embedding。由于属性生成节点的属性被mask了，因此$h_{attr}$中包含的信息通畅会少于 $h_{edge}$。\n\n因此，在GNN的message passing过程中，只使用$h_{edge}$ 作为向其他节点发送的信息。 也就是说，对于每个节点，其聚合邻居 $h_edge$ 的信息和自身信息来生成新的embedding。之后使用不同的decoder来生成节点属性和边。（注意，节点的embedding和节点属性不是一回事。通俗理解，在GNN中节点的属性是input，节点的embedding是hidden layer。）\n\n\n\n对于属性生成，用$Dec^{Attr}(\\cdot)$ 来表示decoder，输入$h_{attr}$ 来生成节点属性。decoder的选择依赖于节点属性的类型，如果是text类型的节点属性，可以使用LSTM等。如果节点属性是vector，可以使用MLP。\n\n定义一个距离函数来度量生成属性和真实属性之间的差异，对于text类型属性，可以使用perplexity困惑度，对于vector属性，可以使用L2距离。因此，可以计算属性生成过程中的loss\n$$\nL_i^{Attr} = Distance(Dec^{Attr}(h_i^{Attr}, X_i))\n$$\n\n\n最小化生成属性和真实属性之间的差异，等价于对generate attribute做MLE，也就是最大化 $p_{\\theta}(X_i|E_{i,o},X_{<i},E_{<i})$ 从而捕捉了图中的节点属性信息。\n\n\n\n对于边生成过程，假设每条边的生成过程和其他边是独立的，由此对likelihood分解：\n$$\np_{\\theta} (E_{i,\\lnot o}|E_{i,o},X_{\\le i},E_{\\le i}) = \\prod_{j^+\\in E_{i,\\lnot o}} p_{\\theta}(j^+|E_{i,o},X_{\\le i},E_{\\le i})\n$$\n得到$h_{edge}$ 后，如果节点i和节点j相连，则使用\n$$\nDec^{Edge} (h_i^{Edge},h_j^{Edge})\n$$\n进行建模，$Dec^{Edge}$ 是一个pairwise score function\n\nloss定义为：\n$$\nL_i^{Edge} = - \\sum_{j^+\\in E_{i,\\lnot o}} log \\frac{exp(Dec^{Edge}(h_i^{Edge},h_{j^+}^{Edge}))}{\\sum_{j\\in S_i^-\\bigcup{j^+} }exp(Dec^{Edge}(h_i^{Edge},h_j^{Edge}))}\n$$\n$S_i^-$ 是指没有和节点i相连的节点\n\n下面是作者给出的属性图生成过程的说明性示例。\n\n![](https://i.loli.net/2021/05/16/i8IYhQ2NbSfEAKe.png)\n\n- a) 对于input graph 确定排列 $\\pi$\n- b) 随机挑选一部分与节点i相连的边作为已观测的$E_{i,o}$ ,剩下的作为masked edges $E_{i,\\lnot o}$ 并删除masked edges\n- c) 把节点分为属性生成节点和边生成节点\n- d) 计算节点 3，4，5的embedding，包括他们的属性生成节点和边生成节点。\n- d)-e) 通过对每个节点并行进行节点属性预测和masked预测来训练一个GNN模型\n\n\n\n具体算法流程：\n\n![](https://i.loli.net/2021/05/16/tGbrz7QJfmKEhdw.png)\n\n输入一个属性图，每次采样一个子图 $\\hat G$作为训练的实例进行训练。首先决定permutation order π。同时，我们希望能够并行化训练，只做一次前向传播，就能得到整个图的embedding，由此可以同时计算所有节点的loss。因此，根据permutation order π来移除边，也就是使每个节点只能从更低order的节点处获得信息。\n 之后，需要决定哪些边被mask。对于每个节点，获得其所有的出边，随机挑选一部分边被mask住，这一过程对应上述line4。\n 之后，对节点进行划分，得到整个图中节点的embedding，用于之后loss的计算，对应line5。\n line 7-9进行loss的计算。\n line 8中，通过整合采样图中未连接的节点和Q中以前计算的节点embedding来选择负样本，这种方式能够减轻对于采样图优化和对于整个图优化的差距。\n 在line11-12中，优化模型并更新Q。\n\n\n\n## GPT-GNN 对于异质的大图\n\n对于异构图，即包含不同类型的点和边的图，唯一的不同在于不同类型的点和边采用不同的decoder。\n 对于大规模的图，可以采样子图来进行训练，即上述算法流程中Sampler的作用。为了计算 $L_{edge}$ 这一loss，需要遍历输入图的所有节点。然而，我们只能在采样的子图上计算这个loss。为了缓解这一差异，提出了adaptive queue，其中存储了之前采样的子图的节点embedding作为负样本。每次采样一个新的子图时，逐步更新这个队列，增加新的节点embedding，移除旧的节点embedding。通过引入adaptive queue，不同采样子图中的节点也能为全局的结构提供信息。\n\n## 实验效果\n\n![](https://i.loli.net/2021/05/16/xER1ftIsSWcaK72.png)\n\n![](https://i.loli.net/2021/05/16/ZNcLJsHUqRGOhCk.png)","tags":["GNN"]},{"title":"Strategies for Pre-training Graph Neural Networks","url":"/2021/05/12/Strategies-for-Pre-training-Graph-Neural-Networks/","content":"\n# Strategies for Pre-training Graph Neural Networks\n\n目前深度学习各个领域的预训练都搞的热火朝天，GNN也是肯定要搞的。那么预训练之后下一个热潮会是什么呢？\n\nICLR2020 首次系统的探索了大规模GNN预训练\n\n提出了一种结合节点级和图级表示的预训练方法来训练模型。\n\n在节点级，使用了两种自监督方法，即上下文预测和属性预测。\n\n在图形级，使用有监督的图级属性预测和结构相似性预测\n\n同时作者建立了两个新的预训练数据集，2M graph的化学数据集和一个有395K graph的生物数据集。\n\n接下来介绍作者这么做的理由\n\n## 发现\n\n因为对于特定任务的有标签数据是很稀少的，但无标签数据却有很多，所以为了充分利用无标签数据，各种自监督方法开始兴起。\n\n所以作者分别在图级和节点级层面上提出了两大类预测方法\n\n- 属性预测：属性mask(节点)、有监督的属性预测(图级)\n- 结构预测：上下文预测(节点)、结构相似性预测(图级)\n\n以往的一些研究表明(Xu et al., 2017; Ching et al., 2018; Wang et al., 2019),一个成功的迁移学习不仅仅是增加与下游任务来自同一领域的标注好的预训练数据集的数量。相反，它需要大量的领域专业知识来仔细选择与感兴趣的下游任务相关的示例和目标标签。否则，知识从相关的预训练任务转移到新的下游任务可能会损害泛化，这被称为负迁移(Rosenstein等人，2005年)，并极大地限制了预训练模型的适用性和可靠性。\n\n作者研究发现朴素的策略要么在整个图的层面上预先训练GNN，要么在单个节点层面上预先训练GNN，所给出的改进有限，甚至可能导致许多下游任务的负迁移。在只有图级的预训练下大约有1/4的任务出现了负迁移。\n\n![](https://i.loli.net/2021/05/12/z5CEtxbX9Tj1WwN.png)\n\n图(a.i)当仅使用节点级预训练时，可以很好地分离不同形状的节点(语义上不同的节点)，但汇集节点级嵌入创建的结果，图嵌入是不可分离的(图嵌入由+和−表示)\n\n图(a.ii)仅在图级预训练的情况下，图嵌入可以很好地分离，但是单个节点的嵌入并不一定捕获它们特定于领域的语义。\n\n图(a.iii) 高质量的节点嵌入使得不同类型的节点能够很好地分开，同时嵌入空间也是可组合的。这允许对整个图形进行准确和健壮的表示，并允许将预先训练的模型健壮地传输到各种下游任务。\n\n\n\n## 预训练策略\n\n在预训练策略的技术核心是在单个节点以及整个图的级别预先训练。这一概念鼓励GNN在两个级别捕获特定域的语义。\n\n\n\n### 节点级预训练\n\n两种自监督方法，上下文预测和属性mask。\n\n![](https://i.loli.net/2021/05/12/RFS46a2tozyNGkp.png)\n\n图(a)在上下文预测中，子图是所选中心节点周围的K跳邻域，其中K是GNN层的数量，上图中设置为K=2。环境定义为中心节点r1-和r2-Hop之间的周围图结构，上图中使用r1=1和r2=4。\n\n图(b) 在属性mask中，输入节点/边属性(例如，分子图中的原子类型)被随机mask，并且要求GNN预测它们。\n\n#### 上下文预测：利用图结构的分布性\n\n使用子图来预测其周围的图结构。目标是预先训练GNN，以便它将出现在类似结构上下文中的节点映射到附近的嵌入。\n\n通过三个步骤：\n\n- 邻居节点和上下文图\n\n  对于每个节点v，定义v的邻居和上下文图。因为GNN信息聚合的是K层邻居，所以节点v的嵌入$h_v$ 依赖于距离v至多k跳节点。上下文图由两个超参数r1和r2来描述，并且它表示远离v的r1跳和r2跳之间的子图(即它是宽度为r2−r1的环)。并且r1<K，以便在邻域和上下文图之间共享一些节点，我们将这些节点称为上下文锚节点。这些锚节点提供关于邻居图和上下文图如何彼此连接的信息。\n\n- 使用一个辅助GNN把上下文编码成固定向量\n\n  由于图的组合性，直接预测上下文图是很困难的。这与自然语言处理不同，在自然语言处理中，单词来自固定和有限的词汇表。为了实现上下文预测，将上下文图编码为固定长度的向量。为此，引入一个上下文GNN作为辅助编码，就是图中的GNN‘。首先用其获得上下文图中的节点嵌入，然后对上下文锚点的嵌入进行平均，得到固定长度的上下文嵌入。对于图G中的节点v，将其对应的上下文嵌入表示为$c^G_v$\n\n- 负采样\n\n  主要的GNN编码邻居节点获取节点的embedding—— $h_v^{(K)}$ ，上下文GNN编码上下文图获取上下文embedding——$c^G_v$。学习目标是一个二分类：是否特定邻域和特定上下文图是否属于同一节点。\n  $$\n  \\sigma(h^{(k)T}_v c_{v'}^{G'}) \\approx 1 \\{\\text{v and v' are the same nodes}\\}\n  $$\n  \n\n  让v‘=v并且G’=G(即正例)，或者我们从随机选择的图G‘中随机抽样v’(即负例)。\n\n#### 属性mask:利用图属性的分布性\n\n目标是通过学习图结构上节点/边属性的分布规律来获取领域知识。\n\n属性mask有节点mask和属性mask两类\n\n工作原理：掩蔽节点/边缘属性，然后让GNN基于相邻结构预测这些属性，这参考了bert的mask。\n\n具体地说，通过用特殊的屏蔽指示符替换输入节点/边属性(例如分子图中的原子类型)来随机屏蔽它们。然后应用GNNs来获得相应的节点/边嵌入(边嵌入:为边的端点的节点嵌入之和来获得)。\n\n最后，在嵌入的基础上应用线性模型来预测被mask的节点/边属性。有趣的是bert的mask其实相当于在全连通的token图上应用了消息传递。\n\n在图结构数据中是对非全连通图进行操作，目的是捕捉节点/边属性在不同图结构上的分布规律。\n\n\n\n### 图级别预训练\n\n我们的目标是确保节点和图嵌入都是高质量的，以便图嵌入是健壮的，并且可以跨下游任务传输。\n\n有两个用于图级预训练的选项：预测整个图的特定于域的属性(监督标签)，或者预测图结构。\n\n#### 有监督的图级属性预测\n\n由于图形级表示 $h_G$ 直接用于对下游预测任务进行微调，希望将特定于域的信息直接编码成 $h_G$。\n\n考虑了一种对图表示进行预训练的实用方法：图级多任务监督预训练，用于联合预测单个图的不同监督标签集。例如，在分子性质预测中，我们可以预先训练GNN来预测到目前为止实验测量的分子的所有性质。在蛋白质功能预测中，目标是预测给定的蛋白质是否具有给定的功能，我们可以预先训练GNN来预测到目前为止已经验证的各种蛋白质功能的存在。\n\n重要的是，单独进行大量的多任务图级预训练可能无法给出可转移的图级表示。(问题来了)\n\n这是因为一些有监督的预训练任务可能与下游感兴趣的任务无关，甚至会损害下游的绩效（负迁移）。一种解决办法是选择“真正相关的”有监督的训练前任务，只对这些任务进行训练前GNN训练。然而，这样的解决方案成本极高，因为选择相关任务需要大量的领域专业知识，并且需要针对不同的下游任务分别进行预训练。\n\n为了缓解这个问题，作者的见解是，多任务监督的预训练只提供图形级的监督；因此，创建图形级嵌入的本地节点嵌入可能没有意义。这种无用的节点嵌入可能会加剧负迁移问题，因为许多不同的预训练任务在节点嵌入空间中更容易相互干扰。受此启发，在执行图级预训练之前，先通过上文描述的节点级预训练方法在单个节点级别对GNN进行正则化。正如作者所料，组合策略产生了更多可转移的图形表示。并且在没有专家选择监督的预训练任务的情况下稳健地改善了下游性能。\n\n\n\n#### 结构相似性预测\n\n目标是对两个图的结构相似性进行建模\n\n此类任务的示例包括对图形编辑距离进行建模(Bai等人，2019年)或预测图形结构相似性(Navarin等人，2018年)。\n\n这里好像作者感觉比较难没有全部实现，留到了以后的工作中\n\n\n\n### 总体预训练策略\n\n预训练策略是首先进行节点级的自监督预训练，然后进行图级多任务监督的预训练。当GNN预训练完成后，我们对下游任务的预训练GNN模型进行微调。具体地说，我们在图级表示的基础上添加线性分类器来预测下游的图标签。随后以端到端的方式微调整个模型，即预先训练的GNN和下游线性分类器。\n\n\n\n## 进一步相关工作\n\n关于图中单个节点的无监督表示学习的文献非常丰富，大致分为两类。\n\n第一类是使用基于局部随机行走的目标的方法(Grover&Leskovec，2016；Perozzi等人，2014；Don等人，2015)以及例如通过预测边的存在来重建图的邻接矩阵的方法。\n\n在第二类中是诸如Deep Graph Infomax的方法，其训练最大化局部节点表示和聚集的全局图表示之间的互信息的节点编码器。(基于对比学习互信息的最近也要研究研究)\n\n这两种方法都鼓励附近的节点具有相似的嵌入表示，最初是针对节点分类和链路预测提出和评估的。然而，这对于图级预测任务来说可能是次优的，在图级预测任务中，捕捉局部邻域的结构相似性通常比捕捉图中节点的位置信息更重要\n\n所以该预训练策略既考虑了节点级的预训练任务，也考虑了图级的预训练任务，并且正如在实验中所显示的，为了使预训练模型获得良好的性能，必须同时使用这两种类型的任务。\n\n\n\n## 实验\n\n![](https://i.loli.net/2021/05/12/cFBosvWCfURYdhx.png)\n\n阴影单元格表示负迁移，即预训练模型的ROC-AUC比未预训练模型的ROC-AUC差。借此说明两个级别共用的重要性。\n\n\n\n![](https://i.loli.net/2021/05/12/HvFtBiY5RadqGMw.png)\n\n在有无预培训的情况下测试不同GNN架构的ROC-AUC(%)性能。\n\n这里表达能力越强的结构预训练效果越好，表达能力较弱的GNN收益较小，甚至有时未负。这一发现证实了先前的观察结果(例如，Erhan等人)。(2010))，使用富有表现力的模型对于充分利用预培训至关重要，当用于表达能力有限的模型(如GCN、GraphSAGE和GAT)时，预培训甚至会影响性能。\n\n并且GAT的表现反而下降了不少。作者认为GAT属于表达能力有限的模型，还有人认为GAT attention的参数比较多，模型结构比较复杂导致。\n\n\n\n![](https://i.loli.net/2021/05/12/kFYCKXIvcU2iLeZ.png)\n\n\n\n\n\n\n\n\n\n","tags":["GNN"]},{"title":"Meta Learning(李宏毅)","url":"/2021/05/09/Meta-Learning-李宏毅/","content":"\n# Meta Learning\n\n李宏毅：https://www.bilibili.com/video/BV15b411g7Wd?p=57&spm_id_from=pageDriver\n\n一个不错的科普：https://www.bilibili.com/video/BV1KB4y1c7gg?from=search&seid=2922012165894972973\n\n## 什么是元学习\n\nMeta Learning = Learn to Learn (学习如何去做学习这件事)\n\n机器在学习了很多task后，在获得过去的任务下所汲取的经验后，学习到了更多的学习技巧，成为了一个更厉害的学习者。\n\n从而有一个新任务，他可以学的更快更好。\n\n比如：task1你教机器去学语音识别，task2你教他去做图片识别，那么task3你让他去学习文字识别，那么他可能学的会更好。\n\n元学习的输入是训练数据，输出的是可以用于下一个任务的function，function也就是万能函数模拟器神经网络的模型参数\n$$\n\\begin{equation}\\begin{split} \n f^* = F(D_{train})\n    \\end{split}\\end{equation}\n$$\n其中F 代表元学习算法，D是数据，f就是function。理解下图：\n\n![](https://i.loli.net/2021/05/09/rMLgmoSywHJcq5u.png)\n\n### 和机器学习的区别\n\n机器学习：定义一系列function--->定一个function好坏的指标-----> 用gradient decent找到一个最好的function\n\n元学习(也是找一个function)：定义一系列大Function----->定一个评价大Function好坏的指标----->找到一个最好的大Function\n\n\n\n### 和终身学习(Life-long learning)有些像？\n\n[持续/终身学习](https://blog.csdn.net/zyy617532750/article/details/104217399)：是让同一个模型可以同时学会很多任务技能\n\n而元学习是不同的任务仍然有不同的模型，我们期待的是模型通过以前的学习经历可以让他在未来别的任务上学的好。\n\n\n\n\n\n## 元学习过程\n\n### 定义一系列学习算法\n\n为什么是一系列学习算法，其实不同的模型参数、不同的结构、不同的学习参数的组合都是不同的学习算法。\n\n![](https://i.loli.net/2021/05/09/P6iANVszETHWB37.png)\n\n以梯度下降法为例，首先定义一个网络结构，初始化一个参数，通过训练数据计算一个梯度g，再通过学习率更新参数。\n\n迭代多次最后得到最终参数$\\hat \\theta$\n\n但上图中红色框框内的都是人为定义的。元学习就是想让这红框内的东西，不让人来设计，让机器根据先验知识来自己学习设计。\n\n### 评估function参数好坏\n\n让模型先学一些任务，去解一些问题看看。\n\n比如Task1：用一些$D_{train}$ 数据去训练模型得到$f_1$ ,再用Task1的$D_{test}$ 去衡量 $f_1$ 得到一个loss $l_1$\n\n一个任务不够，再多找些任务来\n\nTask2：用一些$D_{train}$ 数据去训练模型得到$f_2$ ,再用Task2的$D_{test}$ 去衡量 $f_2$得到一个loss $l_2$\n\n最后得到评价F好坏的Loss：\n$$\n\\begin{equation}\\begin{split} \n L(F) &= \\sum_{n=1}^Nl_n\\\\\n F^* &= argmin_FL(F)\n    \\end{split}\\end{equation}\n$$\nN 为任务数\n\nmeta learning 通常会把task的Train叫做Suppot set，Test叫做Query set\n\n\n\n## MAML(Model Agnostic Meta-Learning)\n\n学一个初始化的参数\n$$\n\\begin{equation}\\begin{split} \n L(\\phi) = \\sum_{n=1}^N l^n(\\hat \\theta^n)\n    \\end{split}\\end{equation}\n$$\n$\\phi$ 输入的初始化参数，$\\hat \\theta^n$ 在第n个task上学出来的model，$\\hat \\theta^n$ 取决于$\\phi$ \n\n$l^n(\\hat \\theta^n)$: 把$\\hat \\theta^n$这组参数拿到第n个task的测试集中去看看效果怎么样\n\n怎么确定初始化的参数好不好，就用初始化参数到不同task上去做训练\n\n最小化$L(\\phi)$ : $\\phi \\gets \\phi-\\alpha ▽_{\\phi}L(\\phi)$\n\n### 和迁移学习(Transfer learning) 预训练有些像？\n\n迁移学习：某一个任务的数据很少，但另外一个任务的数据多。就把model预训练在多的数据上，再fine-tuning在少的数据上。\n\n他的loss function：\n$$\n\\begin{equation}\\begin{split} \n  L(\\phi) = \\sum_{n=1}^N l^n(\\phi)\n    \\end{split}\\end{equation}\n$$\n在MAML里面loss是用$\\phi$ 训练完后的model计算出来的，是训练过后的model\n\n在pretrain里是用现在这个model直接去下游任务中衡量表现怎么样。\n\n有的文章把预训练改成MAML的形式，以缓解预训练任务和下游任务直接目标不同产生的gap。\n\n\n\n在MAML中，我们不在意$\\phi$ 在training task上的表现，在意的是用$\\phi$ 训练出来的$\\hat \\theta^n$的表现如何\n\n（面向的是**学习的过程**，并不是**学习的结果**）\n\n![](https://i.loli.net/2021/05/10/7V2Uua4g8e9R1tk.png)\n\n![](https://i.loli.net/2021/05/10/epRfZzxlFTgSjVI.png)\n\n如上图虽然$\\phi$ 本身表现不够好，但$\\phi$经过训练以后可以变得很强 (潜力如何)\n\n而pretrain在意的是现在这个$\\phi$表现的怎么样，是在找寻在所有task都最好的$\\phi$, 并不保证训练以后会得到好的 $ \\hat \\theta^n$ （现在表现如何）\n\n并且MAML只训练很少的步数，因为\n\n- 为了快速\n- 希望在训练一步就得到很好的结果\n- 在使用算法模型时可以多update\n- 为了适应Few-shot learning \n\n### Toy Example\n\n每一个任务：\n\n- 给一个目标sin函数 $y = a sin(x+b)$ 其中 a、b 都是随机数，每一组 a、b 对应一条正弦曲线\n- 从目标函数中采样k个点\n- 使用采样点去估计目标函数\n\n希望拟合的y越好越好。随机采样不同的a和b就可以得到不同的任务。\n\n![](https://i.loli.net/2021/05/10/9YnTfrxqoBDgVCU.png)\n\n\n\n\n\n\n\n## 参考文献\n\n[元学习-总结](https://zhuanlan.zhihu.com/p/367684934)\n\n[元学习（Meta-learning）——李宏毅老师教学视频笔记](https://zhuanlan.zhihu.com/p/108503451)\n\n[[meta-learning] 对MAML的深度解析](https://zhuanlan.zhihu.com/p/181709693)\n\n","tags":["ML&DL"]},{"title":"Learning to Pre-train Graph Neural Networks","url":"/2021/05/08/Learning-to-Pre-train-Graph-Neural-Networks/","content":"\n# Learning to Pre-train Graph Neural Networks\n\n\n\n## 动机与挑战\n\n图神经网络也是有预训练模型的，预训练之所以可以提升，可以解释为获取了有用的先验知识，并迁移到任务中。\n\n常规的GNN预训练步骤和其他网络一样分为两个步骤：\n\n- 在大量未标记的图数据上预先训练GNN模型，其导出编码固有图属性的通用可转移知识\n- 在特定于任务的图形数据上对预先训练的GNN模型进行微调，以使通用知识适用于下游任务。\n\n但之前有人已经研究过直接进行fine-tuning效果不提反降，产生负迁移效果。应该是出自(Strategies for Pre-training Graph Neural Networks 如何解决的以后看了这篇论文再说) \n\n而这篇文章的主要想解决的是由于预训练和fine-tuning优化目标的不同，两者之间存在明显差距，损害了模型的泛化效果。\n\n引出了第一个挑战：如何缩小不同优化目标带来的差距？ --->>元学习思想\n\n那GNN的预训练模型的特点是不仅要考虑局部的节点级先验知识还要获取图级别的全局先验知识 (现有方法要么只考虑节点级的预训练，或者仍然需要用有监督的图级预训练)\n\n引出了第二个挑战：如何利用完全未标记的图数据同时保留节点级和图形级信息？\n\n提出了L2P-GNN，计了节点级和图级的双重自适应机制，并且是完全自监督的方式。\n\n\n\n## 设计\n\n### GNN\n\n首先定义一个图 $G = (V,E,X,Z)$ , 其中 $V$ 是节点、$E$ 是边、$X \\in R ^{|V|\\times d_v}$ 是节点特征、 $Z \\in R^{|E|\\times d_e}$ 是边的特征。\n\nGNN 一般包含两个关键的计算，一个是聚合信息的操作AGGREGATE，另一个是更新操作UPDATE\n\n节点表示：节点v的l层表示由下式给出：\n$$\n\\begin{equation}\\begin{split} \n h_v^l &= \\Psi (\\psi, A, X,Z)^l\\\\\n &= \\text{UPDATAE}(h_v^{l-1}, AGGREGATE(\\{(h_v^{l-1}, h_u^{l-1}, z_{uv}): u\\in N_v\\}))\n\\end{split}\\end{equation}\n$$\n其中 $z_{uv}$ 是u到v的边特征向量，A是邻接矩阵 ，$N_v$ 是v的邻居节点。$\\Psi$ 是聚合和更新操作的定义，$\\psi$ 是可学习参数。\n\n图级的表示：通常用READOUT \n$$\n\\begin{equation}\\begin{split} \n h_G = \\Omega(w ; H^l) = \\text{READOUT} (\\{h_v^l| v\\in V\\})\n    \\end{split}\\end{equation}\n$$\n其中$H^l = [h_v^l]$ 是节点级表达矩阵。READOUT的典型实现有sum、max、mean池化，或者用其他复杂一点的方法。\n\n### 常规GNN的预训练\n\n1. 预训练：定义 $D^{pre}$ 为预训练图数据，$L^{pre}$ 预训练的loss ，优化目标为：\n\n$$\n\\theta_0 = argmin_{\\theta}  L^{pre} (f_\\theta; D^{pre})\n$$\n\n2. fine-tuning：目标是，在对下游任务的训练集图数据$D^{tr}$进行微调之后，最大化下游测试集图数据$D^{te}$上的表现 \n\n所谓的微调根据预先训练的参数$\\theta_0$来初始化模型，并且用在(通常是批处理的)$D_{tr}$上的多步梯度下降来更新GNN模型 $f_{\\theta}$。\n$$\n\\theta_1 = \\theta_0 - \\eta ▽_{\\theta_0} L^{fine}(f_{\\theta_0};D^{tr})\n$$\n其中 $ \\eta$ 学习率\n\n可见常规的预训练和finetuing是解耦的，参数$\\theta_0$ 和下游没有适应性的联系形式。\n\n为此，作者提出通过构建预训练阶段来模拟下游任务的微调过程，从而直接优化预训练模型对下游任务的快速适应性。\n\n### 新的预训练方法\n\n其实就是元学习的思想 参考上文 [Meta Learning(李宏毅)](https://coding-zuo.github.io/2021/05/09/Meta-Learning-%E6%9D%8E%E5%AE%8F%E6%AF%85/)\n\n现有$G\\in D^{pre}$ 从中采样一些子图 定义为$D^{tr}_{T_G}$ 作为模拟下游任务$T_G$的训练数据——元学习中的support sets，再采样一些子图作为$D^{te}_{T_G}$ 作为模拟的验证集——元学习中的query sets。\n$$\n\\theta_0 = argmin_{\\theta} \\sum_{G\\in D^{pre}} L^{pre}(f_{\\theta - \\alpha ▽_{\\theta}L^{pre}(f_{\\theta}; D^{tr}_{T_G})}; D^{te}_{T_G})\n$$\n$\\theta - \\alpha ▽_{\\theta}L^{pre}(f_{\\theta}; D^{tr}_{T_G})$ 相当于在$D^{tr}_{T_G}$ 预训练的测试集先进行了一次fine-tuning\n\n作者认为：因此，预培训输出$θ_0$并不是为了直接优化任何特定任务的训练或测试数据。相反，θ0通常是最佳的，因为它允许快速适应新任务。\n\n我认为：这类似元学习的思想，还可以从元知识的角度来描述。还有一个点，这个预训练数据集和下游任务相不相关呢？如果相关度不大会不会有用，如果相关会不会更好？\n\n\n\n## L2P_GNN\n\n两个特点：\n\n- 从局部和全局角度捕捉图形中的结构和属性\n- 套用MAML获得元学习的先验知识可以适应新的任务或图表\n\n### 任务实施\n\n定义每个任务的图数据随机采样得到 $T_G = (S_G,Q_G)$ , $S_G$ 为Support set ，$Q_G$ 为Query set\n\n![](/Users/zuoyuhui/Library/Application Support/typora-user-images/image-20210510173143614.png)\n\n多个任务的支持集合查询集为: $S_G =(S_G^1,S_G^2,...,S_G^k) ,Q_G =(Q_G^1,Q_G^2,...,Q_G^k)$\n\n在给定父任务和子任务的情况下，作者设计了一个节点级聚集和图级汇集的自监督基本GNN模型，分别学习节点和图的表示。其核心思想是利用无标签图数据的内在结构作为节点级和图级的自我监督。\n\n\n\n节点级：自监督预测u和v节点有边链接的目标函数\n$$\nL^{node}(\\psi;S_G^c) = \\sum_{(u,v)\\in S_G^e} -ln(\\sigma(h_u^Th_v)) -ln(\\sigma(-h_u^Th_{v'}))\n$$\n其中 $v'$ 是负采样节点，是没有和u有边的节点。\n\n图级：通过图池化获得图表达$h_G$，每个任务的支持集图表达为 $h_{S_G^c} = \\Omega(w;\\{h_u|\\forall u,\\exists v:(u,v) \\in S_G^c\\})$\n$$\nL^{graph} (w; S_G) = \\sum_{c=1}^k -log(\\sigma(h_{S_G^c}^T h_G)) -log(\\sigma(-h^T_{S_G^c}h_{G'}))\n$$\n两个级别的loss综合到一起：\n$$\nL_{T_G}(\\theta;S_G) = L^{graph}(w;S_G) + \\frac{1}{k} \\sum_{c=1}^k L^{node}(\\psi;S_G^c)\n$$\n其中$\\theta = \\{\\psi,w\\}$ 是可学习参数，就是可迁移的先验知识\n\n### 双重适应(图级和节点级)\n\n\n\n![](https://i.loli.net/2021/05/10/ahQdOwrHvFgKIxy.png)\n\n节点级：支持loss采用一个或几个梯度下降步骤，以获得子任务的适应先验 $ψ$。例如，当使用一个具有节点级学习率$α$的梯度更新时:\n$$\n\\psi' = \\psi - \\alpha \\frac{\\partial\\sum_{c=1}^k L^{node}(\\psi;S_G^c)}{\\partial\\psi}\n$$\n图级：\n$$\nw' = \\psi - \\beta \\frac{\\partial  L^{graph}(w;S_G^c)}{\\partial w}\n$$\n所有任务的更新参数过程\n$$\n\\theta \\gets \\theta - \\gamma\\frac{\\partial\\sum_{G\\in D^{pre}}L_{T_G}(\\theta';Q_G) }{\\partial \\theta}\n$$\n\n## 实验\n\n实验的主要目的：要验证有没有缩小预训练和微调的gap图级和节点级预训练策略是否奏效\n\n作者对预训练的GNN模型在下游任务微调前后（命名为model-P和model-F）进行了对比分析，并考虑了三个比较视角：model-P和model-F参数之间的中心核对齐相似性（CKA），训练损失（delta损失）和下游任务测试性能（delta RUC-AUC或Micro-F1）的变化。\n\n![](https://i.loli.net/2021/05/10/wiGa9eSAcgNy62u.png)\n\n如图所示，观察到L2P-GNN参数在微调前后的CKA相似性通常比基线的CKA相似性小，这表明L2P-GNN经历了更大的变化，以便更好地适应下游任务。\n\nCKA 是测量神经网络表示相似性的，可以对迁移学习任务进行评估，值越小越相似。\n\n此外，L2P-GNN的训练损失变化较小，说明L2P-GNN通过快速适应可以很容易地达到新任务的最优点。\n\n\n\n\n\n\n\n## 参考\n\n### GNN预训练的论文\n\nHu, W.; Liu, B.; Gomes, J.; Zitnik, M.; Liang, P.; Pande, V. S.; and Leskovec, J. 2020. Strategies for Pre-training Graph Neural Networks. In *Proceedings of ICLR*.\n\nHu, Z.; Fan, C.; Chen, T.; Chang, K.; and Sun, Y. 2019. Pre-Training Graph Neural Networks for Generic Structural Feature Extraction. *CoRR* abs/1905.13728.\n\nNavarin, N.; Tran, D. V.; and Sperduti, A. 2018. Pre-training Graph Neural Networks with Kernels. *CoRR* abs/1811.06930.\n\n### 元学习\n\nFinn, C.; Abbeel, P.; and Levine, S. 2017. Model-agnostic meta-learning for fast adaptation of deep networks. In *Pro- ceedings of ICML*, 1126–1135.\n\nLu, Y.; Fang, Y.; and Shi, C. 2020. Meta-learning on Hetero- geneous Information Networks for Cold-start Recommenda- tion. In *Proceedings of KDD*, 1563–1573.","tags":["GNN"]},{"title":"DP——最大子序和","url":"/2021/05/06/DP——最大子序和/","content":"\n# DP——最大子序和\n\nhttps://www.acwing.com/problem/content/137/\n\n输入一个长度为 n 的整数序列，从中找出一段长度不超过 m 的连续子序列，使得子序列中所有数的和最大。\n\n**注意：** 子序列的长度至少是 1。\n\n#### 输入格式\n\n第一行输入两个整数 n,m。\n\n第二行输入 n 个数，代表长度为 n 的整数序列。\n\n同一行数之间用空格隔开。\n\n#### 输出格式\n\n输出一个整数，代表该序列的最大子序和。\n\n#### 数据范围\n\n1≤n,m≤300000\n\n#### 输入样例：\n\n```\n6 4\n1 -3 5 1 -2 3\n```\n\n#### 输出样例：\n\n```\n7\n```\n\n\n\n\n\n## 解\n\n![](https://i.loli.net/2021/05/06/QHsdPGY1q7FrtpB.png)\n\n\n\n状态转移方程：集合代表的喊一声所有以i结尾的子段，如果i=3的话，那么集合可能是{1,num[i]}、{1,-3,num[i]}、{1,5,num[i]}、{num[i]} ，目标是求这些集合中的最大值，因为每个集合都有num[i]可先不考虑num[i]。\n\n所以只要考虑f[i-1]+num[i] ,和只有num[i]的集合的最大值。\n\n也就是考虑f[i-1]和0谁最大。\n\n最终的答案是所有集合的值取最大\n\n## 代码\n\nLeetCode53 不限制最大子序列长度\n\n```java\nclass Solution {\n    public int maxSubArray(int[] num) {\n        int last = 0;\n        int res = Integer.MIN_VALUE;\n        for (int i = 0; i < num.length; i++) {\n            int now = Math.max(last, 0) + num[i];\n            res = Math.max(res, now);\n            last = now;\n        }\n        return res;\n    }\n}\n```\n\n\n\nacwing 135 限制最大子序列长度\n\n不同的是，对于每一个i，要求前面长度为m这个段内，求一个最小值\n\n![](https://i.loli.net/2021/05/06/KfOS1Mzt4GxnoUd.png)\n$$\nmax\\{Sum_i - Sum_j\\} , i-m 到 i-1\n$$\n可以用一个队列来维护m个数\n\n每次i向后移动，就插入一个数同时队首出列\n\n- 用一个单调队列\n- 把没用的数删去\n- 变成单调递增的序列\n- 用$0(1)$ 把 min或max找出\n\n```java\n\npublic class Main{\n\n    void run(){\n        int n = jin.nextInt();\n        int m = jin.nextInt();\n        nums.add(0);\n        for (int i = 0 ; i < n ; i++) nums.add(jin.nextInt());\n        for (int i = 1 ; i <= n ; i++) nums.set(i, nums.get(i)+nums.get(i-1));\n\n        int res = Integer.MIN_VALUE;\n        for (int i = 1; i <= n ; i++){\n            while(!queue.isEmpty() && i - queue.peekFirst() > m) queue.removeFirst();\n\n            if (!queue.isEmpty()) res = Math.max(res, nums.get(i) - nums.get(queue.peekFirst())); // why not peekF -1 ?\n            else res = Math.max(res, nums.get(i));                                              // 差点漏掉了\n            while(!queue.isEmpty() && nums.get(i) <= nums.get(queue.peekLast())) queue.removeLast();\n            queue.offerLast(i);\n        }\n        res = Math.max(res, nums.get(n) - nums.get(queue.peekFirst()-1));\n        System.out.println(res);\n    }\n\n    List<Integer> nums = new ArrayList<>();\n    Deque<Integer> queue = new LinkedList<>();\n    private Scanner jin = new Scanner(System.in);\n    public static void main(String[] args) throws Exception {new Main().run();}\n}\n\n```\n\n\n\n\n\n\n\n\n\n\n\n","tags":["DP"]},{"title":"海华阅读理解比赛复盘","url":"/2021/05/01/海华阅读理解比赛复盘/","content":"\n# 海华阅读理解比赛复盘\n\n比赛详情、EMA、Baseline，本文主要记录提分点和模型改进的验证\n\n参考上文 [海华中文阅读理解比赛梳理/多卡并行/transformers](https://coding-zuo.github.io/2021/04/06/%E6%B5%B7%E5%8D%8E%E4%B8%AD%E6%96%87%E9%98%85%E8%AF%BB%E7%90%86%E8%A7%A3%E6%AF%94%E8%B5%9B%E6%A2%B3%E7%90%86-%E5%A4%9A%E5%8D%A1%E5%B9%B6%E8%A1%8C-transformers/)\n\n[github](https://github.com/Coding-Zuo/MRC_multiChoice)\n\n\n\n## 数据增强\n\n数据增强的办法很多参考 https://zhuanlan.zhihu.com/p/145521255\n\n我只采用了句子乱序和数据回译，都是将增强数据和原始数据挨着放到数据集中，在训练的时候停用shuffle。(可能有其他方法：每条数据根据概率来选择性增强)，我这种可能会让数据集臃肿，质量下降。\n\n### 句子乱序\n\n没有提分，也没有降很多。\n\n原因参考：[从知觉谈中文乱序不影响阅读的原因](https://zhuanlan.zhihu.com/p/107594976)\n\n代码：https://github.com/Coding-Zuo/MRC_multiChoice/blob/main/train/data_process.py 中的data_enhancement_sentence_order\n\n### 数据回译\n\n和句子乱序一样和回译到的数据和原始数据挨着放到数据集，没有提分，可能是回译到的数据质量不好。\n\n使用的是百度API，百度限制一个账户免费200万字符，如果超了就多注册几个账户薅羊毛。\n\n代码：https://github.com/Coding-Zuo/MRC_multiChoice/blob/main/TranslateAPI.py\n\n\n\n### 在训练集上打伪标签\n\n由于时间问题，没有直接提交伪标签训练的结果，就直接模型融合。验证集有提高。\n\n用训练好的模型去inference测试集，取了模型认为有百分之85概率认为是正确答案的数据打上伪标签，加入到训练集训练。\n\n\n\n## 优化训练\n\n### EMA\n\n滑动平均exponential moving average\n\n没有提分，反而效果变差。具体原因，还在探索，可能和优化方法有关？\n\n我一直使用的都是adamw，[比较Adam 和Adamw](https://www.cnblogs.com/tfknight/p/13425532.html) [一文告诉你Adam、AdamW、Amsgrad区别和联系](https://zhuanlan.zhihu.com/p/39543160)，AdamW是在Adam+L2正则化的基础上进行改进的算法。\n\n可以和sgd搭配看看效果。(这方面因为时间问题没有尝试充足)\n\n[PyTorch指数移动平均(EMA)手册](https://blog.csdn.net/weixin_43002433/article/details/113531466)\n\n指数移动平均EMA是用于估计变量的局部均值的，它可以使变量的更新不只取决于当前时刻的数据。\n\n而是加权平均了近期一段时间内的历史数据，是的变量的更新更平滑，不易受到某次异常值的影响。\n\n\n\n### labelSmoothing\n\n精度提升不明显，但是缓解了验证集的loss上升。\n\n```python\nclass LabelSmoothingCrossEntropy(nn.Module):\n    def __init__(self, eps=0.1, reduction='mean'):\n        super(LabelSmoothingCrossEntropy, self).__init__()\n        self.eps = eps\n        self.reduction = reduction\n\n    def forward(self, output, target):\n        c = output.size()[-1]\n        log_preds = F.log_softmax(output, dim=-1)\n        if self.reduction == 'sum':\n            loss = -log_preds.sum()\n        else:\n            loss = -log_preds.sum(dim=-1)\n            if self.reduction == 'mean':\n                loss = loss.mean()\n        return loss * self.eps / c + (1 - self.eps) * F.nll_loss(log_preds, target, reduction=self.reduction)\n```\n\n\n\n### 对抗训练\n\n提升两个点以上\n\n可参考我的 [ppt](https://coding-zuo.github.io/adversary/index.html) 和以前文章\n\n主要使用了fgm和pgd两个，都有提升的效果\n\n但有时候pgd并没有提升，可能是在有些参数和加了伪标签的数据情况下，学习困难？\n\n\n\n### 早停\n\nbert的早停不太好控制，有时候一两个epoch之后还会更新，可能跟参数有关。\n\n\n\n\n\n## 模型改进\n\n### 尝试用LongFormer\n\n因为文本比较长，但因为没有时间测试而没有跑，不过已经基本调通，日后跑一跑。\n\n\n\n### 复现DUMA\n\n用co-attention 来分别处理 bert输出的文章编码和问题答案对编码，分别送到co-attention中。\n\n我的方法是分别为文章和问题答案设置一个maxlen， 多的截掉，因为我机器只能最大总长度跑到400，而数据文章又比较长，可能这也会导致学习瓶颈的出现。\n\n我的另一个实现想法但是没有时间做的是，把文章和问题答案拼在一起用sep分割送入bert，输出时只要找到sep的timesteps进行分割，对于得到的两个不等长的向量，在经过对其。送入co-attention。\n\n训练刚开始有一个比较好的提分劲头，但随着深入训练后期效果乏力。可能是因为参数没有调好？DUMA那篇论文没有复现细节。\n\n\n\n### 尝试其他比赛前排模型\n\n![](https://i.loli.net/2021/05/01/f1QIsuWtSVXCcBx.png)\n\n移植后问题：训练集准确率很低，具体问题还需探究。\n\n\n\n### 尝试在bert后加self-attention层\n\n用pool_output,投入自注意力，没有明显提升\n\n在bert后加多层线性也没有明显提升。不过可以尝试加highway network。\n\n\n\n## 模型融合\n\n组合不同参数和结构的打包模型，用argmax的方法融合了九个，达到最好的51.7分，晋级分数最终为52分，遗憾落榜。\n\n还尝试用实现vote投票来融合，并没有最终提交。\n\n以后将会尝试实现bert的stacking融合。\n\n\n\n## 遇到的难题\n\n1. bert换成roberta后始终不收敛，因为没有经验，学习率试过1e-5, 1e-6, 2e-5,和不同batch32、64、128进行组合都不收敛(浪费了很多时间)。最终发现学习率在1e-5,2e-5 ,batch 在8或16才会收敛。\n\n   并参照roberta论文附录中的参数，收敛了，但是效果没有达到预期，不过听说好多人也是用了roberta。\n\n![](https://i.loli.net/2021/05/01/7vZQHiFus6DqJI2.png)\n\n2. 调参没经验，浪费了很多时间。\n\n\n\n## 总结\n\n用了将近一个月的时间来做这个比赛，对模型训练体系、模型理解、微调下游任务、多卡并行、对抗训练。还有好多理论需要通过实践来加深理解。\n\n\n\n\n\n\n\n\n\n\n\n","tags":["DataGame"]},{"title":"阅读理解文献梳理","url":"/2021/04/29/阅读理解文献梳理/","content":"\n# 阅读理解文献梳理\n\n\n\n## 多跳QA\n\n\n\n### 模型在任务中学习的多跳推理行为。\n\nQFE (Nishida et al., 2019) regards evidence extraction as a query-focused summarization task, and reformulates the query in each hop.    将证据提取作为以查询为中心的摘要任务，并在每一跳中重构查询。—— HGN\n\nKosuke Nishida, Kyosuke Nishida, Masaaki Nagata, Atsushi Otsuka, Itsumi Saito, Hisako Asano, and Junji Tomita. 2019. Answering while summarizing: Multi-task learning for multi-hop qa with evidence extraction. In *ACL*.\n\n---\n\n DecompRC (Min et al., 2019b) decomposes a compositional question into simpler sub-questions and leverages single-hop MRC mod- els to answer the sub-questions.  将作文问题分解为更简单的子问题，并利用单跳MRC模型答复子问题—— HGN\n\nSewon Min, Victor Zhong, Luke Zettlemoyer, and Han- naneh Hajishirzi. 2019b. Multi-hop reading compre- hension through question decomposition and rescor- ing. In *ACL*.\n\n---\n\nA neural modular network is also proposed in Jiang and Bansal (2019b), where neural modules are dynamically assembled for more interpretable multi-hop rea- soning.一种神经模块网络，其中神经模块被动态地组装起来，以便更好地解释多跳推理。—— HGN\n\nYichen Jiang and Mohit Bansal. 2019b. Self- assembling modular networks for interpretable multi-hop reasoning. In *EMNLP*.\n\n----\n\n其他\n\nJifan Chen and Greg Durrett. 2019. Understanding dataset design choices for multi-hop reasoning. In *NAACL*.—— HGN\n\nSewon Min, Eric Wallace, Sameer Singh, Matt Gard- ner, Hannaneh Hajishirzi, and Luke Zettlemoyer. 2019a. Compositional questions do not necessitate multi-hop reasoning. In *ACL*.—— HGN\n\nYichen Jiang and Mohit Bansal. 2019a. Avoiding rea- soning shortcuts: Adversarial evaluation, training, and model development for multi-hop qa. In *ACL*.—— HGN\n\n-----\n\n### 与GNN相关的\n\nCoref-GRN (Dhingra et al., 2018) construct an entity graph based on co-reference reso- lution or sliding windows.基于共引用解决方案或滑动窗口构建实体图。—— HGN\n\nBhuwan Dhingra, Qiao Jin, Zhilin Yang, William W Cohen, and Ruslan Salakhutdinov. 2018. Neural models for reasoning over multiple mentions using coreference. In *NAACL*.\n\n----\n\nEntity-GCN (De Cao et al., 2019) considers three different types of edges that connect different entities in the entity graph.考虑连接实体图中不同实体的三种不同类型的边。—— HGN\n\nNicola De Cao, Wilker Aziz, and Ivan Titov. 2019. Question answering by reasoning across documents with graph convolutional networks. In *NAACL*.\n\n---\n\n**(已读)**HDE-Graph (Tu et al., 2019) enriches information in the entity graph by adding document nodes and creating interactions among documents, entities and answer candidates.通过添加文档节点并在文档、实体和候选答案之间创建交互，丰富了实体图中的信息。——HGN\n\n---\n\n**(已读)**Cognitive Graph QA employs an MRC model to predict answer spans and possible next-hop spans, and then organizes them into a cognitive graph.使用MRC模型预测答案跨度和可能的下一跳跨度，然后将它们组织到认知图中。——HGN\n\n----\n\nDFGN (Xiao et al., 2019) constructs a dynamic entity graph, where in each reasoning step irrelevant en- tities are softly masked out and a fusion module is designed to improve the interaction between the entity graph and documents.构建了一个动态实体图，在每个推理步骤中，不相关的实体被软屏蔽，并设计了一个融合模块来改善实体图与文档之间的交互性。——HGN\n\nYunxuan Xiao, Yanru Qu, Lin Qiu, Hao Zhou, Lei Li, Weinan Zhang, and Yong Yu. 2019. Dynamically fused graph network for multi-hop reasoning. In *ACL*.\n\n-----\n\n**(已读)**SAE (Tu et al., 2020) defines three types of edge in the sentence graph based on the named entities and noun phrases appearing in the question and sentences 根据问题和句子中出现的命名实体和名词短语，定义句子图中的三种边——HGN\n\n----\n\nC2F Reader (Shao et al., 2020) uses graph attention or self-attention on entity graph, and argues that this graph may not be necessary for multi-hop reasoning. 在实体图上使用图注意或自我注意，并认为该图对于多跳推理可能不是必需的。——HGN\n\nNan Shao, Yiming Cui, Ting Liu, Wang, and Guop- ing Hu Hu. 2020. Is graph structure necessary for multi-hop reasoningt. *arXiv preprint arXiv:2004.03096*.\n\n------\n\nAsai et al. (2020) proposes a new graph-based recurrent method to find evidence documents as reasoning paths, which is more focused on information retrieval.提出了一种新的基于图的递归方法来寻找证据文档作为推理路径，更侧重于信息检索。——HGN\n\nAkari Asai, Kazuma Hashimoto, Hannaneh Hajishirzi, Richard Socher, and Caiming Xiong. 2020. Learning to retrieve reasoning paths over wikipedia graph for question answering. In *ICLR*.\n\n----\n\n**(已读)**HGN 2020 提出的模型构建了一个层次图，有效地探索了不同粒度之间的关系，并使用不同的节点来执行不同的任务。\n\n\n\n## GNN\n\n### GNN结构机制\n\n- GCN\n- SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS(ICLR 2017)\n- GAT\n- GraphSage\n- MPGNN\n- HGN\n- HAN\n\n### 预训练GNN\n\nHu, W.; Liu, B.; Gomes, J.; Zitnik, M.; Liang, P.; Pande, V. S.; and Leskovec, J. 2020. Strategies for Pre-training Graph Neural Networks. In *Proceedings of ICLR*.——L2P-GNN\n\n提出了不同的策略来预训练图神经网络的节点和图级，虽然在图级需要标记的数据。\n\n----\n\nHu, Z.; Fan, C.; Chen, T.; Chang, K.; and Sun, Y. 2019. Pre-Training Graph Neural Networks for Generic Structural Feature Extraction. *CoRR* abs/1905.13728..——L2P-GNN\n\n使用三个非监督任务预先培训图形编码器，以捕获图形的不同方面。\n\n-----\n\nNavarin, N.; Tran, D. V.; and Sperduti, A. 2018. Pre-training Graph Neural Networks with Kernels. *CoRR* abs/1811.06930..——L2P-GNN\n\n利用图内核进行预培训\n\n\n\n## 元学习及应用\n\nFinn, C.; Abbeel, P.; and Levine, S. 2017. Model-agnostic meta-learning for fast adaptation of deep networks. In *Pro- ceedings of ICML*, 1126–1135.\n\nLu, Y.; Fang, Y.; and Shi, C. 2020. Meta-learning on Hetero- geneous Information Networks for Cold-start Recommenda- tion. In *Proceedings of KDD*, 1563–1573.\n\n\n\n## 预训练语言模型\n\n- ALBERT\n- Roberta\n- Bert\n- LongFormer\n\n## 对抗训练\n\n- FGM\n- PGD\n- FreeLB\n\n\n\n\n\n\n\n\n\n","tags":["GNN&nlp"]},{"title":"Hierarchical Graph Network for Multi-hop Question Answering","url":"/2021/04/29/Hierarchical-Graph-Network-for-Multi-hop-Question-Answering/","content":"\n# Hierarchical Graph Network for Multi-hop Question Answering\n\nhttps://arxiv.org/pdf/1911.03631.pdf\n\n这篇文章也是HotpotQA数据集上的关于解决多跳问答场景的，在干扰项排行榜和全维基排行榜都曾是前列。\n\n多跳QA和HotpotQA数据集 : [HotpotQA数据集：A Dataset for Diverse, Explainable Multi-hop Question Answering](https://coding-zuo.github.io/2021/03/23/HotpotQA%E6%95%B0%E6%8D%AE%E9%9B%86/)\n\n其特点是\n\n- 通过在问题、段落、句子、实体等不同粒度上构建层次图(HGN)\n- 通过HGN这种节点粒度层次可以区分，进一步进行多任务推理：段落选择、支持句预测、实体抽取、最终答案预测\n\n## 如何构图\n\n首先来介绍下作者是如何构图的。\n\n![](https://i.loli.net/2021/05/01/sux1NI4eMgf2bcz.png)\n\n段落由句子组成，每个句子包含多个实体。这个图自然是以层次结构编码的，它也激发了作者构建层次图的动机。\n\n四种节点类型：\n\n- 问题节点Q\n- 实体节点E\n- 段落节点P：对于每个段落节点，在段落中的所有句子之间添加边。\n- 句子节点S：对于每个句子节点，提取句子中的所有实体，并在段落句子节点和这些实体节点之间添加边。\n\n七种边类型：\n\n- 问题节点和定位段落节点有边\n- 问题节点和问题中的实体节点有边\n- 段落节点和段落中的句子节点有边\n- 句子节点与其链接的段落节点之间的边(超链接链接)\n- 句子节点和句子中所提取的实体节点有边\n- 段落和段落之间有边(论文是取和问题最相关的前两个段落)\n- 存在同一个段落的句子节点\n\n\n\n## 挑战与动机\n\nHotpotQA的方案一般是先用一个检索器去找到包含正确答案的段落。然后在用MRC模型去选择段落去预测答案。\n\n目前的挑战：即使通过多个段落成功地确认了推理链，如何从分散的段落中收集不同粒度级别的证据共同回答并支持事实预测，仍然是一个关键的挑战。\n\n作者认为多跳阅读推理直观的步骤：\n\n- 找到与问题相关的段落\n- 在段落中选择强有力的证据\n- 从获得的证据中查明正确答案\n\n作者也是这么实现的，并创新的采用了多个层级的粒度信息去构图推理。\n\n\n\n## HGN \n\n![](https://i.loli.net/2021/05/05/6eL2w9WqRcPdIMj.png)\n\n模型包含四个模块：图构造模块、上下文编码模块、图推理模块、多任务预测模块\n\n### 图构造模块\n\n就是构造上文的七种边四种节点，形成层级图\n\n一共要考虑两步：\n\n- 选择相关段落：\n\n  第一跳：用预训练模型加一个二分类判断段落中是否包含支撑事实，\n\n  如果返回多个段落则选择排名靠前的两个作为段落节点。\n\n  如果标题匹配没有结果，则进一步搜索段落中包含问题实体的。\n\n  如果还是搜索失败，将会从段落排序中选择排名最高的段落。\n\n  确定第一跳后：下一步就是段落中找到可以通向其他相关段落的事实和实体(不再依赖实体链接，这可能会很引入噪音，而是在第一跳段落中使用超链接来发现第二跳段落。)\n\n  \n\n- 添加表示所选段落内的句子/实体之间的连接的边。\n\n### 上下文编码模块\n\n给出构建的层次图，下一步是获得所有图节点的初始表示。首先将所有选定的段落合并到上下文C中，将其与问题Q连接起来，输入Roberta。\n\n$C = \\{c_0,c_1,...,c_{n-1}\\} \\in \\text{R}^{n\\times d } , Q =\\{q_0,q_1,...,q_{m-1}\\}\\in \\text{R}^{m\\times d}$\n\n问题Q随后是一个双向注意力层。(2017. Bidirectional attention flow for machine comprehension. *ICLR*.)\n\n在上下文表示C之上用BiLSTM，并且从BILSTM的输出中提取不同节点的表示，表示为$M∈R^{n×2d}$。\n\n在BiLSTM后通过预测开始和结束位置来得到句子和实体节点。\n\n$p_i$ 第i段落节点、$s_i$ 第i句子节点、 $e_i$ 第i个实体节点、q 问题节点 $\\in \\text{R}^d$\n$$\n\\begin{equation}\\begin{split} \n p_i &= MLP_1 ([M[P^{(i)}_{start}][d:]; M[P^{(i)}_{end}][:d] ])\\\\\n  s_i &= MLP_2 ([M[S^{(i)}_{start}][d:]; M[S^{(i)}_{end}][:d] ])\\\\\n  e_i &= MLP_3 ([M[E^{(i)}_{start}][d:]; M[E^{(i)}_{end}][:d] ])\\\\\n  q &= \\text{max-pooling}(Q)\n    \\end{split}\\end{equation}\n$$\n\n\n\n\n### 图推理模块\n\n获得层次图所需要的节点：\n\n- 段落节点：$P = \\{p_i\\}^{n_p}_{i=1} , n_p=4$   \n- 句子节点：$S = \\{s_i\\}^{n_s}_{i=1}, n_s=40$\n- 实体节点：$E = \\{e_i\\}^{n_e}_{i=1}, n_e=60$\n\n定义图的临界矩阵为$H =  \\{q,P,S,E\\} \\in \\text{R}^{g\\times d }  , g= n_p+n_s+n_e+1$\n\n 经过GAT后，得到更新过后的每个节点表示$P',S',E',q'$\n\n为了让图信息进一步提取上下文答案跨度，这里还用更新后的节点表示H‘和之前的上下文表示M，通过一个门控注意力机制，用于答案跨度的预测。\n\n具体表示为：\n$$\n\\begin{equation}\\begin{split} \n C &= Relu(MW_m) \\cdot Relu(H'W'_m)^T\\\\\n \\hat H &= Softmax(C)\\cdot H'\\\\\n G &= \\sigma([M;\\hat H]W_s) \\cdot Tanh([M;\\hat H]W_t)\n    \\end{split}\\end{equation}\n$$\n其中：$W_m \\in \\text{R}^{2d\\times 2d}$ ，$W’_m \\in \\text{R}^{2d\\times 2d}$ ，$W_s \\in \\text{R}^{4d\\times 4d}$ , $W_t\\in \\text{R}^{4d\\times 4d}$\n\n\n\n### 多任务预测模块\n\n- 基于段落节点的段落选择\n- 基于句子节点的支撑事实预测\n- 基于实体节点和上下文G表示的答案预测\n\n最终目标函数\n$$\n\\begin{equation}\\begin{split} \n \\text{L}_{joint} = \\text{L}_{start} +\\text{L}_{end} + \\lambda_1\\text{L}_{para} + \\lambda_2\\text{L}_{sent} + \\lambda_3\\text{L}_{entity} + \\lambda_4 \\text{L}_{type}\n    \\end{split}\\end{equation}\n$$\n其中$\\lambda_{1,2,3,4}$ 超参数权重\n\n$L_{type}$ 是预测答案类型的损失\n\n\n\n## 错误分析\n\n![](https://i.loli.net/2021/05/05/ephOUw7zXAcK3bH.png)\n\n作者在这分析了模型的弱点(为将来的工作提供了见解)，在dev集中随机抽样了100个答案f1为0的示例。\n\n作者总结了六类错误\n\n- Annotation批注：数据集中提供的批注不正确 \n\n  上图第一行：“Tonka”和“101只斑点狗”是在同一个十年上映的吗？数据集给的答案和实际情况不一样？这种应该是数据集错误吧， 这种错误占了9%。这种问题应该不是模型的弱点吧？\n\n- Multiple-Answers：问题可能有多个正确答案，但数据集中只提供一个答案\n\n  迈克尔·J·亨特取代了成为哪家机构管理员的律师？答案EPA是预测答案的缩写，这种问题也比较难解决，占了24%是比重最多的。\n\n- Discrete Reasoning:  这种类型的错误经常出现在“比较”题中，需要离散推理才能正确回答问题； 16%\n\n  在Mastodon和Hole这两个乐队中，哪个成员更多？ 可能是已知这两个乐队人数，要比较这两个数的大小\n\n- Commonsense & External Knowledge： 要回答这类问题，需要常识或外部知识\n\n  迷你专辑Code#01的艺人第二次延长演出的名字是什么？\n\n- Multi-hop：模型不能进行多跳推理，从错误的段落中找到最终答案 16%\n\n  这部根据5：15出现的摇滚歌剧改编的电影是谁导演的？\n\n- MRC:  模型正确地找到了支持段落和句子，但预测了错误的答案跨度。 20%\n\n  艾达·洛夫莱斯，第一位计算机程序员，在“恰尔德·拜伦”中与拜伦勋爵有什么关系？答案是他的女儿，模型回答成紧张的关系，说明模型没有完全理解问题中的关系。\n\n\n\n可以看出HGN对于阅读理解的进行鲁棒性的回答还是有所不足，面对相同答案的多样性还有进一步的改进空间。\n\n对于句子理解和推理定位还不够特别准确。\n\n\n\n\n\n\n\n\n\n","tags":["GNN&nlp"]},{"title":"二分模板","url":"/2021/04/29/二分模板/","content":"\n# 二分模板\n\nhttps://www.acwing.com/problem/content/791/\n\n二分的本质不是单调性, 单调性的题目一定可以二分, 可以二分的题目不一定有单调性\n\n二分的本质是边界\n二分法用于查找, 每次都选择答案所在的区间再次进行查找, 当区间长度为 1时, 就是答案\n\n![](https://i.loli.net/2021/04/29/Hy4vGqOtus8lQXp.png)\n\n1. 根据 check(mid)来判断 r和 l的取值范围\n2. 根据取值范围选择 mid是否有 + 1操作\n   - mid归于左边, r = mid, mid选择 不 +1\n   - mid归于右边, l = mid, mid选择 +1\n\n```java\nimport java.io.BufferedReader;\nimport java.io.IOException;\nimport java.io.InputStreamReader;\nimport java.util.Arrays;\n\npublic class 模板_二分 {\n\n    public static void main(String[] args) throws IOException {\n        BufferedReader input = new BufferedReader(new InputStreamReader(System.in));\n        int[] line1 = Arrays.asList(input.readLine().split(\" \")).stream().mapToInt(Integer::parseInt).toArray();\n        int n = line1[0];\n        int q = line1[1];\n        int[] line2 = Arrays.asList(input.readLine().split(\" \")).stream().mapToInt(Integer::parseInt).toArray();\n\n        while (q-- != 0) {\n            int target = Integer.parseInt(input.readLine());\n            // 查找左边界 用第一个模板\n            int index_l = bsearch_1(line2, 0, n - 1, target);\n            if (line2[index_l] != target) {\n                System.out.println(\"-1 -1\");\n            } else {\n                System.out.print(index_l + \" \");\n                // 查找右边界 用第二个模板\n                int index_r = bsearch_2(line2, 0, n - 1, target);\n                System.out.print(index_r + \"\\n\");\n            }\n        }\n    }\n\n    public static int bsearch_1(int[] arr, int l, int r, int target) {\n        while (l < r) {\n            int mid = l + r >> 1;\n            if (arr[mid] >= target) {\n                r = mid;\n            } else {\n                l = mid + 1;\n            }\n        }\n        return l;\n    }\n\n    public static int bsearch_2(int[] arr, int l, int r, int target) {\n        while (l < r) {\n            int mid = l + r + 1 >> 1;\n            if (arr[mid] <= target) {\n                l = mid;\n            } else {\n                r = mid - 1;\n            }\n        }\n        return l;\n    }\n\n}\n```\n\n","tags":["刷题"]},{"title":"归并排序模板","url":"/2021/04/28/归并排序模板/","content":"\n# 归并排序模板\n\n分治思想\n\n![](https://i.loli.net/2021/04/28/8g1qixHscOBTv6Q.png)\n\n1. 确定分界点：$mid = (l+r)/2$\n\n2. 先递归分成左右两边\n\n3. 将两个有序数组合并成一个有序序列——归并\n\n   使用两个指针：这个过程时间复杂度为$O(n)$\n\n![](https://i.loli.net/2021/04/28/d23pUiKgLOswDZm.png)\n\n整体时间复杂度$O(nlogn)$\n\n因为分层用了$logn$次\n\n![](https://i.loli.net/2021/04/28/WeSTDRHymJbg5KN.png)\n\n```java\nimport java.io.BufferedReader;\nimport java.io.IOException;\nimport java.io.InputStreamReader;\n\npublic class 模板_归并排序 {\n\n\n    public static void main(String[] args) throws IOException {\n        BufferedReader input = new BufferedReader(new InputStreamReader(System.in));\n        int n = Integer.parseInt(input.readLine());\n        int[] q = new int[n];\n        String[] linelist = input.readLine().split(\" \");\n        for (int i = 0; i < linelist.length; i++) {\n            q[i] = Integer.parseInt(linelist[i]);\n        }\n\n        merge_sort(q, 0, q.length - 1);\n\n        for (int i = 0; i < q.length; i++) {\n            System.out.print(q[i]);\n            System.out.print(\" \");\n        }\n\n    }\n\n\n    public static void merge_sort(int[] q, int l, int r) {\n        if (l >= r) return;\n        // 确定分界点\n        int mid = l + ((r - l) >> 1);\n        // 递归\n        merge_sort(q, l, mid);\n        merge_sort(q, mid + 1, r);\n\n        int[] tmp = new int[r - l + 1]; // 辅助数组\n        // 归并\n        int k = 0; // 表示tmp中有多少个数\n        // 两个指针\n        int i = l, j = mid + 1;\n        while (i <= mid && j <= r) {\n            if (q[i] <= q[j]) {\n                tmp[k++] = q[i++];\n            } else {\n                tmp[k++] = q[j++];\n            }\n        }\n        // 剩余\n        while (i <= mid) tmp[k++] = q[i++];\n        while (j <= r) tmp[k++] = q[j++];\n        // 放回\n        for (i = l, j = 0; i <= r; i++, j++) q[i] = tmp[j];\n    }\n}\n```","tags":["刷题"]},{"title":"Ubantu18.04安装NVIDIA驱动+cuda10.1+cuDNN+Tensorflow2.1.0","url":"/2021/04/26/Ubantu18-04安装NVIDIA驱动-cuda10-1-cuDNN-Tensorflow2-1-0/","content":"\n# Ubantu18-04安装NVIDIA驱动-cuda10-1-cuDNN-Tensorflow2-1-0\n\n注意：TensorFlow2.1 要求 你的GPU算力要达到3.5，检查自己GPU算力\n\n## 安装和卸载NVIDIA驱动\n\n首先要确保驱动已经卸载干净\n\n```\nsudo apt-get purge nvidia*\nsudo apt-get autoremove\n```\n\n检查自己GPU版本，之后到官网去下载，这种办法安装比较稳妥，其他网络安装办法有时候出错不知道咋回事。\n\n```\nlshw -numeric -C display\n```\n\n\n\n![](https://i.loli.net/2021/04/26/tDVckAHU8B7dnla.png)\n\n下载驱动网址：https://www.nvidia.cn/Download/index.aspx?lang=cn\n\n![](https://i.loli.net/2021/04/26/ruzlX3qQ6Ndat9I.png)\n\n禁用Nouveau\n\n```\nNouveau驱动禁用方法：\n\nsudo gedit /etc/modprobe.d/blacklist.conf\n或者\nsudo vim /etc/modprobe.d/blacklist.conf\n \n在最后两行添加：\n \nblacklist nouveau\noptions nouveau modeset=0     // 禁用nouveau第三方驱动，之后也不需要改回来\n \n执行\n \nsudo update -initramfs -u   // 更新内核\n```\n\n\n\n关闭lightdm\n\n\n\n```\nsudo service lightdm stop\n\n　sudo init 3 # 遇见X Server报错执行 \n\n rm -rf /tmp/.X*\n\n ./NVIDIA-Linux-x86_64-418.165.02.run #开始安装驱动 遇见continue就continue 遇见ok就ok\n```\n\n![](https://i.loli.net/2021/04/26/Wf7Imlx8PyKqtUG.png)\n\n## 安装cuda10.1\n\nhttps://tensorflow.google.cn/install/source#linux\n\n在这个网站上对好版本，版本不对可不行，全是坑 \n\nhttps://developer.nvidia.com/cuda-toolkit-archive 选择版本\n\n然后在这里下载cuda 我用的是deb的办法也是本地下载后安装的。**（我这个网络可能是不行，总是apt-get update 总是报错 所以这个方法没成功用runfile成功了。。。）参考一下吧** \n\n![](https://i.loli.net/2021/04/26/wVXLYjvD5zHTNRu.png)\n\n安装\n\n```\nsudo dpkg -i cuda-repo-ubuntu1804-10-0-local-10.0.130-410.48_1.0-1_amd64.deb\nsudo apt-key add /var/cuda-repo-<version>/7fa2af80.pub\nsudo dpkg -i cuda-repo-ubuntu1804-10-0-local-10.0.130-410.48_1.0-1_amd64.deb\nsudo apt-get update\nsudo apt-get install cuda\n```\n\n添加环境变量：\n\n打开 .bashrc\n\n sudo vim ~/.bashrc\n\n```\nexport CUDA_HOME=/usr/local/cuda \nexport PATH=$PATH:$CUDA_HOME/bin \nexport LD_LIBRARY_PATH=/usr/local/cuda-10.1/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}\n```\n\nsource ~/.bashrc\n\nnvcc -V\n\n\n\n## runfile安装cuda\n\n下载runfile\n\n![](https://i.loli.net/2021/04/26/7G8c26kofdjJQBh.png)\n\n![](https://i.loli.net/2021/04/26/LI4shCiMqcKaNQB.png)\n\n一定要取消掉driver 此处！！！，因为已经装了驱动了\n\n![](https://i.loli.net/2021/04/26/5CmNy6BrOIiDlkp.png)\n\n\n\n```python3\nsudo vim ~/.bashrc\n```\n\n\n\n我们在文件最后一行添加：\n\n```\n$ export PATH=/usr/local/cuda-10.1/bin:/usr/local/cuda-10.1/NsightCompute-2019.1${PATH:+:${PATH}}\n$ export LD_LIBRARY_PATH=/usr/local/cuda-10.1/lib64\\\n                         ${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}\n```\n\n\n\n```text\nsource ~/.bashrc\n```\n\n\n\n![](https://i.loli.net/2021/04/26/VDZRTx76oi8MeuK.png)\n\n\n\n## 安装TensorFlow2.1.0_gpu \n\n这上面虽然没写2.1.0_gpu 可是还得得装gpu版\n\n![](https://i.loli.net/2021/04/26/LNxBI3jmDrcGUVT.png)\n\n\n\n完成后 \n\nconda install cudatoolkit=10.1\n\n![](https://img2020.cnblogs.com/blog/1225390/202010/1225390-20201031135739329-731523260.png)\n\n\n\n## 安装cuDNN\n\nhttps://developer.nvidia.com/cudnn\n\n去下载对应版本，但是要登录一下\n\n解压后\n\n```\nsudo cp cuda/include/cudnn.h /usr/local/cuda/include\nsudo cp cuda/lib64/libcudnn* /usr/local/cuda/lib64\nsudo chmod a+r /usr/local/cuda/include/cudnn.h \nsudo chmod a+r /usr/local/cuda/lib64/libcudnn*\n```\n\n以配置cuDNN环境。\n\n通过\n\n```\ncat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2\n```\n\n\n\n查看cuDNN版本\n\nover\n\n\n\n\n\n\n\n","tags":["配置记录"]},{"title":"快速排序模板","url":"/2021/04/26/快速排序模板/","content":"\n快速排序模板\n\n\n\n![](https://i.loli.net/2021/04/26/voAgqKV12i9Rxuz.png)\n\n1. 先确定分界点：$q[l] 、 q[(l+r)/2]、 q[r]$ 或随机\n2. 调整区间：小于等于x的在左半边，大于等于x的在右半边 (如何去调整)\n3. 递归处理左右两段\n\n## 由数据反推算法复杂度和算法内容\n\n![](https://i.loli.net/2021/05/14/i9EQsUqAYdW1rcB.png)\n\n\n\n## 实现\n\n\n\n暴力：\n\n- 声明两个数组 a[] 、b[]\n- 将$q[l~r]$ 遍历 \n- 如果 $q[i] \\le x$ 放到a[]中   \n- 如果 $q[i] \\ge x$ 放到b[]中   \n- 再将a、b数组放回q中\n\n优美：\n\n用两个指针，swap\n\n\n\n[关于JAVA中IO流类：BufferredReader的简单用法](https://blog.csdn.net/qq_42369555/article/details/82745923)\n\nbufferreader要比scanner快\n\n```java\npackage code;\n\nimport java.io.BufferedReader;\nimport java.io.IOException;\nimport java.io.InputStreamReader;\nimport java.util.Collections;\n\npublic class 快排模板 {\n\n    public static void main(String[] args) throws IOException {\n        BufferedReader input = new BufferedReader(new InputStreamReader(System.in));\n        int n = Integer.parseInt(input.readLine());\n        int[] q = new int[n];\n        String[] linelist = input.readLine().split(\" \");\n        for (int i = 0; i < linelist.length; i++) {\n            q[i] = Integer.parseInt(linelist[i]);\n        }\n\n        quick_sort(q, 0, q.length - 1);\n\n        for (int i = 0; i < q.length; i++) {\n            System.out.print(q[i]);\n            System.out.print(\" \");\n        }\n\n    }\n\n    public static void quick_sort(int[] q, int l, int r) {\n        if (l >= r) return;\n        int x = q[l];\n        int i = l - 1;\n        int j = r + 1;\n        while (i < j) {\n            do i++; while (q[i] < x);\n            do j--; while (q[j] > x);\n            if (i < j) {\n                int t = q[i];\n                q[i] = q[j];\n                q[j] = t;\n            }\n        }\n        quick_sort(q, l, j);\n        quick_sort(q, j + 1, r);\n    }\n\n\n}\n\n```\n\n\n\n\n\n\n\n","tags":["刷题"]},{"title":"DP分析——石子合并","url":"/2021/04/24/DP分析——石子合并/","content":"\n# DP分析——石子合并\n\n设有 NN 堆石子排成一排，其编号为 1，2，3，…，N。\n\n每堆石子有一定的质量，可以用一个整数来描述，现在要将这 N 堆石子合并成为一堆。\n\n每次只能合并相邻的两堆，合并的代价为这两堆石子的质量之和，合并后与这两堆石子相邻的石子将和新堆相邻，合并时由于选择的顺序不同，合并的总代价也不相同。\n\n例如有 4 堆石子分别为 `1 3 5 2`， 我们可以先合并 1、2堆，代价为 4，得到 `4 5 2`， 又合并 1，2 堆，代价为 9，得到 `9 2` ，再合并得到 11，总代价为 4+9+11=244+9+11=24；\n\n如果第二步是先合并 2，3 堆，则代价为 7，得到 `4 7`，最后一次合并代价为 11，总代价为 4+7+11=22。\n\n问题是：找出一种合理的方法，使总的代价最小，输出最小代价。\n\n#### 输入格式\n\n第一行一个数 N 表示石子的堆数 N。\n\n第二行 N 个数，表示每堆石子的质量(均不超过 1000)。\n\n#### 输出格式\n\n输出一个整数，表示最小代价。\n\n#### 数据范围\n\n1≤N≤300     1≤N≤300\n\n#### 输入样例：\n\n```\n4\n1 3 5 2\n```\n\n#### 输出样例：\n\n```\n22\n```\n\n## 解\n\n![](https://i.loli.net/2021/04/24/CqE9QcaxYBzZKRw.png)\n\n![](https://i.loli.net/2021/04/24/gPlOsK5oXFcWutE.png)\n\n\n\n```java\npublic class DP_石子合并 {\n\n    public static void main(String[] args) {\n        Scanner scanner = new Scanner(System.in);\n        int N = scanner.nextInt();\n        int[] s = new int[N + 1];  //前缀和\n        for (int i = 1; i <= N; i++) {\n            s[i] = scanner.nextInt();\n            s[i] += s[i - 1];\n        }\n        int[][] dp = new int[N + 1][N + 1];\n\n        for (int len = 2; len <= N; len++) {//先枚举区间长度\n            for (int i = 1; i + len - 1 <= N; i++) {//再枚举区间左端点\n                int j = i + len - 1; //右端点\n                dp[i][j] = 100000000;\n                for (int k = i; k < j; k++) {\n                    dp[i][j] = Math.min(dp[i][j], dp[i][k] + dp[k + 1][j] + s[j] - s[i - 1]);\n                }\n            }\n        }\n        System.out.println(dp[1][N]);\n    }\n}\n```\n\n$O(n^3)$ \n\n---\n\n# 最长公共子序列\n\n给定两个长度分别为 N 和 M 的字符串 A 和 B，求既是 A 的子序列又是 B 的子序列的字符串长度最长是多少。\n\n#### 输入格式\n\n第一行包含两个整数 N 和 M。\n\n第二行包含一个长度为 N 的字符串，表示字符串 A。\n\n第三行包含一个长度为 M 的字符串，表示字符串 B。\n\n字符串均由小写字母构成。\n\n#### 输出格式\n\n输出一个整数，表示最大长度。\n\n#### 数据范围\n\n1≤N,M≤1000       1≤N,M≤1000\n\n#### 输入样例：\n\n```\n4 5\nacbd\nabedc\n```\n\n#### 输出样例：\n\n```\n3\n```\n\n\n\n## 解\n\n最坏情况下 aaaa,aaaaa，A中所有都是由 $2^n$ 个不同子序列。\n\n![](https://i.loli.net/2021/04/24/oxH4yliYPD23LeQ.png)\n\n![](https://i.loli.net/2021/04/24/dVY9UmoHTticMPC.png)\n\n\n\n```java\npublic static void main(String[] args) {\n        Scanner scanner = new Scanner(System.in);\n        int N = scanner.nextInt();\n        int M = scanner.nextInt();\n        String strA = \" \" + scanner.next();\n        String strB = \" \" + scanner.next();\n//        char[] A = strA.toCharArray();\n//        char[] B = strB.toCharArray();\n\n        int[][] dp = new int[N + 1][M + 1];\n\n        for (int i = 1; i <= N; i++) {\n            for (int j = 1; j <= M; j++) {\n                dp[i][j] = Math.max(dp[i - 1][j], dp[i][j - 1]);\n                if (strA.charAt(i) == strB.charAt(j)) {\n                    dp[i][j] = Math.max(dp[i][j], dp[i - 1][j - 1] + 1);\n                }\n            }\n        }\n        System.out.println(dp[N][M]);\n    }\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["DP"]},{"title":"Select, Answer and Explain-Interpretable Multi-hop Reading Comprehension over Multiple Documents","url":"/2021/04/22/Select-Answer-and-Explain-Interpretable-Multi-hop-Reading-Comprehension-over-Multiple-Documents/","content":"\n# Select, Answer and Explain: Interpretable Multi-hop Reading Comprehension over Multiple Documents\n\n\n\n## 摘要\n\n选择、回答和解释(SAE)系统解决多文档RC问题。\n\n首先主要创新，用文档分类器过滤掉与答案无关的文档，从而减少分散注意力的信息量。\n\n然后将所选择的答案相关文档输入到模型以联合预测答案和支持句子。\n\n该模型在答案预测的表征层和支持句子预测的句子层都设置了多任务学习目标，\n\n并在这两个任务之间进行了基于注意力的交互，对模型进行了优化。\n\n关键词：过滤无关文档、多任务学习、混合注意力交互\n\n![](https://i.loli.net/2021/04/22/yArGlY6zuT7eMsW.png)\n\n## 在HotpotQA中什么是gold doc\n\nHotpotQA通过为答案提供支持句来鼓励可解释的QA模型，这些支持句通常来自多个文档，如果文档包含答案或包含对答案的支持句，则称为“黄金文档”。\n\n\n\n应答文本，它可以是一段文本或“是/否”。\n\n作者从答案和支持句标签导出GOLD文档标签。我们使用 $D_i$ 表示文档 i：如果Di是黄金文档，则标记为1，否则标记为0。还将答案类型标记为以下注释之一：“Span”、“Yes”和“No”。\n\n\n\n\n\n ## 选择gold doc(过滤文档)\n\n答案预测和支持句预测的上游任务。将分类排名最靠前的文档作为预测的黄金文档 gold doc。\n\n![](https://i.loli.net/2021/04/22/EapiyjuwNbPt49l.png)\n\n做文档过滤最直接做法就是采用bert的CLS摘要向量，做交叉熵分类\n$$\n\\begin{equation}\\begin{split} \n L = -\\sum_{i=0}^n t_ilogP(D_i) + (1-t_i) log(1-P(D_i))\n    \\end{split}\\end{equation}\n$$\n$t_i$ 是 $D_i$ 的标签，n是文档数，$P(D_i)$ 是文档i在标签 $t_i$ 中的概率。\n\n这种简单的方法的缺点：单独处理每个文档，而不考虑下游多跳推理任务所必需的文档间交互和关系。\n\n为解决此问题，作者提出了一个新的模型，如图上图CLS后，加了一层多头注意力层。\n\n意在：增加对从不同文档生成的“CLS”标记的关注的动机是鼓励文档间的交互。文档间交互对于文档间的多跳推理至关重要。\n\n优化：采用了新的成对学习排序损失。还将问题从分类问题描述为两两学习排序问题，\n\n通过将文档与所有其他文档进行比较，该模型能够更好地将一小部分黄金文档与睡觉分散注意力的文档区分开来。\n\n给每个文档一共分数 $S(.)$\n\n如果 $D_i$ 是gold doc $S(D_i) = 1 $, 否则 $S(D_i) = 0$\n\n然后，标记每对输入文档：给定一对输入文档 $(D_i，D_j)$，标签 $l$设置为：\n$$\n\\begin{equation}\\begin{split} \n l_{i,j} = \n\\begin{cases}\n 1, &if\\ S(D_i) \\gt S(D_j) \\\\\n 0 , &if\\  S(D_i) \\le S(D_j)\n\\end{cases}\n    \\end{split}\\end{equation}\n$$\n还认为包含答案范围的文档对于下游任务更重要。因此，如果$D_i$是包含答案跨度的黄金文献，$S(D_i)=2$。\n\n再将MHSA输出传递给双线性层来输出每对文档的概率，双线性层基于二元交叉熵进行训练，如下所示：\n$$\n\\begin{equation}\\begin{split} \n L = - \\sum_{i=0,j=0}^n \\sum_{j\\neq i} l_{i,j} logP(D_i,D_j) + (1-l_{i,j}) log(1-P(D_i,D_j))\n    \\end{split}\\end{equation}\n$$\n相关性定义为$ R_i=􏰅\\sum_j^n(P(D_i，D_j)>0.5)$。将来自该相关性排序的前k个排序的文档作为的过滤文档。\n\n\n\n\n\n## 答案和解释\n\n模型采用多任务学习的方式进行训练，以联合预测答案和对黄金文档的支持意义。\n\n基于GNN构建多跳推理图，将上下文语句嵌入作为节点，而不是像以往的工作那样以实体作为节点，直接输出带有答案预测的支持语句。\n\n为什么不用NER因为作者认为：\n\n目前GNN在QA任务中的应用通常需要实体作为图形节点，并且通过在具有上下文信息的节点上进行消息传递来实现推理。这仅在预定义的一组目标实体可用时才有可能。否则，需要使用命名实体识别(NER)工具来提取实体，这可能会导致图推理中的冗余实体和噪声实体。如果答案不是命名实体，则需要进一步处理以定位最终答案。\n\n token-level and sentence-level 多任务学习\n\n\n\n基于一种新的混合注意池机制\n\n将GNN中使用的上下文语句嵌入归结到令牌表示上。注意力权重是根据令牌表示上的答案广度日志和自我注意输出来计算的。这种基于注意力的交互能够利用“回答”和“解释”任务之间的互补信息。\n\n\n\n### 答案预测\n\n针对bert输出的每一个$H_i$ 用两层MLP做答案起始位置预测 $L$ 为长度\n$$\n\\begin{equation}\\begin{split} \n \\hat Y &= f_{span} (H^i) \\in R^{L\\times2}\\\\\n L ^{span} &= \\frac{1}{2}(CE(\\hat Y[:,0], y^{start}) + CE(\\hat Y[:,1], y^{end}))\n    \\end{split}\\end{equation}\n$$\n其中$\\hat Y$的第一行是起始位置的逻辑，第二行是结束位置的逻辑。$y^{star}t$和 $y^{end}$ 是范围 [0，L-1] 中的开始位置和结束位置的标签。CE表示交叉熵损失函数。\n\n\n\n### 支持句预测\n\n预测输入上下文中的句子是否为答案预测的支持证据。为了实现句子级预测，我们首先获得$H_i$中每个句子的序列表示。$H_i$ 是bert的token输出。\n$$\n\\begin{equation}\\begin{split} \n S^j - H[j^s:j^e,:] \\in R^{L^j\\times d}\n    \\end{split}\\end{equation}\n$$\n$S^j$是表示语句 j 内的标记嵌入的矩阵( 这里省略了样本索引i)。 $j^s$ 和 $j^e$ 定义了开始和结束位置，$L_j$ 是语句$j$ 的长度。\n\n\n\n### 多任务\n\n答案预测任务和支持句预测任务可以相辅相成。\n\n据观察，答案预测任务总是可以帮助支持句子预测任务，因为有答案的句子总是一条证据；\n\n但反过来情况不是一样的，因为可能有多个支持句子，概率最高的句子可能不包含答案\n\n所以答案预测任务总 可以帮助支持句子预测任务，因为有答案的句子总是一个证据；\n\n反之亦然，因为可能有多个支持句子，概率最高的句子可能不包含答案。\n\n因此，为了揭示这两个互补任务之间的相互作用，提出了一种基于注意力的总结句子表示法，以引入来自回答预测的互补信息。\n\n注意力权重的计算方法如下：在Sj上用自我注意计算一部分注意力，另一部分来自答案预测任务的起始位置日志和结束位置日志的总和。\n$$\n\\begin{equation}\\begin{split} \n \\alpha^j &= \\sigma(f_{att}(S^j) + \\hat Y[j^s:j^e,0] + \\hat Y[j^s:j^e,1])\\\\\n s^j &= \\sum^{L^j}_{k=0} \\alpha^j_k S^j[k,:] \\in R^{1\\times d}\n    \\end{split}\\end{equation}\n$$\nSj是表示语句j 的标记嵌入的矩阵\n\n$f_{att}$ 是一个两层MLP输出size为1，$\\sigma$是softmax\n\n$α_j ∈ R^{L^j×1}$表示句子j的每个token上的关注度权重。\n\n### 构建GNN\n\n接下来，在语句嵌入Sj上建立GNN模型，以显式地促进对预测gold doc中所有语句的多跳推理，从而更好地利用复杂的关系信息。使用语句嵌入Sj来初始化图的节点特征。采用基于多关系图卷积网络(GCN)的消息传递策略来更新图的节点特征，并将最终的节点特征输入到MLP中，得到每个句子的分类。\n\n![](https://i.loli.net/2021/04/22/kfrJdNaDZBqyAhV.png)\n\n根据问题和句子中出现的命名实体和名词短语设计了三种类型的边：\n\n- 如果两个节点最初来自同一文档，则在这两个节点之间添加一条边(上图中的实节点)\n- 如果表示两个节点的句子在问题中都具有命名实体或名词短语(可以是不同的)，则在来自不同文档的两个节点之间添加边。(图中的虚线)\n- 如果表示两个节点的句子具有相同的命名实体或名词短语，则在来自不同文档的两个节点之间添加一条边。(图中的虚线)\n\n第一种类型的边的动机是希望GNN掌握每个文档中呈现的全局信息。\n\n第二类和第三类边，为了以更好地捕捉这种跨文档推理路径。跨文档推理是通过从问题中的实体跳到未知的桥梁实体或比较问题中两个实体的属性来实现的 。\n\n\n\n对于消息传递，使用具有门控机制的多关系GCN。\n\n假设 $h^0_j$ 表示从语句嵌入 $S_j$的初始节点嵌入，则一跳(或一层)之后的节点嵌入计算可表示为:\n$$\n\\begin{equation}\\begin{split} \n h_j^{k+1} &= act(u_j^k) \\odot g^k_j + h^k_j \\odot (1-g^k_j) \\\\\n u^k_j &= f_s(h^k_j) + \\sum_{r\\in R} \\frac{1}{|N_j^r|} \\sum_{n\\in N^r_j} f_r(h_n^k)\\\\\n g_j^k &= sigmoid (f_g([u_j^k; h^k_j])) \n    \\end{split}\\end{equation}\n$$\n\n\n其中R 是一些列边类型， $N^r_j$ 是边类型为r的 j 节点的邻居。\n\n$h^k_n$ 是节点n的第k层节点表示。\n\n$f_r、f_s、f_g$中的每一个都定义了输入节点表示上的变换，并且可以使用MLP来实现。\n\n门控$g_j^k$ 是由0和1之间的值组成的向量，用于控制来自计算的更新$u^k_j$ 或来自原始节点表示的信息。\n\n函数$act$表示非线性激活函数。\n\n最后得到每个节点的最终表示 $h_j$ 后用两层MLP 最终预测 。\n\n$\\hat y^{sp}_j = sigmoid(f_{sp}(h_j))$ \n\n\n\n除了支持句子预测任务之外，还在GNN输出之上添加了另一个任务，以说明“Yes/No”类型的问题。\n\n预测任务描述为3类(“Yes”、“No”和“span”)分类\n\n引入：\n\n$h = \\sum_j a_jh_j$\n\n$a = \\sigma(\\hat y^{sp})$\n\n$\\hat y^{ans} = f_{ans}(h)$\n\n最终loss表达为：\n$$\n\\begin{equation}\\begin{split} \n L = \\gamma L^{span} + BCE(\\hat y^{sp}, y^{sp}) + CE(\\hat y^{ans}, y^{ans})\n    \\end{split}\\end{equation}\n$$\n$BCE()$ 二元交叉熵函数\n\n为了考虑不同损失的尺度差异，在跨度损失中加入了一个权重γ。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["GNN&nlp"]},{"title":"DP分析法--01背包问题","url":"/2021/04/20/DP分析法——01背包问题/","content":"\n# DP分析法--01背包问题\n\n从集合角度来分析DP问题，DP问题的题目一般都是从有限集中求得最值的问题。\n\n![](https://i.loli.net/2021/04/20/SlgJ96RzdyGp5fw.png)\n\n[01背包问题](https://www.acwing.com/problem/content/2/)\n\n有 N 件物品和一个容量是 V 的背包。每件物品只能使用一次。\n\n第 i 件物品的体积是 $v_i$，价值是 $w_i$。\n\n求解将哪些物品装入背包，可使这些物品的总体积不超过背包容量，且总价值最大。\n输出最大价值。\n\n#### 输入格式\n\n第一行两个整数，N，V，用空格隔开，分别表示物品数量和背包容积。\n\n接下来有 N 行，每行两个整数 $v_i,w_i$，用空格隔开，分别表示第 i 件物品的体积和价值。\n\n#### 输出格式\n\n输出一个整数，表示最大价值。\n\n#### 数据范围\n\n0<N,V≤10000<N,V≤1000\n0<vi,wi≤10000<vi,wi≤1000\n\n#### 输入样例\n\n```\n4 5\n1 2\n2 4\n3 4\n4 5\n```\n\n#### 输出样例：\n\n```\n8\n```\n\n\n\n\n\n## 解\n\n最多$2^N$, 从$2^N$ 个方案里找总价值最大的方案。——有限集合的最值问题\n\n状态表示：\n\n- 选择问题一般$f(i,j)$ 第一维表示前i个物品,第二维是限制 (经验)\n\n- 集合：所有只考虑前i个物品，且总体积不超过j的选法的集合。\n- 属性：集合中每一个方案的最大价值Max\n\n状态计算：\n\n- 所有不选第i个物品的方案 $f(i-1,j)$\n- 所有选择第i个物品的方案 $f(i-1,j-v_i) + w_i$\n- $Max(f(i-1,j), f(i-1,j-v_i)+w_i)$\n\n```java\nimport java.util.Scanner;\n\npublic class Main{\n    public static void main(String[] args) throws Exception {\n        // 读入数据的代码\n        Scanner reader = new Scanner(System.in);\n        // 物品的数量为N\n        int N = reader.nextInt();\n        // 背包的容量为V\n        int V = reader.nextInt();\n        // 一个长度为N的数组，第i个元素表示第i个物品的体积；\n        int[] v = new int[N + 1] ;\n        // 一个长度为N的数组，第i个元素表示第i个物品的价值；\n        int[] w = new int[N + 1] ;\n\n        for (int i=1 ; i <= N ; i++){\n            // 接下来有 N 行，每行有两个整数:v[i],w[i]，用空格隔开，分别表示第i件物品的体积和价值\n            v[i] = reader.nextInt();\n            w[i] = reader.nextInt();\n        }\n        reader.close() ;\n\n        // 正式工作的代码\n        /*\n        定义一个二阶矩阵dp[N+1][V+1],\n        这里之所以要N+1和V+1，是因为第0行表示只能选择第0个物品的时候，即没有物品的时候\n        第0列表示背包的体积为0的时候，即不能装任何东西的时候\n\n        dp[i][j]表示在 只能选择前i个物品，背包容量为j的情况下，背包中物品的最大价值\n        对于dp[i][j]有两种情况：\n        1. 不选择当前的第i件物品/第i件物品比背包容量要大，则dp[i][j] = dp[i-1][j]\n        2. 选择当前的第i件物品（潜在要求第i件物品体积小于等于背包总容量），则能装入的物品最大价值为：\n            当前物品的价值 加上 背包剩余容量在只能选前i-1件物品的情况下的最大价值\n            dp[i][j] = dp[i-1][j-v[i]] + w[i]\n        dp[i][j]在两种情况中选择比较大的情况作为当前的最优解；\n        即：\n        if(j >= v[i]):\n            dp[i][j] = max(dp[i-1][j], dp[i-1][j-v[i]] + w[i])\n        else:\n            dp[i][j] = dp[i-1][j]\n        */\n        int[][] dp = new int[N+1][V+1];\n        dp[0][0] = 0;\n        for(int i = 1; i <= N; i++){\n            for(int j = 0; j <= V; j++){\n                if(j >= v[i]){\n                    dp[i][j] = Math.max(dp[i-1][j], dp[i-1][j-v[i]] + w[i]);\n                }else{\n                    dp[i][j] = dp[i-1][j];\n                }\n            }\n        }\n        System.out.println(dp[N][V]);\n    }\n}\n\n\n```\n\n优化后\n\n```java\nimport java.util.Scanner;\n\npublic class Main{\n    public static void main(String[] args) throws Exception {\n        // 读入数据的代码\n        Scanner reader = new Scanner(System.in);\n        // 物品的数量为N\n        int N = reader.nextInt();\n        // 背包的容量为V\n        int V = reader.nextInt();\n        // 一个长度为N的数组，第i个元素表示第i个物品的体积；\n        int[] v = new int[N + 1] ;\n        // 一个长度为N的数组，第i个元素表示第i个物品的价值；\n        int[] w = new int[N + 1] ;\n\n        for (int i=1 ; i <= N ; i++){\n            // 接下来有 N 行，每行有两个整数:v[i],w[i]，用空格隔开，分别表示第i件物品的体积和价值\n            v[i] = reader.nextInt();\n            w[i] = reader.nextInt();\n        }\n        reader.close() ;\n\n        // 正式算法的代码\n        // 将dp优化为一维数组\n        /*\n        注意，这里第二层循环的时候，还是小到大循环的话，那么\n\n        dp[i][j] = Math.max(dp[i-1][j], dp[i-1][j-v[i]] + w[i])\n        实际上变成了\n        dp[i][j] = Math.max(dp[i][j], dp[i][j-v[i]] + w[i]);\n\n        因为i-1的值已经在前面被更新过了，覆盖了\n        为了避免这个问题，所以要逆序更新，即先更新第i个，然后更新第i-1个，从而保证第i-1个不被覆盖\n\n        如果不逆序的话，输出结果为10，dp数组实际为：\n        0 0 0 0 0 0 \n        0 2 4 6 8 10\n        0 2 4 6 8 10\n        0 2 4 6 8 10\n        0 2 4 6 8 10\n        */\n        int[] dp = new int[V+1];\n        dp[0] = 0;\n        for(int i = 1; i <= N; i++){\n            for(int j = V; j >= v[i]; j--){\n                dp[j] = Math.max(dp[j], dp[j-v[i]] + w[i]);\n            }\n            // for(int j = 0; j <= V; j++){\n            //     System.out.print(dp[j]);\n            //     System.out.print(\" \");\n            // }\n            // System.out.print(\"\\n\");\n        }\n        System.out.println(dp[V]);\n    }\n}\n\n```\n\n\n\n\n\n\n\n```java\n    public static int o1bagSolutionOptimization(int[] weight, int[] value, int bagWeight) {\n        int num = weight.length;\n        int[] dp = new int[bagWeight + 1];\n        dp[0] = 0;\n        for (int i = 1; i <= num; i++) {\n            for (int j = bagWeight; j >= 1; j--) {\n                if (j >= weight[i - 1]) {\n                    dp[j] = Math.max(dp[j], dp[j - weight[i - 1]] + value[i - 1]);\n                }\n            }\n        }\n\n\n        return dp[bagWeight];\n    }\n    public static void main(String[] args) {\n        Scanner sc = new Scanner(System.in);\n        int itemsNumber = sc.nextInt();\n        int bagWeight = sc.nextInt();\n        int[][] arr = new int[itemsNumber][2];\n        int[] weight = new int[itemsNumber];\n        int[] value = new int[itemsNumber];\n        for(int i = 0; i < itemsNumber; i++) {\n            for(int j = 0; j < 2; j++) {\n                arr[i][j] = sc.nextInt();\n            }\n            weight[i] = arr[i][0];\n            value[i]=   arr[i][1];\n        }\n        System.out.println(o1bagSolutionOptimization(weight, value, bagWeight));\n    }\n\n\n```\n\n\n\n## 完全背包问题\n\n```java\npublic class 完全背包问题 {\n    // 完全背包和01背包的区别是完全背包中每个物品可以用无限次\n// 01背包：f[i][j] = max(f[i-1][j], f[i-1][j-v]+w)\n// 完全背包：f[i][j] = max(f[i-1][j], f[i][j-v]+w)\n    public static void main(String[] args) throws Exception {\n        Scanner reader = new Scanner(System.in);\n        int N = reader.nextInt();\n        int V = reader.nextInt();\n        int[] v = new int[N + 1];\n        int[] w = new int[N + 1];\n\n        for (int i = 1; i <= N; i++) {\n            v[i] = reader.nextInt();\n            w[i] = reader.nextInt();\n        }\n        reader.close();\n\n        int[] dp = new int[V + 1];\n        dp[0] = 0;\n        for (int i = 1; i <= N; i++) {\n            for (int j = 0; j <= V; j++) {\n                if (j >= v[i]) {\n                    dp[j] = Math.max(dp[j], dp[j - v[i]] + w[i]);\n                }\n            }\n        }\n        System.out.println(dp[V]);\n    }\n\n    // int nativeDp(int n,int m){\n    //     int[] f = new int[maxN];\n    //     for(int i=1;i<=n;i++){\n    //         for(int j=m;j>=v[i];j--){\n    //             for(int k=0;k*v[i]<=j;k++){\n    //                 f[j] = Math.max(f[j], f[j-k*v[i]]+k*w[i]);\n    //             }\n    //         }\n    //     }\n    // }\n}\n```\n\n\n\n\n\n","tags":["DP"]},{"title":"LongFormer:The Long-Document Transformer","url":"/2021/04/18/LongFormer-The-Long-Document-Transformer/","content":"\n# LongFormer:The Long-Document Transformer\n\n主要记录一些Longfromer的原理和使用时的细节。\n\n## 摘要\n\n针对的问题：\n\n- 基于Transformer的模型，由于self-attention的操作，导致不能处理很长的序列。\n- self-attention的处理规模和序列长度是成二次关系的。\n\n![](https://i.loli.net/2021/04/18/3YtkrO18p2dAvmV.png)\n\n因为self-attention对于每个token都要计算打分，也就是缩放点积中的$QK^T$ 矩阵运算。\n\n这相当于对每个token之间都照顾到了注意信息。\n\n每个token代表一个小格，自注意力机制的QK都是自己，所以是个正方形。\n\n为解决这个问题，作者引入了三种具有随序列长度线性缩放的注意机制，将规模缩减成线性。\n\n分别是局部窗口注意和任务激活的全局注意力。\n\n并且还提供了LongFormer的预训练模型。\n\n定义了生成结构为Long-Forward-Encoding-Decoder(LED) \n\n\n\n\n\n## 引入&相关工作\n\n熟知的Bert等预训练模型，最大长度为512，多的就要截断，这样可能会潜在地导致重要的跨分区信息丢失问题。\n\n然而当时已有的针对解决长文本的方法，都是基于自回归语言模型的。\n\n而LongFormer是可以应用于迁移学习环境中的文档级NLP任务的。\n\n![](https://i.loli.net/2021/04/18/KNJa3dZx6fCG8eH.png)\n\n之后可能会读几篇。ltr从左到右的模型，其受益于双向语境(自回归或从左到右的语言建模被粗略地定义为在给定输入序列中的先前符号/字符的情况下估计现有符号/字符的概率分布)。\n\nspare代表模型通过稀疏性来进行优化。\n\nGenerating long se-quences with sparse transformers.其使用由BlockSparse提供的大小为8x8的块的扩展滑动窗口的形式，但没有探索预训练设置。等等\n\n\n\n## LongFormer\n\n原始Transformer的自注意力机制有$O(n^2)$ 的时间和空间内存复杂度。\n\n为了解决这个问题，作者根据指定相互关注的输入位置对的“注意模式”来稀疏完整的自我注意矩阵\n\n与full self-attention不同的是，提出的注意力模式与输入序列成线性关系，这使得它对较长的序列是有效的。\n\n### 注意力模式\n\n#### 滑动窗口 (Sliding Window)\n\n设固定窗口大小为 w，transformer层数为$l$, token的每边 $\\frac{1}{2}w$  计算复杂度为$O(n\\times w)$\n\n![](https://i.loli.net/2021/04/18/XaDokntURBWdNSe.png)\n\n作者认为：根据应用程序的不同，为每个图层使用不同的w值可能有助于在效率和模型表达能力之间取得平衡。\n\n\n\n#### 空洞滑窗(Dilated Sliding Window)\n\n类似于CNN的空洞卷积\n\n空洞尺寸 $d$ 感受野是 $l\\times d\\times w$\n\n![](https://i.loli.net/2021/04/18/SxDhujGwCVIvt2g.png)\n\n在多头注意力中，每个注意力头部计算不同的注意力分数。\n\n作者发现，每个头具有不同扩张配置设置的话效果会好：\n\n允许一些没有空洞的头部专注于局部语境，而另一些带空洞的则专注于更长的语境，从而提高了性能。\n\n\n\n#### 全局注意力(Global Attention)\n\n![](https://i.loli.net/2021/04/18/tVGNpUa3o9gIluf.png)\n\n例如对于QA，问题和文档连接在一起，允许模型通过自我关注将问题与文档进行比较。\n\n有时需要使用特殊的全局CLS作为整体的表达，所以就需要再这某些个关键点地方计算全局注意力，关注每一个token。其他的还是滑窗的形式。\n\n我们在几个预先选择的输入位置添加了“全局关注”。\n\n由于这样的记号token的数量相对于n很小，并且与n无关，因此组合的局部和全局注意的复杂度仍然是O(N)。\n\n这时，计算打分函数就可以分为两组QKV，分别是全局的$Q_g,K_g,V_g$ 和 滑窗局部的 $Q_s,K_s,V_s$\n\n昂贵的运算是矩阵乘法 $QK^T$，因为Q和K都具有n(序列长度)投影。对于LongFormer，空洞滑动窗口注意只计算固定数量$QK^T$的对角线。\n\n在实现的时候主要用到了带状乘法。还定制了特别的CUDA内核。。\n\n\n\n### 对于自回归的语言模型\n\n可以使用空洞滑动窗口注意力，并且可以跨层使用不同尺寸的窗口，效果可能更佳。\n\n对较低层使用较小的窗口大小，并在移动到较高层时增加窗口大小\n\n这允许顶层了解整个序列的较高级别表示，同时使较低层捕获本地信息。此外，它还在效率和性能之间取得平衡。\n\n(窗口大小越小，非零值越少，计算开销越小)\n\n(窗口大小越大，表示能力更丰富，通常会带来性能提升)\n\n\n\n## 实验\n\n和训练长文本的模型进行对比 ，BPC值越小越好\n\n![](https://i.loli.net/2021/04/18/Oxo2A1SCsaIeDL8.png)\n\n\n\n## 在QA上的Finetuning\n\n分别采用了我比较关注的多文档数据集 WikiHop/HotpotQA(干扰榜)/TriviaQA\n\n将问题和文档连接成一个长序列放入Longformer，最后加一个预测层。\n\n![](https://i.loli.net/2021/04/18/lqTB5cSPrD8Z3w7.png)\n\n### WikiHop\n\n数据特点：\n\n- 候选答案个数由2个到79个不等。\n\n- 文章段落数量由3段到63段不等\n\n数据集不为多跳推理链提供任何中间注释，需要模型代之以从间接答案监督中推断它们。\n\n数据预处理：\n\n将问题和答案与特殊令牌连接在一起\n\n$ [q] question [/q] [ent] candidate1 [/ent] ... [ent] candidateN [/ent] $\n\n上下文也是使用文档分隔符进行间隔\n\n$</s> context1 </s> ... </s> contextM </s>$\n\n在准备好输入数据后，从每个模型的顶层开始计算活动。获取问题和答案候选并将它们连接到尽可能多的上下文直到模型序列长度(Roberta为512，LongFormer为4,096)，在模型中运行序列，收集输出激活，并重复，直到用尽所有上下文(除了LongFormor-Large之外的所有模型，由于存储器要求，我们只包括第一个4,096长度的序列)。然后，将所有块的所有激活连接成一个长序列。在Longformer的下，使用全局注意力来关注整个问答候选序列。\n\n最终预测，对每个[ent] 附加一个线性层，输出一个logit，最后平均所有候选答案的logits。 用softmax和交叉熵得出最终答案。\n\n优化策略：\n\nAdam、Linear warmup超过200梯度更新对于最大LR，然后linear decay剩余训练。\n\n使用梯度累积最终batch达到32\n\n其他超参Dropout weight decay 都和Roberta相同。\n\n对LR[2e-5，3e-5，5e-5]和epoch[5，10，15]进行网格搜索。\n\nLR=3e-5，15个epoch是最好的Longform-Base配置。\n\n\n\n### TriviaQA\n\nTriviaQA有超过10万个问题、答案、文档。\n\n文档是维基百科文章，答案是文章中提到的命名实体。\n\n回答问题的跨度没有注释，但可以使用简单的文本匹配找到它。\n\n数据预处理：\n\n$[s] question [/s]document [/s]$\n\n在所有问题符号上都使用全局注意力。\n\n\n\n## HotpotQA\n\n使用两阶段首先确定相关段落，然后确定最终答案范围和证据。\n\n这主要是因为首先删除分散注意力的段落，可以降低最终认识和范围检测的噪声，这一点也被发现非常重要此数据集中最新的最新方法。\n\n数据预处理：\n\n$[CLS] [q] question [/q] ⟨t⟩ title1 ⟨/t⟩ sent1,1 [s] sent1,2 [s] ...⟨t⟩ title2 ⟨/t⟩ sent2,1 [s] sent2,2 [s] ...$\n\n使用全局注意力来问句标记、段落计时开始标记以及句子标记。\n\n在段落标题顶部增加了前馈层，用于预测相关段落的开始标记，以及用于预测证据句子的句子标记。\n\n在对第一阶段模型进行训练后，预测了训练集和开发集的相关段落得分。然后，保留最多5个原始得分高于预先指定的阈值(-3.0)的段落，并从上下文中删除其他段落。然后，根据得到的缩短上下文训练第二阶段模型。\n\n将跨度、问题分类、句子和段落损失结合起来，使用线性损失组合对模型进行多任务训练。\n\n使用ADAM优化器对模型进行了训练，并进行了线性warmup(1000步)和线性衰减。我们使用最小超参数调整，使用3E-5和5E-5的LR和3到7的epoch，发现LR为3E-5和5个历元的模型效果最好。\n\n![](https://i.loli.net/2021/04/19/LuOCHUx1eMPwDW9.png)\n\n","tags":["nlp"]},{"title":"Kaggle上传dataset的方法","url":"/2021/04/15/Kaggle上传dataset的方法/","content":"\n# Kaggle快速上传dataset的方法\n\n\n\n## 原理\n\n从国内上传到有cdn的地方(如GitHub), 再在kaggle的kernel上下载下来，直接上传dataset。\n\n\n\n## 方法\n\n\n\n首先需要掌握kaggle-api的使用，kaggle-api是kaggle官方提供的命令行工具，可以从命理完成比赛数据的下载、dataset下载上传，获取榜单等操作。\n\nhttps://github.com/Kaggle/kaggle-api\n\n本地安装：pip install kaggle\n\nKaggle已经安装好了，不用再安装\n\n\n\n步骤1：下载账户API json\n\nhttps://www.kaggle.com/me/account\n\n步骤2：在页面创建一个dataset\n\nhttps://www.kaggle.com/datasets\n\n步骤3：下载dataset的metadata\n\n运行：kaggle datasets metadata shopee-models\n\n步骤4：下载数据集并上传到dataset\n\n完整代码：\n\n```sh\n# 将API json文件写到这里\n!mkdir /root/.kaggle\nlines = '''{\"username\":\"写你的用户名\",\"key\":\"写你的key\"}'''\nwith open('/root/.kaggle/kaggle.json', 'w') as up:    \n\t\tup.write(lines)\n# 创建文件夹，写入dataset的metadata\n!mkdir hubmapkidneysegmentation\nlines = '''{\n\t\"id\": \"finlay/shopee-models\",\n\t\"id_no\": 122348,\n\t\"title\": \"shopee_models\",\n\t\"subtitle\": \"\",\n\t\"description\": \"\",\n\t\"keywords\": [],\n\t\"resources\": []\n}'''\nwith open('hubmapkidneysegmentation/dataset-metadata.json', 'w') as up:\n\t\tup.write(lines)\n# 下载文件，这里用axel多线程下载，直接用wget也可以的。\n!apt-get install axel\n!axel -n 12 https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b7-dcc49843.pth -o hubmapkidneysegmentation/baseline_fold0_densenet_224_epoch50.pth\n# 上传文件，这里会覆盖上传\n!kaggle datasets version -p ./hubmapkidneysegmentation -m \"Updated data fcn\"\n```\n\n","tags":["DataGame"]},{"title":"DUMA: Reading Comprehension with Transposition Thinking","url":"/2021/04/14/DUMA-Reading-Comprehension-with-Transposition-Thinking/","content":"\n# DUMA: Reading Comprehension with Transposition Thinking\n\nDUMA：DUal Multi-head Co-Attention model\n\n这是一篇针对解决多项选择任务的MRC网络结构。题目中的Transposition Think，被作者赋义为分别从文章和问题的角度来考虑对方的关注点。\n\n主要特点：\n\n- 基于预训练语言模型(得到表示编码，替代复杂的匹配网络)\n- 衔接多层co-attention(从三元组中捕捉关系)\n\n多项选择任务可以抽象为(文章P，问题q，选项a) 三元组。\n\n针对多项选择的特点多项选择MRC尤其依赖于匹配网络的设计，它被认为是有效地捕捉文章、问题和答案三元组之间的关系。(不能只考虑推理如何做的更好，还要考虑答案出现的关键位置也就是匹配网络的作用)\n\n \n\n文中总结的人在做阅读理解题时的特点：\n\n- 快速通读文章的整体内容，问题和回答选项，以建立全局印象，然后进行换角度思考过程。\n- 根据问答选项的特有信息，重新考虑文章的细节，收集问答选项的支持证据。\n- 根据文章中的特有信息，重新考虑问题和答案选项，以确定正确的选项，排除错误的选项。\n\n当人们重读文章时，他们倾向于根据对问答选项的印象提取关键信息，重读问答选项时也是如此\n\n\n\n---\n\n## DUMA\n\n多项选择问题可以定义模型需要学习一个概率分布$F(A_1,A_2,...,A_t|P,Q)$\n\n![](https://i.loli.net/2021/04/14/IE9asGiRTlLJNV2.png)\n\nEncoder 接受文本输入生成一个全局序列表达，这个过程类似人类第一次阅读整个内容以获得总体印象。\n\nDecoder则收集所有信息的答案预测以选择正确答案选项。\n\nDUMA层位于encoder和decoder之间，意在模仿人类转换思考角度的过程，从问题文章和关键词中捕捉关系信息。\n\n\n\n\n\n### Encoder\n\n作者用的是PrLMs，其将文章、问题和所有不同的候选答案拼接作为输入。\n\n$P=[p_1,p_2,..,p_m]$    ， $Q=[q_1,q_2,...,q_n]$ ,   $A=[a_1,a_2,...,a_k]$\n$$\n\\begin{equation}\\begin{split} \n E = Enc(P \\oplus Q \\oplus A )\n \\end{split}\\end{equation}\n$$\n这个输入到预训练的方式可能会遇到点问题，一般预训练语言模型比如bert都会限制一个输入的大小，如果文章过长的话，模型看不到问题和选项可能会导致训练效果不佳。可以改为 Q、A、P的形式，因为一般Q和A都比较短。\n\n$E = [e_1,e_2,...,e_{m+n+k}]$  \n\n$e_i$ 为固定维度$d_{model}$ 的向量，是各自的token。\n\n### Dual Multi-head Co-Attention\n\n使用双多头共同注意模型来计算文章和问答的attention表征。(可堆叠k层)\n\n其实就是一个多头co-attention，定义一个Q、K、V (Q不是上面的问题Q)\n\n先从E中分离出$E^P = [e^P_1,e^P_2,...,E^P_{t_p}]$、$E^{QA} = [e^{qA},e^{qA},...,E^{qA}_{t_{q_a}}]$\n\n使用两种计算attention的方法：\n\n- $E^P$ 做Query ，$E^{QA}$ 做 Key和Value\n\n- $E^{QA}$ 做Query ，$E^{P}$ 做 Key和Value\n\n$$\n\\begin{equation}\\begin{split} \n Attention(E^P,E^{QA},E^{QA}) &= softmax(\\frac{E^P(E^{QA})^T}{\\sqrt{d_k}})E^{QA}\\\\\n head_i &= Attention(E^PW^Q_i,E^{QA}W^K_i)\\\\\n MIIA(E^P, E^{QA}, E^{QA}) &= Concat(head_1,head_2,...,head_h) W^O\\\\\n MHA_1 &= MHA(E^P, E^{QA}, E^{QA}) \\\\\n MHA_2 &= MHA(E^{QA}, E^{P}, E^P) \\\\\n DUMA (E^P, E^{QA}) &= Fuse(MHA_1,MHA_2)\\\\\n    \\end{split}\\end{equation}\n$$\n\n \n\n其中$W_i^Q \\in R^{d_{model} \\times d_q}$ 、 $W_i^K \\in R^{d_{model} \\times d_k}$、  $W_i^V \\in R^{d_{model} \\times d_q}$ 、$W_i^O \\in R^{hd_v \\times d_{model}}$  : h 头数\n\n$MHA$: 多头注意力\n\n$Fuse$ 函数先使用均值池化来汇集$MHA(·)$的序列输出，然后再聚合两个池化的输出。\n\n后文实验了三种聚合方法 元素乘法  元素相加  concat\n\n表示在决定哪个是最佳答案选项之前，对所有关键信息进行混合。\n\n### Decoder\n\n$$\n\\begin{equation}\\begin{split} \n O_i &= DUMA(E^P, E^{QA_i}) \\\\\n L(A_r|P,Q) &= -log\\frac{exp(W^TO_r)}{\\sum_{i=1}^s exp(W^TO_i)}\n \\end{split}\\end{equation}\n$$\n\ns 是选项数量\n\n\n\n## Multi-choice MRC数据集\n\nDREAM and RACE\n\n![](https://i.loli.net/2021/04/14/63cBOaFhfGIgd58.png)\n\n## 实验\n\n![](https://i.loli.net/2021/04/14/3tQ1BCvzHSo9bTU.png)\n\n![](https://i.loli.net/2021/04/14/NchfAZRWxCIuQeS.png)\n\n![](https://i.loli.net/2021/04/14/d6JDXcVaTEmZPLF.png)\n\n","tags":["nlp"]},{"title":"FREELB: ENHANCED ADVERSARIAL TRAINING FOR NATURAL LANGUAGE UNDERSTANDING","url":"/2021/04/09/FREELB-ENHANCED-ADVERSARIAL-TRAINING-FOR-NATURAL-LANGUAGE-UNDERSTANDING/","content":"\n# FreeLB: Enhanced Adversarial Training For Natural Language Understanding\n\n[nlp中的对抗训练](https://coding-zuo.github.io/2021/04/07/nlp%E4%B8%AD%E7%9A%84%E5%AF%B9%E6%8A%97%E8%AE%AD%E7%BB%83-%E4%B8%8Ebert%E7%BB%93%E5%90%88/)\n\n承接上文，上文主要讲对抗训练的原理与物理意义与发展，对抗性训练是创建健壮神经网络的一种方法。在对抗性训练期间，小批次的训练样本受到对抗性扰动的污染，然后用于更新网络参数，直到得到的模型学会抵抗此类攻击，并且对模型起到了正则化的效果，提高模型泛化能力并且防止过拟合。\n\n这篇论文结合现在流行的预训练模型或transformer模型只能结合到下游任务的embedding中。\n\n提出FreeLB算法在GLUE上结合Roberta达到了当时的SOTA，是基于Transformer的自然语言理解和常识推理任务模型来做对抗。\n\n\n\n## 摘要\n\n对抗性训练可以最小化标签保留输入扰动的最大风险，已被证明对提高语言模型的泛化能力是有效的。\n\nFreeLB (Free Large-Batch)，通过在单词嵌入中添加对抗性扰动，并最小化输入样本周围不同区域内的对抗性风险，从而提高了嵌入空间的不变性。\n\n在GLUE基准上的实验表明，当仅应用于精调阶段时，它能够将BERT-BASE模型的整体测试分数从78.3提高到79.4，将Roberta-Large模型的测试分数从88.5提高到88.8。\n\n\n\n## 创新点\n\n针对PGD算法的问题：当K较小时，基于PGD的对抗性训练仍然会导致高度卷积和非线性的损失面，在更强的对手下很容易被打破，当K大时计算开销又很大。\n\n利用最近提出的“Free”训练策略在不同范数约束下用多样化的对抗样本来丰富训练数据，\n\n“Free”的对抗性训练算法在一次反向传递中同时更新模型参数和对抗性扰动。\n\n还使用将大部分对抗性更新限制在第一层，有效减少的对抗过程正反向传播总量。\n\n比PGD计算成本小，能在大规模的预训练模型上进行对抗训练。\n\n\n\n## 文本的对抗样本(对手) \n\n1. 黑盒环境下对embedding进行扰动(对手不是从样本进行攻击)\n2. 在输入中添加分散注意力的句子(人工)\n3. 用GANs将输入投影到潜在空间，并搜索接近原始的文本对手\n\n![](https://i.loli.net/2021/04/09/daKoDQkv35hwmEP.png)\n\n第二三算是一种辅助模型，数据增强的一种形式。\n\n如何在没有人工评估的情况下通过单词/字符替换来构建保留标签的对抗性示例仍然不清楚，因为每个单词/字符的含义取决于上下文。\n\n所以主要还是采用第一种进行对抗训练。\n\n因为词的输入表达有很多种，像词embedding、句子embedding和位置embedding。作者和其他对抗训练一样只干扰词embedding和拼接词的embedding。\n\n注意，基于Embedding的对手严格来说比更传统的基于文本的对手更强大，因为对手可以在单词嵌入上进行在文本域中不可能进行的操作。因为CV都是从样本层面进行扰动，这个扰动从embedding上扰动，相当于在更高级的层面，所以更强大。\n\n## FreeLB\n\n此前预训练语言模型对于下游任务已被证实很有效。\n\n作者的目标是通过在下游语言理解任务的精调过程中增强它们在嵌入空间中的鲁棒性，进一步提高这些预先训练的语言模型在下游语言理解任务上的泛化能力。\n\n由于这篇论文只对对抗性训练的效果感兴趣，而不是产生实际的对抗性示例，因此使用基于梯度的方法在输入句子的嵌入中添加范数有界的对抗性扰动。\n\n定义模型的输入One-hot向量为 $ Z=[z_1,z_2,...,z_n]$\n\n嵌入矩阵为V\n\n语言模型看成是一个 $y=f_{\\theta}(X), X=VZ$ , y是模型输出 $\\theta$是可学习参数。\n\n定义对抗扰动为 $\\delta$ \n\n新的预测输出变为 $y'=f_{\\theta}(X+\\delta)$\n\n为了保持语义，我们将δ的范数限制为较小，并假设模型的预测在扰动后不会改变。\n\n上面的定义和其他人的研究基本都是相同的，FreeLB区别在于不要求X归一化。\n\nFreeLB吸取了FreeAT和YOPO加速方法, 几乎不需要任何开销就可以获得参数的梯度。实现了与标准PGD训练模型相当的健壮性和泛化能力，只使用与自然训练相同或略多的正反向传播。\n\n### FreeAT (Free Adversarial Training): NIPS2019\n\n从FGSM到PGD，主要是优化对抗扰动的计算，虽然取得了更好的效果，但计算量也一步步增加。对于每个样本，FGSM和FGM都只用计算两次，一次是计算x的前后向，一次是计算x+r的前后向。而PGD则计算了K+1次，消耗了更多的计算资源。因此FreeAT被提了出来，在PGD的基础上进行训练速度的优化。\n\nFreeAT的思想是在对每个样本x连续重复m次训练，计算r时复用上一步的梯度，为了保证速度，整体epoch会除以m。r的更新公式为：\n$$\n\\begin{equation}\\begin{split} \n r_{t+1} = r_t + \\epsilon \\cdot sign(g)\n    \\end{split}\\end{equation}\n$$\n伪代码：\n\n```text\n初始化r=0\n对于epoch=1...N/m:\n  对于每个x:\n    对于每步m:\n      1.利用上一步的r，计算x+r的前后向，得到梯度\n      2.根据梯度更新参数\n      3.根据梯度更新r\n```\n\n缺点：FreeLB指出，FreeAT的问题在于每次的r对于当前的参数都是次优的（无法最大化loss），因为当前r是由r(t-1)和theta(t-1)计算出来的，是对于theta(t-1)的最优。\n\n代码：[https://github.com/mahyarnajibi...](https://link.zhihu.com/?target=https%3A//github.com/mahyarnajibi/FreeAdversarialTraining/blob/d70774030871fa3207e09ce8528c1b84cd690603/main_free.py%23L160)\n\n### YOPO (You Only Propagate Once): NIPS2019\n\n代码：[https://github.com/a1600012888/YOPO-You-Only-Propagate-Once](https://link.zhihu.com/?target=https%3A//github.com/a1600012888/YOPO-You-Only-Propagate-Once)\n\n可以参考[加速对抗训练——YOPO算法浅析](https://zhuanlan.zhihu.com/p/95904001)\n\n极大值原理PMP(Pontryagin's maximum principle)是optimizer的一种，它将神经网络看作动力学系统。这个方法的优点是在优化网络参数时，层之间是解藕的。通过这个思想，我们可以想到，既然扰动是加在embedding层的，为什么每次还要计算完整的前后向传播呢？\n\n基于这个想法，作者想复用后几层的梯度，假设p为定值：\n\n![[公式]](https://www.zhihu.com/equation?tex=p+%3D+%5Cnabla_%7Bg_%7B%5Ctilde%5Ctheta%7D%7D%28l%28g_%7B%5Ctilde%5Ctheta%7D%28f_0%28x_i%2Br_i%5E%7Bj%2C0%7D%2C+%5Ctheta_0%29%29%2Cy_i%29%29%5Ccdot%5Cnabla_%7Bf_0%7D%28g_%7B%5Ctilde%5Ctheta%7D%28f_0%28x_i%2Br_i%5E%7Bj%2C0%7D%2C+%5Ctheta_0%29%29%29+%5C%5C)\n\n则对r的更新就可以变为\n\n![[公式]](https://www.zhihu.com/equation?tex=r_i%5E%7Bj%2Cs%2B1%7D+%3D+r_i%5E%7Bj%2Cs%7D%2B%5Calpha_1p%5Ccdot%5Cnabla_%7Br_i%7Df_0%28x_i%2Br_i%5E%7Bj%2Cs%7D%2C%5Ctheta_0%29+%5C%5C)\n\n我们可以先写出YOPO的梯度下降版本：\n\n```text\n对于每个样本x\n初始化r(1,0)\n对于j=1,2,...,m:\n  1.根据r(j,0),计算p\n  对于s=0,1,...,n-1:\n    2.计算r(j,s+1)\n  3.另r(j+1,0)=r(j,n)\n```\n\n作者又提出了PMP版本的YOPO，并证明SGD的YOPO是PMP版的一种特殊形式。这样每次迭代r就只用到embedding的梯度就可以了。\n\nYOPO还主张在每次反向传播后，应将第一隐层的梯度作为常数，利用该常数与网络第一层的雅可比的乘积对对手进行多次额外更新，以获得强对手。\n\n### 回到FreeLB\n\n与FreeAT不同的是，YOPO从每个上升步长开始累加参数的梯度，并且只在K个内上升步长之后更新一次参数。\n$$\n\\begin{equation}\\begin{split} \n  min_{\\theta}\\mathbb{E}_{(Z,y)∼ D ,{m∼M }} [\\frac {1}{K}\\sum_{t=0}^{K-1} max_{\\delta_t\\in \\Omega_t\t}L(f_{\\theta}(x+\\delta_t),y)] \n \\end{split}\\end{equation}\n$$\n\n对比 PGD:\n$$\n\\begin{equation}\\begin{split} \n  min_{\\theta}\\mathbb{E}_{(x,y)∼ D} [max_{\\Delta x\\in \\Omega\t}L(x+\\Delta x,y;\\Theta)] \n    \\end{split}\\end{equation}\n$$\n\nFreeLB和PGD主要有两点区别：\n\n1. PGD是迭代K次r后取最后一次扰动的梯度更新参数，FreeLB是取K次迭代中的平均梯度\n2. PGD的扰动范围都在epsilon内，因为伪代码第3步将梯度归0了，每次投影都会回到以第1步x为圆心，半径是epsilon的圆内，而FreeLB每次的x都会迭代，所以r的范围更加灵活，更可能接近局部最优：\n\n![](https://i.loli.net/2021/04/10/ZMxvfdq4FXRn69S.jpg)\n\n它执行多次PGD迭代来构造对抗性实例，并在每次迭代中同时累积“free”参数梯度∇θL。\n\n伪代码：\n\n```text\n对于每个x:\n  1.通过均匀分布初始化r，梯度g为0\n  对于每步t=1...K:\n    2.根据x+r计算前后向，累计梯度g\n    3.更新r\n  4.根据g/K更新梯度\n```\n\n论文中还指出了很重要的一点，就是**对抗训练和dropout不能同时使用**，加上dropout相当于改变了网络结构，会影响r的计算。如果要用的话需要在**K步中都使用同一个mask**。\n\n![](https://i.loli.net/2021/04/10/WTh7O4Ui5YenzNM.png)\n\n\n\n\n\n## 参考文献\n\n[一文搞懂NLP中的对抗训练FGSM/FGM/PGD/FreeAT/YOPO/FreeLB/SMART](https://zhuanlan.zhihu.com/p/103593948)\n\n[对抗训练的理解，以及FGM、PGD和FreeLB的详细介绍](https://blog.csdn.net/weixin_41712499/article/details/110878322)\n\n","tags":["nlp"]},{"title":"图神经网络的对抗攻击","url":"/2021/04/08/图神经网络的对抗攻击/","content":"\n# 图神经网络的对抗攻击\n\n最近要汇报一个关于安全方面的研究。本来打算讲一些和安全擦边的关于nlp对抗训练提升模型鲁棒性的内容，正好和最近学习的阅读理解比赛相关，可以作为一个提分trick。\n\n但老师强调要和安全相关少讲过程。而nlp中的对抗样本不可以加在原始样本中，只能在embedding中加入扰动，这样就没法攻击，多数用来提升模型鲁棒性。所以就拍马研究了一下图网络的对抗攻击。\n\n刚开始了解，希望可以从中找出可以和我研究方向结合的地方。\n\n如有不对的地方还希望联系我指点一下。\n\n[nlp中的对抗训练&与bert结合](https://coding-zuo.github.io/2021/04/07/nlp%E4%B8%AD%E7%9A%84%E5%AF%B9%E6%8A%97%E8%AE%AD%E7%BB%83-%E4%B8%8Ebert%E7%BB%93%E5%90%88/)\n\n在上一篇文章中主要介绍的是对抗训练，其实是一种防御的策略，对提高模型而言FGM相当于加了一个正则项。 \n\n## 图网络攻击难点\n\n- 离散的结构/特征，难以直接利用现有的基于梯度的方法。\n\n- 对于“无法感知”的扰动如何定义。\n\n- 节点分类往往属于直推式学习，训练数据和测试数据联合使用以学习模型，这就使得攻击方法注定是与poisoning/causative attack相关，而非仅是evasion attack。\n\n\n\n\n\n\n\n\n\n\n\n## 参考文献\n\n[图对抗攻击 Graph Adversarial Attack](https://zhuanlan.zhihu.com/p/88934914)\n\n","tags":["GNN"]},{"title":"nlp中的对抗训练&与bert结合","url":"/2021/04/07/nlp中的对抗训练-与bert结合/","content":"\n#  nlp中的对抗训练学习\n\nPPT : https://coding-zuo.github.io/adversary/index.html\n\n由于深度神经网络强大的表示学习能力，在许多领域都取得了很大的成功，包括计算机视觉、自然语言处理、语音识别等。然而，在其卓越性能的背后，深度神经网络作为一个黑箱，缺乏可解释性与鲁棒性，使得它易受到对抗攻击而对抗性攻击的存在可能是深度学习模型的一个固有弱点。\n\n深度学习的对抗一般有两种含义：\n\n- 一是生成对抗网络(Generative Adversarial Network,GAN) 代表一大类先进的生成模型。(这方面我不是很了解)\n- 另一个则是跟对抗攻击、对抗样本相关的领域。(主要关心模型在小扰动下的稳健性)\n\n\n\n## 方法介绍\n\n在CV领域，我们需要通过对模型的对抗攻击和防御来增强模型的稳健型，比如在自动驾驶系统中，要防止模型因为一些随机噪声就将红灯识别为绿灯。\n\n在NLP领域，类似的对抗训练也是存在的，不过NLP中的对抗训练更多是作为一种正则化手段来提高模型的泛化能力！\n\n这使得对抗训练成为了NLP刷榜的“神器”之一，前有微软通过RoBERTa+对抗训练在[GLUE](https://gluebenchmark.com/leaderboard)上超过了原生RoBERTa。\n\n\n\n## 对抗样本\n\n要认识对抗训练，首先要了解“对抗样本”，它首先出现在论文[《Intriguing properties of neural networks》](http://https//arxiv.org/abs/1312.6199)之中。简单来说，它是指对于人类来说“看起来”几乎一样、但对于模型来说预测结果却完全不一样的样本，比如下面的经典例子：\n\n![](https://i.loli.net/2021/04/07/EizJ85fCHyX2drj.png)\n\n“对抗攻击”，其实就是想办法造出更多的对抗样本。\n\n“对抗防御”，就是想办法让模型能正确识别更多的对抗样本。\n\n所谓对抗训练，则是属于对抗防御的一种，它构造了一些对抗样本加入到原数据集中，希望增强模型对对抗样本的鲁棒性；同时，如本文开篇所提到的，在NLP中它通常还能提高模型的表现。\n\n用对抗训练的思路来提升NLP模型，有两个实现角度：\n\n1. 因为nlp的输入通常是one-hot向量，两个one-hot向量其欧式距离恒为$\\sqrt 2$ ，理论上不存在微小的扰动，不想cv图像那样可以对连续实数向量来做。比如，$\\Delta x$ 是实数向量，$x+\\Delta x$还是一个有意义的图。所以很多研究都是在embedding层上做扰动的，因为embedding层是我们自己训练的，所以不太可能出现认为的恶意对抗攻击。\n\n   ![](https://i.loli.net/2021/04/09/daTOFDIU3EtfyGs.png)\n\n2. 这种角度不知道还算不算对抗，但可以说是一种数据增强手段。如上图中下面的问题，经过缩写，添加标点，或者同义词近义词替换等等。通过辅助模型提升鲁棒性。\n\n\n\n## Min-Max\n\n对抗训练可以统一写成如下格式：\n$$\n\\begin{equation}\\begin{split} \n min_{\\theta}\\mathbb{E}_{(x,y)∼ D} [max_{\\Delta x\\in \\Omega\t}L(x+\\Delta x,y;\\Theta)] \n    \\end{split}\\end{equation}\n$$\n其中$D$ 代表训练集，x代表输入，y代表标签，θ是可学习模型参数，L(x,y;θ)是单个样本的loss，Δx是对抗扰动，Ω是扰动空间。\n\n理解为：\n\n1. $max_{\\Delta x\\in \\Omega}L(x+\\Delta x,y;\\theta)$ ，往输入x中注入扰动$\\Delta x$， 目的是希望 $ L(x+\\Delta x,y;\\theta)$ 损失越大越好，也就是让现有模型的预测出错;\n\n2. 当然$\\Delta x$ 不能太大、无约束，否则达不到“看起来几乎一样”的效果，所以$Δx$要满足一定的约束，常规的约束是$‖Δx‖≤ϵ$，其中$ϵ$是一个常数；\n\n3. 构造好对抗样本后，用$x+\\Delta x,y$作为数据去最小化loss，来更新参数$\\theta$ (梯度下降)\n4. 重复执行1.2.3步。\n\n整个对抗训练优化过程是一个max和min交替执行的过程：通过注入max损失，在梯度下降让损失变min。\n\n\n\n## 如何计算$\\Delta x$——快速梯度FGM\n\n$\\Delta x$的目的是增大Loss，而我们知道让loss减少的方法是梯度下降，那反过来，让loss增大的方法自然就是梯度上升，因此可以简单地取\n$$\n\\begin{equation}\\begin{split} \n \\Delta x &= ϵ∇_xL(x,y;θ)\\\\\n ∇_xL(x,y;θ) &= (\\frac {\\partial L }{\\partial x})\n    \\end{split}\\end{equation}\n$$\n求loss对x的梯度，然后根据梯度给Δx赋值，来实现对输入的干扰，完成干扰之后再执行常规的梯度下降。\n\n为了防止$\\Delta x$过大，通常要对 $∇xL(x,y;θ)$ 标准化，常见方式为：\n$$\n\\begin{equation}\\begin{split} \n \t\\Delta x = ϵ \\frac {∇_xL(x,y;θ)}{||∇_xL(x,y;θ)||} \\text{或} \\Delta x=  ϵsign(∇_xL(x,y;θ))\n    \\end{split}\\end{equation}\n$$\n采用右边的取扰动值的算法叫FGSM(ICLR2015)，理解为扰动是沿着梯度方向向损失值的极大值走。\n\n采用左边取扰动值的算法叫FGM(ICLR2017)，理解为在每个方向上都走相同的一步找到更好的对抗样本。\n\n有了$\\Delta x$，得到：\n$$\n\\begin{equation}\\begin{split} \n min_{\\theta}\\mathbb{E}_{(x,y)∼ D} [L(x+\\Delta x,y;\\Theta)] \n    \\end{split}\\end{equation}\n$$\n这就构成了一种对抗训练方法，被称为**Fast Gradient Method（FGM）**，它由GAN之父Goodfellow在论文[《Explaining and Harnessing Adversarial Examples》](https://arxiv.org/abs/1412.6572)首先提出。\n\n此外，对抗训练还有一种方法，叫做**Projected Gradient Descent（PGD）**，其实就是通过多迭代几步来达到让$L(x+Δx,y;θ)$更大的$Δx$（如果迭代过程中模长超过了$ϵ$，[《Towards Deep Learning Models Resistant to Adversarial Attacks》](https://arxiv.org/abs/1706.06083)。在后文....\n\n### 梯度惩罚\n\n假设已经得到对抗扰动 $\\Delta x$ ,更新 $\\theta$ 时，对 L 进行泰勒展开：\n$$\n\\begin{equation}\\begin{split} \n min_{\\theta} \\mathbb{E}_{(x,y)∼ D} [L(x+\\Delta x,y;\\theta)] &\\approx min_{\\theta} \\mathbb{E}_{(x,y)∼ D}[L(x,y;\\theta) + <∇_xL(x,y;θ), \\Delta x>] \\\\\n &= min_{\\theta} \\mathbb{E}_{(x,y)∼ D}[L(x,y;\\theta) + ∇_xL(x,y;θ) \\cdot \\Delta  x ] \\\\\n &= min_{\\theta} \\mathbb{E}_{(x,y)∼ D}[L(x,y;\\theta) + ∇_xL(x,y;θ)^T  \\Delta  x ] \n    \\end{split}\\end{equation}\n$$\n对应的 $\\theta$ 的梯度为:\n$$\n\\begin{equation}\\begin{split} \n ∇_{\\theta} L(x,y;\\theta) + ∇_{\\theta} ∇_xL(x,y;θ)^T  \\Delta  x \n    \\end{split}\\end{equation}\n$$\n代入 $ \\Delta x = ϵ∇_xL(x,y;θ)$:\n$$\n\\begin{equation}\\begin{split} \n &∇_{\\theta} L(x,y;\\theta) + ϵ ∇_{\\theta} ∇_xL(x,y;θ)^T  ∇_xL(x,y;θ)\\\\ &= ∇_{\\theta}(L(x,y;θ) + \\frac{1}{2} ϵ ||∇_xL(x,y;θ)||^2)\n    \\end{split}\\end{equation}\n$$\n这个结果表示，对输入样本施加 $ϵ∇xL(x,y;θ)$ 的对抗扰动，一定程度上等价于往loss里边加入“梯度惩罚”\n$$\n\\begin{equation}\\begin{split} \n \\frac{1}{2} ϵ ||∇_xL(x,y;θ)||^2\n    \\end{split}\\end{equation}\n$$\n\n如果对抗扰动是$ϵ‖∇xL(x,y;θ)‖$ ，那么对应的梯度惩罚项则是$ϵ‖∇xL(x,y;θ)‖$（少了个1/2，也少了个2次方）。\n\n### 几何图像\n\n事实上，关于梯度惩罚，我们有一个非常直观的几何图像。以常规的分类问题为例，假设有n个类别，那么模型相当于挖了n个坑，然后让同类的样本放到同一个坑里边去：\n\n![](https://i.loli.net/2021/04/09/xeOucXmabjkrS4A.png)\n\n梯度惩罚则说“同类样本不仅要放在同一个坑内，还要放在坑底”，这就要求每个坑的内部要长这样：\n\n![](https://i.loli.net/2021/04/09/tHylhowkCpvP2IM.png)\n\n为什么要在坑底呢？因为物理学告诉我们，坑底最稳定呀，所以就越不容易受干扰呀，这不就是对抗训练的目的么？\n\n那坑底意味着什么呢？极小值点呀，导数（梯度）为零呀，所以不就是希望‖∇xL(x,y;θ)‖‖∇xL(x,y;θ)‖越小越好么？这便是梯度惩罚的几何意义了。\n\n![](https://kexue.fm/usr/uploads/2020/03/3963498733.gif)\n\n苏神代码基于keras的：\n\n> https://github.com/bojone/keras_adversarial_training\n\n## Projected Gradient Descent (PGD)\n\n内部max的过程，本质上是一个非凹的约束优化问题，FGM解决的思路其实就是梯度上升，**那么FGM简单粗暴的“一步到位”，是不是有可能并不能走到约束内的最优点呢？**当然是有可能的。于是，一个很intuitive的改进诞生了：Madry在18年的ICLR中，提出了用Projected Gradient Descent（PGD）的方法，简单的说，就是**“小步走，多走几步”**，如果走出了扰动半径为$\\epsilon$的空间，就映射回“球面”上，以保证扰动不要过大：\n\n其中$\\mathcal{S}=\\{r\\in\\mathbb{R}^d:||r||_2 \\leq \\epsilon\\}$ 为扰动的约束空间，$\\alpha$为小步的步长。\n\n作者将这一类通过一阶梯度得到的对抗样本称之为“一阶对抗”，在实验中，作者发现，经过PGD训练过的模型，对于所有的一阶对抗都能得到一个低且集中的损失值，如下图所示：\n\n![](https://i.loli.net/2021/04/09/SosrVAW9UGYNm6T.png)\n\n我们可以看到，面对约束空间 $\\mathcal{S}$ 内随机采样的十万个扰动，PGD模型能够得到一个**非常低且集中的loss分布**，因此，在论文中，作者称PGD为**“一阶最强对抗”**。也就是说，只要能搞定PGD对抗，别的一阶对抗就不在话下了。\n\n```\n对于每个x:\n  1.计算x的前向loss、反向传播得到梯度并备份\n  对于每步t:\n      2.根据embedding矩阵的梯度计算出r，并加到当前embedding上，相当于x+r(超出范围则投影回epsilon内)\n      3.t不是最后一步: 将梯度归0，根据1的x+r计算前后向并得到梯度\n      4.t是最后一步: 恢复(1)的梯度，计算最后的x+r并将梯度累加到(1)上\n  5.将embedding恢复为(1)时的值\n  6.根据(4)的梯度对参数进行更新\n```\n\n基于PGD的对抗性训练被广泛认为是最有效的，因为它在很大程度上避免了模糊的梯度问题。它将一类对抗性训练算法转化为求解交叉熵损失的极大极小问题，该问题可以通过多次投影梯度上升步骤和随后的SGD步骤可靠地实现。\n\n\n\n## Virtual Adversarial Training\n\n除了监督训练，对抗训练还可以用在半监督任务中，尤其对于NLP任务来说，很多时候输入的无监督文本多的很，但是很难大规模地进行标注，那么就可以参考[13]中提到的Virtual Adversarial Training进行半监督训练。\n\n首先，我们抽取一个随机标准正态扰动（$d\\sim \\mathcal{N}(0, I)\\in \\mathbb{R}^d$），加到embedding上，并用KL散度计算梯度：\n\n然后，用得到的梯度，计算对抗扰动，并进行对抗训练：\n\n![](https://i.loli.net/2021/04/09/KYX3zILWf4A1Htg.png)\n\n实现方法跟FGM差不多\n\n## FreeAT & YOPO & FreeLB\n\n**优化的主要方向有两点：得到更优的扰动 & 提升训练速度**\n\n其实PGD效果不错但是它迭代多步计算开销很大，所以出现了这些针对效率上的优化，并且结合预训练语言模型。\n\n具体的就搜这些论文来看吧。\n\nFGSM: Explaining and Harnessing Adversarial Examples\n\nFGM: Adversarial Training Methods for Semi-Supervised Text Classification\n\nFreeAT: Adversarial Training for Free!\n\nYOPO: You Only Propagate Once: Accelerating Adversarial Training via Maximal Principle\n\nFreeLB: Enhanced Adversarial Training for Language Understanding\n\nSMART: Robust and Efficient Fine-Tuning for Pre-trained Natural\n\n## 参考文献\n\n[[对抗训练浅谈：意义、方法和思考（附Keras实现）](https://kexue.fm/archives/7234)]\n\n[【炼丹技巧】功守道：NLP中的对抗训练 + PyTorch实现](https://fyubang.com/2019/10/15/adversarial-train/)\n\n[NLP --- >对抗学习：从FGM, PGD到FreeLB](https://blog.csdn.net/chencas/article/details/103551852)\n\n[TAVAT: Token-Aware Virtual Adversarial Training for Language Understanding](https://arxiv.org/pdf/2004.14543v3.pdf)\n\n[Adversarial Training Methods for Semi-Supervised Text Classification](https://arxiv.org/abs/1605.07725)\n[Adversarial Text Classification原作实现](https://github.com/tensorflow/models/blob/e97e22dfcde0805379ffa25526a53835f887a860/research/adversarial_text/adversarial_losses.py)\n\n[NLP(文本)中的对抗训练](https://blog.csdn.net/ganxiwu9686/article/details/105931668)\n\n[对抗训练的理解，以及FGM、PGD和FreeLB的详细介绍](https://blog.csdn.net/weixin_41712499/article/details/110878322)\n\n","tags":["nlp"]},{"title":"数组范围内计数","url":"/2021/04/07/数组范围内计数/","content":"\n# 数组范围内计数\n\n数组为 3,2,2,3,1, 查询为（0,3,2)。\n\n意思是在数组里下标 0-3 这个范围上，有几个 2? \n\n假设给一个数组 arr，对这个数组的查询非常频繁请返回所有查询的结果。\n\n给出：arr[    ]\n\n要查多个范围：\n\n[[0,3,2],\n\n[1,4,0]]\n\n结果返回：[第一个数组结果，第二个数组结果]\n\n暴力解法直接遍历肯定不可以。\n\n## 解法\n\n一、做一个map映射，遍历一遍数组，将每个值和每个值出现的下标位置数组做成key-value\n\n在根据查询的V，在所在值的数组内做二分查找。\n\n```java\npublic static class QueryBox2 {\n        private HashMap<Integer, ArrayList<Integer>> map;\n\n        public QueryBox2(int[] arr) {\n            map = new HashMap<>();\n            for (int i = 0; i < arr.length; i++) {\n                if (!map.containsKey(arr[i])) {\n                    map.put(arr[i], new ArrayList<>());\n                }\n                map.get(arr[i]).add(i);\n            }\n        }\n\n        public int query(int L, int R, int value) {\n            if (!map.containsKey(value)) return 0;\n            ArrayList<Integer> indexArr = map.get(value);\n            // 查询<L的下标有几个\n            int a = countLess(indexArr, L);\n            // 查询<R+1的下标有几个\n            int b = countLess(indexArr, R + 1);\n            return b - a;\n        }\n\n        // 在有序数组中，用二分法数出<limit 的数有几个\n        // 也就是用二分法，找到<limit的数中最右的位置\n        private int countLess(ArrayList<Integer> arr, int limit) {\n            int L = 0;\n            int R = arr.size() - 1;\n            int mostRight = -1;\n            while (L <= R) {\n                int mid = L + ((R - L) >> 1);\n                if (arr.get(mid) < limit) {\n                    mostRight = mid;\n                    L = mid + 1;\n                } else {\n                    R = mid - 1;\n                }\n            }\n            return mostRight + 1;\n        }\n    }\n```\n\n$O(mlogn)$\n\n\n\n扩展：\n\n如果是求范围内累加和\n\n可以生成一个前缀和数组类似本题\n\n\n\n\n\n## 腾讯原题\n\n给定整数 power。给定一个数组 arr。给定一个数组 reverse。含义如下\n\narr 的长度一定是 2 的 power 次方，reverse1 每个值一定都在 0 ~ power范围。\n\n例如 power=2, ar={3,1,4,2}, reverse={0,1,0,2}\n\n针对reverse的数组中每一个值 \n\n如第一个值为0，就是对$2^0=1$ 每一个arr数组以1个数为单位逆序。\n\n如第二个值为1，就是对$2^1=2$ 对arr数组每两个数逆序\n\n任何一个在前的数字可以和任何一个在后的数组，构成一对数。可能是升序关系、相等关系或者降序关系。\n\n最后求调整完的arr数组有多少个降序对。\n\n比如 arr 开始时有如下的降序对：(3,1)、（3.2)、（4.2），一共 3 个。\n\n以2个数调整后arr由{3,1,4,2} 变成{1,3,2,4} 降序对有{3,2} ，共1个\n\n\n\n经典做法每次都reverse\n\n```java\n// originArr长度一定是2的power次方\n    // reverseArr中每一个值，都是0-power范围上的数\n    public static int[] reversePair1(int[] originArr, int[] reverseArr, int power) {\n        int[] ans = new int[reverseArr.length];\n        for (int i = 0; i < reverseArr.length; i++) {\n            // 1 << (reverseArr[i]) == r[i]的2次方\n            reverseArray(originArr, 1 << (reverseArr[i]));\n            ans[i] = countReversePair(originArr);\n        }\n        return ans;\n    }\n\n    public static void reverseArray(int[] originArr, int teamSize) {\n        if (teamSize < 2) return;\n        for (int i = 0; i < originArr.length; i += teamSize) {\n            reversePart(originArr, i, i + teamSize - 1);\n        }\n    }\n\n    public static void reversePart(int[] arr, int L, int R) {\n        while (L < R) {\n            int temp = arr[L];\n            arr[L++] = arr[R];\n            arr[R--] = temp;\n        }\n    }\n\n    public static int countReversePair(int[] originArr) {\n        int ans = 0;\n        for (int i = 0; i < originArr.length; i++) {\n            for (int j = i + 1; j < originArr.length; j++) {\n                if (originArr[i] > originArr[j]) {\n                    ans++;\n                }\n            }\n        }\n        return ans;\n    }\n```\n\n\n\n优化方案\n\n[3,2 4,5, 0,1 3,5]\n\n两个数一组：  1个逆序对，3个升序对\n\n四个数一组： 0个逆序对，8个升序对\n\n八个数一组：10个逆序对，4个升序对\n\n每个数组的逆序对数是2、4、9个一组的加和\n\n当数组进行几个数一组翻转时\n\n翻转后的逆序对和升序对数量，和翻转前的升序对和逆序对相等，数量调换了。\n\n小的数调整后数量不影响大数量调整后的数量。\n\n\n\n所以直接查2、4、8、16个 数量再交换相加。\n\n如何高效生成预处理记录\n\n输入数据状况\n\npower范围[0,20]\n\narr长度范围[1,10e7]\n\nreverse长度范围[1,10e6]\n\n```java\npublic static int[] reversePair2(int[] originArr, int[] reverseArr, int power) {\n        int[] originReverse = Arrays.copyOf(originArr, originArr.length);\n        reversePart(originReverse, 0, originReverse.length - 1);\n        int[] recordDown = new int[power + 1];\n        int[] recordUp = new int[power + 1];\n        process(originArr, 0, originArr.length - 1, power, recordDown);\n        process(originReverse, 0, originReverse.length - 1, power, recordUp);\n\n        // recordDown[i] 2的i次方个数一组的划分中，降序的数量\n        // recordUp[i] 2的i次方个数一组的划分中，升序的数量\n        int[] ans = new int[reverseArr.length];\n        for (int i = 0; i < reverseArr.length; i++) {\n            int curPower = reverseArr[i]; // =3  2的1次方、2次方、3次方 要调整\n            for (int p = 1; p <= curPower; p++) {\n                int tmp = recordDown[p];\n                recordDown[p] = recordUp[p];\n                recordUp[p] = tmp;\n            }\n            for (int p = 1; p <= power; p++) {\n                ans[i] += recordDown[p];\n            }\n        }\n        return ans;\n    }\n\n    public static void process(int[] originArr, int L, int R, int power, int[] record) {\n        if (L == R) {\n            return;\n        }\n        int mid = L + ((R - L) >> 1);\n        process(originArr, L, mid, power - 1, record);\n        process(originArr, mid + 1, R, power - 1, record);\n        record[power] += merge(originArr, L, mid, R);\n    }\n\n    public static int merge(int[] arr, int L, int m, int r) {\n        int[] help = new int[r - L + 1];\n        int i = 0;\n        int p1 = L;\n        int p2 = m + 1;\n        int ans = 0;\n        while (p1 <= m && p2 <= r) {\n            ans += arr[p1] <= arr[p2] ? arr[p1++] : arr[p2++];\n            help[i++] = arr[p1] <= arr[p2] ? arr[p1++] : arr[p2++];\n        }\n        while (p1 <= m) {\n            help[i++] = arr[p1++];\n        }\n        while (p2 <= r) {\n            help[i++] = arr[p2++];\n        }\n        for (i = 0; i < help.length; i++) {\n            arr[L + i] = help[i];\n        }\n        return ans;\n    }\n```\n\n","tags":["刷题"]},{"title":"海华中文阅读理解比赛梳理/多卡并行/transformers","url":"/2021/04/06/海华中文阅读理解比赛梳理-多卡并行-transformers/","content":"\n# 海华中文阅读理解比赛梳理\n\n文文言文古诗词现代诗词\n\n1 字词解释 2 标点符号作用 3 句子解释 4 填空 5 选择正读音 6 推理总结 7 态度情感 8 外部知识\n\n不需要先验知识的问题\n\n如一个问题能够在文档中进行匹配，回答起来就几乎不需要先验知识需要先验知识的问題\n\n1、关于语言的知识：需要词汇/语法知识,例如:习语、谚语、否定、反义词、同义词语法转换\n\n2、特定领域的知识：需要但不限于些事实上的知识，这些事实与特定领域的概念概念定义和属性，概念之间的关系\n\n3、一般世界的知识：需要有关世界如何运作的一般知识，或者被称为常识。比如百科全书中的知识\n\n这个赛题的难点是有些预训练语言模型没有学到的先验知识怎么学\n\n## 赛题概述\n\n- train 训练集提供了6313条数据数据格式是和中小学生做的阅读题一样，一篇文章有两到三个问题每个问题有两到四个答案选项。\n- validation 验证集提供了1000条数据。\n\n原始单条数据格式如下：\n\n```json\n{\n    \"ID\": \"0001\",\n    \"Content\": \"春之怀古张晓风春天必然曾经是这样的：从绿意内敛的山头，一把雪再也撑不住了，噗嗤的一声，将冷面笑成花面，一首澌澌然的歌便从云端唱到山麓，从山麓唱到低低的荒村。。。。。很多省略。\",\n    \"Questions\": [\n      {\n        \"Q_id\": \"000101\",\n        \"Question\": \"鸟又可以开始丈量天空了。”这句话的意思是   （   ）\",\n        \"Choices\": [\n          \"A．鸟又可以飞了。\",\n          \"B． 鸟又要远飞了。\",\n          \"C．鸟又可以筑巢了。\"\n        ],\n        \"Answer\": \"A\"\n      },\n      {\n        \"Q_id\": \"000102\",\n        \"Question\": \"本文写景非常含蓄，请读一读找一找哪些不在作者的笔下有所描述\",\n        \"Choices\": [\n          \"A．冰雪融化\",\n          \"B． 蝴蝶在花间飞舞\",\n          \"C．白云在空中飘\",\n          \"D．小鸟在空中自由地飞\"\n        ],\n        \"Answer\": \"C\"\n      }\n    ]\n}\n```\n\n## EDA 与预处理\n\n将原始数据每个问题抽出来以 [文章- 问题 -答案] 作为一条数据。\n\n```json\n{\n    \"Question\": \"下列对这首诗的理解和赏析，不正确的一项是\",\n    \"Choices\": [\n        \"A．作者写作此诗之时，皮日休正患病居家，闭门谢客，与外界不通音讯。\",\n        \"B．由于友人患病，原有的约会被暂时搁置，作者游春的诗篇也未能写出。\",\n        \"C．作者虽然身在书斋从事教学，但心中盼望能走进自然，领略美好春光。\",\n        \"D．尾联使用了关于沈约的典故，可以由此推测皮日休所患的疾病是目疾。\"\n    ],\n    \"Answer\": \"A\",\n    \"Q_id\": \"000101\",\n    \"Content\": \"奉和袭美抱疾杜门见寄次韵  陆龟蒙虽失春城醉上期，下帷裁遍未裁诗。因吟郢岸百亩蕙，欲采商崖三秀芝。栖野鹤笼宽使织，施山僧饭别教炊。但医沈约重瞳健，不怕江花不满枝。\"\n}\n```\n\n训练集从6313变为15421条数据，相当于有15421个问题\n\n验证集从1000变为2444条数据，相当于有2444个问题\n\n接下来看看文章的长度如何？\n\n![](https://i.loli.net/2021/04/06/UXPvh1c6CIRY54J.png)\n\n```\ncount    15421.000000\nmean      1039.781272\nstd        435.583878\nmin         38.000000\n25%        744.000000\n50%       1067.000000\n75%       1251.000000\nmax       3047.000000\nName: content_len, dtype: float64\ncount    2444.000000\nmean      927.508592\nstd       481.552693\nmin        40.000000\n25%       596.000000\n50%       938.000000\n75%      1179.500000\nmax      3047.000000\nName: content_len, dtype: float64\n```\n\n发现content文章都非常长，绝大多数都超过了512。\n\n使用预训练模型bert的话，如何训练很长的文章是是个提高的点。\n\n我的想法是bert模型一个这个提高的点、看看最近比较火的Longformer怎么做，再用几个和长度无关的模型像lstm等最后做集成。\n\n![](https://i.loli.net/2021/04/06/gBUFiwHtaK195rq.png)\n\n答案中选C的居多，点歌都选C。。。\n\n\n\n在提供的测试集中有一个特别的地方，赛方给出了文章的类型。\n\n00 现代文 11文言文 22 古诗词 33现代诗词\n\n![](https://i.loli.net/2021/04/06/ZoVXJGdhrf7wga5.png)\n\n测试集还给了难度，使用想法：\n\n可以训练一个模型预测文本的难度和类型，标注训练集，可能会有提升。\n\n\n\n接下来将标签从ABCD转成0123\n\n```python\ntrain_df['label'] = train_df['Answer'].apply(lambda x:['A','B','C','D'].index(x)) \n\ntest_df['label'] = 0\n```\n\n\n\n## Baseline\n\n### 分词器\n\n采用transformers提供的bert分词器\n\n```python\ntokenizer = BertTokenizer.from_pretrained('model') #加载bert的分词器\n```\n\n这里我试过如果要将bert改成roberta，分词器还是要采用BertTokenizer，如果用RobertaTokenizer会报错。\n\n参考[关于transformers库中不同模型的Tokenizer](https://zhuanlan.zhihu.com/p/121787628)\n\n**由于中文的特殊性不太适合采用byte级别的编码，所以大部分开源的中文Roberta预训练模型仍然采用的是单字词表，所以直接使用`BertTokenizer`读取即可，** 不需要使用`RobertaTokenizer`。\n\n\n\n### 模型部分\n\nBertForMultipleChoice https://huggingface.co/transformers/model_doc/bert.html#bertformultiplechoice\n\n把每个问题和文章的不同选项拆开拼成一个输入。如下图第一行\n\n![](https://i.loli.net/2021/04/08/sgbWnyIqdT9hcrE.png)\n\nbaseline采用transformers提供的调包，封装好的BertForMultipleChoice (多项选择任务)，它的源码：\n\n```python\nclass BertForMultipleChoice(BertPreTrainedModel):\n    def __init__(self, config):\n        super().__init__(config)\n\n        self.bert = BertModel(config)\n        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n        self.classifier = nn.Linear(config.hidden_size, 1)\n\n        self.init_weights()\n\n    \n    def forward(\n        self,\n        input_ids=None,\n        attention_mask=None,\n        token_type_ids=None,\n        position_ids=None,\n        head_mask=None,\n        inputs_embeds=None,\n        labels=None,\n    ):\n       \n        num_choices = input_ids.shape[1]\n\n        input_ids = input_ids.view(-1, input_ids.size(-1))\n        attention_mask = attention_mask.view(-1, attention_mask.size(-1)) if attention_mask is not None else None\n        token_type_ids = token_type_ids.view(-1, token_type_ids.size(-1)) if token_type_ids is not None else None\n        position_ids = position_ids.view(-1, position_ids.size(-1)) if position_ids is not None else None\n\t\t\t\t# 将bert三个输入展平 输入到bertmodel\n        outputs = self.bert(\n            input_ids,\n            attention_mask=attention_mask,\n            token_type_ids=token_type_ids,\n            position_ids=position_ids,\n            head_mask=head_mask,\n            inputs_embeds=inputs_embeds,\n        )\n\t\t\t\t# 隐层输出\n        # last_hidden_state: [32=4*batch, seq_len,768]\n        # pooler_ouput: [32=4*batch,768]\n        pooled_output = outputs[1] # CLS https://www.cnblogs.com/webbery/p/12167552.html\n        # bert_output = outputs[0] # last_hidden\n\n        pooled_output = self.dropout(pooled_output)\n        logits = self.classifier(pooled_output)\n        reshaped_logits = logits.view(-1, num_choices)\n\n        outputs = (reshaped_logits,) + outputs[2:]  # add hidden states and attention if they are here\n\n        if labels is not None:\n            loss_fct = CrossEntropyLoss()\n            loss = loss_fct(reshaped_logits, labels)\n            outputs = (loss,) + outputs\n\n        return outputs  # (loss), reshaped_logits, (hidden_states), (attentions)\n```\n\n做bert方面的模型扩展可以参考上面，其实就是BertModel加上了线性层。\n\n\n\n\n\n### 制造模型输入数据\n\n```python\nclass MyDataset(Dataset):\n    def __init__(self, dataframe):\n        self.df = dataframe\n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx): \n      #将一条数据从(文章,问题,4个选项)转成(文章,问题,选项1)、(文章,问题,选项2)...\n        label = self.df.label.values[idx]\n        question = self.df.Question.values[idx]\n        content = self.df.Content.values[idx]\n        choice = self.df.Choices.values[idx][2:-2].split('\\', \\'')\n        if len(choice) < 4: #如果选项不满四个，就补“不知道”\n            for i in range(4-len(choice)):\n                choice.append('D．不知道')\n        \n        content = [content for i in range(len(choice))]\n        pair = [question + ' ' + i[2:] for i in choice]\n        \n        return content, pair, label\n```\n\n$61536 = 15325\\times 4 + 71 \\times3+ 25\\times2 $\n\n数据将变成61536条\n\n如果用五折交叉验证： 训练集 49228 验证集12307\n\n如果Using 8 dataloader workers every process\n\n每个batch 8条数据的话  约等于每个epoch 训练集运行772次，验证集193次\n\n(这个地方不知道算的对不对)\n\n将数据做成bert需要的三种编码：\n\n```python\ndef collate_fn(data): \n  # 将文章问题选项拼在一起后，得到分词后的数字id，输出的size是(batch, n_choices, max_len)\n    input_ids, attention_mask, token_type_ids = [], [], []\n    for x in data:\n        text = tokenizer(x[1],\n                         text_pair=x[0],\n                         padding='max_length',  # 填充到使用参数max_length指定的最大长度，或者填充到模型的最大可接受输入长度(如果未提供该参数)。\n                         truncation=True,\n                         # TRUE或‘LIMEST_FIRST’：截断到使用参数max_length指定的最大长度，或者截断到模型的最大可接受输入长度(如果没有提供该参数)。这将逐个令牌截断令牌，如果提供了一对序列(或一批对)，则从该对中最长的序列中删除一个令牌。\n                         max_length=Param['max_len'],\n                         return_tensors='pt')  # 返回pytorch tensor格式\n        input_ids.append(text['input_ids'].tolist())\n        attention_mask.append(text['attention_mask'].tolist())\n        token_type_ids.append(text['token_type_ids'].tolist())\n    input_ids = torch.tensor(input_ids)\n    attention_mask = torch.tensor(attention_mask)\n    token_type_ids = torch.tensor(token_type_ids)\n    label = torch.tensor([x[-1] for x in data])\n    return input_ids, attention_mask, token_type_ids, label\n```\n\nDataLoader\n\n```python\ntrain_set = utils.MyDataset(train)\nval_set = utils.MyDataset(val)\n\n\"\"\"单卡直接写\"\"\"\ntrain_loader = DataLoader(train_set, batch_size=CFG['train_bs'], collate_fn=collate_fn, shuffle=True, num_workers=CFG['num_workers'])\nval_loader = DataLoader(val_set, batch_size=CFG['valid_bs'], collate_fn=collate_fn, shuffle=False, num_workers=CFG['num_workers'])\n\n\"\"\"多卡写法\"\"\"\n # 给每个rank对应的进程分配训练的样本索引\ntrain_sampler = DistributedSampler(train_set)\nval_sampler = DistributedSampler(val_set)\n # 将样本索引每batch_size个元素组成一个list 验证集不用\ntrain_batch_sampler = torch.utils.data.BatchSampler(train_sampler, batch_size=args.batch_size, drop_last=True)\n\n\ntrain_loader = DataLoader(train_set, batch_sampler=train_batch_sampler, pin_memory=False,\n                                  collate_fn=collate_fn, num_workers=2)\nval_loader = DataLoader(val_set, batch_size=args.batch_size, sampler=val_sampler, pin_memory=False, collate_fn=collate_fn, num_workers=2)\n```\n\nDistributedSampler/BatchSampler:\n\n[四Sampler源码](https://blog.csdn.net/m0_37400316/article/details/107210970)\n\n[（TORCH.NN.PARALLEL.DISTRIBUTEDDATAPARALLEL）时，DISTRIBUTEDSAMPLER(DATASET)用法解释](https://www.freesion.com/article/6505681767/)\n\n\n\n\n\n\n\nDataloader 中的 num_workers:\n\n加快训练进程\n为了加快训练过程，使用DataLoader类的num workers可选属性。\nnum workers属性告诉数据加载器实例要使用多少子进程来加载数据。默认情况下，num  workers值设置为0，值为0告诉加载程序在主进程内加载数据。\n这意味着训练将在主进程中按顺序工作。在训练过程中使用了一个batch，并且需要另一个batch之后，从磁盘读取批数据。现在，如果我们有一个worker进程，我们可以利用机器多个核的。这意味着在主进程准备好进行另一批处理时，下一批处理已经可以加载并准备就绪。这就是加速的来源。批处理使用其他工作进程加载，并在内存中排队。\n\n\n\n\n\n### 训练过程\n\n\n\n\n\n#### 优化配置\n\n多层不同学习率\n\n```python\nfc_para = list(map(id, model.module.classifier.parameters()))\nlstm_para = list(map(id, model.module.lstm.parameters()))\ngru_para = list(map(id, model.module.gru.parameters()))\nbase_para = filter(lambda p: id(p) not in fc_para, model.module.parameters())\nparams = [{'params': base_para},\n{'params': model.module.lstm.parameters(), 'lr': args.other_lr},\n{'params': model.module.gru.parameters(), 'lr': args.other_lr},\n{'params': model.module.classifier.parameters(), 'lr': args.fc_lr}]\nscaler = GradScaler() # 有v100的话还可以开半精度\noptimizer = AdamW(model.module.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n# criterion = nn.CrossEntropyLoss().cuda(local_rank)\ncriterion = utils.LabelSmoothingCrossEntropy().cuda(local_rank) # 标签平滑\n```\n\n\n\n#### 梯度累积\n\n由于机器显存限制，不得不用梯度累积来达到目的batch数。\n\n用多次小的 mini-batch 来模拟一个较大的 mini-batch，即：global_batch_size = batch_size*iter_size\n\nbatch size 和 learning rate 要等比例放大。但需要注意：特别大的 batch size 还需要再加上其他 trick 如 warmup 才能保证训练顺利（因为太大的初始 lr 很容易 train 出 nan）。\n\n```python\nloss = criterion(output, y) / args.accum_iter\n\nif ((step + 1) % args.accum_iter == 0) or ((step + 1) == len(train_loader)):\n    scaler.step(optimizer)\n    scaler.update()\n    scheduler.step()\n    optimizer.zero_grad()\n```\n\n苏神:[ 用时间换取效果：Keras梯度累积优化器](https://kexue.fm/archives/6794)\n\n\n\n\n\n#### loss计算与warmup\n\nwarmup顾名思义就是热身，在刚刚开始训练时以很小的学习率进行训练，使得网络熟悉数据，随着训练的进行学习率慢慢变大，到了一定程度，以设置的初始学习率进行训练，接着过了一些inter后，学习率再慢慢变小；学习率变化：上升——平稳——下降；\n\nwarm up setp（一般等于epoch*inter_per_epoch），当step小于warm up setp时，学习率等于基础学习率×(当前step/warmup_step)，由于后者是一个小于1的数值，因此在整个warm up的过程中，学习率是一个递增的过程！当warm up结束后，学习率以基础学习率进行训练，再学习率开始递减\n\n1、当网络非常容易nan时候，采用warm up进行训练，可使得网络正常训练；\n\n2、如果训练集损失很低，准确率高，但测试集损失大，准确率低，可用warm up；具体可看：https://blog.csdn.net/u011995719/article/details/77884728\n\n[[LR Scheduler]warmup](https://blog.zhujian.life/posts/f311f0.html)\n\n\n\n#### 模型保存与加载\n\n这里有个小地方要注意，因为多卡并行时model用DistributedDataParallel包装了，所以在save时不时直接的model.state_dict()，而是model.module.state_dict()。 这个问题当时困扰了我好久，模型保存完的都是没经过学习的参数。\n\n```python\nif val_acc > best_acc:\n    best_acc = val_acc\n    print(\"best:\", best_acc)\n    if distribute_utils.is_main_process():\n        torch.save(model.module.state_dict(),\n                   'spawn_adv_pgd_{}_fold_{}.pt'.format(args.model.split('/')[-1], fold))\n```\n\n\n\n\n\n\n\n\n\n## 提升点\n\n更长的文本（512、sliding window、xinet、longformer） \n\n- 滑动窗口把文章截成很多段然后取平均softmax\n- xlnet 不限制长度，时间长\n- longformer 4096 transformers有提供\n\n更好的模型（roberta、large、DUMA）\n\n- DUMA bert上再加attention\n\n更多的数据（爬虫、C3）\n\n- 先训练C3中文的有提升 但新改了规则说不让用外部数据了。\n\n比赛复盘[海华阅读理解比赛复盘]()\n\n\n\n\n\n\n\n## 遇到的问题\n\n1. 五折交叉验证有的轮次收敛有的轮次不收敛\n\n数据shuffle过，要加warmup用cosine lr，学习率往小调从2e-5调到1e-5\n\n还有一种情况是因为label不均衡造成的，每折数据不一样\n\n2. 验证集loss和acc都上涨\n\n现象很常见，原因是过拟合或者训练验证数据分布不一致造成。就是在训练后期，预测的结果趋向于极端，使少数预测错的样本主导了loss，但同时少数样本不影响整体的验证acc情况。\n\n\n\n\n\n\n\n## 可能用到的外部数据\n\n1、RACE dataset\n2、SQuAD2.0 and CoQA dataset\n3、ARC dataset\n4、DREAM dataset\n5、ChineseSquad，https://github.com/zengjunjun/ChineseSquad\n6、cmrc2018，https://github.com/ymcui/cmrc2018\n7、c3 dataset\n8、dureader dataset\n\n1、 爬取中学语文阅读理解试题（全部选项、无标注） https://github.com/sz128/ext_data_for_haihua_ai_mrc （内含网盘下载链接）\n2、C3数据：https://github.com/nlpdata/c3\n3、 开源的中文预训练语言模型：\n\nMacBERT (https://github.com/ymcui/MacBERT)\nChinese-BERT-wwm（https://github.com/ymcui/Chinese-BERT-wwm）\nChinese-ELECTRA（https://github.com/ymcui/Chinese-ELECTRA)\nALBERT-zh (https://github.com/brightmart/albert_zh)\nguwenBERT (https://github.com/Ethan-yt/guwenbert);","tags":["DataGame"]},{"title":"bfprt算法","url":"/2021/04/06/bfprt算法/","content":"\n# bfprt算法 求TopK\n\n**中位数的中位数算法** 最坏时间复杂度 $O(n)$\n\n在做topk问题时，最容易想到的就是先对所有数据进行一次排序，然后取其前k个。但问题有二：\n\n- 快排时间复杂度 $O(nlogn)$ ，但最坏时间复杂度 $O(n^2)$\n- 我们只要前k大的，而对其余的数也进行了排序，浪费了大量排序时间。\n\n除了这种方法堆排序也是一个比较好的选择，可以维护一个大小为k的堆，时间复杂度为 $O(nlogk)$\n\n## 堆排序topk\n\n- Heap是一种数据结构具有以下的特点：\n  1）**完全二叉树**；\n  2）heap中存储的值是**偏序**；\n- **Min-heap**: 父节点的值小于或等于子节点的值；\n  **Max-heap**: 父节点的值大于或等于子节点的值；\n- 一般都用数组来表示堆，i结点的父结点下标就为(i–1)/2。它的左右子结点下标分别为2 * i + 1和2 * i + 2\n- 堆中每次都删除第0个数据。为了便于重建堆，实际的操作是将最后一个数据的值赋给根结点，然后再从根结点开始进行一次从上向下的调整。\n\n```java\n# 大根堆比较器 top小\npublic  static class MaxheapComparator implements Comparator<Integer>{\n  @Override\n  public int compare(Integer o1, Integer o2){\n    return o2-o1;\n  }\n}\npublic static PriorityQueue getMinKNumsByHeap(int[] arr,int k){\n  if(k<1 || k>arr.length){\n    return null;\n  }\n  PriorityQueue<Integer> kHeap = new PriorityQueue<Integer>(k, new MaxheapComparator());\n  for(int i=0;i!=k;i++){\n    kHeap.add(arr[i]);\n  }\n  for(int i=k;i!=arr.length;i++){\n    if(arr[i]<kHeap.peek()){ // 返回第一个元素，而不从此PriorityQueue中删除一个元素。\n      kHeap.poll(); // 返回第一个元素，并从此PriorityQueue中删除一个元素。\n      kHeap.add(arr[i]);\n    }\n  }\n  return kHeap;\n}\npublic static void main(String[] args) {\n         int[] arr = { 1, 3, 2, 5, 9 };\n         // 测试普通方法\n         System.out.println(getMinKNumsByHeap(arr, 1).peek());\n         System.out.println(getMinKNumsByHeap(arr, 2).peek());\n         System.out.println(getMinKNumsByHeap(arr, 3).peek());\n         System.out.println(getMinKNumsByHeap(arr, 4).peek());\n         System.out.println(getMinKNumsByHeap(arr, 5).peek());\n     }\n```\n\n\n\n## 原理过程\n\n在快排基础上，先通过判断主元位置与k的大小使递归的规模变小。\n\n再通过修改快速排序中主元的选取方法来降低快速排序在最坏情况下的时间复杂度。\n\n- 选取主元\n\n- 以选取的主元为分界点，把小于主元的放到左边，大于主元的放到右边\n\n- 分别对左边和右边进行递归，重复上述过程\n\n  \n\n  \n\n\n\n1. 数组被划分为了 N/5 个小部分，每个部分的5个数排序需要 O(1) ，所有部分排完需要 O(N/5)=O(N)\n\n2. 取出每个小部分的中位数，一共有 N/5 个，递归调用BFPRT算法得到这些数中第 (N/5)/2 小的数（即这些数 的中位数），记为 pivot\n\n3. 以 pivot 作为比较，将整个数组划分为 <pivot , =pivot , >pivot 三个区域\n\n4. 判断第K小的数在哪个区域，如果在 = 区域则直接返回 pivot ，如果在 < 或 > 区域，则将这个区域的数递 归调用BFPRT算法\n\n5. base case ：在某次递归调用BFPRT算法时发现这个区域只有一个数，那么这个数就是我们要找的数\n\n```java\npublic static int getMinKthNum(int[] arr, int k){\n  if(arr==null || k>arr.length){\n    return Integer.MIN_VALUE;\n  }\n  int[] copyArr = Arrays.copyOf(arr, arr.length);\n  return BFPRT(copyArr, 0, arr.length-1, k-1);\n}\n// 取出每个小部分的中位数，一共有 N/5 个，递归调用BFPRT算法得到这些数中第 (N/5)/2 小的数（即这些数 的中位数），记为 pivot. 以 pivot 作为比较，将整个数组划分为 <pivot , =pivot , >pivot 三个区域\nprivate static int BFPRT(int[] arr, int begin, int end, int i){\n  if(begin==end) return arr[begin];\n  int pivot = medianOfMedians(arr, begin, end);\n  int[] pivotRange = partition(arr, begin, end, pivot);\n  if(i>= pivotRange[0] && i<=pivotRange[1]){\n    return arr[i];\n  } else if(i<pivotRange[0]){\n    return BFPRT(arr, begin, pivotRange[0]-1, i);\n  } else{\n    return BFPRT(arr, pivotRange[1]+1, end, i);\n  }\n}\n\nprivate static int[] partition(int[] arr, int begin, int end, int pivot){\n  int L= begin-1;\n  int R= end + 1;\n  int cur = begin;\n  while(cur!=R){\n    if(arr[cur]>pivot){\n      swap(arr, cur, --R);\n    } else if(arr[cur]<pivot){\n      swap(arr, cur++, ++L)\n    } else{\n      cur++;\n    }\n  }\n  return new int[]{L+1, R-1};\n}\n\nprivate static int medianOfMedians(int[] arr, int begin, int end){\n  int num = end - begin +1;\n  int offset = num % 5 ==0 ? 0 : 1;\n  int[] medians = new int[num/5 + offset];\n  for(int i=0;i<medians.length; i++){\n    int beginI = begin+i*5;\n    int endI = beginI + 4;\n    medians[i] = getMedian(arr, beginI, Math.min(endI, end));\n  }\n  return BFPRT(medians, 0, medians.length-1, medians.length/2);\n}\n\nprivate static int get Median(int[] arr, int begin, int end){\n  insertionSort(arr, begin, end);\n  int sum = end+begin;\n  int mid = (sum/2) + (sum%2);\n  return arr[mid];\n}\nprivate static void insertionSort(int[] arr, int begin, int end){\n  if (begin>=end) return;\n  for(int i=begin+1; i<=end; i++){\n    for(int j=i; j>begin; j--){\n      if(arr[j] < arr[j-1]){\n        swap(arr, j, j-1);\n      }else{\n        break;\n      }\n    }\n  }\n}\n```\n\n\n\n## 时间复杂度\n\n最坏情况下是 $O(n)$\n\n令 $T(n)$ 为所求的时间复杂度，则：\n$$\n\\begin{equation}\\begin{split} \n T(n) \\le T(\\frac {n}{5}) + T(\\frac{7n}{10}) + c\\cdot n\n    \\end{split}\\end{equation}\n$$\n\n\n- $T(\\frac n 5)$ 来自 GetPivotIndex()，n 个元素，5 个一组，共有 $⌊\\frac n5⌋$ 个中位数；\n- $T(\\frac {7n}{10})$ 来自 BFPRT()，在 $⌊\\frac n5⌋$ 个中位数中，主元 x 大于其中 $\\frac 12⋅\\frac n5=\\frac n{10}$ 的中位数，而每个中位数在其本来的 5 个数的小组中又大于或等于其中的 3 个数，所以主元 x 至少大于所有数中的 $\\frac n{10}⋅3=\\frac {3n}{10}$ 个。即划分之后，任意一边的长度至少为 $\\frac 3{10}$，在最坏情况下，每次选择都选到了 $\\frac 7{10}$ 的那一部分。\n- $c⋅n$ 来自其它操作，比如 InsertSort()，以及 GetPivotIndex() 和 Partition() 里所需的一些额外操作。\n\n设 $T(n)=t⋅n$，其中 t 为未知，它可以是一个正常数，也可以是一个关于 n 的函数，代入上式：\n\n$$ \\begin{align} t⋅n&≤\\frac {t⋅n}5+\\frac{7t⋅n}{10}+c⋅n \\tag{两边消去 n}\\\\ t&≤\\frac t 5+\\frac {7t}{10}+c \\tag{再化简}\\\\ t&≤10c \\tag{c 为一个正常数} \\end{align} $$\n\n其中 c 为一个正常数，故t也是一个正常数，即 $T(n)≤10c⋅n$，因此 $T(n)=O(n)$，至此证明结束。\n\n接下来我们再来探讨下 BFPRT 算法为何选 5 作为分组主元，而不是 2, 3, 7, 9 呢？\n\n首先排除偶数，对于偶数我们很难取舍其中位数，而奇数很容易。再者对于 3 而言，会有 $T(n)≤T(\\frac n 3)+T(\\frac {2n}3)+c⋅n$，它本身还是操作了 n 个元素，与以 5 为主元的 $\\frac {9n}{10}$ 相比，其复杂度并没有减少。对于 7，9，... 而言，上式中的 10c，其整体都会增加，所以与 5 相比，5 更适合。\n\n\n\n\n\n\n\n\n\n","tags":["刷题"]},{"title":"RoBERTa & Albert","url":"/2021/04/05/RoBERTa-Albert/","content":"\n# RoBERTa & Albert\n\n2021年了，bert的改进体也越来越多，Roberta和Albert是比较出名的两个改进体。\n\nRoberta主要针对bert的预训练任务如NSP，mask进行改进。并且扩大了batchsize和使用更长的序列训练，这两点可能在长文本竞赛上有作用。\n\nAlbert主要针对bert参数量太大，训练慢来进行改进。引入了跨层参数共享，embedding解绑分解，取消dropout和添加SOP预训练任务。\n\n\n\n## RoBERTa\n\n1. 使用更大的batch在更大的数据集上对Bert进行深度训练\n2. 不再使用NSP(Next Sentence Prediction)任务\n3. 使用更长的序列进行训练\n4. 动态改变训练数据的MASK模式\n\n\n\n### 静态Masking vs 动态Masking\n\n- 静态Masking:在数据预处理期间Mask矩阵就已经生成好了，每个样本只会进行一次随机Mask，每个epoch都是相同的。\n- 修改版静态Masking: 在预处理时将数据拷贝10份，每一份拷贝都采用不同的Mask，也就是说，同样的一句话有十种不同的mask 方式，然后每份数据都训练N/10个epoch\n- 动态Masking:每次向模型输入一个序列时，都会生成一种新的Mask方式，即不在预处理的时候进行mask，而是在向模型提供输入时动态生成Mask。\n\n![](https://i.loli.net/2021/04/05/zFrQXsCIgc98pu3.png)\n\n### 取消NSP任务\n\nRoBERTa 实验了 4 种方法：\n\n- SEGMENT-PAIR + NSP：输入包含两部分，每个部分是来自同一文档或者不同文档的 segment （segment 是连续的多个句子），这两个 segment 的 token 总数少于 512 。预训练包含 MLM 任务和 NSP 任务。这是原始 BERT 的做法\n- SENTENCE-PAIR + NSP：输入也是包含两部分，每个部分是来自同一个文档或者不同文档的单个句子，这两个句子的 token 总数少于 512 。由于这些输入明显少于 512 个 tokens，因此增加 batch size 的大小，以使 tokens 总数保持与 SEGMENT-PAIR + NSP 相似。预训练包含 MLM 任务和 NSP 任务\n- FULL-SENTENCES：输入只有一部分（而不是两部分），来自同一个文档或者不同文档的连续多个句子，token 总数不超过 512 。输入可能跨越文档边界，如果跨文档，则在上一个文档末尾添加标志文档边界的 token 。预训练不包含 NSP 任务\n- DOC-SENTENCES：输入只有一部分（而不是两部分），输入的构造类似于 FULL-SENTENCES，只是不需要跨越文档边界，其输入来自同一个文档的连续句子，token 总数不超过 512 。在文档末尾附近采样的输入可以短于 512 个 tokens， 因此在这些情况下动态增加 batch size 大小以达到与 FULL-SENTENCES 相同的 tokens 总数。预训练不包含 NSP 任务\n\n![](https://i.loli.net/2021/04/05/TqvNDS2WIXHBnAl.png)\n\n\n\n### 扩大Batch Size\n\n公认的因素：降低batch size会显著降低实验效果，具体可参考BERT，XLNet目录的相关Issue。\n\nRoberta 作者也证实了这一点。\n\n![](https://i.loli.net/2021/04/05/jRdWv3gEVMlLk14.png)\n\n其中，bsz 是 Batch Size；steps 是训练步数（为了保证 bsz*steps 近似相同，所以大 bsz 必定对应小 steps）；lr 是学习率；ppl 是困惑度，越小越好；最后两项是不同任务的准确率。\n\n### 文本编码\n\n- 基于 char-level ：原始 BERT 的方式，它通过对输入文本进行启发式的词干化之后处理得到。\n- 基于 bytes-level：与 char-level 的区别在于bytes-level 使用 bytes 而不是 unicode 字符作为 sub-word 的基本单位，因此可以编码任何输入文本而不会引入 UNKOWN 标记。\n\n\n\n\n\n## Albert\n\n最近在 NLP 领域的研究趋势是使用越来越大的模型，以获得更好的性能。ALBERT 的研究表明，无脑堆叠模型参数可能导致效果降低\n\n在论文中，作者做了一个有趣的实验\n\n> 如果更大的模型可以带来更好的性能，为什么不将最大的 BERT 模型 (BERT-large) 的隐含层单元增加一倍，从 1024 个单元增加到 2048 个单元呢？\n\n他们称之为 \"BERT-xlarge\"。令人惊讶的是，无论是在语言建模任务还是阅读理解测试（RACE）中，这个更大的模型的表现都不如 BERT-large\n\n![](https://i.loli.net/2021/04/05/5kJfDmlt8xiUFCv.png)\n\n\n\n### 概述\n\nALBERT 利用了参数共享、矩阵分解等技术大大减少了模型参数，用 SOP（Sentence Order Prediction） Loss 取代 NSP（Next Sentence Prediction） Loss 提升了下游任务的表现。但是 ALBERT 的层数并未减少，因此**推理时间（Inference Time）还是没有得到改进**。不过参数减少的确使得训练变快，同时 ALBERT 可以扩展到比 BERT 更大的模型（ALBERT-xxlarge），因此能得到更好的表现\n\n具体的创新部分有三个：\n\n1. embedding 层参数因式分解\n2. 跨层参数共享\n3. 将 NSP 任务改为 SOP 任务\n\n#### Factorized Embedding Parameterization\n\n原始的 BERT 模型以及各种依据 Transformer 的预训连语言模型都有一个共同特点，即 E=H，其中 E 指的是 Embedding Dimension，H 指的是 Hidden Dimension。这就会导致一个问题，当提升 Hidden Dimension 时，Embedding Dimension 也需要提升，最终会导致参数量呈平方级的增加。\n\n所以 ALBERT 的作者将 **E 和 H 进行解绑**，具体的操作就是**在 Embedding 后面加入一个矩阵进行维度变换**。E 的维度是不变的，如果 H 增大了，我们只需要在 E 后面进行一个升维操作即可\n\n![](https://i.loli.net/2021/04/05/8FjUN5XrKWAqvsP.png)\n\n所以，ALBERT 不直接将原本的 one-hot 向量映射到 hidden space size of H，而是分解成两个矩阵，原本参数数量为 V∗H，V 表示的是 Vocab Size。分解成两步则减少为 V∗E+E∗H，当 H 的值很大时，这样的做法能够大幅降低参数数量\n\n> V∗H=30000∗768=23,040,000\n>\n> V∗E+E∗H=30000∗256+256∗768=7,876,608\n>\n> 举个例子，当 V 为 30000，H 为 768，E 为 256 时，参数量从 2300 万降低到 780 万\n\n通过因式分解 Embedding 的实验可以看出，对于参数不共享的版本，随着 E 的增大，效果是不断提升的。但是参数共享的版本似乎不是这样，E 最大并不是效果最好。同时也能发现参数共享对于效果可能带来 1-2 个点的下降\n\n![](https://i.loli.net/2021/04/05/5W9ytZiukCfdLmQ.png)\n\n```python\ndef __init__(self):\n  self.emb = nn.Embedding(vocab_size, 128)\n  self.fc = nn.Linear(128, 1024)\ndef forward(self, x):\n  x = self.emb(x)\n  x = self.fc(x) # [batch_size, seq_len, 1024]\n```\n\n\n\n#### Cross-Layer Parameter Sharing\n\n传统 Transformer 的每一层参数都是独立的，包括各层的 self-attention、全连接。这样就导致层数增加时，参数量也会明显上升。之前有工作试过单独将 self-attention 或者全连接层进行共享，都取得了一些效果。ALBERT 作者尝试将所有层的参数进行共享，相当于只学习第一层的参数，并在剩下的所有层中重用该层的参数，而不是每个层都学习不同的参数\n\n![](https://i.loli.net/2021/04/05/zOjWTLiGyaXMvnq.png)\n\n使用参数共享提升了模型 的稳定性，曲线更平滑了。\n\nBERT-base 和 ALBERT 使用相同的层数以及 768 个隐藏单元，结果 BERT-base 共有 1.1 亿个参数，而 ALBERT 只有 3100 万个参数。通过实验发现，feed-forward 层的参数共享会对精度产生比较大的影响；共享注意力参数的影响是最小的\n\n![](https://i.loli.net/2021/04/05/V3Tf6EhcAiuXder.png)\n\n```python\n# 参数共享例子\ndef __init__(self):\n    self.enc_layer = TransformerEncoder()\ndef forward(self, x):\n    for _ in range(12):\n        x = self.enc_layer(x)\n# 参数不共享例子        \ndef __init__(self):\n    self.enc_layer1 = TransformerEncoder()\n    self.enc_layer2 = TransformerEncoder()\n    ....\n    self.enc_layer12 = TransformerEncoder()\ndef forward(self, x):\n    x = self.enc_layer1(x)\n    x = self.enc_layer2(x)\n    ....\n    x = self.enc_layer12(x)\n# 分组参数共享\ndef __init__(self):\n    self.enc_layer1 = TransformerEncoder()\n    self.enc_layer2 = TransformerEncoder()\ndef forward(self, x):\n    for i in range(11):\n      enc_inputs = self.encoder_layer(enc_inputs)\n    x = self.enc_layer2(x)\n```\n\n#### Sentence-Order Prediciton (SOP)\n\n**BERT** 引入了一个叫做**下一个句子预测**的二分类问题。这是专门为提高使用句子对，如 \"自然语言推理\" 的下游任务的性能而创建的。但是像 RoBERTa 和 XLNet 这样的论文已经阐明了 NSP 的无效性，并且发现它对下游任务的影响是不可靠的\n\n因此，ALBERT 提出了另一个任务 —— **句子顺序预测**。关键思想是：\n\n- 从同一个文档中取两个连续的句子作为一个正样本\n- 交换这两个句子的顺序，并使用它作为一个负样本\n\n![](https://i.loli.net/2021/04/05/XHDghABQW6Y2Fdf.png)\n\n![](https://i.loli.net/2021/04/05/K7vIQg5C2GthUda.png)\n\n#### Adding Data & Remove Dropout\n\n以上 ALBERT 都是使用跟 BERT 相同的训练数据。但是增加训练数据或许可以提升模型的表现，于是 ALBERT 加上 STORIES Dataset 后总共训练了 157G 的数据。另外，训练到 1M 步的时候，模型还没有对训练集 Overfit，所以作者直接把 Dropout 移除，最终在 MLM 验证集上的效果得到了大幅提升\n\n![](https://i.loli.net/2021/04/05/8u3sZJXQ4EFcn2C.png)\n\n\n\n#### Conclusion\n\n刚开始看这篇文章是很惊喜的，因为它直接把同等量级的 BERT 缩小了 10 + 倍，让普通用户有了运行可能。但是仔细看了实验后才发现参数量的减小是需要付出代价的\n\n![](https://i.loli.net/2021/04/05/U37dpafWzxT4lqD.png)\n\n需要注意的是，Speedup 是训练时间而不是 Inference 时间。Inference 时间并未得到改善，因为即使是使用了共享参数机制，还是得跑完 12 层 Encoder，故 Inference 时间跟 BERT 是差不多的\n\n实验用的参数如下\n\n![](https://i.loli.net/2021/04/05/svcV1HRtMd7jxX8.png)\n\n可以得出的结论是：\n\n1. 在相同的训练时间下，ALBERT 得到的效果确实比 BERT 好\n2. 在相同的 Inference 时间下，ALBERT base 和 large 的效果都没有 BERT 好，而且差了 2-3 个点，作者在最后也提到了会继续寻找提高速度的方法（Sparse attention 和 Block attention）\n\n另外，结合 **Universal Transformer** 可以想到的是，在训练和 Inference 阶段可以动态地调整 Transformer 层数（告别 12、24、48 的配置）。同时可以想办法去避免纯参数共享带来的效果下降，毕竟 Transformer 中越深层学到的任务相关信息越多，可以改进 Transformer 模块，加入记忆单元、每层个性化的 Embedding\n\n\n\n\n\n\n\n","tags":["nlp"]},{"title":"Heterogeneous Graph Neural Network","url":"/2021/03/30/Heterogeneous-Graph-Neural-Network/","content":"\n# Heterogeneous Graph Neural Network\n\n\n\n## 摘要\n\n挑战：不仅是因为需要合并由多种类型的节点和边组成的异质结构(图)信息，而且还因为需要考虑与每个节点相关联的异质属性或内容(例如，文字或图像)。\n\n方法：C1引入了一种带重启的随机游走策略，对每个节点的固定大小的强相关异构邻居进行采样，并根据节点类型对它们进行分组。\n\n接下来，设计一个包含两个模块的神经网络体系结构，用来聚合那些采样的相邻节点的特征信息。\n\n第一个模块C2：对异构内容的“深度”特征交互进行编码，并为每个节点生成内容Embedding。\n\n第二个模块C3：聚合不同相邻组(类型)的内容(属性)嵌入，并通过考虑不同组的影响来进一步组合它们，以获得最终的节点嵌入。\n\nHetGNN用途：在边链接预测、推荐、节点分类和聚类以及归纳节点分类和聚类等各种图挖掘任务\n\n\n\n## 异质图\n\n![](https://i.loli.net/2021/03/30/BAJN9XrwndLE5zW.png)\n\n学术图中，\n\n关系：作者与论文(写作)、论文与论文(引文)、论文与期刊(出版)\n\n此外，该图中的节点携带属性 如作者有id属性、文本有论文摘要属性。\n\n## 挑战\n\n![](https://i.loli.net/2021/03/30/a74yHiAdxeXI1jn.png)\n\n- 1：现有的GNN大多只聚合直接（一阶）相邻节点的特征信息，特征传播过程可能会削弱远邻节点的影响。此外，“中心”节点的嵌入生成受到弱相关邻居（“噪声”邻居）的影响，“冷启动”节点的嵌入由于邻居信息有限而没有得到充分的表示。因此，挑战1是：如何为HetG中的每个节点采样与嵌入生成密切相关的异构邻居。如上图C1。(信息聚合考虑的信息不够多)\n\n  方法：基于重启策略的随机游走，采样固定大小强相关异构邻居，并根据节点类型进行分组。\n\n- 2：HETG中的一个节点可以携带非结构化的异构内容。如上图C2，type1有属性＋文本，type2有属性+图片。因此挑战2是：如何设计节点内容编码器来解决HetG中不同节点的内容异构性。(异构属性信息如何嵌入)\n\n  方法：聚合模块1，用RNN对异构内容的“深层”特征交互进行编码，得到每个节点的内容嵌入。\n\n- 3：不同类型的邻居对HetG中节点嵌入的贡献不同。目前的GNN主要集中在齐次图上，没有考虑节点类型的影响。因此，挑战3是：如何通过考虑不同节点类型的影响来聚合异构邻居的特征信息，如图上图C3。(不同类型节点如何聚合)\n\n  方法：聚合模块2，利用另一个RNN聚合不同邻域组的内容嵌入，并进一步通过注意力机制进行组合，以度量异构节点类型的不同影响，并获得最终的节点嵌入。\n\n\n\n和其他模型对比\n\n![](https://i.loli.net/2021/03/30/a5wPN1Uc8hnB9Tu.png)\n\n## C-HetG\n\n内容关联异质图\n\n定义为有多种类型的节点V和边E的图。$G=(V，E，O_V，R_E)$。\n\n$O_V$ 和 $R_E$ 分别表示对象类型的集合和关系类型的集合。\n\n此外，每个节点与不同种类的内容相关联(例如，属性、文本或图像)。\n\n\n\n## 基于重启策略的随机游走 C1\n\n和GAT/GCN采样一阶邻居不一样。他们不能聚合多种类型节点的信息，并且采样信息不完整。\n\nHetGNN用这个方法采样。\n\nStep1：采样固定大小长度的随机游走路径$RWR(v)$ 。以概率p决定是走到当前节点还是返回上一节点。 v是起始节点，$RWR(v)$ 中不同类型节点的数量受到限制，以确保可以采样所有节点类型。\n\nStep2:：对不同类型的邻居进行分组。对于每个节点类型t，根据频率从 $RWR(v)$ 中选择前kt个节点，并将它们作为节点v的t型相关邻居的集合。\n\n保证了手机每个节点都有所有类型邻居的信息，并且对相同类型的邻居进行分组，以便后续任务。\n\n\n\n## 异质内容编码 C2\n\n![](https://i.loli.net/2021/03/30/O34hFWBto5xnsYT.png)\n\n对于第二个挑战，设计此模块去提取图中的异质内容$C_v$ ,编码为固定大小的embedding。\n\n定义$C_v$ 中的第i个特征表达为 $x_i \\in R^{d_f\\times 1}$\n\n$x_i$ 可以根据不同类型的内容采用不同的技术进行预训练。例如，可以利用Par2Vec来预先训练文本内容，或者使用CNNs来预先训练图像内容。 下面的 $FC_{\\theta_x}$ 就代表不同的特征转换器，参数为$\\theta_x$。\n\n采用双向LSTM学习深度特征：\n$$\n\\begin{equation}\\begin{split} \n    f_1(v) =\\frac {\\sum_{i\\in C_v}[\\overrightarrow{LSTM}\\{FC_{\\theta_x}(x_i) \\} \\oplus \\overleftarrow{LSTM} \\{ FC_{\\theta_x}(x_i)  \\}]}{ |C_v|}\n    \\end{split}\\end{equation}\n$$\n\n\n$\\oplus$ 链接操作。LSTM公式：\n$$\n\\begin{equation}\\begin{split} \n z_i &= \\sigma (U_zFC_{\\theta_x}(x_i) + W_zh_{i-1} + b_z) \\\\\n  f_i &= \\sigma (U_fFC_{\\theta_x}(x_i) + W_fh_{i-1} + b_z) \\\\\n   o_i &= \\sigma (U_oFC_{\\theta_x}(x_i) + W_oh_{i-1} + b_z) \\\\\n   \\tilde c_i &= tanh(U_cFC_{\\theta_x}(x_i)+ W_ch_{i-1} + b_c)\\\\\n   c_i &= f_i \\circ c_{i-1} + z_i \\circ \\tilde c_i\\\\\n   h_i &= tanh(c_i) \\circ o_i\n \\end{split}\\end{equation}\n$$\n\n## 聚合异构邻居 C3\n\n包含两个步骤：\n\n- 同类邻居聚合\n- 类型邻居聚合\n\n### 同类型聚合\n\n![](https://i.loli.net/2021/03/30/uh5zVmLsHNKiMyf.png)\n\n使用随机游走对每个节点的不同节点类型的固定大小邻居进行采样后。\n\n将$v∈V$ 的t类型抽样邻居集表示为$N_t(v)$\n\n经过上面的内容嵌入后变为$ v' \\in N_t(v)$ \n\n然后使用神经网络$f_2^t$ 来聚合得到的内容嵌入。\n\n聚合嵌入公式为：\n$$\n\\begin{equation}\\begin{split} \n f_2^t(v) = AGG_{v'\\in N_t(v)}^t \\{ f_1(v')\\}\n    \\end{split}\\end{equation}\n$$\n还是使用的Bi-LSTM：\n$$\n\\begin{equation}\\begin{split} \n f_2^t(v) =\\frac {\\sum_{v'\\in N_{t(v)}}[\\overrightarrow{LSTM}\\{f_1(v') \\} \\oplus \\overleftarrow{LSTM} \\{ f_1(v')  \\}]}{ |N_{t(v)}|}\n    \\end{split}\\end{equation}\n$$\n使用Bi-LSTM来聚集所有t型邻居的内容嵌入，并使用所有隐藏状态的平均值来表示一般的聚集嵌入。我们使用不同的Bi-LSTM来区分邻居聚合的不同节点类型。Bi-LSTM对无序邻域集进行操作，该集合的灵感来自于GraphSAGE\n\n### 类型邻居聚合\n\n![](https://i.loli.net/2021/03/30/4yp3YDo8l7JhSAc.png)\n\n上一步为节点v生成$|O_v|$ 聚集嵌入 (图中的节点类型集)。\n\n为了将这些基于类型的邻居嵌入与v的内容嵌入相结合，采用了注意机制。\n\n其动机是不同类型的邻居将对v的最终表示做出不同的贡献。因此，输出嵌入被表示为：\n$$\n\\begin{equation}\\begin{split} \n \\epsilon_v = a^{v,v} f_1(v) + \\sum_{t\\in O_v} \\alpha^{v,t} f_2^t(v)\n    \\end{split}\\end{equation}\n$$\n$\\epsilon_v \\in \\Re^{d\\times 1}$  , d 是嵌入维度\n\n$f_1(v)$ 是获得v的内容嵌入\n\n$f_2^t(v)$ 是类型聚合嵌入\n\n$\\alpha^{v,*}$  表示不同嵌入的重要性\n\n定义：$F(v) =\\{ f_1(v) \\bigcup (f_2^t(v) ,t\\in O_v)\\}$\n$$\n\\begin{equation}\\begin{split} \n \\alpha^{v,i} = \\frac{ exp \\{LeakyReLU(u^T[f_i\\oplus f_1(v)])\\}}{\\sum_{f_j\\in F(v)} exp\\{ LeakyReLU(u^T[f_j\\oplus f_1(v)]) \\}}\n    \\end{split}\\end{equation}\n$$\n\n\n## \n\n\n\n\n\n\n\n\n\n## HetGNN\n\n![](https://i.loli.net/2021/03/30/FKu5qcMT1AahHlk.png)\n\n四个组成部分\n\n- 采样异质邻居\n- 编码节点的异质内容\n- 聚合异质邻居\n- 制定目标函数，设计训练过程。\n\n\n\n\n\n\n\n","tags":["GNN"]},{"title":"Cognitive Graph for Multi-Hop Reading Comprehension at Scale(ACL2019)","url":"/2021/03/27/Cognitive-Graph-for-Multi-Hop-Reading-Comprehension-at-Scale-ACL2019/","content":"\n# Cognitive Graph for Multi-Hop Reading Comprehension at Scale(ACL2019)\n\nppt : https://coding-zuo.github.io/CogQA_RevealJS/ \n\n## 认知图谱\n\n知识图谱+认知推理+逻辑表达。\n认知图谱依据人类认知的双加工理论，动态构建带有上下文信息的知识图谱并进行推理。\n认知图谱可以被解释为“基于原始文本数据，针对特定问题情境，使用强大的机器学习模型动态构建的，节点带有上下文语义信息的知识图谱”。\n\n**认知图谱和知识图谱的区别？**\n认知图谱是包含知识图谱的相关技术的。知识图谱的任务主要是包括知识图谱的表示、构建和存储。这些是构建知识库的过程。认知推理的底层是知识推理，而知识图谱目的是完善知识。面向知识图谱的认知推理可以基于已有的知识推理出新的知识，或者发现错误矛盾的知识。认知图谱是为了解决复杂理解问题或少样本知识图谱推理问题如歧义问题、链接困难、关系的冗余与组合爆炸等。认知推理其实更具有人脑特性，相对更动态一些，可以基于知识感知来调整推理，也可以基于推理来调整知识和感知。交叉了认知科学对人类知识的总结，有助于划分和处理知识图谱的相关问题。\n\n认知图谱主要有三方面创新，分别对应人类认知智能的三个方面：\n\n1.（长期记忆）直接存储带索引的文本数据，使用信息检索算法代替知识图谱的显式边来访问相关知识。\n\n2.（系统1推理）图谱依据查询动态、多步构建，实体节点通过相关实体识别模型产生。\n\n3.（系统2推理）图中节点产生的同时拥有上下文信息的隐表示，可通过图神经网络等模型进行可解释的关系推理。\n\n本质上，认知图谱的改进思路是减少图谱构建时的信息损失(两元一谓)，将信息处理压力转移给检索和自然语言理解算法，同时保留图结构进行可解释关系推理。\n\n![](https://i.loli.net/2021/03/27/2mdSVkFas3NlWhQ.png)\n\n\n\n\n\n## 摘要\n\n- 提出新的多跳QA框架CogQA\n- 基于双过程理论System1:隐式提取，System2:显式推理\n- 可以给出答案的解释路径\n- 基于Bert和GNN处理HotpotQA数据集\n- 评估指标F1 score\n\n## Introduction\n\n现在的单段阅读理解机器已经超过人了，像SQuAD。但要跨过机器阅读理解和人阅读理解的鸿沟还很难。\n\n主要有三个主要挑战：\n\n- 理解能力：如对抗性测试所揭示的那样，单段问答模型倾向于在与问题匹配的意义中寻找答案，这不涉及复杂的推理。因此多跳阅读是要克服的。\n- 可解释性：显式推理路径能够验证逻辑严格性，对质量保证系统的可靠性至关重要。数据集中给出的是无序的句子级别的解释，但我们人可以通过逻辑一步一步给出有序的、实体级别的解释。\n- 大规模的(时间成本)：任何QA系统都要处理大规模的知识。现在已有的DrQA是通过预检索来减少规模到几个段落的范围。这个框架是单段阅读和多段阅读的结合，但和人脑中大量记忆和知识而言是一种折中的做法。时间成本不会随着段落增加而增加。\n\n### 两个系统的工作\n\n**隐式提取System1**：模仿大脑通过隐式注意提取相关信息，是直觉和无意识的系统。\n从段落中提取与问题相关的实体和答案日期，并对其语义信息进行编码。\n\n![](https://i.loli.net/2021/03/27/jY967V5RuPvpgm8.jpg)\n\n如上图，系统一从段落和语义信息中提取问题相关的实体和答案候选。\n\n**显式推理System2**：在System1基础上进行有意识的的可控的推理。\n\n系统一根据提出的问题提供给系统二资源，系统二根据信息进行深度推理，挖掘相关信息。两个系统协作，迭代的给出快慢思考。\n\n在信息一提出出的信息图上，搜集线索。并且指导系统一更好的提取下一跳实体。\n\n迭代直到所有可能的答案都被找到，再由系统二推理出最终答案。\n\n![](https://i.loli.net/2021/03/27/lO9sy8hDARqk3uI.jpg)\n\n\n\n`系统1(system 1)负责经验性的直觉判断，这一黑盒过程提取重要信息，并动态构建认知图谱；系统2(system 2)则在图上进行关系推理，由于认知图谱保留了实体节点上语义信息的隐表示，所以在符号逻辑之外，比如图神经网络等深度学习模型也可以大显身手。`\n\n![](https://i.loli.net/2021/03/27/SPXlQ4nOkLcpARH.jpg)\n\n这块有一个缺点，GCN在有节点新加入的时候要重新训练图模型？这个要等我研究研究源码\n\n前沿节点(frontier node)有两种:\n\n- 新添加的节点\n- 图中新添加边的节点(需重新访问)\n\n\n系统1在线索和问题Q的指导下读取para[x]，提取跨度并生成语义向量sem[x，Q，clues]。同时，系统2更新隐藏表示X，并为任何后继节点y准备线索clues[y，G]。基于X进行最终预测。\n\n算法流程\n1.提取在问题Q中提到的实体作为认知图的初始化，并且标记为前沿节点。\n2.重复下面过程直到21(在每一步中，我们访问一个前沿节点x)\n3.从前沿节点中跳出一个节点x\n4.从前沿节点收集线索clues[x,G],例如线索可以是提及x的句子。(线索句可以是提到的x的句子)\n5.在词库W中找到包含x的段落para[x]\n6.system1生成语义向量sem[x,Q,clues],初始化X[x]\n7.如果x是一个hop节点\n8.system1在para[x]中找到hop和answer的局部\n9.遍历hop内容，每个内容为y\n10.如果内容y不在G内并且y在词库W内\n11.用y创建一个新的hop节点\n12.如果y属于G，并且x和y的边不在图内\n13.在图中添加x和y的连线\n14.让节点y作为一个前沿节点\n15.循环结束\n16.答案部分，每个答案是y\n17.添加一个新的答案节点y和edge(x,y)到G中\n18.循环结束\n19.x过程结束\n20.用System2更新隐含X的表示\n21.直到G中没有前沿节点或G足够大；\n22.返回答案节点中概率最大的节点作为最终答案。\n\n关于可解释性，认知图谱有显式的路径，除了简单的路径，认知图还可以清楚地显示联合或循环推理过程。\n在这些过程中，可能会带来关于答案的新线索。\n\n尺度可伸缩性，框架理论上是可伸缩的，因为引用所有段落的唯一操作是通过标题索引访问哪些段落。\n\n对于多跳问题，传统的检索-抽取框架可能会牺牲后续模型的潜力，因为距离问题多跳的段落可能共享的常用词很少，与问题的语义关系也很小，导致检索失败。然而，这些段落可以通过在我们的框架中使用线索迭代展开来发现。\n\n## 实施方案\n\n![](https://i.loli.net/2021/03/27/A7W8mvJ1z2sioSc.jpg)\n\n### System1\n系统1的作用，在线索clues和问题Q的指导下提取spans并生成语义向量sem[x,Q,clus]。\nclues是前置节点段落的句子，从文中直接提取原始句子，这样做方便BERT训练。\n\n![](https://i.loli.net/2021/03/27/A7W8mvJ1z2sioSc.jpg)\n\nBert的输入句子分为A和B两部分：\n$$\n    \\begin{equation}\\begin{split} \n    A:[CLE]Question[SEP]clues[x,G][SEP]B:Para[x]\n    \\end{split}\\end{equation}\n$$\n\n\\[CLE\\]:放在每个句子的第一位，classification用于下游分类任务。\n为什么用CLS？因为self-attention，[CLS]的output含有整句话的完整信息。在每个词的时候，对自己这个词的评分会很大。用无意义的CLS可以公平的反应整个句子的特征。\n\\[SEP\\]:separator分隔连接token序列的符号。\n\n![](https://i.loli.net/2021/03/27/7ROBPrVjkQfH91s.jpg)\n\n$$\n    \\begin{equation}\\begin{split} \n    P^{start}_{ans}[i]=\\frac{e^{S_{ans} \\cdot T_i}}{\\sum_je^{S_{ans}\\cdot T_j}}\n    \\end{split}\\end{equation}\n$$\n\n$S_{hop}$、$E_{hop}$、$S_{ans}$、$E_{ans}$ :可学习的参数，用来预测目标span。\n$T\\in R^{L\\times H}$:是bert的输出向量,L是输入序列长度，H是隐层维度。\n$P^{start}_{ans}[i]$:是第i个输入token到ans范围内开始位置的概率。\n\n\n\n\n\n我们只聚焦topK开始的概率${start_k}$,对于每个k的结束位置$end_k$:\n$$\n    \\begin{equation}\\begin{split} \n    end_k = argmax_{start_k\\leq j\\leq start_k + maxL }P^{end}_{ans}[j]\n    \\end{split}\\end{equation}\n$$\nmaxL：是最大概率的span长度。\n$P^{end}_{ans}[j]$:是第j个输入token到ans范围内结束位置的概率。\n\n文章说是这么区分下一跳和答案的：\n答案和下一跳协议具有不同的属性。答案提取在很大程度上依赖于问题所指示的字符。例如，“纽约市”比“2019”更有可能是WHERE问题的答案，而下一跳实体通常是其描述与问题中的语句相匹配的实体。\n\n为了识别不相关的段落，利用在§3.4.1中引入负抽样进行训练，系统1生成负阈值。在顶部\nk个跨度，起始概率小于负阈值将被丢弃。因为对第0个token[CLS]进行预训练以合成\n用于下一句预测的所有输入标记任务Pstart[0]充当ANS这是我们实施过程中的一个阈值。\n\n### System2\n系统2，更新隐藏表示X，并为任何后继节点y准备clues[y，G]。基于X输出最终预测结果。\n\n第一个功能是为前沿节点准备clues[x，G]，我们将其实现为收集提到x的x个前置节点的原始语句。\n第二个功能是更新隐含表示X，这是系统2的核心功能。隐含表示$X∈R^{n×H}$代表G中所有n个实体的理解。要完全理解实体x与问题q之间的关系，仅仅分析语义sem[x，Q，clues]是不够的。由于图结构的归纳偏差，GNN已被提出用于对图进行深入学习，特别是关系推理。\n\n$$\n    \\begin{equation}\\begin{split} \n    \\Delta = \\sigma((AD^{-1})^T\\sigma(XW_1))\n    \\end{split}\\end{equation}\n$$\n$$\n    \\begin{equation}\\begin{split} \n    X’=\\sigma(XW_2+\\Delta)\n    \\end{split}\\end{equation}\n$$\n$W_1,W_2 \\in R^{H\\times H}$:权重矩阵\n$\\sigma(XW_1)$ 左乘$(AD^{-1})^T$(列归一化A):可以解释为局部化光谱过滤.\n在访问边界节点x的迭代步骤中，其隐藏表示X[x]按照公式(4)(5)更新。\n在实验中发现“异步更新”在性能上没有明显的差别，在G最终确定后，将所有节点的X一起分多步更新，效率更高，在实践中被采用。\n\n\n\n### 训练细节\n\n模型采用负采样，在训练集的段落中预先提取下一跳hop和answer span。\n对于每个para[x]和问题Q有下面这种字典数据。\n$$\n    \\begin{equation}\\begin{split} \n    D[x,Q] = \\{(y_1,start_1,end_1),...,(y_n,start_n,end_n)\\}\n    \\end{split}\\end{equation}\n$$\n$start_i$和$end_i$ 是在para[x] 中根据一个实体或者答案$y_i$模糊匹配出来的。\n\n### 任务1：Span Extraction\n\n基于$D[x,Q]$，得到$P^{start}_{ans}$,$P^{end}_{ans}$,$P^{start}_{hop}$,$P^{end}_{hop}$\n在每个段落中最多出现一个$answer(y,start,end)$\n因此，定义一个one-hot向量$g_{ans}^{start}$ ，其中$g_{ans}^{start}[start]=1$。然而，一个段落中可能出现多个不同的ans next-hop spans，因此$g_{hop}^{start_i}[start]=1/k$ ，其中k是下一跳跨度的数量。\n\n为了能够区分不相关的段落，在G中预先增加了不相关的negative-hop节点。\n\n### 任务2：预测答案节点\n\n\n\n\n\n## 实验\n\n### 数据集\n\n使用HotpotQA的全维基设置来构建实验。基于维基百科文档中的第一段图，众包收集了112,779个问题，其中84%的问题需要多跳推理。数据被分成训练集(90,564个问题)、发展集(7,405个问题)和测试集(7,405个问题)。开发和测试集中的所有问题都是困难的多跳案例。\n\n \n\n## 总结&展望\n系统2的推理如何实现？现在的方法（如图神经网络）虽然使用关系边作为归纳偏置，却仍然无法执行可控、可解释、鲁棒的符号计算。系统1如何为现有的神经-符号计算方法提供可行前续工作？\n\n文本库应该如何预处理或预训练，才能有助于访问相关知识的检索？\n\n另辟蹊径？本文介绍的认知图谱是基于认知科学的双通道理论，是否还存在其他支撑理论？或者直接构建一个符号推理和深度学习相结合的新型学习架构？\n\n如何与人类记忆机理相结合？人类记忆机理包括长期记忆和短期记忆，但其工作模式和工作机理并不清楚。长期记忆可能存储的是一个记忆模型，记忆模型不再是一个概念的网络，而是一个计算模型的网络。\n\n认知图谱如何与外界反馈相结合是一个全新的问题。当然这里可以考虑通过反馈强化学习来实现，但具体方法和实现模式还需要深入探讨。\n\n## 参考文献\n[浅谈多跳阅读理解](https://zhuanlan.zhihu.com/p/133483274)\n[BERT的[CLS]有什么用](https://www.pianshen.com/article/5232700066/)\n[从Word Embedding到Bert模型—自然语言处理中的预训练技术发展史](https://zhuanlan.zhihu.com/p/49271699)\n[从知识图谱到认知图谱：历史、发展与展望](http://toutiao.secjia.com/knowledge-map-to-cognitive-map-0820/)\n[图神经网络及其在知识图谱中的应用](https://zhuanlan.zhihu.com/p/208697908?utm_source=wechat_timeline)\n[还在用[CLS]？从BERT得到最强句子Embedding的打开方式！](http://www.360doc.com/content/20/1227/10/7673502_953710193.shtml)\n\n\n\n\n\n","tags":["GNN&nlp"]},{"title":"Multi-hop Reading Comprehension across Multiple Documents by Reasoning over Heterogeneous Graphs","url":"/2021/03/27/Multi-hop-Reading-Comprehension-across-Multiple-Documents-by-Reasoning-over-Heterogeneous-Graphs/","content":"\n# Multi-hop Reading Comprehension across Multiple Documents by Reasoning over Heterogeneous Graphs\n\n\n\n京东出品19年采用异质图网络的一篇多跳阅读理解，这篇是在WikiHopQA数据集上，在没有使用预训练语言模型的情况下第一次超过人类表现。20年还有一篇在HotpotQA上的，过两天准备也读一读。前一阵子用京东在线客服和智能语音客服的时候，感觉效果不错，果然发现这两篇文章。\n\n先说一下WikiHopQA\n\n训练集43,738个样本，开发集5129个。候选答案个数2-79个之间，平均19.8个。文档数3-63个，平均13.7篇。每篇文档的字数4-2046字，平均100.4个字。该数据集的难度在于，要从多篇文章中找相关文档，还要依据多篇文章做推理。推理跳数的增加，与问题的相关性越来越小，统计距离较远，非参数化的检索方法如传统的TF-IDF，无法搜索到最终答案所在的上下文。如下图：\n\n![](https://i.loli.net/2021/03/27/IrqT6k5tdo9Az37.png)\n\n每个样本包含字段：dict_keys(['answer', 'id', 'candidates', 'query', 'supports'])\n\n目前主要做法有三种思路：构造推理链，一般用RNN网络进行链式推理；从网络模型角度改进；构造graph，利用GCN，GAT等方法在图上推理。\n\n和HotpotQA一样都是属于多跳阅读理解数据集。针对一个问题给出多个支撑文档，来做推理。可看之前的文章[HotpotQA数据集](https://coding-zuo.github.io/2021/03/23/HotpotQA%E6%95%B0%E6%8D%AE%E9%9B%86/)\n\n不同的是，WikiHopQA给出了候选答案，可以看成是多项选择题。\n\n\n\n\n\n## 创新点\n\n提出Heterogeneous Document-Entity  graph (HDE graph) ，可以从候选答案、文档和实体中，聚合不同级别的信息粒度。\n\n使得不同类型的节点之间能够进行丰富的信息交互，从而便于精确的推理。不同类型的节点与不同类型的边相连，以突出查询、文档和候选之间呈现的各种结构信息。\n\n\n\n## 如何设计\n\n![](https://i.loli.net/2021/03/28/disz9JgGEIf5u1C.png)\n\n数据集提供的是候选答案、问题和一系列文档。分布作为输入，分别表示为：$C_q, q(s,r,?), S_q $\n\n其中，$q(s,r,?)$  内分别表示为主体、关系和位置客体。任务是预测查询的正确答案$a^*$。\n\n首先将这些输入文字，映射成词向量，分别为 $X_q\\in R^{l_q\\times d}$ 、$X_s^i\\in R^{l_s^i\\times d}$ 其中i为第i个词、  $, X_c^j\\in R^{l_c^j\\times d}$  其中j为第j个词。\n\n$l$ 为每段文字长度 ，d为词向量维度。\n\n这就是上图中的最下面一层。\n\n--------\n\n再往上一层encoder采用的是双向GRU，分别对C/q/S 的上下文信息进行编码。\n\n编码后的维度是  $ H_q\\in R^{l_q\\times h}$  、 $H_s^i\\in R^{l_s^i\\times h}$ 、 $H_c^j\\in R^{l_c^j\\times h}$   其中h是RNN输出维度。\n\n再观察上图，发现在encoder上面一层，Documents上面和其他两个地方不同，中间加了一个实体提取。\n\n是作者发现有些通过查询query和候选答案C，在文档中提取被提及的实体。提取到每个mentions的开始位置和结束位置。\n\n每一次提及都被视为一个实体Entiry。第i个文档提出的实体表示为 $H_s^i, M\\in R^{l_m\\times h}$   , $l_m$ 是实体长度。\n\n------\n\n再向上一层，是co-attention协同注意力机制，特意读了下协同注意力DCN那篇文章[协同注意力和自注意力的区别(DCN+)](https://coding-zuo.github.io/2021/03/25/%E5%8D%8F%E5%90%8C%E6%B3%A8%E6%84%8F%E5%8A%9B%E5%92%8C%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E7%9A%84%E5%8C%BA%E5%88%AB/)\n\n用到这个任务上其实就是一个协同每两个特征来提取新特征。\n\n通俗上讲，Q和S 相互co-attention就是带着问题看文章，读完文章看问题。C和Q做带着选项看问题。\n\n拿RNN输出的问题序列$H_q \\in R^{l_q\\times h}$ 和文档$H_s^i\\in R^{l_s^i\\times h}$为例计算过程如下：\n$$\n\\begin{equation}\\begin{split} \n    A^i_{qs} = H_s^i(H_q)^T  \\in R^{l_s^i\\times l_q}\n    \\end{split}\\end{equation}\n$$\n得到查询和每个字的点积打分。\n\n为简化起见，在后面的上下文中，我们使用上标i，它表示对第i个文档的操作。\n$$\n\\begin{equation}\\begin{split} \n    C_q &= softmax(A_{qs}^T)H_s \\in R^{l_q\\times h}\\\\\n    C_s &= softmax(A_{qs})H_q \\in R^{l_s\\times h}\n    \\end{split}\\end{equation}\n$$\n进一步使用GRU ,f 对共同参与的文档上下文进行编码\n$$\n\\begin{equation}\\begin{split} \n    D_s = f(softmax(A_{qs})C_q)\\in R^{l_s\\times h}\n    \\end{split}\\end{equation}\n$$\n最终拼接\n$$\n\\begin{equation}\\begin{split} \n   S_{ca} =[C_s;D_s] \\in R^{l_s\\times 2h}\n    \\end{split}\\end{equation}\n$$\n同样的co-attention应用在query和候选，query和实体得到 $C_{CA},E_{ca}$ 。\n\n注意，作者不在查询和对应于查询主题的实体之间共同关注，因为查询主题已经是查询的一部分。为了保持维度的一致性，应用了一个具有tanh激活函数的单层多感知器(MLP)，将查询主题实体的维数增加到2h。\n\n这个查询主题query subject到底是什么我有点疑问。\n\n-----\n\n再往上是一个自注意力池化。\n\n当co-attention产生文档的查询感知上下文表示时，自关注集合被设计为通过选择重要的查询感知信息将顺序上下文表示转换为固定维度的非顺序特征向量。\n$$\n\\begin{equation}\\begin{split} \n    a_s&=softmax(MLP(S_ca))\\in R^{l_s\\times 1}\\\\\n    s_{sa}&= a_s^TS_{ca} \\in R^{1\\times 2h}\n    \\end{split}\\end{equation}\n$$\n\n\n同样，对每个实体和候选，可得到  $c_{sa}, e_{sa}$  。\n\n------\n\n再接下来就是构建异质图了。\n\n![](https://i.loli.net/2021/03/28/AtPhugd79czJ3k2.png)\n\n\n\n一共三种类型的节点，绿色是文档节点、蓝色是实体节点、黄色是候选答案节点。\n\n七种建边规则：\n\n- 文档节点和候选节点：如果候选节点在文档中出现时建立一条边。\n- 文档节点和实体节点：如果实体节点从这个文档中提取出来建立一条边。\n- 候选节点和实体节点：如果实体节点被候选答案提及建立一条边。\n- 两个实体节点之间：如果他们在同一个文档中被提取时建立一条边。\n- 两个实体节点之间: 如果他们被相同的候选或问题提及，且实体在不同的文档中时建立一条边。\n- 所有的候选节点相互连接\n- 不满足以上条件的不进行相连。\n\n## HGN传播聚合机制\n\n信息传递\n$$\n\\begin{equation}\\begin{split} \n    z_i^k = \\sum_{r\\in R} \\frac{1}{|N_i^r|} \\sum_{j\\in N_i^r} f_r(h_j^k)\n    \\end{split}\\end{equation}\n$$\n\n\n其中R 是所有边的类型\n\n$N_i^r$ 是 第i个节点边类型是r的邻居集合\n\n$h_j^k$ 是第j个邻居节点的第k层表达\n\n$h_j^0$ 是self-attention的输出\n\n$f_r$ 是MLP\n\n$z_i^k$ 是第i个节点第k层的局和信息\n\n可以与变换更新后的节点i：\n$$\n\\begin{equation}\\begin{split} \n    u_i^k = f_s(h_i^k) + z_i^k\n    \\end{split}\\end{equation}\n$$\n$f_s$ :MLP\n\n为了解决多层GNN的过平滑问题，作者采用了加门控的方式。\n$$\n\\begin{equation}\\begin{split} \n    g_i^k &= sigmoid(f_g([u_i^k;h_i^k]))\\\\\n    h_i^{h+1} &= tanh(u_i^k)\\odot g_i^k + h_i^k \\odot (1-g_i^k)\n    \\end{split}\\end{equation}\n$$\n$\\odot$ :element-wise product = element-wise multiplication = Hadamard product\n\n含义：两个矩阵对应位置元素进行乘积\n\n以上的$f$ 都是单层MLP 输出维度为2h\n\n## 最终预测\n\n使用候选节点和与候选提及相对应的实体节点的最终节点表示来计算分类分数：\n$$\n\\begin{equation}\\begin{split} \n    a = f_C(H^C)+ACC_{max}(f_E(H^E))\n    \\end{split}\\end{equation}\n$$\n$H^C \\in R^{C\\times 2h}$ , C是候选数量\n\n$H^M \\in R^{M\\times 2h}$ , M是节点数量\n\n$f_C,f_E$ 两层MLP\n\n$ACC_{max}$ :是对属于同一候选者的实体的分数取最大值的操作。\n\n隐含层大小为输入维的一半，输出维数为1，我们将可预测节点和实体节点的得分直接相加，作为多个候选者的最终得分。因此，输出分数向量$a∈r^{c×1}$给出了所有候选的分布。由于任务是多类分类，采用交叉熵损失作为训练目标，以a和标签作为输入。\n\n\n\n## 实验\n\n![](https://i.loli.net/2021/03/28/ZMIraibAGWv9VL8.png)\n\n\n\n![](https://i.loli.net/2021/03/28/3JDMT6lNtiWIBQf.png)\n\n\n\n\n\n\n\n\n\n","tags":["GNN&nlp"]},{"title":"Pytorch多GPU并行实例","url":"/2021/03/27/Pytorch多GPU并行实例/","content":"\n# Pytorch Train_Multi_GPU\n\nhttps://pytorch.org/tutorials/intermediate/ddp_tutorial.html\n\n两种方式：\n\n- DataParallel（DP）：Parameter Server模式，一张卡位reducer，实现也超级简单，一行代码。\n- DistributedDataParallel（DDP）：All-Reduce模式，本意是用来分布式训练，但是也可用于单机多卡。\n\n最后还有一个pycharm远程服务器的配置，还有如何在pycharm里配置run参数为：\n\n```\npython -m torch.distributed.launch --nproc_per_node=4 --use_env train_multi_gpu_using_launch.py\n```\n\n这个行运行命令是用DistributedDataParallel时的，指定的运行参数。具体介绍在后面写。\n\n\n\n### DataParallel vs DistributedDataParallel\n\n- 如果模型太大而无法容纳在单个GPU上，则必须使用 **model parallel** 将其拆分到多个GPU中。 DistributedDataParallel与模型并行工作； DataParallel目前不提供。\n\n- DataParallel是单进程、多线程的，只能在单机上工作，而DistributedDataParallel是多进程的，既可用于单机，也可用于多机。即使在一台机器上，DataParallel通常也比DistributedDataParallel慢，这是因为线程间的GIL争用、每次迭代复制模型以及分散输入和收集输出带来的额外开销。\n\n- DistributedDataParallel适用于模型并行；DataParallel目前不能。当DDP与模型并行相结合时，每个DDP进程使用模型并行，所有进程共同使用数据并行。\n\n\n\n## 单机多卡理论基础\n\n- 按照并行方式来分：模型并行 vs 数据并行\n- 按照更新方式来分：同步更新 vs 异步更新\n- 按照算法来分：Parameter Server算法 vs AllReduce算法\n\n### 常见的多GPU使用 \n\n![jz0tf9.png](https://i.loli.net/2021/03/27/stRfpYBavhDPwnu.png)\n\n模型并行，将网络不同模块放到不同GPU上去运行。训练速度无提升，但可让非常大的模型分布在多块gpu。\n\n![](https://i.loli.net/2021/03/27/syT1vPiIwEMUYXF.png)\n\n数据并行，将数据和模型同时放到多个GPU，同时进行正向传播和反向传播，并行输入样本进行训练， 相当于加大了batchsize，训练速度也加快了。\n\n\n\n### 数据如何在不同设备间进行分配\n\n\n\n\n\n### 误差梯度如何在不同设备间通信\n\n\n\n\n\n\n\n\n### 多GPU训练常用启动方式\n\n- [torch.distributed.lauch](https://pytorch.org/docs/stable/distributed.html?highlight=distributed#module-torch.distributed.launch) : 代码量少，启动速度快。如果开始训练后，手动强制终止程序，有小概率会出现进程没有杀掉的情况。\n- torch.multiprocessing: 拥有更好的控制和灵活性\n\n## DataParallel\n\nhttps://pytorch.org/tutorials/beginner/blitz/data_parallel_tutorial.html\n\n\n\n\n\n## DistributedDataParallel（DDP）\n\nDistributedDataParallel（DDP）在module级别实现数据并行性。它使用[torch.distributed](https://link.zhihu.com/?target=https%3A//pytorch.org/tutorials/intermediate/dist_tuto.html)包communication collectives来同步梯度，参数和缓冲区。并行性在单个进程内部和跨进程均有用。在一个进程中，DDP将input module 复制到device_ids指定的设备，相应地按batch维度分别扔进模型，并将输出收集到output_device，这与[DataParallel](https://link.zhihu.com/?target=https%3A//pytorch.org/tutorials/beginner/blitz/data_parallel_tutorial.html)相似。\n\n### 处理速度不同步时\n\n在DDP中，Model, forward method 和 differentiation of the outputs是分布式的同步点。期望不同的过程以相同的顺序到达同步点，并在大致相同的时间进入每个同步点。否则，快速流程可能会提早到达，并在等待时超时。因此，用户负责进程之间的工作负载分配。有时，由于例如网络延迟，资源争用，不可预测的工作量峰值，不可避免地会出现不同步的处理速度。为了避免在这些情况下超时，请确保在调用[init_process_group](https://link.zhihu.com/?target=https%3A//pytorch.org/docs/stable/distributed.html%23torch.distributed.init_process_group)时传递足够大`timeout`value\n\n\n\n\n\n\n\n\n\n## 常见报错\n\nsubprocess.CalledProcessError: Command ‘[’/home/labpos/anaconda3/envs/idr/bin/python’, ‘-u’, ‘main_distribute.py’, ‘–local_rank=1’]’ returned non-zero exit status 1.\n\n这个错出现是前面有代码写的不对，可以先在DistributedDataParallel 中加入find_unused_parameters=True。试试，一般不是分布式部分的错，是前面哪里写的不对。很可能是data_loader哪里仔细检查一下。\n\n\n\n验证集loss和acc都上涨\n\n验证集loss上升，acc也上升这种现象很常见，原因是过拟合或者训练验证数据分布不一致导致，就是在训练后期，预测的结果趋向于极端，使少数预测错的样本主导了loss，但同时少数样本不影响整体的验证acc情况。\n\n问一下，这时如果设置早停，是不是以loss最小早停合理点？以前见过用准确率设置早停的。假设交叉熵损失，训练与验证集分布大概一致的条件下\n\n答：准确率比较好\n\n## 遇到问题\n\nloss下降但最终效果不好，得到的模型结果像是只在四分之一数据做训练后的效果。\n\n\n\n\n\n## 参考文献\n\n[PyTorch分布式训练简介](https://blog.csdn.net/baidu_19518247/article/details/89635181)\n\n[Pytorch多机多卡分布式训练](https://zhuanlan.zhihu.com/p/68717029)\n\n[【分布式训练】单机多卡的正确打开方式（三）：PyTorch](https://zhuanlan.zhihu.com/p/74792767)\n\n[PyTorch 24.单机多卡的理论基础](https://zhuanlan.zhihu.com/p/158886284)\n\n[【分布式训练】单机多卡的正确打开方式（三）：PyTorch](https://zhuanlan.zhihu.com/p/74792767)\n\n[PyTorch 20.GPU训练](https://zhuanlan.zhihu.com/p/158375254)\n\n[pytorch 分布式训练 distributed parallel 笔记](https://blog.csdn.net/m0_38008956/article/details/86559432)\n\n[Pytorch 分布式训练](https://zhuanlan.zhihu.com/p/76638962)\n\n[Pycharm：运行、调试pytorch分布式训练代码](https://blog.csdn.net/lxb206/article/details/114293060)\n\n[如何在pycharm中运行/调试torch分布式训练](https://zhuanlan.zhihu.com/p/144815822)\n\n[pytorch 分布式训练 distributed parallel 笔记](https://blog.csdn.net/m0_38008956/article/details/86559432?utm_medium=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7EBlogCommendFromMachineLearnPai2%7Edefault-1.control&dist_request_id=&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7EBlogCommendFromMachineLearnPai2%7Edefault-1.control)\n\n","tags":["DataGame"]},{"title":"协同注意力和自注意力的区别(DCN+)","url":"/2021/03/25/协同注意力和自注意力的区别/","content":"\n# 协同注意力和自注意力的区别(DCN+)\n\n读阅读理解QA的论文发现co-attention没见过，self-attention和attention又忘得差不多了。\n\n就先读了一下DCN和DCN+的论文\n\nDYNAMIC COATTENTION NETWORKS FOR QUESTION ANSWERING\n\nDCN+: MIXED OBJECTIVE AND DEEP RESIDUAL COATTENTION FOR QUESTION ANSWERING+\n\n注意力机制有很多种变形，这里我只考虑最近接触可能会用的。\n\n- soft&hard attention\n- key-value pair attention\n- self-attention\n- Multi-head attention\n- co-attention\n\n## attention\n\n注意力机制就是计算机模仿人的注意力，对信息分配一个权重，对关注的信息分配较大的权重，不重要的信息反之。\n\n例如，我们的视觉系统倾向于关注图像中辅助判断的部分信息，并忽略掉不相关的信息。同样，在涉及语言或视觉的问题中，输入的某些部分可能会比其他部分对决策更有帮助。例如，在翻译和总结任务中，输入序列中只有某些单词可能与预测下一个单词相关。同样，在image-caption问题中，输入图像中只有某些区域可能与生成caption的下一个单词更相关.\n\n### soft和hard的区别\n\nSoft attention是一种全局的attention，其中权重被softly地放在源图像所有区域\n\nHard attention一次关注图像的一个区域，采用0-1编码，时间花费较少，但是不可微分，所以需要更复杂的技术来进行训练\n\n在机器学习中soft 常常表示可微分，比如sigmoid和softmax机制，而hard常常表示不可微分\n\nsoft hard attention机制是在图像生成标题任务中被提出的，其原始任务如下:\n\n![](https://i.loli.net/2021/03/25/4bCNYj5f6kQcIXt.png)\n\n上面是soft 下面是hard，我们可以看到，soft的权重是每次被放置在整张图像上，注重强调的部分（越白）的数值越接近1，越黑越接近0\n\n下面的一排非黑即白，白色区域为1，黑色区域为0。\n\n\n\n现在主流用soft比较多，其主要步骤有两个：\n\n针对输入$X=[x_1,x_2...x_3]$ (提取对象)\n\n- 1计算输入信息熵的注意力分布\n- 2根据注意力分布计算输入信息的加权平均\n\n### 计算注意力分布\n\n给定一个和任务相关的查询向量q，用注意力变量$z \\in [1,N]$ 表示被选择信息的索引位置，即 z=i，表示选择了第i个输入信息。\n\n其中查询向量q可以是动态生成的，也可以是可学习的参数。\n\n#### Soft-attention计算分布\n\n在给定输入信息x的查询变量q下，选择第i个输入信息的概率。\n$$\n\\begin{equation}\\begin{split} \n\\alpha_i &= p(z=i|x,q) \\\\\n&= softmax(s(x_i,q))\n\\end{split}\\end{equation}\n$$\n其中$\\alpha_i$ 为注意力分布，$s(x_i,q)$ 为打分函数。\n\n常用的打分函数:\n\n- 加性模型: $s(x_i,q) = v^Ttanh(Wx_i+Vq)$\n- 双线性：$s(x_i,q)=x_i^TWq$\n- 点积：$s(x_i,q)=x_i^Tq$\n- 缩放点积:$s(x_i,q)= \\frac{x_i^Tq}{d^{\\frac{1}{2}}}$\n\n#### 加权平均\n\n$$\n\\begin{equation}\\begin{split} \natt(X,q) &= \\sum_{i=1}^N \\alpha_i x_i \\\\\n&=E_{z\\sim p(z|X,q)}[X]\n\\end{split}\\end{equation}\n$$\n\n\n\n\n\n![](https://i.loli.net/2021/03/25/XrtYUMNH8J1KvLP.png)\n\n\n\n\n\n#### key-value pair attention\n\n其实就是输入信息是(k,v)键值对形式。$(K,V)=[(k_1,v_1),(k_2,v_2),...,(k_n,v_n)]$\n\n其中键用来计算注意力分布$\\alpha_i$，值用来计算聚合信息\n\n当K=V时，键值对注意力=柔性注意力\n\n![](https://i.loli.net/2021/03/25/hWkdyl3TGVjsRY4.png)\n\n如上图，计算注意力分布\n$$\n\\begin{equation}\\begin{split} \n\\alpha_i &= \\frac{exp(s(k_i,q))}{\\sum_{j=1}^Nexp(s(k_j,q))} \\\\\natt((K,V),q) &= \\sum_{i=1}^N \\alpha_iv_i \\\\\n&=\\frac{exp(s(k_i,q))}{\\sum_{j=1}^Nexp(s(k_j,q))} v_i\n\\end{split}\\end{equation}\n$$\n\n\n#### self-attention \n\n查询向量q、键向量k、值向量v ， 都等于输入向量序列。\n\n可参考下面的多头自注意力\n\n#### multi-head self attention\n\n查询向量Q、键向量K、值向量V ， 都等于输入向量序列的线性表示。\n\n假设输入序列 $X=[x_1,x_2,...,x_n]\\in R^{d_1\\times R}$，输出的是$H=[h_1,h_2,...,h_n]\\in R^{d_2\\times R}$\n\n$$Q = W_qX \\in d_3\\times N$$\n\n$$K = W_kX \\in d_3\\times N$$\n\n$$V = W_vX \\in d_2\\times N$$\n$$\n\\begin{equation}\\begin{split} \n\\hat h_i &= att((K,V),q_i) = \\sum_{j=1}^N \\alpha_{ij} v_j \\\\\n&= \\sum_{j=1}^N softmax(s(k_j,q_i))v_j\n\\end{split}\\end{equation}\n$$\n其中$i,j\\in[1,N]$ 为输出和输入的向量序列位置\n\nTransformer里用的是上面的缩放点积打分函数s\n\n\n\n![](https://i.loli.net/2021/03/25/OGKUbvgx9jY4PiS.png)\n\n如果在encoder-decoder架构中\n\nattention一般用在encoder和decoder之间做衔接的部分\n\nself-attention 一般在块内部\n\n比如在翻译任务中，Sourse和Target内部通常用self-attention提取特征，两者之间用attention\n\n\n\n\n\n\n\n## DCN\n\nCo-attention 共同注意力机制就从DCN讲起，DCN是一个QA模型，为了解决然而，问答场景中单次通过的性质，对于不正确答案的局部最大值恢复的问题。它首先融合了问题和文档的共同依赖表示，以便集中于两 者的相关部分。然后，动态指向解码器迭代潜在的答案跨度，该迭代过程使模型能够从对应于不正确答案的初始局部最大值中恢复。这个是论文的话，其实不是coattention来恢复的，是动态指向解码器。\n\n其实就是因为一段内容里可能多多个正确答案，但是我们在模型输出的时候选的是最大概率的开始和结尾，DCN用一种迭代的方式，以找到局部极值概率点来当做答案。\n\n![](https://i.loli.net/2021/03/25/jx5iEAS3KZlwpb9.png)\n\n所以，co-attention就是带着问题去阅读，融合问题和文档的特征调整的attention机制。\n\n\n\nDynamic Decoder \n\n![](https://i.loli.net/2021/03/25/Kkg8E5pAJLVbZyu.png)\n\nHMN\n\n![](https://i.loli.net/2021/03/25/thIAcEHed1ZWpwv.png)\n\n![](https://i.loli.net/2021/03/25/SsvJj6t3iaP4DRm.png)\n\n\n\nmax运算计算张量第一维上的最大值。第一个maxout层和最后一个maxout层的输出之间存在高速连接。\n\n### DCN+\n\n![](https://i.loli.net/2021/03/25/V7nA6PkYDpLh5Ka.png)\n\n","tags":["nlp"]},{"title":"字符串无序匹配","url":"/2021/03/25/字符串无序匹配/","content":"\n给定长度为 m 的字符串 aim，以及一个长度为 n 的字符串 str 问能否在 str 中找到一个长度为 m 的连续子串，使得这个子串刚好由 aim 的 m 个字符组成，顺序无所谓返回任意满足条件的一个子串的起始位置，未找到返回-1。\n\n思路：\n\n找到一个串和aim排序对比\n\n```java\npublic static void main(String[] args) {\n        Scanner input = new Scanner(System.in);\n        while (input.hasNext()) {\n            String aim = input.next();\n            String str = input.next();\n            int m = aim.length();\n            int i = 0;\n            int j = m - 1;\n            char[] charAim = aim.toCharArray();\n            Arrays.sort(charAim);\n            int flag = 0;\n            while (j != m) {\n                char[] sub = str.substring(i, j + 1).toCharArray();\n                Arrays.sort(sub);\n                flag = 0;\n                for (int k = 0; k < sub.length; k++) {\n                    if (sub[k] != charAim[k]) {\n                        flag = 1;\n                        break;\n                    }\n                }\n                if (flag == 1) {\n                    i++;\n                    j++;\n                    continue;\n                } else {\n                    System.out.println(\"true\");\n                    break;\n                }\n            }\n            if (flag == 1) System.out.println(\"false\");\n        }\n    }\n```\n\n面试上写这个暴力算法没有分 O(n^3*logN)\n\n优化O(N*M):\n\n```java\npublic boolean isTY(char[] str, int L, char[] aim) {\n        // 0-255 统计数组\n        // 'a' 97\n        // count[97] ++;\n        int[] count = new int[256];\n        for (int i = 0; i < aim.length; i++) {\n            count[aim[i]]++;\n        }\n        //count 中含有0-255\n        for (int i = 0; i < str.length; i++) {\n            if (count[str[i]] == 0) {\n                return false;\n            }\n            count[str[i]]--;\n        }\n        return true;\n    }\n\n    public int containExactly2(String a, String b) {\n        if (a == null || b == null || a.length() < b.length()) {\n            return -1;\n        }\n        char[] str = a.toCharArray();\n        char[] aim = b.toCharArray();\n        for (int L = 0; L <= str.length - aim.length; L++) {\n            if (isTY(str, L, aim)) {\n                return L;\n            }\n        }\n        return -1;\n    }\n\n```\n\n一共有N-M个要判断匹配的串，要遍历M个长度\n\n\n\n最后优化:O(n)\n\n先把目标字符串做成一个字典表。\n\n出现了的字符做成一个计数字典\n\n没有出现的就认为是0\n\n遍历输入字符串的时候\n\n让滑动窗口内的计数减减，多的可以记成负数\n\n每次从窗口右边进来的我都减\n\n从窗口左边画出的我都加一\n\n最终遍历完看无效的负数点有没有来判断有没有同源异构\n\n```java\npublic int containExactly(String a, String b) {\n        if (a == null || b == null || a.length() < b.length()) {\n            return -1;\n        }\n        char[] str = a.toCharArray();\n        char[] aim = b.toCharArray();\n        int[] count = new int[256];\n        for (int i = 0; i < aim.length; i++) {\n            count[aim[i]]++;\n        }\n        int M = aim.length;\n        int inValidTimes = 0;\n        int R = 0;\n        // 先让窗口用于M个字符\n        for (; R < M; R++) {\n            if (count[str[R]]-- <= 0) {\n                inValidTimes++;\n            }\n        }\n        // 如果第一个是同源异构词\n        if (inValidTimes == 0) {\n            return R - M;\n        }\n        // 窗口滑动\n        for (; R < str.length; R++) {\n            if (inValidTimes == 0) {\n                return R - M;\n            }\n            // 0[0..M-1]M\n            // [1..M]\n            // [2...M+1]\n            if (count[str[R]]-- <= 0) {\n                inValidTimes++;\n            }\n            if (count[str[R - M]]++ < 0) {\n                inValidTimes--;\n            }\n        }\n        return inValidTimes == 0 ? R - M : -1;\n    }\n\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["刷题"]},{"title":"已知后序序列构建二叉搜索树","url":"/2021/03/24/已知后序序列构建二叉搜索树/","content":"\n# 已知后序序列构建二叉搜索树\n\n思路：\n\n[2,4,3,6,8,7,5]\n\n最后一个是根节点，从后往前找，第一个比根小的数是左子树的根，根前面的数是右子树的根。\n\n就变成了子问题，已知他们的根，怎么构建左子树和右子树\n\n时间复杂度$O(N^2)$\n\n优化用二分法，找比根小的节点，一直找到无法二分。就可以找到有序的部分。遍历行为替换成二分。\n\n```java\npublic class PosArrayToBST {\n\n    public static class Node {\n        public int value;\n        public Node left;\n        public Node right;\n\n        public Node(int v) {\n            value = v;\n        }\n    }\n\n    public static Node posArrayToBST1(int[] posArr) {\n        return process1(posArr, 0, posArr.length - 1);\n    }\n\n    public static Node process1(int[] posArr, int L, int R) {\n        if (L > R) return null;\n        Node head = new Node(posArr[R]);\n        if (L == R) return head;\n        int M = L - 1; // 为了全部是全左或全右子树\n        for (int i = L; i < R; i++) {\n            if (posArr[i] < posArr[R]) {\n                M = i;\n            }\n        }\n        head.left = process1(posArr, L, M);\n        head.right = process1(posArr, M + 1, R - 1);\n        return head;\n    }\n\n    public static Node process2(int[] posArr, int L, int R) {\n        Node head = new Node(posArr[R]);\n        if (L == R) return head;\n        int M = -1;\n        for (int i = L; i < R; i++) {\n            if (posArr[i] < posArr[R]) {\n                M = i;\n            }\n        }\n\n        if (M == -1) {\n            head.right = process1(posArr, L, R - 1);\n        } else if (M == R - 1) {\n            head.left = process2(posArr, L, R - 1)\n        } else {\n            head.left = process1(posArr, L, M);\n            head.right = process1(posArr, M + 1, R - 1);\n        }\n\n        return head;\n    }\n\n    public static Node process3(int[] posArr, int L, int R) {\n        if (L > R) return null;\n        Node head = new Node(posArr[R]);\n        if (L == R) return head;\n        int M = L - 1;\n        int left = L;\n        int right = R - 1;\n        while (left <= right) {\n            int mid = left + ((right - left) >> 1);\n            if (posArr[mid] < posArr[R]) {\n                M = mid;\n                left = mid + 1;\n            } else {\n                right = mid - 1;\n            }\n        }\n        head.left = process2(posArr, L, M);\n        head.right = process2(posArr, M + 1, R - 1);\n        return head;\n    }\n\n}\n```\n\n","tags":["刷题"]},{"title":"HotpotQA数据集","url":"/2021/03/23/HotpotQA数据集/","content":"\n# HotpotQA数据集：A Dataset for Diverse, Explainable Multi-hop Question Answering\n\n\n\n官方地址：https://hotpotqa.github.io/index.html\n\n为解决当前QA数据集不能训练系统回答复杂问题和提供可解释的答案问题而提出。\n\n## 摘要\n\nHotpotQA基于113k(十一万三千)个维基百科问答对，有四个特点：\n\n- 问题需要对多个支持文档进行查找和推理才能回答\n- 问题是多样的，不受任何预先存在的知识库或知识模式的限制\n- 提供句子级别的推理所需的事实支持，允许QA系统在强有力的监督下进行推理和解释预测\n- 提供了一种新型的拟事实比较问题来测试QA系统提取相关事实和进行必要比较的能力。\n\n[![6HJiz6.png](https://z3.ax1x.com/2021/03/23/6HJiz6.png)](https://imgtu.com/i/6HJiz6)\n\n所构建的多跳问答数据集样式\n\n## 贡献\n\n\n\n### 构建维基百科超链接图\n\n使用整个英文维基百科做为语料库。\n\n- 维基百科文章中的超链接通常自然地涉及上下文中的两个(已经消除歧义的)实体之间的关系，这可能被用来促进多跳推理。\n- 每篇文章的第一段通常包含许多可以有意义地查询的信息。\n\n基于这些观察，我们从所有维基百科文章的第一段中提取了所有的超链接。用这些超链接，构建了一个有向图G，edge(a,b) 表示超链接从文章的第一段a 到 文章b。\n\n\n\n\n\n### 生成候选段落对\n\n为了生成用于与超连接图G的多跳问题回答的有意义的段落对，引入了一个桥梁实体“bridge entity”。\n\n比如问题是：when was the singer and songwriter of Radiohead born？\n\n为了回答这个问题，我们需要推理出 “singer and songwriter of Radiohead”是“Thom Yorke”\n\n在从文章中计算出他的生日。“Thom Yorke”就是桥梁实体。\n\n对于G中的edge(a,b)。桥梁实体通常是链接a和文档b的桥梁\n\n也就是说打开维基百科，第一段全是超链接的段就是a，超链接上面的名字通常是桥梁实体，链接过去的文章就是b。\n\n文章b通常确定a和b之间共享上下文的主题，但并不是所有文章b都适合收集多跳问题。例如，像国家这样的实体在维基百科中经常被提及，但与所有传入链接不一定有太多共同之处。\n\n\n\n### 比较问题\n\n收集了新一种类型的多跳问题----比较问题。\n\n其主要思想是，比较来自同一类别的两个实体通常会产生有趣的多跳问题\n\n例如：Who has played for more NBA teams, Michael Jordan or Kobe Bryant?\n\n还在比较问题中引入了是/否问题子集。\n\n回答这些问题通常需要算术比较，例如比较给定的出生日期的年龄。\n\n\n\n### 收集支持事实\n\n为了增强问答系统的可解释性，我们希望它们在生成答案时输出一组得出答案所需的支持事实。\n\n这些佐证事实可以作为关注哪些判决的有力监督。此外，现在可以通过将预测的支持事实与基础事实进行比较来检验模型的解释能力。\n\n\n\n\n\n## 处理和基准设置\n\n[![6HdD61.png](https://z3.ax1x.com/2021/03/23/6HdD61.png)](https://imgtu.com/i/6HdD61)\n\ntrain_easy: 单跳问题 18089 个。\n\ntrain_medium: 56,814个，占多跳示例的60% ,是baseline可以回答正确的问题。\n\n把难的问题分为四个子集：\n\ntrain_hard: 15661个\n\ndev : 7405个\n\ntest-distractor ：7405个\n\ntest-fullwiki : 7405个\n\nTest-distractor 和 Test-fullwiki 是两个基线，官网上的两个表单。\n\n### Distractor\n\n用tfidf检索8个段落作为干扰项，混合两个gold段落(用来收集问题和答案) shuffle构成干扰设置。()\n\n### Fullwiki\n\n要求模型回答所有维基百科文章的第一段(没有指定黄金段落)来充分测试模型定位相关事实以及对它们进行推理的能力。\n\n(真正的野外推理)\n\n两个test不能同时用，答案会泄露。\n\n\n\n## 数据集分析\n\n分析数据集中涵盖的问题类型、答案类型和多跳推理类型。\n\n### 问题类型\n\n![](https://i.loli.net/2021/03/24/LvZhegMF8RwVDUA.png)\n\n### 答案类型\n\n![](https://i.loli.net/2021/03/24/fliA8Zm65y9NdEB.png)\n\n### 推理类型\n\n![](https://i.loli.net/2021/03/24/yTm2pasAt6hJL75.png)\n\n","tags":["nlp"]},{"title":"Spatial-Temporal Graph Convolutional Network for Video-based Person Re-identification(CVPR2020)","url":"/2021/03/23/Spatial-Temporal-Graph-Convolutional-Network-for-Video-based-Person-Re-identification-CVPR2020/","content":"\nSpatial-Temporal Graph Convolutional Network for Video-based Person Re-identification(CVPR2020)\n===============================================================================================\n我做的ppt：https://coding-zuo.github.io/re-id-ppt/index.html\n\n行人重识别\n----------\n\n行人重识别（Person\nRe-identification），简称为ReID，是利用计算机视觉技术判断图像或者视频序列中是否存在特定行人的技术。广泛被认为是一个图像检索的子问题。给定一个监控行人图像，检索跨设备下的该行人图像。\n\n方法分为以下几类： \n- 基于表征学习的ReID方法 \n- 基于度量学习的ReID方法 \n- 基于局部特征的ReID方法 \n- 基于视频序列的ReID方法 \n- 基于GAN造图的ReID方法\n\n本文基于视频序列的ReID方法\n--------------------------\n\n通常单帧图像的信息是有限的，因此有很多工作集中在利用视频序列来进行行人重识别方法的研究（本篇论文就是）。基于视频序列的方法最主要的不同点就是这类方法不仅考虑了图像的内容信息，还考虑了帧与帧之间的运动信息等。\n\n### CNN&RNN\n\n利用CNN来提取图像的空间特征，而基于视频序列的方法主要思想是利用CNN\n来提取空间特征的同时利用RNN来提取时序特征。\n![](https://pic4.zhimg.com/v2-d01de4281c4079b3fd25e58a0351c27f_r.jpg \"Title\")\n\nRNN在Re-ID任务中对时间信息的建模效果有限，或者由于其复杂的结构而难以训练。\n\n### AMOC\n\n累计运动背景网络(Accumulative motion context network,\nAMOC)。AMOC输入的包括原始的图像序列和提取的光流序列。通常提取光流信息需要用到传统的光流提取算法，但是这些算法计算耗时，并且无法与深度学习网络兼容。\n![](https://pic3.zhimg.com/v2-9ed4efb7e67f29891e9ca0bda0729a6a_r.jpg \"Title\")\n\n光流法是非常耗时的，并且光流对于遮挡和噪声来说不够健壮。\n\n### temporal pooling & spatial-temporal attenttion\n\n论文：这些方法没有充分考虑人体各部分在不同帧之间的时间关系，效果有限。\n\n### 瓶颈问题\n\n方向的存在挑战： \n- 不同下摄像头造成行人外观的巨大变化； \n- 目标遮挡（Occlusion）导致部分特征丢失； \n- 不同的 View Illumination导致同一目标的特征差异； \n- 不同目标衣服颜色近似、特征近似导致区分度下降；\n\n论文解决挑战：\n1.仅使用外观特征不足以区分，但它们的身体结构信息是不同的。利用序列中各部分之间的时空关系可以缓解这些问题。\n\n2.当边界框不完美，或者存在噪声或遮挡时，基于外观的要素可能效果较差，并且基于图像的re-ID在这种情况下可能不能很好地工作。\n\n论文方法解决：显式地利用不同帧之间补丁的时间关系，以缓解遮挡和不对准问题。\n具体地说，通过连接不同帧的所有块来构建图来建模时间关系，目的是提供不同块之间的互补信息，从而缓解拥塞和错位问题。另一方面，我们还考虑了帧内的结构信息，通过为视频中的每一帧构造补丁图来提供互补的外观信息。\n\n3.基于图像的识别最具挑战性的难点之一是如何区分视觉上相似的身份，而大多数基于图像的方法只能依赖于提取细粒度的外观特征。\n\n在基于视频的人Re-ID中，相同身份的结构信息(例如形状信息)将更加完整和精确，因为每个视频具有许多帧，这些帧可能覆盖更多的视图和姿势。Structural\nGCN Module\n\n### Spatial-Temporal Graph Convolutional Network\n\n《Person re-identification with deep similarity-guided graph neural\nnetwork》2018 《Learning context graph for person search》2019 《Videos\nas space-time region graphs》2018 --- 视频分类\n\n论文：它们忽略了帧内或帧间不同身体部位之间的关系，是基于图像的，不考虑时间关系。\n\n《Adaptive graph representation learning for video person\nre-identification》2019---------引入图神经网络，利用姿态对齐连接和特征相似性连接实现相关区域特征之间的上下文交互。此外，该方法连接了所有帧的不同部分的特征，不对每帧身体部分的空间关系进行建模，忽略了帧内的结构信息。\n\n创新点、贡献\n------------\n\n（1）利用GCN来模拟人体不同部位在一帧内和帧间的潜在关系，为人们提供更具鉴别力和鲁棒性的信息\n（2）提出了时空GCN框架来联合建模视频层的整体斑块关系和帧级的单个帧的结构信息，该框架可以学习斑块之间的区分和鲁棒的时空关系，从而促进基于视频的Re-ID。\n\n模型设计\n--------\n\n设计了3个分支 \n- 上部分支是用于从相邻帧上的斑块中提取时间线索的时间分支 \n- 中间分支是通过对空间关系建模来提取人体结构信息的空间分支 \n- 底层分支是提取行人外观特征的全局分支。\n\n![-w1414](https://i.loli.net/2021/03/23/BC3YgrzAhbtFqHW.png)\n\n-   首先把每一帧放到CNN中，得到Fi ∈ Rh×w×c，F ={F1,F2,...,FT}，T为帧数。\n-   再把没个feature map Fi水平切分成P个patch，pi = 1,...,N。\n-   patch数量N为T\\*P，把每个P做平均池化后得到patch特征向量为xi ∈ Rc, i =\n    1,...,N.\n\n用GCN去学习patches之间的关系。 G(V,E)有N个节点，vi ∈ V,eij = (vi,vj) ∈\nE. 每个patches就是图中的节点，边e代表他们之间的关系。 A ∈ RN×N\n是这个图的邻接矩阵。 ![-w621](https://i.loli.net/2021/03/23/jKIY7PWqREQ8Dpm.png)\n\n![-w406](https://i.loli.net/2021/03/23/kdoSKRwTjizyW2A.png)\n这个式子，表示两个patch的关系，φ表示原始面要素的对称变换，φ =\nwx。w是可通过反向传播学习的d×d维权重。\n这个变换的意义是：它允许我们自适应地选择和学习帧内或跨不同帧的不同补丁的相关性，结合其他节点的信息。\n\n归一化 神经网络一般对输入数据的规模很敏感。\n对于亲和力矩阵的每一行，所有边值(即连接到面片i的边)的总和应为1。\n邻接矩阵的每个元素都应该是非负的，系数应该在(0，1)的范围内。\n![-w394](https://i.loli.net/2021/03/23/g96qEtu8sfFAjBy.png)\n接着给邻接矩阵加上单位矩阵\n![-w171](https://i.loli.net/2021/03/23/O7au8z49APyMwfb.png)\n这么做是因为将来GCN拿邻接矩阵A和权重相乘，意味着对于每个节点，我们把这个节点的所有邻接节点的feature向量加了起来，但没有加自己这个点。\n之后，使用re-normalization技巧来近似图-拉普拉斯：\n![-w210](https://i.loli.net/2021/03/23/xA5hYeUioD4M1G8.png)\n邻接矩阵乘以度矩阵减小数据规模，度矩阵也反应了一些节点信息。 \n### Temporal branch\n作用：使用不同帧的所有补丁来构建图，其目的是捕捉跨帧的补丁之间的互补信息。\n方法：使用GCN捕获pathches时域关系，构建M层GCN\n![-w289](https://i.loli.net/2021/03/23/AECcOzH2sY3fBFm.png)\nXm是第m层隐层特征，X0是通过CNN获得的特征patch。 Wm是被学习的参数矩阵。\n每层图卷积后跟一个nomalization层用和LeakyRelu\n![-w421](https://i.loli.net/2021/03/23/8zmZVbWfaovcIJO.png) 最后使用Max\npooling作用于Xm 最后得到 ft ∈ R1×dm 是时域GCN特征，dm设置为2048\n\n#### Structural GCN Module(spatial relations branch)\n\n作用：提供额外的辨别性信息，以加强重新识别系统。\n方法：使用GCN捕获不同patch的空间关系。然后，对视频中各帧的GCN特征进行融合，得到视频中的内在结构特征。\nGis (Vis , Eis ), Vis = {xi,1 , xi,2 , . . . , xi,P }\n下标i表示第i帧，并且每个帧被分成P个patch\n![-w511](https://i.loli.net/2021/03/23/HADw5CYgLnSaZsb.png)\n\n独立地利用每一帧的块之间的关系来捕获视频序列中的结构信息。我们将GCNs的所有输出特征聚合在一起，形成视频的结构特征。\n![-w318](https://i.loli.net/2021/03/23/maljbhcMGAX5fNJ.png)\n邻接矩阵公式和上面介绍的一样。k为第i帧上的第k层图卷积。 Wik ∈ Rdk ×dk\n输出的经过Max pooling降维后的特征矩阵为：XiK ∈ RP ×256\n最后，将视频的特征连接起来，最后的特征表示为fs。\n\n### Global branch\n全局分支提取每个视频的全局外观特征。\n\n### loss function \nbatch hard triplet和softmax cross-entropy Ltriplet\nand Lsoftmax \n### Triplet loss \nTriplet loss学到的是一个好的embedding，相似的图像在embedding空间里是相近的，可以判断是否是同一个人脸。\\[3\\]\n\nTriplet loos 需要三份数据(可以从一个batch中选择):Anchor、Positive、Positive\n- 其中Anchor表示当前数据，Positive是跟A相同人的数据，Positive是不同人的数据。\n- 当前向量、同一人不同向量、不同人不同向量\n- 将一个图像经过特征提取后是一个向量，让这个向量和postive更近更好，让这个向量和negative越远越好。\n![](media/16070719577662/16093032756806.jpg)\n\n目的：让A和P非常接近，A与N尽可能远离\n公式：$ \\lVert f(A)-f(P)\\rVert^2 \\le \\lVert f(A)-f(N)\\rVert^2 $ 其中f表示通过网络进行编码。\n是否会存在问题？如果f把所有的输入都编码成0，依然成立。\n\n那么，这个目标就改为: $\\lVert f(A)-f(P)\\rVert^2 - \\lVert f(A)-f(N)\\rVert^2 + a \\le 0$ \n其中a是margin间隔，表示d(A,P)和d(A,N)相差多少。\n\n\n\n同类之间的距离至少要比不同类距离要少多少。\nTriplet loss:\n$$\n\\begin{equation}\\begin{split} \n    L(A,P,N) = max(\\lVert f(A)-f(P)\\rVert^2-\\lVert f(A)-f(N)\\rVert^2 +a,0)\n    \\end{split}\\end{equation}\n$$\n但是对于约束条件:$d(A,P)+a \\le d(A,N)$ 理论上都是A与P很近，A与N较远。\n实际中用的最多的是hard negative方法，也就是在选择样本的时候，让$d(A,P)\\approx d(A,N)$ 这样给网络一些挑战，才能激励它学习。\n\n- 在同一个人P的特征中找最不像的距离最大的P。\n- 在不同人N的特征中找最像的距离最小的N。\n\n![](https://i.loli.net/2021/03/23/J4kSqvmjgdhYc5i.png) \n![](https://i.loli.net/2021/03/23/7gEZUoy6LNbaAXt.png)\n\n\n\n论文在三个分支上分别计算loss加在一起。\n![-w499](https://i.loli.net/2021/03/23/EoyTcBunLpFNRHM.png)\n\n三个分支输出的特征 fglobal , ft, fs。 fall = \\[fglobal, ft, fs\\]\n把fall放到softmax cross-entropy loss\n![-w373](https://i.loli.net/2021/03/23/1RiZHSQ4TF2pYUc.png)\n\n实验\n----\n\n### 数据集 \nDukeMTMC-VideoReID和MARS，是两个行人重识别的数据集。 \n\n- MARS有1261个身份id，的17503个tracklet和3,248个distractor序列。 \n- DukeMTMC-VideoReID 有1812个身份id，4832个tracklets\n\n评估协议：累积匹配特性曲线（CMC）和平均精度（map）来评价提出的模型的性能。\n\n### 细节(复现用)\nCNN模型用的是在imagenet预训练后的ResNet50，并且最后一层必输设为1。\n采用受限随机采样策略从每个视频中随机采样T=8帧。\n把图片resize为256x128并且随机水平翻转。 模型训练800轮。\n初始化学习率为0.0003，每200轮缩小十倍\nAdam优化器、16个身份为一个batch每个身份有四个追踪器tracklet,16 × 4 × 8 =\n512 images。\n\nTGCN有3层、SGCN有2层 把每个feature map水平切分的P为4\n\n为什么SGCN、TGCN选P=4 当Patch的数量太多时，Patch太小包含不了足够的信息。\n相反，当Patch的数量太少时，Patch可能会忽略细微但有区别的线索。\n\n### 代码\n![](https://i.loli.net/2021/03/23/Zv1cF3AXMJfzTsP.png)\n![](https://z3.ax1x.com/2021/03/23/6TfXSf.png)\n\n### 性能对比\n\n#### 纵向对比其他模型性能\n\n![-w712](https://i.loli.net/2021/03/23/dJQOKyHc9DUM7Tj.png)\n\n![-w694](https://i.loli.net/2021/03/23/C6UKZeWf3dBoYaS.png)\n现有的基于注意力的方法(包括STA、GLTR)独立地处理不同区域和帧，并且它们没有充分考虑补丁之间的内在关系。\nM3D,3D卷积运算计算量大，并且对空间不对准很敏感。 Wu et\nal. 对比这个图方法的模型，在两个数据集都优于他。\n\n#### 向内对比，三分支搭配性能\n![-w732](media/16070719577662/16072629848124.jpg)\n\n提出的方法综合考虑了人体不同部位在同一帧内和不同帧之间的潜在关系，可以提供更具区分性和鲁棒性的信息，并且能够进行端到端的训练。这些实验结果验证了该方法的优越性。\n\n主要创新点：考虑了人体不同部位在同一帧内和不同帧之间的潜在关系。\n\n#### 向内对比，替换GCN为全连接层性能\n![-w655](https://i.loli.net/2021/03/23/AlkZ4XIGOm8hioB.png) 证明了图卷积的必要性。\n\n结论\n----\n\n1.利用斑块间的时间关系缓解遮挡问题，利用斑块间的空间关系区分外观相似的歧义样本的有效性。\n2.提出STGCN模型\nSGCN:空间分支通过建模各帧面片之间的关系来学习人体的结构信息。\nTGCN:时态分支通过对不同帧之间的斑块的时态关系进行建模，可以缓解遮挡问题。\n\n未来方向，问题\n--------------\n\n加深层数会使模型效果不好，两层图卷积叫深度？浅层GCN不能有效地将节点信息传播到整个数据图。这个是GCN的过平滑的通病，还没有解决这个问题。\n\n如下图表现的一样。 ![-w645](https://i.loli.net/2021/03/23/so8cnV4RIBm3dMf.png)\n\n我个人觉得这篇论文，在GCN的结构上是可以改进的。是不是可以考虑残差思想来改进GCN网络结构，或者引入其他结构来优化？\n而且论文代码暂时未开放，模型的复杂度到底如何，还需进一步看看。\n\n## 参考文献\n\n[1][基于深度学习的行人重识别研究综述](https://zhuanlan.zhihu.com/p/31921944)\n[2][基于深度学习的person re-identification综述 Deep Learning for Person Re-identification: A Survey and Outlook](https://blog.csdn.net/rytyy/article/details/105232594)\n[3][Triplet-Loss原理及其实现、应用](https://blog.csdn.net/u013082989/article/details/83537370)\n[4][如何通俗的解释交叉熵与相对熵?](https://www.zhihu.com/question/41252833)\n[5][卷积神经网络系列之softmax，softmax loss和cross entropy的讲解](https://blog.csdn.net/u014380165/article/details/77284921)\n[6][卷积神经网络系列之softmax loss对输入的求导推导](https://blog.csdn.net/u014380165/article/details/79632950)\n[7][中山大学提出行人重识别新方法和史上最大数据集SYSU-30k，已开源！](https://zhuanlan.zhihu.com/p/329077441)\n[8][基于视频的行人再识别（1）：从认识Mars数据集开始](https://blog.csdn.net/qq_34132310/article/details/83869605)\n\n[CVPR 2020 | 旷视研究院提出新方法，优化解决遮挡行人重识别问题](https://mp.weixin.qq.com/s/EhAeaA68Ek27EptkTfZiBQ)\n[目标检测中mAP的计算方法](https://zhuanlan.zhihu.com/p/94597205)\n[视觉算法的工业部署及落地方面的技术知识，怎么学？](https://www.zhihu.com/question/428800593)","tags":["GNN&cv"]},{"title":"LeetCode470随机函数返回等概率的值","url":"/2021/03/23/随机函数返回等概率的值/","content":"\n# LeetCode470随机函数返回等概率的值\n\n\n\n![](https://i.loli.net/2021/03/23/jdgCOPBTVRs5W9U.png)\n\n问题描述：\n\n1. 给定一个随机函数f，等概率返回1~5中的一个数字，\n   这是唯一可以是使用的随机机制，如何实现等概率\n   返回1~7中的一个数字。\n2. 给定一个随机函数f，等概率返回a~b中的一个字母，\n   这是唯一可以是使用的随机机制，如何实现等概率\n   返回a~d中的一个数字。\n\n这种做法一般考虑用二进制的方法，等概率的返回0和1。\n\n如有一个等概率返回12345的函数f\n\nf':如果是1和2返回0，4或5返回1，如果是3重新调用f'。\n\n用0和1拼出一个数这样就可以实现等概率。\n\n只有两个二进制位，可以等概率返回0到3。00、01、10、11\n\n三个二进制位，可以等概率返回0到7。000，001，010，011，100，101，110，111\n\nLeetcode:\n\n```java\nclass Solution extends SolBase {\n    public int rand10() {\n        int ans = 0;\n        do {\n            ans = (rand01() << 3) + (rand01() << 2) + (rand01() << 1) + rand01();\n//        } while (ans == 15 || ans == 14 || ans == 13 || ans == 12 || ans == 11 || ans == 10);\n        } while (ans > 9);\n        return ans + 1;\n    }\n\n\n    public int rand01() {\n        int ans = 0;\n        do {\n            ans = rand7();\n        } while (ans == 4);\n        return ans < 4 ? 0 : 1;\n    }\n }\n```\n\n通用：\n\n```java\npublic class RandomBox {\n\n    //13 - 17\n    // 13+ [0,4]\n    public int random() {\n        return min + (int) (Math.random() * (max - min + 1));\n    }\n\n    public int rand01(int min, int max) {\n        int size = max - min + 1;\n        // size是奇数还是偶数\n        boolean odd = (size & 1) != 0;\n        int mid = size / 2;\n        int ans = 0;\n        do {\n            ans = random() - min;\n        } while (odd && ans == mid);\n        return ans < mid ? 0 : 1;\n    }\n\n    public int rand(int min, int max, int from, int to) {\n        if (from == to) {\n            return from;\n        }\n        // 3-9\n        // 0-6\n        int range = to - from;\n        int num = 1;\n        //求0-range需要几个2进制位\n        while ((1 << num) - 1 < range) {\n            num++;\n        }\n\n        int ans = 0;\n        do {\n            ans = 0;\n            for (int i = 0; i < num; i++) {\n                ans |= (rand01(min, max) << i);\n            }\n        } while (ans > range);\n        return ans + from;\n    }\n\n}\n\n```\n\n再一题：\n\n给一个随机函数f，以p概率返回0，以1-p概率返回1\n\n这是唯一可以用的随机机制，如何实现等概率返回0和1 \n\n思路：\n\n如果连续两次返回00或11 重新选取，如果返回01取为0，如果返回10取为1\n\n```java\n public int f() {\n \t\t\treturn Math.random() < 0.92 ? 0 : 1;\n }\n\n public int g() {\n     int first = 0;\n     do {\n         first = f();\n     } while (first == f());\n     return first;\n  }\n```\n\n","tags":["刷题"]},{"title":"HopRetriever:Retrieve Hops over Wikipedia to Answer Complex Questions(AAAI2020)","url":"/2021/03/22/HopRetriever-Retrieve-Hops-over-Wikipedia-to-Answer-Complex-Questions-AAAI2020/","content":"\n# HopRetriever:Retrieve Hops over Wikipedia to Answer Complex Questions(AAAI2020)\nhttps://arxiv.org/abs/2012.15534\n\n## 摘要\n\n- 大型文本语料库中收集支持证据对于开放领域问答(QA)是一个巨大的挑战。\n- 本文方法：\n  - 将hop定义为**超链接**和**出站链接文档**的组合\n  - 超链接编码成**提及嵌入**，相当于在上下文被提及的结构知识，表示出站链接实体建模。\n  - 出站链接文档编码成**文档嵌入**，相当于非结构化的知识。\n- 使用Hotpot数据集，该数据集文章我在这里写过[TODO]\n\nme:想要更好的检索，光用匹配一种检索方式不好，可以结合相关语义信息同时进行检索，会更准确。\n\n那么难点就是如何找到相关部分提取语义信息用于检索。\n\n\n\n## 介绍\n\n多跳问答任务需要从多个支持文档中搜集分散的证据，来提取答案。最近主流方法是将多跳证据收集视为迭代文档检索问题。\n\n在开放域下，多跳QA的一个关键部分是从整个知识源中检索证据路径，分解成几个单步文档检索。\n\n另一part是在基于知识库KB下，并尝试像虚拟结构化知识库(KB)那样遍历文本数据，专注于提到的实体。\n\n如这篇文章关于认知图谱的[TODO]我也写过。\n\n\n\n作者认为，线索收集可以分为两种\n\n- 实体介绍性文档内的信息丰富非结构的事实，关注非结构实体知识。\n- 实体本身之间的结构化和隐式关系，关注结构化实体知识。\n\n![](https://z3.ax1x.com/2021/03/22/6TmCef.png)\n\n\n\n结构性知识是指提及关系。可能是对应的Q1从一篇文章中提及的。Q1的左边好像是文章\n\n非结构性知识是指知识库之类外来知识。可能是对应Q2从知识库得来。Q2的左边好像是个知识库\n\n回答一个复杂的问题需要结合上面两种知识，我觉得对啊，就像问人一个问题，我已有的知识可能不够，我通过搜索引擎搜到一些知识来补充我回答这个问题的能力。\n\n本文作者要考虑的问题是，基于什么证据可以跳到第二个文档进行进一步检索。\n\nQ1是基于文档匹配\"directed by\"来找到下一个跳，从而可以有充足的证据。\n\nQ2问题更复杂一点，有三首歌被提及，只有其中一首是相关问题的，像上面那种关系不足以去在三者中做选择。这就需要通过和实体相关的无结构知识才能找到答案。\n\n---\n\n### 出发点\n\n所以作者认为，为了在Wikipedia中收集足够的支持证据，有必要同时考虑实体之间的关系结构和隐藏在介绍性文档中的非结构化知识。\n\n当应答过程遵循“顺藤摸瓜”的模式时，隐含的实体层次关系使得检索更加高效。但是，当关系链失败时，文档中的那些非结构化事实就会登台。\n\n本文研究如何将结构化知识和非结构化知识结合起来，共同为证据收集做出贡献。\n\n### 定义hop\n\n定义hop为超链接和相应出站链接文档的组合，后面要将两种embedding结合为hop。\n\n维基百科中的超链接暗示一个实体的介绍性文档如何提及其他一些内容\n\n而出站链接文档存储所有非结构化的事实和事件，这使得一跳包含关系证据和拟事实证据，以供将来检索。\n\n\n\n### HopRetriever思路\n\n对于维基百科文档中提到的每个实体，我们将其周围的文本上下文编码到提及嵌入中，以表示隐含的结构化知识。\n\n对于文档中非结构化知识的表示，与以往的工作一样，使用BERT对文档文本进行编码，条件是原始问题。\n\n对于每个步骤检索，从一个文档(实体)到另一个文档(实体)的跳跃可以从两个角度收集证据：\n\n- 当前文档是如何提到另一个文档。\n\n- 在另一实体的介绍性文件中隐藏了哪些事实\n\n\n\n## 相关工作\n\n### 文档级推理\n\n这种方法在不知道先前检索到的证据文档的情况下独立地查找证据文档，当证据文档中的一个与原始问题有少量语义关系时，可能会导致检索失败。\n\n为避免这个问题有些人提出引入多步检索器，实现对多个证据文件的重复检索。\n\n最近2020年一个PathRetriver，是沿着文本图的出站链接检索文档路径的。利用文档的图结构，减少了每一步检索过程中文档的搜索空间，这比以往的迭代检索器要小得多。(这个可以看看是不是用图网络来对出站非结构关系知识进行学习的) \n\nHopRetriever和他的最大不同是多考虑了，在文章之间的结构化和多值关系。\n\n\n\n### 以实体为中心的推理\n\n大多数QA都是以实体为中心进行推理的。通过实体提及来收集证据。\n\n代表一个是认知图谱那篇，一个是Differentiable Reasoning over a Virtual Knowledge Base(*ICLR 2020,*)(这个可以安排读一读)\n\n作者认为他们的问题是，当问题不是“顺藤摸瓜”时，提及本身不能为跳过哪个实体提供足够的推理证据。\n\n我感觉不太认可，认知图谱那篇同样是用bert来提取下一跳hop，可以是相同语境下的一些线索啊，不是一定提及本身啊。可能bert学的没那么强大？\n\n\n\n### 对问题分解\n\n建议将一个复杂的问题分解为几个更简单的子问题，并在每个步骤进行单跳QA。\n\n问题分解的挑战是确保每个子问题收集真正必要的证据。\n\n如果结构化关系建立失败，可能不会建立出一个可推理的子问题，用于进一步跳跃。\n\n\n\n## 方法细节\n\n这块公式参数细节比较多，一点一点梳理。\n\n### 任务定义\n\n开放域的多跳问答一般分为两个模型：\n\n- 检索模型 $D_q=Retriever(q,K)$ : 用来从大范围知识源K中收集很多证据。$D_q$ 应包含回答多跳问题所需的多个文档。\n- 阅读模型 $a=Reader(q,D_q)$ : 将$D_q$和q中的所有文本事实连接在一起，并馈送到答案提取模型阅读器中，以获得答案a\n\n每个维基百科页面对应一个实体 $e_i$\n附有介绍性的文档尾 $d_i$ ，如果在$D_i$中存在链接到$e_j$的锚点。就定义一个提及关系 $m_{i,j} = e_i \\rightharpoonup^{d_i} e_j$ 。\n\n知识源的定义为$K=\\{D,E,M\\}$\n\nM 是 提及关系$m_{i,j}$的集合\n\nE 是 实体$e_i$的集合\n\nD 是 附加文档$d_i$的集合\n\n论文的任务只是检索模型，且$D_q$ 是迭代得到的。在每个检索步骤，通过不仅检查包含在中的非结构化事实，而且还检查在最新选择的文档中对其的提及来获取文档。为了实现这一点，将非结构化的文本事实和提及分别编码，然后在一跳内将它们一起表示。当通过维基百科进行检索时，HopRetriever使用跃点hop作为匹配对象。\n\n![]( https://z3.ax1x.com/2021/03/23/6T4MDg.png)\n\n\n\n### Hop 如何Embedding\n\n$$\n\\begin{equation}\\begin{split} \n    hop_{i,j} = 提及关系的比重 \\cdot 提及Embedding的线性表示(结构化知识) + 外部文档关系的比重 \\cdot 外部文档Embedding的线性表示(非结构化知识)\n\\end{split}\\end{equation}\n$$\n\n\n\nMention Embedding提及嵌入(结构化实体关系)\n\n就是把包含entity的文档fed给bert，并且添加两个[MARKER] tokens选第一个被marker的作为mention embeding。\n\n如果文中没有直接提到entity，就用一个可学习的向量$m_p$表示\n$$\n\\begin{equation}\\begin{split} \n    m_{i,j}=\n    \\begin{cases}\n    BERT_{[M-j]}(q;d_i), &if\\ m_{i,j}\\in M\\\\\n    m_p, &if\\  otherwise\n    \\end{cases}\n\\end{split}\\end{equation}\n$$\n\n\n![](https://z3.ax1x.com/2021/03/23/6Tvkyd.png)\n\n\n\nDocument Embedding\n\n将$d_j$中的文本事实(与q拼接)送入BERT，将关于实体$e_j$的非结构化知识编码为文档嵌入$u_j$，并将[cls]的输出表示作为文档嵌入向量：\n$$\n\\begin{equation}\\begin{split} \n    u_j = BERT_{[CLS]}(q;d_j)\n\\end{split}\\end{equation}\n$$\n\n\nKnowledge fusion\n\n总体过程为，h为检索的历史向量。\n$$\n\\begin{equation}\\begin{split} \n    a_m &= hW_km{i,j}\\\\\n    a_u &= hW_ku_j \\\\\n    \\{w_m,w_u\\} &= softmax(\\{a_m, a_u\\})\\\\\n    hop_{i,j} &= w_m\\cdot W_vm_{i,j} + w_u\\cdot W_uu_j\n\\end{split}\\end{equation}\n$$\n\n\n![](https://z3.ax1x.com/2021/03/23/6TvonA.png)\n\n在第t步选择的$d_j$ 的概率计算为\n$$\n\\begin{equation}\\begin{split} \n    p(d_j) = sigmoid(h_t^Thop_{i,j})\n\\end{split}\\end{equation}\n$$\n\n\n### 细粒度句子级检索\n\n一个文档不可能所有的句子都是答案所必须的，指出必须的那些支持句子，对于明确推理线索是必须的。\n\n计算一个句子是不是留下采用以下公式：\n$$\n\\begin{equation}\\begin{split} \n    s_{i,l} &= BERT_{[SM-l]}(q;d_i) \\\\\n    p(s_i, l) &= sigmoid(h_tW_s,s_{i,l})\n\\end{split}\\end{equation}\n$$\n\n\n大于0.5定义为支持句。\n\n\n\n\n\n### 目标函数\n\n序列预测模型就是上面的RNN图，在t步下的目标函数为\n$$\nlogp(d_j) + \\sum_{\\hat d_j \\in D, \\hat d_j\\neq d_j}log(1-p(s_{s_i,l}))\n$$\n辅助支持句的预测任务，在第t步目标函数为\n$$\n\\sum_{l\\in L_i}logp(s_{i,l}) + \\sum_{l\\in L_i}log(1-p(s_{i,l}))\n$$\n\n\n## 实验\n\n数据集采用 HotpotQA [我要写TODO] 0564 个问答对。主要关注 fullwiki 部分。支持文档分散在 5M 的维基百科中。 \n\n实验包括三个部分：\n\n- 初步检索。基于 TF-IDF 选取前 500 个文档，作为初始文档。\n- 支持文档检索和支持句子预测。迭代检索初始文档。\n- 答案提取。通过 BERT 获取答案。\n\n作者还采用了一种基于 BERT 的神经排序器，获取更精确的前 500 个文档。同时，使用 ELECTRA （ELECTRA: Pre-training Text Encoders as Discrimi- nators Rather Than Generators. In *International Conference on Learning Representations*.）代替 BERT 进行答案获取。结果作为 HopRetriever-plus。这也体现了更好的初步检索的重要性。\n\n\n\n不同类型问题的embedding权重，结构和非结构\n\n![](https://z3.ax1x.com/2021/03/23/67PbrD.png)\n\n不同case的权重\n\n[![67iaQK.png](https://z3.ax1x.com/2021/03/23/67iaQK.png)](https://imgtu.com/i/67iaQK)\n\ncase3 当没有提及时，非结构化的文档embedding发挥主要作用\n\n\n\n\n\n## 结论\n\nHopRetriever 能够将结构性知识和非结构性知识进行结合，确定比较好的跃点hop。同时，跃点迭代模型能够一步步寻找下一个跃点，最终确定答案实体。除此之外，初步文档检索也是十分重要的内容，文章采用的神经排序器效果不错，值得后面继续研究。\n\n\n\n## 参考文献\n\n[HopRetriever: Retrieve Hops over Wikipedia to Answer Complex Questions 论文阅读笔记]([https://www.bluestragglers.com/kgqa-%e8%ae%ba%e6%96%87%e9%98%85%e8%af%bb%e7%ac%94%e8%ae%b0%ef%bc%88%e5%8d%81%e4%ba%8c%ef%bc%89/](https://www.bluestragglers.com/kgqa-论文阅读笔记（十二）/))\n\n\n\n","tags":["GNN&nlp"]},{"title":"LeetCode面试17_21直方图装水","url":"/2021/03/22/LeetCode面试17-21直方图装水/","content":"\n# 直方图装水\n\n![](https://i.loli.net/2021/03/22/UJAq2P9xl7D1VWa.png)\n\n\n\n## 思路\n\n- 如果用程序来描述直方图高度的话不好描述\n- 问题可以想成，每个数组下标下当前列中可以放多少水\n- 每个横坐标下的最大存水量=min(当前的左边最大高度，当前右边的最大高度)\n- 如果我当前高度比左右两边最大值都大，那么我横坐标上肯定没水\n- 当前i水量=min{max左，max右} - arr[i] > 0 ? 当前i水量 ： 0\n- 总的存水量=每个横坐标上能存水量的加和\n- 第0个和最后一个就肯定无水\n\n## 优化\n\n普通方法，像上面的思路，到每个i位置都会向左向右遍历一个最大值，复杂度有点高。\n\n技巧：预处理数组，为的是不用每次都遍历去求最大最小值,用的时候直接取\n\n比如原始数组为[3,1,6,7,2,4,3]\n\n从左到右，从右到左，正反遍历此数组，如果当前数比之前的数小就取之前的值作为当前值，当前数比钱已给数大就还选本来的值。\n\n从左到右遍历后为[3,3,6,7,7,7,7]\n\n从右到左遍历后为[7,7,7,7,4,4,3]\n\n以空间换时间，还不是最优\n\n技巧二：(最优)\n\n声明两个指针，L和R。因为数组两端点不会有水L=1,R=N-2。\n\n再声明两变量，LMax：L扫过的部分的最大值，RMax：R扫过的部分最大值。初值为LMax=arr[0],RMax=arr[N-1]\n\n此时就可以计算出L和R当前所能存水的最大值。因为R左边最大值肯定大于等于LMax，L右边最大值肯定大于等于RMax\n\n当LMax大于RMax时，R处的值可求 \n\n当RMax大于LMax事，L处的值可求\n\n相等事，LR可同时求算\n\nRMax和LMax随遍历进行更新。\n\n```java\nclass Solution {\n    public static int water1(int[] arr) {\n        if (arr == null && arr.length < 2) {\n            return 0;\n        }\n        int N = arr.length;\n        int water = 0;\n        for (int i = 0; i < N; i++) {\n            int leftMax = Integer.MIN_VALUE;\n            for (int j = 0; j < i; j++) {\n                leftMax = Math.max(leftMax, arr[j]);\n            }\n            int rightMax = Integer.MIN_VALUE;\n            for (int j = i + 1; j < N; j++) {\n                rightMax = Math.max(rightMax, arr[j]);\n            }\n            water += Math.max(Math.min(leftMax, rightMax) - arr[i], 0);\n        }\n        return water;\n    }\n\n    public static int water2(int[] arr) {\n        if (arr == null && arr.length < 2) {\n            return 0;\n        }\n        int N = arr.length;\n        int water = 0;\n        int left = Integer.MIN_VALUE;\n        int[] leftMaxs = new int[N];\n        for (int i = 0; i < N; i++) {\n            leftMaxs[i] = Math.max(leftMaxs[i - 1], arr[i]);\n        }\n        int[] rightMaxs = new int[N];\n        rightMaxs[N - 1] = Integer.MIN_VALUE;\n        for (int i = N - 1; i >= 9; i--) {\n            rightMaxs[i] = Math.max(rightMaxs[i + 1], arr[i]);\n        }\n        int warter = 0;\n        for (int i = 0; i < N; i++) {\n            warter += Math.max(Math.min(leftMaxs[i-1], rightMaxs[i+1]) - arr[i], 0);\n        }\n\n        return water;\n    }\n    public static int water3(int arr[]) {\n          if (arr == null && arr.length < 2) {\n              return 0;\n          }\n          int N = arr.length;\n          int L = 1;\n          int R = N - 2;\n          int leftMax = arr[0];\n          int rightMax = arr[N - 1];\n          int water = 0;\n          while (L <= R) {\n              if (leftMax <= rightMax) {\n                  water += Math.max(0, leftMax - arr[L]);\n                  leftMax = Math.max(leftMax, arr[L++]);\n              } else {\n                  water += Math.max(0, rightMax - arr[R]);\n                  rightMax = Math.max(rightMax, arr[R--]);\n              }\n          }\n     }\n}\n```\n\n\n\n","tags":["刷题"]},{"title":"阅读理解数据集综述","url":"/2021/03/22/阅读理解数据集综述/","content":"\n# 阅读理解数据集综述\n\n## 1. 阅读理解任务定义\n\n阅读理解任务可以被当作是一个有监督学习问题，具体来说，该任务可 以详细描述为:给定一个数据集 T，其中 T 的每一个样本都以下的三元组来表示:\n$$\nT = {(P_i, Q_i, A_i)}_{i=1}^n\n$$\n其中，$P_i$ 代表第 $i$ 个样本中的文章片段，$Q_i$ 代表第 $i$ 个样本中的问题，$A_i$  代表第 $i$  个样本中根据文章和问题所回答的答案。阅读理解的任务是通过学习得到一个预测函数 $f$ ，使得我们能够通过给定的 $P_i$  与 $Q_i$  来预测出 $A_i$ :\n$$\nf(P_i, Q_i) \\to A_i\n$$\n通俗来讲，阅读理解任务就是通过给定一个文章片段，给定一个问题，要求计算机能够通过文章片段与问题来获得答案。\n\n## 2. 阅读理解任务类型\n\n阅读理解有多种类型，其划分的一个主要依据是根据答案的类型进行划分，这么区分的主要原因在于答案的不同使得模型输出层，损失函数，评估方式等发生很大变化。\n\n目前来看，阅读理解任务根据具体答案形式的不同可以大致区分为以下四类:\n\n- **填空式阅读理解。**\n\n  填空式阅读理解有一个很明显的特点：答案往往是一个单词而非句子。填空式阅读理解任务可以描述为:给定一段文章片段与一个问题，要求机器根据文章片段与问题来推理出合理的答案， 且答案往往是文章片段的某个词。\n\n  填空式阅读理解在阅读理解发展的早 期起到了至关重要的作用，现在已经退出主流数据集了，具体典型的数据集 有:CNN&Daily Mail，Who did What等数据集。\n\n- **抽取式阅读理解。**\n\n  抽取式阅读理解任务可以描述为:给定一段文章片 段，给定一个问题，要求机器根据该问题从文章片段中找出一个连续的片段作为答案。\n\n  考虑到输出问题，此类问题又转化为预测答案的开始与结束的两 个位置 $pos_{start}$ 与 $pos_{end}$ 。此时，问题就转化成为一个分类问题，答案可以用篇章词片段表示为 $[ pos_{start} , pos_{end} ]$ 。\n\n  在过去两年中，此类数据集一直是学术界的主流数据集，极大的推动了阅读理解领域的发展，其中最典型的数据集包括 SQuAD，MS Marco，NewsQA，TriviaQA等数据集。\n\n- **多选式阅读理解。**\n\n  多选式阅读理解任务可以描述为：给定一段文章片段，给定一个问题，给定多个选项，要求机器根据文章片段与问题从答案选项中选择一个最合适的答案。\n\n  通过将阅读理解问题转化为分类问题可以更准 确的评估机器对语言的理解能力，这也是此类数据集强于抽取式数据集的一 大原因。\n\n  此类数据集是目前研究人员研究的热点之一，代表性的数据集有 RACE，CLOTH等。\n\n- **生成式阅读理解。**\n\n  生成式阅读理解任务可以描述为：给定一段文章片 段，给定一个问题，要求机器基于文章片段与问题生成一个合适的答案，该答案不局限于文章中存在的词语，而是自由生成的。\n\n  此类型的阅读理解任务 更适合实际生活场景，但是由于生成的句子无法做准确评估，因此一直无法 成为业界的主流数据集。代表性的数据集有 NARRATIVEQA，CoQA等。\n\n\n\n## 3. 阅读理解任务的评估方式\n\n| 任务类型       | 评估方法           |\n| -------------- | ------------------ |\n| 填空式阅读理解 | 准确率(Accuracy)   |\n| 抽取式阅读理解 | EM(完全匹配值)，F1 |\n| 多选式阅读理解 | 准确率(Accuracy)   |\n| 生成式阅读理解 | BLEU，ROUGE        |\n\n对于抽取式阅读理解任务，由于答案通常为一个片段，一般同时采用两\n种评估方式:\n\n- 完全匹配值(Exact Match，EM)。该指标用来判定预测的答案与给 定的答案是否完全相同，即预测的开始位置 $pos^{pred}_{start}$ 与终止位置 $pos^{pred}_{end}$ 是否与真实值相同，其计算公式下：\n  $$\n  EM = \\begin{cases} 1, & pos^{pred}_{start} == pos^{real}_{start}  \\, and \\, pos^{pred}_{end} == pos^{real}_{end} \\\\ 0, & otherwise \\end{cases}\n  $$\n\n- F1 值。该指标主要评估预测的答案片段与正确答案的重合率，其计 算公式如下所示：\n  $$\n  F1 = \\frac{2 \\times Precision \\times Recall}{Precision + Recall}\n  $$\n\n## 4. 现有数据集分类\n\n本节汇集了当前大多数的阅读理解数据集，并对其进行简单描述\n\n### 1. 填空式阅读理解\n\n考虑到这部分其实已经几乎没人在搞了，因此就不做详细描述了。\n\n| 数据集            | 语言    | 状态             |\n| ----------------- | ------- | ---------------- |\n| MCTest [1]        | English | 过时，不推荐研究 |\n| CNN/Daily Mail[2] | English | 过时，不推荐研究 |\n| CBT[3]            | English | 过时，不推荐研究 |\n| Quasar-S[4]       | English | 过时，不推荐研究 |\n\n- CNN&Daily Mail： 最具代表的数据聚集，数据来源于CNN 和 Daily Mail。\n- CBT：数据来源于儿童读物。\n\n### 2. 抽取式阅读理解\n\nhttps://www.leiphone.com/news/201903/QcmBwrYSo8QyWXRb.html\n\n| 数据集                                                       | 语言        | 状态                                 |\n| ------------------------------------------------------------ | ----------- | ------------------------------------ |\n| [SQuAD 1.0](https://rajpurkar.github.io/SQuAD-explorer/) [5] | English     | 过时                                 |\n| [**SQuAD 2.0**](https://rajpurkar.github.io/SQuAD-explorer/) [6] | **English** | **热点**                             |\n| [**DuReader**](https://zhuanlan.zhihu.com/p/36415104)        | **Chinese** | **热点**                             |\n| [**MS MARCO**](https://zhuanlan.zhihu.com/p/53525750)        | **English** | **非研究热点，但跟搜索引擎紧密结合** |\n| [CoQA](https://zhuanlan.zhihu.com/p/43050014) [9]            | English     | 热点，接替SQuAD                      |\n| [TriviaQA](http://nlp.cs.washington.edu/triviaqa/) [10]      | English     | 热点                                 |\n| [HotpotQA](https://hotpotqa.github.io/) [11]                 | English     | 热点                                 |\n| Quasar-T [4]                                                 | English     | 非研究热点                           |\n| SearchQA[12]                                                 | English     | 非研究热点                           |\n| [CMRC 2018](https://hfl-rc.github.io/cmrc2018/open_challenge/) | Chinese     | 研究热点                             |\n| [CMRC 2019](https://hfl-rc.github.io/cmrc2019/)              | Chinese     | 热点                                 |\n| [NewsQA](https://www.microsoft.com/en-us/research/project/newsqa-dataset/) [13] | English     | 有点意思                             |\n| [QuAC](http://quac.ai/) [14]                                 | English     | 非热点                               |\n\n- SQuAD 1.0：来源于维基百科，给定 context 于 question， 从 context 中截取一个片段，该片段作为答案。 是一个典型的抽取式问题。\n- SQuAD 2.0：在 SQuAD 1.0 的基础上新增超过5万无法回答的问题。这要求模型不仅要在能够在问题可回答时给出答案，还要判断哪些问题是阅读文本中没有材料支持的，并拒绝回答这些问题。\n- DuReader： 中文阅读理解数据集，应该是国内最棒的阅读理解数据集。它的格式跟 下面的 MS MARCO 相似。DuReader中的问题和文档均来自百度搜索和百度知道。答案是人为产生的，而不是原始上下文中的片段。DuReader之所以与众不同，是因为它提供了新的问题类型，例如yes、no和opinion。与事实性问题相比，这些问题有时需要对文档的多个部分进行汇总。\n- MS MARCO：， 很工业化的数据集，来自Bing 用户查询，因此跟搜索引擎技术紧密相连，十分适合学习。为了克服以前的数据集的弱点，它具有四个主要功能。首先，所有问题都是从真实用户查询中收集的；其次，对于每个问题，使用Bing搜索引擎搜索10个相关文档作为上下文；第三，人为这些问题标注了答案，因此它们不仅限于上下文范围，还需要更多的推理和总结；第四，每个问题有多个答案，有时甚至冲突，这使得机器选择正确的答案更具挑战性。MS MARCO使MRC数据集更接近真实世界。\n- CoQA：， 对话式阅读理解数据集，这跟现实生活又近了一步，是现在研究的热点。CoQA包含约8000轮对话，问题的答案有五种类型，分别为Yes、No、Unknown，文章中的一个span和生成式答案。当根据文章和之前的对话信息无法回答当前问题时，答案为Unknown。该数据集不仅提供答案，而且给出了答案的依据，每一种类型的答案的依据都是文章中的一个span。\n\n- TriviaQA：。该数据集构造问答对，然后从维基百科等页面中寻找对应的论据。最终通过上述方式构造了约65,000个“问题-答案-论据”三元组，通过这种方式构造的数据集比SQuAD更接近实际使用场景。对比SQuAD数据集，其主要集中于是推理方面的问题，并且实验证明一些在SQuAD上表现良好的模型在TriviaQA上并不能获得理想的结果。\n- HotpotQA：研究基于多个信息内容的多步推理，然后回答问题。这意味着答案并不仅仅来源于单一文档。\n- Quasar-T：不建议深入研究。\n- SearchQA：作者构建该数据集的目的是构建能反映检索系统噪声的阅读理解数据集，作者通爬取 Jeopardy 上的问题，然后将问题作为query 在Google 上检索，获得 answer snippets。 该数据集是通过程序生成的，因此噪声不可避免的比较高，因此不建议深入研究。\n- NewsQA：该数据集是从CNN新闻网站上构造的，构造方法与SQuAD一致。\n\n- QuAC： 对话式阅读理解数据集。\n\n### 3. 多选式阅读理解\n\n| 数据集                                                       | 语言    | 状态             |\n| ------------------------------------------------------------ | ------- | ---------------- |\n| [RACE](http://www.qizhexie.com//data/RACE_leaderboard) [15]  | English | 热点，可研究     |\n| [CLOTH](http://www.qizhexie.com/data/CLOTH_leaderboard) [16] | English | 一般，已解决     |\n| [ARC](https://allenai.org/data/arc) [17]                     | English | 一般，不推荐     |\n| Who did What [18]                                            | English | 过时，不推荐研究 |\n| [OpenBookQA](https://leaderboard.allenai.org/open_book_qa/submissions/public) [19] | English | 一般，不推荐     |\n| [CommonsenseQA](https://www.tau-nlp.org/commonsenseqa)  [20] | English | 一般，不推荐     |\n| [COSMOS QA](https://wilburone.github.io/cosmos/) [21]        | English | 一般             |\n\n- RACE： RACE 取自于中国中高考阅读理解题型，我个人认为这是目前最能体现阅读理解能力的数据集之一，十分值得研究。\n- CLOTH：来自中文中高考完形填空题型，相较于RACE， CLOTH 天然的适合 BERT 这种 AE 模型来填词，因此 CLOTH 可以说是已经被解决了，准确率比人高。\n- ARC：ARC 取自中学生考试中的科学问题，并进一步分为ARC-Challenge 于 ARC-Easy 两个子集，共包含大约8000个问题，此外，该数据集中提供与该任务相关的包含14M科学事实的语料库用来回答这些问题。\n- OpenBookQA：包含大约6000个问题，每个问题包括四个选项，此外，与ARC数据集相似，该数据集也提供了参考语料库，包含1326个事实，每个问题期望结合语料库中的某一个事实来得到答案。此外，还需要结合一些常识知识。如何准确的利用参考语料库与常识知识成为了该数据集的主要问题之一。\n- CommonsenseQA：来自于ConceptNet，其包含大约12000个需要结合背景知识的问题。在该数据集中，标注者根据ConceptNet中的实体概念来自由构造问题，来使问题包含人类所具有的、但难以在网络资源中检索到的背景知识，故回答问题需要利用问题、候选答案，以及仅仅使用检索策略无法检索到的背景知识。\n- COSMOS QA：包含35600个需要常识阅读理解的问题，其专注于解决需要跨越上下文、而不是定位指定片段的推理问题。\n\n### 4. 生成式阅读理解\n\n生成式阅读理解目前还没有热起来的趋势，相关的数据集也没有进入主流视野，个人不建议做这方面的研究。 这一大原因在于文本生成作为单一的任务迟迟得不到突破，至少目前为止（2020年），看不到突破的影子，个人觉得还需要一些时间。\n\n### 5. 其他\n\n其他还有一些数据集，如bAbi，LAMBADA， SCT，MCScript，NarrativeQA，DuoRC，CliCR 等，水平有限，累了，就不做赘述了。\n\n## 最后\n\n本文总结了大多数的数据集，但是并没有对数据集进行详细描述，一来是因为工作量比较大，二来是觉得没有必要。 一般做阅读理解紧跟几个主流数据集就行，太多数据集反而会乱了自身阵脚。\n\n## Reference\n\n### 1. 博客参考\n\n[赛尔笔记 | 机器阅读理解简述](https://zhuanlan.zhihu.com/p/111410698)\n\n[RCPapers](https://github.com/thunlp/RCPapers)\n\n### 2. 填空式阅读理解\n\n[1] (MCTest) **MCTest: A Challenge Dataset for the Open-Domain Machine Comprehension of Text.** Matthew Richardson, Christopher J.C. Burges, and Erin Renshaw. EMNLP 2013. [paper](http://www.aclweb.org/anthology/D13-1020).\n\n[2] (CNN/Daily Mail) **Teaching Machines to Read and Comprehend.** Hermann, Karl Moritz, Tomas Kocisky, Edward Grefenstette, Lasse Espeholt, Will Kay, Mustafa Suleyman, and Phil Blunsom. NIPS 2015. [paper](https://papers.nips.cc/paper/5945-teaching-machines-to-read-and-comprehend.pdf)\n\n[3] (CBT) **The Goldilocks Principle: Reading Children's Books with Explicit Memory Representations.** Felix Hill, Antoine Bordes, Sumit Chopra, and Jason Weston. arXiv preprint arXiv:1511.02301 (2015). [paper](https://arxiv.org/pdf/1511.02301)\n\n[4] (Quasar) **Quasar: Datasets for Question Answering by Search and Reading.** Bhuwan Dhingra, Kathryn Mazaitis, and William W. Cohen. arXiv preprint arXiv:1707.03904 (2017). [paper](https://arxiv.org/pdf/1707.03904)\n\n### 3. 抽取式阅读理解\n\n[5 ]  (SQuAD 1.0) **SQuAD: 100,000+ Questions for Machine Comprehension of Text.** Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. EMNLP 2016. [paper](https://aclweb.org/anthology/D16-1264)\n\n[6] (SQuAD 2.0) **Know What You Don't Know: Unanswerable Questions for SQuAD.** Pranav Rajpurkar, Robin Jia, and Percy Liang. ACL 2018. [paper](http://aclweb.org/anthology/P18-2124)\n\n[7] (DuReader) **DuReader: a Chinese Machine Reading Comprehension Dataset from Real-world Applications.** Wei He, Kai Liu, Yajuan Lyu, Shiqi Zhao, Xinyan Xiao, Yuan Liu, Yizhong Wang, Hua Wu, Qiaoqiao She, Xuan Liu, Tian Wu, and Haifeng Wang. ACL 2018 Workshop. [paper](https://arxiv.org/abs/1711.05073)\n\n[8]  (MS MARCO) **MS MARCO: A Human Generated MAchine Reading COmprehension Dataset.** Tri Nguyen, Mir Rosenberg, Xia Song, Jianfeng Gao, Saurabh Tiwary, Rangan Majumder, and Li Deng.  arXiv preprint arXiv:1611.09268 (2016). [paper](https://arxiv.org/pdf/1611.09268)\n\n[9] (CoQA) **CoQA: A Conversational Question Answering Challenge.** Siva Reddy, Danqi Chen, and Christopher D. Manning. arXiv preprint arXiv:1808.07042 (2018). [paper](https://arxiv.org/pdf/1808.07042)\n\n[10] (TriviaQA) **TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension.** Mandar Joshi, Eunsol Choi, Daniel S. Weld, Luke Zettlemoyer. arXiv preprint arXiv:1705.03551 (2017). [paper](https://arxiv.org/pdf/1705.03551)\n\n[11] (HotpotQA) **HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question Answering**. Yang Z , Qi P , Zhang S , et al. . 2018.[paper](https://arxiv.org/abs/1809.09600v1)\n\n[12] (SearchQA) **SearchQA: A New Q&A Dataset Augmented with Context from a Search Engine.** Matthew Dunn, Levent Sagun, Mike Higgins, V. Ugur Guney, Volkan Cirik, and Kyunghyun Cho. arXiv preprint arXiv:1704.05179 (2017). [paper](https://arxiv.org/pdf/1704.05179)\n\n[13] (NewsQA) **NewsQA: A Machine Comprehension Dataset.** Adam Trischler, Tong Wang, Xingdi Yuan, Justin Harris, Alessandro Sordoni, Philip Bachman, and Kaheer Suleman. arXiv preprint arXiv:1611.09830 (2016). [paper](https://arxiv.org/pdf/1611.09830)\n\n[14] (QuAC) **QuAC : Question Answering in Context.** Eunsol Choi, He He, Mohit Iyyer, Mark Yatskar, Wen-tau Yih, Yejin Choi, Percy Liang, and  Luke Zettlemoyer. arXiv preprint arXiv:1808.07036 (2018). [paper](https://arxiv.org/pdf/1808.07036)\n\n### 3.  多选式阅读理解\n\n[15] (RACE) **RACE: Large-scale ReAding Comprehension Dataset From Examinations.** Guokun Lai, Qizhe Xie, Hanxiao Liu, Yiming Yang, and Eduard Hovy. EMNLP 2017. [paper](http://aclweb.org/anthology/D17-1082)\n\n[16] (CLOTH) **Large-scale Cloze Test Dataset Created by Teachers.** Qizhe Xie, Guokun Lai, Zihang Dai, and Eduard Hovy. EMNLP 2018. [paper](https://arxiv.org/pdf/1711.03225)\n\n[17] (ARC) **Think you have Solved Question Answering?Try ARC, the AI2 Reasoning Challenge.** Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot,Ashish Sabharwal, Carissa Schoenick, and Oyvind Tafjord. arXiv preprint arXiv:1803.05457 (2018). [paper](https://arxiv.org/pdf/1803.05457)\n\n[18] (Who did What) **Who did What: A Large-Scale Person-Centered Cloze Dataset** Takeshi Onishi, Hai Wang, Mohit Bansal, Kevin Gimpel, and David McAllester. EMNLP 2016. [paper](https://aclweb.org/anthology/D16-1241)\n\n[19] (OpenBookQA) Mihaylov T, Clark P, Khot T, et al. Can a suit of armor conduct electricity? a new dataset for open book question answering[J].  2018. [paper](https://arxiv.org/abs/1809.02789)\n\n[20] Talmor A, Herzig J, Lourie N, et al. Commonsenseqa: A question answering challenge targeting commonsense knowledge[J]. 2018. [paper](https://arxiv.org/abs/1811.00937)\n\n[21] Huang L, Bras R L, Bhagavatula C, et al. Cosmos QA: Machine reading comprehension with contextual commonsense reasoning[J]. arXiv, 2019. [paper](https://arxiv.org/abs/1909.00277)\n\n### 其他\n\n[22] (bAbi) **Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks.** Jason Weston, Antoine Bordes, Sumit Chopra, Alexander M. Rush, Bart van Merriënboer, Armand Joulin, and Tomas Mikolov. arXiv preprint arXiv:1502.05698 (2015). [paper](https://arxiv.org/pdf/1502.05698)\n\n[23] (LAMBADA) **The LAMBADA Dataset:Word Prediction Requiring a Broad Discourse Context.** Denis Paperno, Germ ́an Kruszewski, Angeliki Lazaridou, Quan Ngoc Pham, Raffaella Bernardi, Sandro Pezzelle, Marco Baroni, Gemma Boleda, and Raquel Fern ́andez. ACL 2016. [paper](https://www.aclweb.org/anthology/P16-1144)\n\n[24] (SCT) **LSDSem 2017 Shared Task: The Story Cloze Test.** Nasrin Mostafazadeh, Michael Roth, Annie Louis,Nathanael Chambers, and James F. Allen. ACL 2017 workshop. [paper](http://aclweb.org/anthology/W17-0906)\n\n[25] (MCScript) **MCScript: A Novel Dataset for Assessing Machine Comprehension Using Script Knowledge.** Simon Ostermann, Ashutosh Modi, Michael Roth, Stefan Thater, and Manfred Pinkal. arXiv preprint arXiv:1803.05223.  [paper](https://arxiv.org/pdf/1803.05223.pdf)\n\n[26] (NarrativeQA) **The NarrativeQA Reading Comprehension Challenge**.\nTomáš Kočiský, Jonathan Schwarz, Phil Blunsom, Chris Dyer, Karl Moritz Hermann, Gábor Melis, and Edward Grefenstette. TACL 2018. [paper](http://aclweb.org/anthology/Q18-1023)\n\n[27] (DuoRC) **DuoRC: Towards Complex Language Understanding with Paraphrased Reading Comprehension.** Amrita Saha, Rahul Aralikatte, Mitesh M. Khapra, and Karthik Sankaranarayanan. ACL 2018. [paper](http://aclweb.org/anthology/P18-1156)\n\n[28] (CliCR) **CliCR: a Dataset of Clinical Case Reports for Machine Reading Comprehension.** Simon Suster and Walter Daelemans. NAACL 2018. [paper](http://aclweb.org/anthology/N18-1140) ","tags":["nlp"]},{"title":"天池赛题:天猫重复购学习笔记(我的EDA模板)","url":"/2021/01/29/16080066587381/","content":"highlight_shrink:\n---\n\n# 天池赛题:天猫重复购学习笔记(我的EDA模板)\n\n字段解释都在:[这里](https://tianchi.aliyun.com/competition/entrance/231576/information)\n代码在GitHub:[这里](https://github.com/Coding-Zuo/DataGame/tree/main/tianchi/%E5%A4%A9%E7%8C%AB%E7%94%A8%E6%88%B7%E9%87%8D%E5%A4%8D%E8%B4%AD)\n- 复购率 = 重复购买用户数量/用户样本数量\n- 复购率 = 重复购买行为次数(或 交易次数)/用户样本数量\n\n[TOC]\n\n## EDA步骤\n\n### 1.看数据类型、数量、样例\n无疑是一些pd.read_csv(_)和data.info()、data.head()。大致看一看\n查看是否有单一值变量\n\n```python\n#查看训练集测试集中特征属性只有一值的特征\ntrain_one_value = [col for col in train.columns if train[col].nunique() <= 1]\ntest_one_value = [col for col in test.columns if test[col].nunique() <= 1]\nprint('one value featrues in train:',train_one_value)\nprint('one value featrues in test: ',test_one_value)\n```\n\n### 2.区分类别变量和连续变量\n一般类别变量的处理和连续型变量的处理不一样\n类别型可能会encode，看一些数量分布。\n连续型可能会看一看核分布。\n\n```python\n#区分类别特征与连续特征\ndef split_features(df,colnums,nums=30):\n    label_features={}\n    continue_features={}\n    for key in colnums:\n        nunique=df[key].nunique()\n        if np.issubdtype(df[key][0],np.int) and nunique<=nums:\n            label_features.update({key:nunique})\n        elif np.issubdtype(df[key][0],np.float) and nunique<=nums:\n            label_features.update({key:nunique})\n        else:\n            continue_features.update({key:nunique})\n    print(label_features)\n    #return label_features,continue_features\n\nuser_info_colnums=user_info.columns.values\nuser_log_colnums=user_log.columns.values\ntrain_colnums=train.columns.values\nlable_nunique_maxnums=20\nprint('user_info:')\nsplit_features(user_info,colnums=user_info_colnums,nums=lable_nunique_maxnums)\nprint('user_log :')\nsplit_features(user_log,colnums=user_log_colnums,nums=lable_nunique_maxnums)\nprint('train :')\nsplit_features(train,colnums=train_colnums,nums=lable_nunique_maxnums)\n```\n可知 \nuser_info:\n{'age_range': 9, 'gender': 3}\nuser_log :\n{'action_type': 4}\ntrain :\n{'label': 2}\n\n### 3.看是否有缺失值\n\n| 插补方法      | 说明                                                         | 优点                             | 缺点                                   | 使用环境         |\n| ------------- | :----------------------------------------------------------- | -------------------------------- | -------------------------------------- | ---------------- |\n| 类均值插补    | 数值型：均值。<br/>非数值型：众数（出现频率最高的值）值比较稳定性；低估资料变异 | 简单易行：被插补的值比较稳定     | 不能反映缺失值的变异性；低估资料变异   | 低缺失率首选     |\n| 类随机插补    | 聚类填充；使用所有可能的值填充；组合完整化方法               | 能体现数据变异性                 | 依赖于观测值                           | 低缺失率         |\n| 回归插补      | 基于完整的数据集，建立回归方程（模型）                       | 方差估计好                       | 稳定性依赖于辅助变量，抽样误差不易控制 | 变量间的相关性强 |\n| Em 插补       | 通过观测数据的边际分布可以对未知参数进行极大似然估计         | 利用充分，考虑了缺失值的不确定性 | 计算复杂                               | 高缺失率         |\n| 多重插补 MCMC | 估计出持插补的值，然后加上不同的噪声，形成多组可选插补值     | 利用充分，考虑了缺失值的不确定性 | 计算复杂                               | 高缺失率首选     |\n\n\n\n```python\n# 有时0代表缺失值，对于缺失值严重的一般删除处理\n# 缺失值较少一般三种：\n#统计量填充：连续值推荐用中位数，离散值：用众数，不能用均值和中位数\n#特殊值填充：正常范围内取值\n#不处理：xgb、lgb对缺失值不太敏感，算法本身有一套缺失值处理方法\ndef missing_value_rate(data,col_name):\n    rate_list = {}\n    for col in col_name:\n        rate = (data.shape[0]-data[col].count())/data.shape[0]\n#         na_zero_num = data[data[col].isna() | (data[data[col]==0])].count()\n        lable_foamt = 'rate:{}'.format(rate)\n        rate_list[col]=lable_foamt\n    return rate_list\n```\n\n```python\nprint('age_range:',user_info[user_info['age_range'].isna() | (user_info['age_range']==0)].count())\nprint()\nprint('gender:',user_info[user_info['gender'].isna() | (user_info['gender']==0)].count())\nmissing_value_rate(user_info,user_info.columns)\n```\n\n### 4.观察数据分布、不均衡样本\n不均衡样本，可采用\n\n- 随机欠采样\n- 随机过采样\n- 基于聚类的过采样\n- SMOTE算法\n- 基于数据清洗的SMOTE\n\n首先describe()看一看。\n#### 正负样本分布\n```python\nlabel_gp = train.groupby('label')['user_id'].count()\nprint('正负样本数量:',label_gp)\n```\n\n```python\nfig = plt.figure()\n# 样本分布不均匀 可采用负样本过采样技术，训练多个模型后求平均或者调整模型的损失函数样本比例的权重\nax = plt.subplot(1,2,1)\nlabels = [0,1]\nsizes = [label_gp[0],label_gp[1]]\nexplode = (0,0)\nplt.pie(sizes,explode=explode,labels=labels,autopct='%1.1f%%',shadow=False,startangle=150)\n\nplt.subplot(1,2,2)\nsns.countplot(train['label'])\nplt.show()  \n```\n![-w355](https://i.loli.net/2021/03/22/VuwAyesYqEUKkib.png)\n\n\n\n#### 对店铺的分析\n\n```python\n#top5销量店铺\ntrain.merchant_id.value_counts().head()\ntrain_data_merchant = train.copy()\ntrain_data_merchant['TOP5']=train_data_merchant['merchant_id'].map(lambda x:1 if x in [4044,3828,4173,1102,4976] else 0)\ntrain_data_merchant = train_data_merchant[train_data_merchant['TOP5']==1]\nplt.figure(figsize=(8,6))\nplt.title('Merchant vs Label')\nsax = sns.countplot('merchant_id',hue='label',data=train_data_merchant)\n```\n对比一下top5店铺回购的比例，可看出不同店铺复购率不同，可能与店铺售卖商品和运营有关。\n![-w507](https://i.loli.net/2021/03/22/6brYGId4tyvh2js.png)\n\n```python\n# 查看店铺的复购分布\nmerchant_repeat_buy = [rate for rate in train.groupby(['merchant_id'])['label'].mean() if rate<=1 and rate>0]\n\nplt.figure(figsize=(8,4))\n\nimport scipy.stats as stats\nax = plt.subplot(1,2,1)\nsns.distplot(merchant_repeat_buy,fit=stats.norm)\nax = plt.subplot(1,2,2)\nres = stats.probplot(merchant_repeat_buy,plot=plt)\n```\n不同店铺有不同的复购率，在0到0.3之间。\n![-w495](https://i.loli.net/2021/03/22/YfWSRQaX3x8wdGh.png)\n\n#### 对用户方面的分析\n通过user_id/age_range/gender等方面\n\n```python\n# 对用户分析\nuser_repeat_buy = [\n    rate for rate in train.groupby(['user_id'])['label'].mean()\n    if rate <=1 and rate>0\n]\n\nplt.figure(figsize=(8,6))\nax = plt.subplot(1,2,1)\nsns.distplot(user_repeat_buy,fit=stats.norm)\nax = plt.subplot(1,2,2)\nres = stats.probplot(user_repeat_buy,plot=plt)\n```\n看出进六个月用户复购概率很小，基本为一次买主\n![-w509](https://i.loli.net/2021/03/22/8ve2dRhlVkCXaxI.png)\n\n```python\n# 用户性别分析\ntrain_user_info =train.merge(user_info,on=['user_id'],how='left')\n\nplt.figure(figsize=(8,8))\nplt.title('Gender vs label')\nax = sns.countplot('gender',hue='label',data=train_user_info)\nfor p in ax.patches:\n    height = p.get_height()\n```\n![-w519](https://i.loli.net/2021/03/22/OARdpIU5tBqMGjy.png)\n```python\n# 不同性别对用户的复购率不同\nrepeat_buy = [rate for rate in train_user_info.groupby(['gender'])['label'].mean()]\n\nplt.figure(figsize=(8,4))\nax = plt.subplot(1,2,1)\nsns.distplot(repeat_buy,fit=stats.norm)\n\nax = plt.subplot(1,2,2)\nres = stats.probplot(repeat_buy,plot=plt) \n```\nprobplot主要是直观的表示观测与预测值之间的差异。一般我们所取得数量性状数据都为正态分布数据。预测的线是一条从原点出发的45度角的虚线，事件观测值是实心点。\n偏离线越大，则两个数据集来自具有不同分布的群体的结论的证据就越大。\n![-w494](https://i.loli.net/2021/03/22/Y2xQn74AGUZTHsl.png)\n\n```python\n# 对用户年龄分析\nplt.figure(figsize=(8,8))\nplt.title('Age vs label')\nax = sns.countplot('age_range',hue='label',data = train_user_info)\n```\n![-w514](https://i.loli.net/2021/03/22/cwrPBGtfKVZbJRC.png)\n```python\n# 用户年龄复购的分布\n# 不同年龄段对用户的复购率不同\nrepeat_buy = [rate for rate in train_user_info.groupby(['age_range'])['label'].mean()]\n\nplt.figure(figsize=(8,4))\n\nax = plt.subplot(1,2,1)\nsns.distplot(repeat_buy,fit=stats.norm)\nax = plt.subplot(1,2,2)\nres = stats.probplot(repeat_buy,plot=plt)\n```\n![-w499](https://i.loli.net/2021/03/22/jkeTh1aUYZq9ELH.png)\n\n### 5.对比训练集和测试集分布\n\n```python\n\n```\n### 6.探查重要影响因素\n\n```python\ncolormap = plt.cm.viridis\nplt.figure(figsize=(14,12))\nplt.title('Pearson Correaltion of Feature',y=1.05,size=15)\nsns.heatmap(train_user_info.astype(float).corr(),linewidths=0.1,vmax=1.0,square=True,cmap=colormap,linecolor='white',annot=True)\n```\n\n## 特征工程\n类别型特征的转换：决策树等少数模型能直接处理字符串形式的输入。\n逻辑回归、svm等需类别型特征处理成数值型特征后才能工作。\n现在比赛基本上都是lightgbm和xgb这些GDBT比较有优势，所以也不用怎么做。了解一些处理方法。\n\n- 序号编码\n- 独热编码\n- 二进制编码\n\n\n### 特征组合\n1、离散特征可两两组合成高阶组合特征，高维组合特征处理的目的是提高复杂关系的拟合能力。\n如： 语言：中文、英文\n    剧集类型：电影电视剧\n    可组合成：中文电影、中文电视剧、英文电影、英文电视剧\n当引入ID特征时，通常要降维。以推荐为例。通常有：\n\n| 是否点击 | uid=1,item=1 | uid=2,item=2 | .... | uid=n,item=n |\n| -------- | ------------ | ------------ | ---- | ------------ |\n| 0        | 1            | 0            | ...  | 0            |\n| 1        | 0            | 1            | ...  | 0            |\n\n\n\n当uid有10000个，item有10000个时有100000000一般可采用SVD分解降低参数，还可以增加参数的迭代拟合数量，防止过拟合。\n\n\n\n2、决策树组合特征：\n![](https://i.loli.net/2021/03/22/RB9qlWDKb3try6c.png)\n\n\n​    \n## 模型训练\n## 模型验证\n## 特征优化\n\n## EDA代码技巧罗列(方便快速拷贝)\n\n### 画字段测试集和训练集数量对比饼图\n\n```python\n#画字段测试集和训练集数量对比饼图\ndef pie_category(train,test):\n    plt.figure(figsize=[9,7])\n    train.value_counts().plot.pie()\n    print(\"train:\",Counter(train))  \n    print(\"test:\",Counter(test))  \n\npie_category(train.XINGBIE,test.XINGBIE)\n```\n### 选择Dataframe数据集中的某几列\n\n```python\n#选择Dataframe数据集中的某几列\nfrom sklearn.base import BaseEstimator,TransformerMixin\n\nclass DataFrameSelector(BaseEstimator,TransformerMixin):\n    def __init__(self,attribute_names):\n        self.attribute_names = attribute_names\n    def fit(self,X,y=None):\n        return self\n    def transform(self,X):\n        return X[self.attribute_names]\n        \nlianxu_train = DataFrameSelector(column_lianxu).transform(train)\nlianxu_test =  DataFrameSelector(column_lianxu).transform(test)\n```\n### 多列KDE分布\n\n```python\n# 多列KDE分布\ndist_cols = 3\ndist_rows = len(column_lianxu)\nplt.figure(figsize=(4 * dist_cols, 4 * dist_rows))\n\nlianxu_train = DataFrameSelector(column_lianxu).transform(train)\nlianxu_test =  DataFrameSelector(column_lianxu).transform(test)\n\ni = 1\nfor col in column_lianxu:\n    ax = plt.subplot(dist_rows, dist_cols, i)\n    ax = sns.kdeplot(lianxu_train[col], color=\"Red\", shade=True)\n    ax = sns.kdeplot(lianxu_test[col], color=\"Blue\", shade=True)\n    ax.set_xlabel(col)\n    ax.set_ylabel(\"Frequency\")\n    ax = ax.legend([\"train\", \"test\"])\n\n    i += 1\nplt.show()\n```\n### 包库常用设置拷贝\n```python\n# 包库常用设置拷贝\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport lightgbm as lgb\nfrom scipy import stats\nimport matplotlib\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split\nimport gc\nimport warnings\nfrom collections import Counter\nwarnings.filterwarnings(\"ignore\")\nimport matplotlib.pyplot as plt\nplt.rcParams.update({'figure.max_open_warning': 0})\npd.set_option('expand_frame_repr', False) #数据超过总宽度后，是否折叠显示\npd.set_option('display.width', 100) #数据显示总宽度\npd.set_option('max_rows', 100) #显示最多行数，超出该数以省略号表示\npd.set_option('max_columns', 100) #显示最多列数，超出该数以省略号表示\npd.set_option('max_colwidth', 16) #设置单列的宽度，用字符个数表示，单个数据长度超出该数时以省略号表示\npd.set_option('large_repr', 'truncate') #数据超过设置显示最大行列数时，带省略号显示/若是info则是统计信息显示\npd.set_option('show_dimensions', True) #当数据带省略号显示时，是否在最后显示数据的维度\n\nsns.set_style(\"whitegrid\")\nmatplotlib.rcParams['font.sans-serif'] = ['SimHei']\nmatplotlib.rcParams['font.family']='sans-serif' \nmatplotlib.rcParams['axes.unicode_minus'] = False\nmatplotlib.fontsize='20'\n```\n### 查看类别特征是否测试集类别有不在训练集的\n\n```python\n#查看类别特征是否测试集类别有不在训练集的\ntest_outof_train=[]\nfor key in label_features:\n    test_unique=test_df[key].unique().tolist()\n    train_unique=train_df[key].unique().tolist()\n    for index in test_unique:\n        if index not in train_unique:\n            test_outof_train.append(key)\n            break\ntest_outof_train\n```\n### 类别特征分布\n```python\n# 类别特征分布\ndef show_label_features_distribution(df1,df2,Y=None):\n    df1=df1.value_counts().sort_index()\n    df2=df2.value_counts().sort_index()\n    df=pd.concat([df1,df2],axis=1)\n    feature_name=df.columns[0]\n    df.columns=['train','test'] \n    df.plot.bar(title=feature_name)\n    print(feature_name,'\\n',df)\n\nfor key in label_features:q\n    show_label_features_distribution(train_df[key],test_df[key])\n```\n### 连续特征分布\n```python\n# 连续特征分布\ndef show_continue_features_distribution(df1,df2):\n    feature_name=df1.name\n    g = sns.kdeplot(df1.values, color=\"Red\", shade = True)\n    g = sns.kdeplot(df2.values, ax =g, color=\"Green\", shade= True)\n    g.set_xlabel(feature_name)\n    g.set_ylabel(\"Frequency\")\n    g = g.legend([\"train\",\"test\"])\n    plt.show()\n    describe=pd.concat([df1.describe(),df2.describe()],axis=1)\n    describe.columns=[f'train {feature_name}',f'test {feature_name}']\n    print(describe)\n\nfor key in continue_featues:\n    show_continue_features_distribution(train_df[key],test_df[key])\n```\n### 清理缓存\n```python\ndef clear_mem():\n    %reset -f out\n    %reset -f in\n    gc.collect()\n```\n## 参考文献\n[matplotlib 知识点11：绘制饼图（pie 函数精讲）](https://www.cnblogs.com/biyoulin/p/9565350.html)\n[决策树中的类别特征问题（关于label encode还是one-hot的讨论）](https://blog.csdn.net/m0_37870649/article/details/104551969)\n[kaggle编码categorical feature总结](https://zhuanlan.zhihu.com/p/40231966)\n[TF-IDF算法介绍及实现](https://blog.csdn.net/asialee_bird/article/details/81486700)\n[Python中的TfidfVectorizer参数解析](https://blog.csdn.net/laobai1015/article/details/80451371)\n[关于target encoding与count encoding](https://blog.csdn.net/ssswill/article/details/90271293)","tags":["DataGame"]},{"title":"High-Order Information Matters Learning Relation and Topology for Occluded Person Re-Identification(CVPR2020)(泛读)","url":"/2021/01/29/16088026276866/","content":"# High-Order Information Matters: Learning Relation and Topology for Occluded Person Re-Identification(CVPR2020)(泛读)\n\nhttps://arxiv.org/abs/2003.08177\n## 解决方案\n主要解决遮蔽现象。\n整体思路可以再各种跟验证相关的任务中去套用。\n\n\n针对遮蔽数据集Occluded-DukeMTMC\n提出三阶段模型：\n- 关键点局部特征提取 (关键点数据集或者关键点识别模型)\n- 图卷积融合关键点特征\n- 基于图匹配的方式来计算相似度并训练模型\n完成特征提取，重点解决遮蔽问题。\n\n![](https://i.loli.net/2021/03/22/pGFgesWTlOBR7fH.png)\n关键点可以学习人体走路运动的先验知识。\n\n1、关键点局部特征提取 \n关键点数据集或者关键点识别模型\n\n2、图卷积融合贯机电特征\n传统算法是点与点进行匹配，但当两个图像遮蔽位置不一致时，就没法进行对比关键点。\n图卷积就会好好利用未被遮挡的区域。\n\n3、基于图匹配的方式来计算相似度并训练模型\n匹配图像中哪些能用哪些不能用，能用的该怎么用，不能用的该怎么减少。\n计算U匹配矩阵(13x13)关键点。\n\n![](https://i.loli.net/2021/03/22/JxhiZMtfjGT2w1c.png)\n\n### 第一阶段S(关键点局部特征提取)\n根据CNN提取到feature map和十三个关键点的信息。\nlocal是十三个关键点信息。\nglobal是feature map(global average pooling得到)\n![-w417](https://i.loli.net/2021/03/22/82pZIRDka5mWf6B.png)\n热度图是关键点乘以feature map\n选择一个pose estimation模型即可，得到的是各个关键点的热度图信息，通过热度图得到原始特征图的局部信息。\n![](https://i.loli.net/2021/03/22/RexpiASI2hQcVBK.png)\n用feature map和关键点信息相乘，相当于在特征图中把信息画出来。\n得到一共十四个特征+global\n把local和global都进行训练，添加多个损失。\n\n### 第二阶段R(如何利用各个点的特征，用图卷积局部特征关系整合)\n![](https://i.loli.net/2021/03/22/3axhY2EUwpvDzSW.png)\n做特征的整合，得到的还是local和global，是一个有了相互关系的拓扑结构，相当于一个attention机制。\n将得到的邻接矩阵A来指导每个关键点特征如何跟其他关键点特征进行计算，并且A矩阵也要进行学习。\n\n如何利用好局部特征？加入关系\n先初始化邻接矩阵来进行图卷积，邻接矩阵在学习过程中更新，综合利用各关键点直接的信息。\n\n如何才能更好的针对每个输入利用不同的局部特征？没有边的就不用\n\n和整体差异越大的，越离群。\n利用差异特征来学习邻居矩阵A\n有了A就能开始图卷积了，用他来指导如何利用不同关键点的特征进行组合，最终再与输入的局部特征进行整合。\n\n![](https://i.loli.net/2021/03/22/ILAd2y5hYOR6vbt.png)\n$K=13$ 13个关键点\n$V_l^{in}$ 关键点特征向量 $batch*13*2048$\n$V_g^{in}$ 全局特征向量   $1*13*2048$\nrepeat调整向量大小把$1*13*2048$变成$batch*13*2048$后做减法\n然后经过abs绝对值、bn层、fc层后得到一个$K*K$的矩阵$A^{adp}$。\n用学习到的$A^{adp}$和邻接矩阵A做乘法。$A'=A^{adp}*A$\n之后在用$V_l^{in}$和上面相乘得到的结果当成$V_l^{in}*A'$相当于图卷积过程。\n再将本身特征$V_l^{in}$和图卷积后的关系特征相加。\n再concat全局特征向量$V_g^{in}$得到输出\n\n\n\n\n\n\n\n\n\n\n\n### 第三阶段T(图匹配，相似度计算)\n\n输入两张图像(经过了前两阶段后的结果)\n\nGraph Matching 计算一个14X14的相似度矩阵U，对一下关键点。表示两个图之间的关系。\n![-w454](https://i.loli.net/2021/03/22/WkqcwQo9avTXibR.png)\n进入了新的验证损失函数。\n就是sigmoid(emb1,emb2)的结果。\n\n![](https://i.loli.net/2021/03/22/s2ZIxedCYqESvk7.png)\n输入两个编码后的特征向量。\n先经过fc+relu提取下特征，再进行图匹配得出相似度矩阵U。\n然后是一个交叉cross的过程，分别交叉来得到个子匹配的特征结果。知道了哪里该匹配哪里不该，再进过fc+relu得到最终特征。\n\n## 参考文献\n[这篇的旷世推文](https://mp.weixin.qq.com/s/EhAeaA68Ek27EptkTfZiBQ)\n[【CVPR2020】：High-Order Information Matters: Learning Relation and Topology for Occluded Person Re-Ide](https://blog.csdn.net/baidu_41617231/article/details/107421943)\n[【唐宇迪】CVPR2020最新行人重识别论文解读](https://www.bilibili.com/video/BV1764y1c7jZ?p=3)\n[图解行人重识别论文系列](https://www.bilibili.com/video/BV13W411K7jM?from=search&seid=5052861388779194545)","tags":["GNN&cv"]}]