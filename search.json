[{"title":"GPT-GNN: Generative Pre-Training of Graph Neural Networks","url":"/2021/05/15/GPT-GNN-Generative-Pre-Training-of-Graph-Neural-Networks/","content":"\n# GPT-GNN: Generative Pre-Training of Graph Neural Networks\n\nSelf-Supervised Learning分成两种方法:一种是生成式模型，一种是判别式模型(对比学习)。\n\n以输入图片信号为例，生成式模型，输入一张图片，通过Encoder编码和Decoder解码还原输入图片信息，监督信号是输入输出尽可能相似。判别式模型，输入两张图片，通过Encoder编码，监督信号是判断两张图是否相似(例如，输入同一个人的两张照片，判断输入相似，输出1；输入两个人的照片，判断输入不相似，输出0)。\n\n## 文章贡献\n\n继上一文 [Strategies for Pre-training Graph Neural Networks](https://coding-zuo.github.io/2021/05/12/Strategies-for-Pre-training-Graph-Neural-Networks/) 对预训练GNN做了大规模的实验，并提出提出了一种结合节点级和图级表示的预训练方法，优化了单单使用一种级别做预训练后产生的负迁移效果。\n\n又以生成式自监督的方式，来在预训练阶段捕捉图数据的结构信息和语义信息。分别是边生成任务和属性生成任务。\n\n它们联合优化等价于最大化整个属性图的概率似然，这样预训练模型可以捕捉到节点属性与图结构之间的内在依赖关系。\n\n预训练的GNN网络目标主要是异质单个(大规模)图上预训练，并进行节点级迁移。\n\n然后优化了预训练模型可以让其处理大规模的图采样子图，采用的是通过自适应的嵌入队列，减轻负采样带来的不准确损失。\n\n接下来主要介绍两种自监督任务和这个优化方法。\n\n\n\n## 行文逻辑\n\n通过行文逻辑，学习怎么写论文。\n\n首先作者先是说GNN有用，预训练GNN刚刚被证明有用！接下来从充分利用无标签数据做无监督任务说，大规模的图数据标记成本昂贵。NLP的数据也一样标注昂贵，所以有了bert那样的预训练语言模型，并且提高了下游任务性能。同样在cv领域也是。\n\n列举了GAE、GraphRNN、半监督GCN等图生成技术，但他们不适合用于预训练GNN。因为：首先，它们大多只关注于生成无属性的图结构，而没有定义节点属性与图结构之间的底层模式，图结构是GNNs中卷积聚合的核心。其次，它们被设计用来处理迄今为止的小图形，限制了它们在大规模图形上进行预训练的潜力。\n\n然后介绍了下预训练和finetuning的流程，就不多说了。\n\n然后切入正题介绍他的贡献，上文介绍过。\n\n----\n\n然后是准备工作和相关工作，介绍GNN的传统机制，信息传递和信息聚合的基本原理，不多介绍。\n\n和GNN发展历史，其中有一个Graph Infomax 最近可能要学习一下，最大化了从GNNs获得的节点表示和图pooling表示之间的互信息，也就是节点级和图级。作者认为其，在纯监督学习环境下表现出改进，但学习任务通过强迫附近节点具有相似的嵌入来实现，而忽略了图的丰富语义和高阶结构。\n\n介绍预训练在cv和nlp的成功。不过我最近听说cv圈有一篇文章，最近2021的有一篇预训练CNN其效果并不比基于transformer的模型差。\n\n介绍生成预训练任务的数学定义，之后是具体细节和模型方法，再到实验结论等等。\n\n\n\n## 关于生成式预训练任务的框架流程\n\n形式上给出图数据 $G = (V,E,X)$  和GNN模型 $f_{\\theta}$\n\n我们通过这个GNN将此图上的可能性建模为 $p(G;θ)$ -----表示G中的节点是如何属性化和连接其他节点的(可以理解为先验知识)。\n\n其目的是通过最大化图的似然，得到参数 $θ^∗=max_{θ}p(G;θ)$ 来预先训练广义神经网络模型。\n\n那么问题变成了如何对 $p(G;\\theta)$ 进行适当的建模。\n\n现在大多的现有图生成方法都是遵循自回归方式来分解目标概率分布，也就是图中的节点是按顺序来的，并且边是通过将每个新到达的节点连接到现有节点来生成的。什么是自回归？\n$$\nX_t = c+\\sum_{i=1}^p\\phi_iX_{t-i}+\\epsilon_t\n$$\n如上式，c 为常数项，$\\epsilon$ 为随机误差，概况来说就是X的当前期值等于一个或数个前期值的线性组合加常数项和睡觉误差。\n\n\n\n类似的作者也通过一个排列向量 $\\pi$ 来确定节点顺序，其中 $i^{\\pi}$ 表示向量中第i个位置的节点id。因此，图的分布$p(G;\\theta)$ 等价于所有可能排列上的期望似然：\n$$\np(G;\\theta) = \\mathbb{E}_{\\pi} [p_{\\theta}(X^{\\pi},E^{\\pi})]\n$$\n其中$X^{\\pi} \\in R^{|V|\\times d}$ ，$E$ 是边集 ，$E_{i}^{\\pi}$ 表示所有连接节点$i^{\\pi}$ 的边。\n\n为简单起见，假设观察到任何节点排序 $π$ 的概率相等，并且在下面的章节中说明一个排列的生成过程时也省略了下标 $π$。给定一个排列顺序，我们可以将对数似然率自动回归分解-每次迭代生成一个节点，如下所示：\n$$\nlogp_{\\theta}(X,E) = \\sum_{i=1}^{|V|}logp_{\\theta}(X_i,E_i|X_{\\lt i},E_{\\lt i})\n$$\n在第i步，使用所有 i 之前已生成的节点，他们的属性和边分别是 $X_{\\lt i}$ ，$E_{\\lt i}$ ，给定 $X_{\\lt i}$ $E_{\\lt i}$ 生成节点 i 的概率log加和。\n\n从本质上讲，等式中的目标。描述了属性图的自回归生成过程。问题变成：如何对条件概率 $p_θ(X_i，E_i|X_{<i}，E_{<i})$ 建模？\n\n### 因式分解属性图生成\n\n为了计算 $p_{\\theta}(X_i,E_i|X_{\\lt i},E_{\\lt i})$ ，一种天真的解决方案可以是简单地假设 $X_i$ 和 $E_i$是独立的，即 :\n$$\np_{\\theta}(X_i,E_i|X_{\\lt i},E_{\\lt i}) = p_{\\theta}(X_i|X_{\\lt i},E_{\\lt i}) \\cdot p_{\\theta}(E_i|X_{\\lt i},E_{\\lt i})\n$$\n然而通过这样的分解，对于每个节点，其属性和连接之间的依赖性被完全忽略。\n\n然而，被忽略的依赖性是属性图的核心性质，也是GNNs中卷积聚集的基础。因此，这种天真的分解不能为训练前的GNN提供信息指导。\n\n就比如，物以类聚人以群分，我和相似的人右边是因为我们有相似的属性。\n\n为了解决这个问题，作者提出了属性图生成过程的依赖感知分解机制。具体地说，当估计一个新节点的属性时，我们会得到它的结构信息，反之当估计一个新的结构边信息时，我们会考虑到它的属性信息。在该过程中，可以将生成分解为两个耦合部分：\n\n- 1.给出观测边的边，生成节点属性\n- 2.给出观测边和1中已经生成的节点属性，生成剩余的边\n\n通过这种方式，模型可以捕获每个节点的属性和结构之间的依赖关系。\n\n正式的定义如何建模，定义一个变量 $o$ , 表示$E_i$内所有观测边的索引向量。\n\n$E_{i,o}$ 是已观测的边，$\\lnot o$表示要生成的所有mask边的索引。通过所有的已观测边来重写条件概率作为一个期望似然如下：\n\n![](https://i.loli.net/2021/05/16/qIjAo2HyNkF5WcS.png)\n\n这里的理解非常重要，第一个等式中，把 $E_i$ 拆成了$E_{i,¬o}$和 $E_{i,o}$ ，也就是说指定了哪些边是观测边，哪些边是masked边。需要注意的是，当o确定下来了，$\\lnot o$ 也是确定的。因此等式外面加上了对o的累加，这里可以理解为类似于全概率公司去对所有可能的o求和。\n\n此外，这里要注意  $E_i, E_{<i},E_{i,o},E_{i,\\lnot o}$  四个符号分别表示什么：\n\n- 现在位于step i，$E_{<i}$ 是指在step i 之前生成的边\n- $E_i$ 指在step i 将会生成的边 (与节点i 相连，有好多边)\n- 将 $E_i$ 的边生成过程拆分成一件生成的和将要生成的两部分，即 $E_{i,o},E_{i,\\lnot o}$\n\n在第二个等式中，把p 看成是概率分布，写作对于o 期望的形式。\n\n最后把 $X_i$ 和 $E_{i,\\lnot o}$ 看做独立的过程，拆成两个概率分布。\n\n这种分解的优势在于，没有忽略 $X_i$ 和 $E_{i,o}$ 的联系。第一项表示given观测边，聚合目标节点i的邻居信息来生成其属性$X_i$ 。第二项表示given观测边和刚生成的属性$X_i$，预测$E_{i,¬o}$中的边是否存在。\n\n![](https://i.loli.net/2021/05/16/hTuqivsBcRC1fon.png)\n\n如上图所示，给出一个例子。对于academic图，我们要去生成一个paper node，它的属性为title。我们要去生成一个paper node，它的属性为title，并且其和author，publish venue，reference相连。上图中的实线部分为已经观测到的边，首先生成节点的属性，即title。然后基于author1，author2，author3和刚生成的节点属性title，预测剩下的边，即虚线部分。\n\n### 高效的属性和边生成 \n\n出于效率考虑希望：\n\n- 对于输入图只跑一次GNN就能计算节点属性生成和边生成过程的loss\n- 希望节点属性生成和边生成能同时运行\n\n然而边生成需要用到节点属性信息，如果两个生成过程同时进行，会导致信息泄露。为避免这个问题，将节点分成两种类型：\n\n- 属性生成节点，mask住这些节点的属性，用一个公用的dummy token，并学习一个共享向量$X^{init}$来代替 和$X_i$ 维度相同。\n- 边生成节点，对于这些节点，保留他们的属性。\n\n需要注意的是，同一个节点在不同阶段扮演不同的角色，可能是属性生成节点也可能是边生成节点。只在某一阶段，一个节点有一个确定的角色。\n\n在graph上训练GNN 来生成各个节点的embedding，用$h_{attr}$ 和 $h_{edge}$ 来分别表示属性生成节点和边生成节点的embedding。由于属性生成节点的属性被mask了，因此$h_{attr}$中包含的信息通畅会少于 $h_{edge}$。\n\n因此，在GNN的message passing过程中，只使用$h_{edge}$ 作为向其他节点发送的信息。 也就是说，对于每个节点，其聚合邻居 $h_edge$ 的信息和自身信息来生成新的embedding。之后使用不同的decoder来生成节点属性和边。（注意，节点的embedding和节点属性不是一回事。通俗理解，在GNN中节点的属性是input，节点的embedding是hidden layer。）\n\n\n\n对于属性生成，用$Dec^{Attr}(\\cdot)$ 来表示decoder，输入$h_{attr}$ 来生成节点属性。decoder的选择依赖于节点属性的类型，如果是text类型的节点属性，可以使用LSTM等。如果节点属性是vector，可以使用MLP。\n\n定义一个距离函数来度量生成属性和真实属性之间的差异，对于text类型属性，可以使用perplexity困惑度，对于vector属性，可以使用L2距离。因此，可以计算属性生成过程中的loss\n$$\nL_i^{Attr} = Distance(Dec^{Attr}(h_i^{Attr}, X_i))\n$$\n\n\n最小化生成属性和真实属性之间的差异，等价于对generate attribute做MLE，也就是最大化 $p_{\\theta}(X_i|E_{i,o},X_{<i},E_{<i})$ 从而捕捉了图中的节点属性信息。\n\n\n\n对于边生成过程，假设每条边的生成过程和其他边是独立的，由此对likelihood分解：\n$$\np_{\\theta} (E_{i,\\lnot o}|E_{i,o},X_{\\le i},E_{\\le i}) = \\prod_{j^+\\in E_{i,\\lnot o}} p_{\\theta}(j^+|E_{i,o},X_{\\le i},E_{\\le i})\n$$\n得到$h_{edge}$ 后，如果节点i和节点j相连，则使用\n$$\nDec^{Edge} (h_i^{Edge},h_j^{Edge})\n$$\n进行建模，$Dec^{Edge}$ 是一个pairwise score function\n\nloss定义为：\n$$\nL_i^{Edge} = - \\sum_{j^+\\in E_{i,\\lnot o}} log \\frac{exp(Dec^{Edge}(h_i^{Edge},h_{j^+}^{Edge}))}{\\sum_{j\\in S_i^-\\bigcup{j^+} }exp(Dec^{Edge}(h_i^{Edge},h_j^{Edge}))}\n$$\n$S_i^-$ 是指没有和节点i相连的节点\n\n下面是作者给出的属性图生成过程的说明性示例。\n\n![](https://i.loli.net/2021/05/16/i8IYhQ2NbSfEAKe.png)\n\n- a) 对于input graph 确定排列 $\\pi$\n- b) 随机挑选一部分与节点i相连的边作为已观测的$E_{i,o}$ ,剩下的作为masked edges $E_{i,\\lnot o}$ 并删除masked edges\n- c) 把节点分为属性生成节点和边生成节点\n- d) 计算节点 3，4，5的embedding，包括他们的属性生成节点和边生成节点。\n- d)-e) 通过对每个节点并行进行节点属性预测和masked预测来训练一个GNN模型\n\n\n\n具体算法流程：\n\n![](https://i.loli.net/2021/05/16/tGbrz7QJfmKEhdw.png)\n\n输入一个属性图，每次采样一个子图 $\\hat G$作为训练的实例进行训练。首先决定permutation order π。同时，我们希望能够并行化训练，只做一次前向传播，就能得到整个图的embedding，由此可以同时计算所有节点的loss。因此，根据permutation order π来移除边，也就是使每个节点只能从更低order的节点处获得信息。\n 之后，需要决定哪些边被mask。对于每个节点，获得其所有的出边，随机挑选一部分边被mask住，这一过程对应上述line4。\n 之后，对节点进行划分，得到整个图中节点的embedding，用于之后loss的计算，对应line5。\n line 7-9进行loss的计算。\n line 8中，通过整合采样图中未连接的节点和Q中以前计算的节点embedding来选择负样本，这种方式能够减轻对于采样图优化和对于整个图优化的差距。\n 在line11-12中，优化模型并更新Q。\n\n\n\n## GPT-GNN 对于异质的大图\n\n对于异构图，即包含不同类型的点和边的图，唯一的不同在于不同类型的点和边采用不同的decoder。\n 对于大规模的图，可以采样子图来进行训练，即上述算法流程中Sampler的作用。为了计算 $L_{edge}$ 这一loss，需要遍历输入图的所有节点。然而，我们只能在采样的子图上计算这个loss。为了缓解这一差异，提出了adaptive queue，其中存储了之前采样的子图的节点embedding作为负样本。每次采样一个新的子图时，逐步更新这个队列，增加新的节点embedding，移除旧的节点embedding。通过引入adaptive queue，不同采样子图中的节点也能为全局的结构提供信息。\n\n## 实验效果\n\n![](https://i.loli.net/2021/05/16/xER1ftIsSWcaK72.png)\n\n![](https://i.loli.net/2021/05/16/ZNcLJsHUqRGOhCk.png)","tags":["GNN"]},{"title":"Strategies for Pre-training Graph Neural Networks","url":"/2021/05/12/Strategies-for-Pre-training-Graph-Neural-Networks/","content":"\n# Strategies for Pre-training Graph Neural Networks\n\n目前深度学习各个领域的预训练都搞的热火朝天，GNN也是肯定要搞的。那么预训练之后下一个热潮会是什么呢？\n\nICLR2020 首次系统的探索了大规模GNN预训练\n\n提出了一种结合节点级和图级表示的预训练方法来训练模型。\n\n在节点级，使用了两种自监督方法，即上下文预测和属性预测。\n\n在图形级，使用有监督的图级属性预测和结构相似性预测\n\n同时作者建立了两个新的预训练数据集，2M graph的化学数据集和一个有395K graph的生物数据集。\n\n接下来介绍作者这么做的理由\n\n## 发现\n\n因为对于特定任务的有标签数据是很稀少的，但无标签数据却有很多，所以为了充分利用无标签数据，各种自监督方法开始兴起。\n\n所以作者分别在图级和节点级层面上提出了两大类预测方法\n\n- 属性预测：属性mask(节点)、有监督的属性预测(图级)\n- 结构预测：上下文预测(节点)、结构相似性预测(图级)\n\n以往的一些研究表明(Xu et al., 2017; Ching et al., 2018; Wang et al., 2019),一个成功的迁移学习不仅仅是增加与下游任务来自同一领域的标注好的预训练数据集的数量。相反，它需要大量的领域专业知识来仔细选择与感兴趣的下游任务相关的示例和目标标签。否则，知识从相关的预训练任务转移到新的下游任务可能会损害泛化，这被称为负迁移(Rosenstein等人，2005年)，并极大地限制了预训练模型的适用性和可靠性。\n\n作者研究发现朴素的策略要么在整个图的层面上预先训练GNN，要么在单个节点层面上预先训练GNN，所给出的改进有限，甚至可能导致许多下游任务的负迁移。在只有图级的预训练下大约有1/4的任务出现了负迁移。\n\n![](https://i.loli.net/2021/05/12/z5CEtxbX9Tj1WwN.png)\n\n图(a.i)当仅使用节点级预训练时，可以很好地分离不同形状的节点(语义上不同的节点)，但汇集节点级嵌入创建的结果，图嵌入是不可分离的(图嵌入由+和−表示)\n\n图(a.ii)仅在图级预训练的情况下，图嵌入可以很好地分离，但是单个节点的嵌入并不一定捕获它们特定于领域的语义。\n\n图(a.iii) 高质量的节点嵌入使得不同类型的节点能够很好地分开，同时嵌入空间也是可组合的。这允许对整个图形进行准确和健壮的表示，并允许将预先训练的模型健壮地传输到各种下游任务。\n\n\n\n## 预训练策略\n\n在预训练策略的技术核心是在单个节点以及整个图的级别预先训练。这一概念鼓励GNN在两个级别捕获特定域的语义。\n\n\n\n### 节点级预训练\n\n两种自监督方法，上下文预测和属性mask。\n\n![](https://i.loli.net/2021/05/12/RFS46a2tozyNGkp.png)\n\n图(a)在上下文预测中，子图是所选中心节点周围的K跳邻域，其中K是GNN层的数量，上图中设置为K=2。环境定义为中心节点r1-和r2-Hop之间的周围图结构，上图中使用r1=1和r2=4。\n\n图(b) 在属性mask中，输入节点/边属性(例如，分子图中的原子类型)被随机mask，并且要求GNN预测它们。\n\n#### 上下文预测：利用图结构的分布性\n\n使用子图来预测其周围的图结构。目标是预先训练GNN，以便它将出现在类似结构上下文中的节点映射到附近的嵌入。\n\n通过三个步骤：\n\n- 邻居节点和上下文图\n\n  对于每个节点v，定义v的邻居和上下文图。因为GNN信息聚合的是K层邻居，所以节点v的嵌入$h_v$ 依赖于距离v至多k跳节点。上下文图由两个超参数r1和r2来描述，并且它表示远离v的r1跳和r2跳之间的子图(即它是宽度为r2−r1的环)。并且r1<K，以便在邻域和上下文图之间共享一些节点，我们将这些节点称为上下文锚节点。这些锚节点提供关于邻居图和上下文图如何彼此连接的信息。\n\n- 使用一个辅助GNN把上下文编码成固定向量\n\n  由于图的组合性，直接预测上下文图是很困难的。这与自然语言处理不同，在自然语言处理中，单词来自固定和有限的词汇表。为了实现上下文预测，将上下文图编码为固定长度的向量。为此，引入一个上下文GNN作为辅助编码，就是图中的GNN‘。首先用其获得上下文图中的节点嵌入，然后对上下文锚点的嵌入进行平均，得到固定长度的上下文嵌入。对于图G中的节点v，将其对应的上下文嵌入表示为$c^G_v$\n\n- 负采样\n\n  主要的GNN编码邻居节点获取节点的embedding—— $h_v^{(K)}$ ，上下文GNN编码上下文图获取上下文embedding——$c^G_v$。学习目标是一个二分类：是否特定邻域和特定上下文图是否属于同一节点。\n  $$\n  \\sigma(h^{(k)T}_v c_{v'}^{G'}) \\approx 1 \\{\\text{v and v' are the same nodes}\\}\n  $$\n  \n\n  让v‘=v并且G’=G(即正例)，或者我们从随机选择的图G‘中随机抽样v’(即负例)。\n\n#### 属性mask:利用图属性的分布性\n\n目标是通过学习图结构上节点/边属性的分布规律来获取领域知识。\n\n属性mask有节点mask和属性mask两类\n\n工作原理：掩蔽节点/边缘属性，然后让GNN基于相邻结构预测这些属性，这参考了bert的mask。\n\n具体地说，通过用特殊的屏蔽指示符替换输入节点/边属性(例如分子图中的原子类型)来随机屏蔽它们。然后应用GNNs来获得相应的节点/边嵌入(边嵌入:为边的端点的节点嵌入之和来获得)。\n\n最后，在嵌入的基础上应用线性模型来预测被mask的节点/边属性。有趣的是bert的mask其实相当于在全连通的token图上应用了消息传递。\n\n在图结构数据中是对非全连通图进行操作，目的是捕捉节点/边属性在不同图结构上的分布规律。\n\n\n\n### 图级别预训练\n\n我们的目标是确保节点和图嵌入都是高质量的，以便图嵌入是健壮的，并且可以跨下游任务传输。\n\n有两个用于图级预训练的选项：预测整个图的特定于域的属性(监督标签)，或者预测图结构。\n\n#### 有监督的图级属性预测\n\n由于图形级表示 $h_G$ 直接用于对下游预测任务进行微调，希望将特定于域的信息直接编码成 $h_G$。\n\n考虑了一种对图表示进行预训练的实用方法：图级多任务监督预训练，用于联合预测单个图的不同监督标签集。例如，在分子性质预测中，我们可以预先训练GNN来预测到目前为止实验测量的分子的所有性质。在蛋白质功能预测中，目标是预测给定的蛋白质是否具有给定的功能，我们可以预先训练GNN来预测到目前为止已经验证的各种蛋白质功能的存在。\n\n重要的是，单独进行大量的多任务图级预训练可能无法给出可转移的图级表示。(问题来了)\n\n这是因为一些有监督的预训练任务可能与下游感兴趣的任务无关，甚至会损害下游的绩效（负迁移）。一种解决办法是选择“真正相关的”有监督的训练前任务，只对这些任务进行训练前GNN训练。然而，这样的解决方案成本极高，因为选择相关任务需要大量的领域专业知识，并且需要针对不同的下游任务分别进行预训练。\n\n为了缓解这个问题，作者的见解是，多任务监督的预训练只提供图形级的监督；因此，创建图形级嵌入的本地节点嵌入可能没有意义。这种无用的节点嵌入可能会加剧负迁移问题，因为许多不同的预训练任务在节点嵌入空间中更容易相互干扰。受此启发，在执行图级预训练之前，先通过上文描述的节点级预训练方法在单个节点级别对GNN进行正则化。正如作者所料，组合策略产生了更多可转移的图形表示。并且在没有专家选择监督的预训练任务的情况下稳健地改善了下游性能。\n\n\n\n#### 结构相似性预测\n\n目标是对两个图的结构相似性进行建模\n\n此类任务的示例包括对图形编辑距离进行建模(Bai等人，2019年)或预测图形结构相似性(Navarin等人，2018年)。\n\n这里好像作者感觉比较难没有全部实现，留到了以后的工作中\n\n\n\n### 总体预训练策略\n\n预训练策略是首先进行节点级的自监督预训练，然后进行图级多任务监督的预训练。当GNN预训练完成后，我们对下游任务的预训练GNN模型进行微调。具体地说，我们在图级表示的基础上添加线性分类器来预测下游的图标签。随后以端到端的方式微调整个模型，即预先训练的GNN和下游线性分类器。\n\n\n\n## 进一步相关工作\n\n关于图中单个节点的无监督表示学习的文献非常丰富，大致分为两类。\n\n第一类是使用基于局部随机行走的目标的方法(Grover&Leskovec，2016；Perozzi等人，2014；Don等人，2015)以及例如通过预测边的存在来重建图的邻接矩阵的方法。\n\n在第二类中是诸如Deep Graph Infomax的方法，其训练最大化局部节点表示和聚集的全局图表示之间的互信息的节点编码器。(基于对比学习互信息的最近也要研究研究)\n\n这两种方法都鼓励附近的节点具有相似的嵌入表示，最初是针对节点分类和链路预测提出和评估的。然而，这对于图级预测任务来说可能是次优的，在图级预测任务中，捕捉局部邻域的结构相似性通常比捕捉图中节点的位置信息更重要\n\n所以该预训练策略既考虑了节点级的预训练任务，也考虑了图级的预训练任务，并且正如在实验中所显示的，为了使预训练模型获得良好的性能，必须同时使用这两种类型的任务。\n\n\n\n## 实验\n\n![](https://i.loli.net/2021/05/12/cFBosvWCfURYdhx.png)\n\n阴影单元格表示负迁移，即预训练模型的ROC-AUC比未预训练模型的ROC-AUC差。借此说明两个级别共用的重要性。\n\n\n\n![](https://i.loli.net/2021/05/12/HvFtBiY5RadqGMw.png)\n\n在有无预培训的情况下测试不同GNN架构的ROC-AUC(%)性能。\n\n这里表达能力越强的结构预训练效果越好，表达能力较弱的GNN收益较小，甚至有时未负。这一发现证实了先前的观察结果(例如，Erhan等人)。(2010))，使用富有表现力的模型对于充分利用预培训至关重要，当用于表达能力有限的模型(如GCN、GraphSAGE和GAT)时，预培训甚至会影响性能。\n\n并且GAT的表现反而下降了不少。作者认为GAT属于表达能力有限的模型，还有人认为GAT attention的参数比较多，模型结构比较复杂导致。\n\n\n\n![](https://i.loli.net/2021/05/12/kFYCKXIvcU2iLeZ.png)\n\n\n\n\n\n\n\n\n\n","tags":["GNN"]},{"title":"Meta Learning(李宏毅)","url":"/2021/05/09/Meta-Learning-李宏毅/","content":"\n# Meta Learning\n\n李宏毅：https://www.bilibili.com/video/BV15b411g7Wd?p=57&spm_id_from=pageDriver\n\n一个不错的科普：https://www.bilibili.com/video/BV1KB4y1c7gg?from=search&seid=2922012165894972973\n\n## 什么是元学习\n\nMeta Learning = Learn to Learn (学习如何去做学习这件事)\n\n机器在学习了很多task后，在获得过去的任务下所汲取的经验后，学习到了更多的学习技巧，成为了一个更厉害的学习者。\n\n从而有一个新任务，他可以学的更快更好。\n\n比如：task1你教机器去学语音识别，task2你教他去做图片识别，那么task3你让他去学习文字识别，那么他可能学的会更好。\n\n元学习的输入是训练数据，输出的是可以用于下一个任务的function，function也就是万能函数模拟器神经网络的模型参数\n$$\n\\begin{equation}\\begin{split} \n f^* = F(D_{train})\n    \\end{split}\\end{equation}\n$$\n其中F 代表元学习算法，D是数据，f就是function。理解下图：\n\n![](https://i.loli.net/2021/05/09/rMLgmoSywHJcq5u.png)\n\n### 和机器学习的区别\n\n机器学习：定义一系列function--->定一个function好坏的指标-----> 用gradient decent找到一个最好的function\n\n元学习(也是找一个function)：定义一系列大Function----->定一个评价大Function好坏的指标----->找到一个最好的大Function\n\n\n\n### 和终身学习(Life-long learning)有些像？\n\n[持续/终身学习](https://blog.csdn.net/zyy617532750/article/details/104217399)：是让同一个模型可以同时学会很多任务技能\n\n而元学习是不同的任务仍然有不同的模型，我们期待的是模型通过以前的学习经历可以让他在未来别的任务上学的好。\n\n\n\n\n\n## 元学习过程\n\n### 定义一系列学习算法\n\n为什么是一系列学习算法，其实不同的模型参数、不同的结构、不同的学习参数的组合都是不同的学习算法。\n\n![](https://i.loli.net/2021/05/09/P6iANVszETHWB37.png)\n\n以梯度下降法为例，首先定义一个网络结构，初始化一个参数，通过训练数据计算一个梯度g，再通过学习率更新参数。\n\n迭代多次最后得到最终参数$\\hat \\theta$\n\n但上图中红色框框内的都是人为定义的。元学习就是想让这红框内的东西，不让人来设计，让机器根据先验知识来自己学习设计。\n\n### 评估function参数好坏\n\n让模型先学一些任务，去解一些问题看看。\n\n比如Task1：用一些$D_{train}$ 数据去训练模型得到$f_1$ ,再用Task1的$D_{test}$ 去衡量 $f_1$ 得到一个loss $l_1$\n\n一个任务不够，再多找些任务来\n\nTask2：用一些$D_{train}$ 数据去训练模型得到$f_2$ ,再用Task2的$D_{test}$ 去衡量 $f_2$得到一个loss $l_2$\n\n最后得到评价F好坏的Loss：\n$$\n\\begin{equation}\\begin{split} \n L(F) &= \\sum_{n=1}^Nl_n\\\\\n F^* &= argmin_FL(F)\n    \\end{split}\\end{equation}\n$$\nN 为任务数\n\nmeta learning 通常会把task的Train叫做Suppot set，Test叫做Query set\n\n\n\n## MAML(Model Agnostic Meta-Learning)\n\n学一个初始化的参数\n$$\n\\begin{equation}\\begin{split} \n L(\\phi) = \\sum_{n=1}^N l^n(\\hat \\theta^n)\n    \\end{split}\\end{equation}\n$$\n$\\phi$ 输入的初始化参数，$\\hat \\theta^n$ 在第n个task上学出来的model，$\\hat \\theta^n$ 取决于$\\phi$ \n\n$l^n(\\hat \\theta^n)$: 把$\\hat \\theta^n$这组参数拿到第n个task的测试集中去看看效果怎么样\n\n怎么确定初始化的参数好不好，就用初始化参数到不同task上去做训练\n\n最小化$L(\\phi)$ : $\\phi \\gets \\phi-\\alpha ▽_{\\phi}L(\\phi)$\n\n### 和迁移学习(Transfer learning) 预训练有些像？\n\n迁移学习：某一个任务的数据很少，但另外一个任务的数据多。就把model预训练在多的数据上，再fine-tuning在少的数据上。\n\n他的loss function：\n$$\n\\begin{equation}\\begin{split} \n  L(\\phi) = \\sum_{n=1}^N l^n(\\phi)\n    \\end{split}\\end{equation}\n$$\n在MAML里面loss是用$\\phi$ 训练完后的model计算出来的，是训练过后的model\n\n在pretrain里是用现在这个model直接去下游任务中衡量表现怎么样。\n\n有的文章把预训练改成MAML的形式，以缓解预训练任务和下游任务直接目标不同产生的gap。\n\n\n\n在MAML中，我们不在意$\\phi$ 在training task上的表现，在意的是用$\\phi$ 训练出来的$\\hat \\theta^n$的表现如何\n\n（面向的是**学习的过程**，并不是**学习的结果**）\n\n![](https://i.loli.net/2021/05/10/7V2Uua4g8e9R1tk.png)\n\n![](https://i.loli.net/2021/05/10/epRfZzxlFTgSjVI.png)\n\n如上图虽然$\\phi$ 本身表现不够好，但$\\phi$经过训练以后可以变得很强 (潜力如何)\n\n而pretrain在意的是现在这个$\\phi$表现的怎么样，是在找寻在所有task都最好的$\\phi$, 并不保证训练以后会得到好的 $ \\hat \\theta^n$ （现在表现如何）\n\n并且MAML只训练很少的步数，因为\n\n- 为了快速\n- 希望在训练一步就得到很好的结果\n- 在使用算法模型时可以多update\n- 为了适应Few-shot learning \n\n### Toy Example\n\n每一个任务：\n\n- 给一个目标sin函数 $y = a sin(x+b)$ 其中 a、b 都是随机数，每一组 a、b 对应一条正弦曲线\n- 从目标函数中采样k个点\n- 使用采样点去估计目标函数\n\n希望拟合的y越好越好。随机采样不同的a和b就可以得到不同的任务。\n\n![](https://i.loli.net/2021/05/10/9YnTfrxqoBDgVCU.png)\n\n\n\n\n\n\n\n## 参考文献\n\n[元学习-总结](https://zhuanlan.zhihu.com/p/367684934)\n\n[元学习（Meta-learning）——李宏毅老师教学视频笔记](https://zhuanlan.zhihu.com/p/108503451)\n\n[[meta-learning] 对MAML的深度解析](https://zhuanlan.zhihu.com/p/181709693)\n\n","tags":["Meta Learning"]},{"title":"Learning to Pre-train Graph Neural Networks","url":"/2021/05/08/Learning-to-Pre-train-Graph-Neural-Networks/","content":"\n# Learning to Pre-train Graph Neural Networks\n\n\n\n## 动机与挑战\n\n图神经网络也是有预训练模型的，预训练之所以可以提升，可以解释为获取了有用的先验知识，并迁移到任务中。\n\n常规的GNN预训练步骤和其他网络一样分为两个步骤：\n\n- 在大量未标记的图数据上预先训练GNN模型，其导出编码固有图属性的通用可转移知识\n- 在特定于任务的图形数据上对预先训练的GNN模型进行微调，以使通用知识适用于下游任务。\n\n但之前有人已经研究过直接进行fine-tuning效果不提反降，产生负迁移效果。应该是出自(Strategies for Pre-training Graph Neural Networks 如何解决的以后看了这篇论文再说) \n\n而这篇文章的主要想解决的是由于预训练和fine-tuning优化目标的不同，两者之间存在明显差距，损害了模型的泛化效果。\n\n引出了第一个挑战：如何缩小不同优化目标带来的差距？ --->>元学习思想\n\n那GNN的预训练模型的特点是不仅要考虑局部的节点级先验知识还要获取图级别的全局先验知识 (现有方法要么只考虑节点级的预训练，或者仍然需要用有监督的图级预训练)\n\n引出了第二个挑战：如何利用完全未标记的图数据同时保留节点级和图形级信息？\n\n提出了L2P-GNN，计了节点级和图级的双重自适应机制，并且是完全自监督的方式。\n\n\n\n## 设计\n\n### GNN\n\n首先定义一个图 $G = (V,E,X,Z)$ , 其中 $V$ 是节点、$E$ 是边、$X \\in R ^{|V|\\times d_v}$ 是节点特征、 $Z \\in R^{|E|\\times d_e}$ 是边的特征。\n\nGNN 一般包含两个关键的计算，一个是聚合信息的操作AGGREGATE，另一个是更新操作UPDATE\n\n节点表示：节点v的l层表示由下式给出：\n$$\n\\begin{equation}\\begin{split} \n h_v^l &= \\Psi (\\psi, A, X,Z)^l\\\\\n &= \\text{UPDATAE}(h_v^{l-1}, AGGREGATE(\\{(h_v^{l-1}, h_u^{l-1}, z_{uv}): u\\in N_v\\}))\n\\end{split}\\end{equation}\n$$\n其中 $z_{uv}$ 是u到v的边特征向量，A是邻接矩阵 ，$N_v$ 是v的邻居节点。$\\Psi$ 是聚合和更新操作的定义，$\\psi$ 是可学习参数。\n\n图级的表示：通常用READOUT \n$$\n\\begin{equation}\\begin{split} \n h_G = \\Omega(w ; H^l) = \\text{READOUT} (\\{h_v^l| v\\in V\\})\n    \\end{split}\\end{equation}\n$$\n其中$H^l = [h_v^l]$ 是节点级表达矩阵。READOUT的典型实现有sum、max、mean池化，或者用其他复杂一点的方法。\n\n### 常规GNN的预训练\n\n1. 预训练：定义 $D^{pre}$ 为预训练图数据，$L^{pre}$ 预训练的loss ，优化目标为：\n\n$$\n\\theta_0 = argmin_{\\theta}  L^{pre} (f_\\theta; D^{pre})\n$$\n\n2. fine-tuning：目标是，在对下游任务的训练集图数据$D^{tr}$进行微调之后，最大化下游测试集图数据$D^{te}$上的表现 \n\n所谓的微调根据预先训练的参数$\\theta_0$来初始化模型，并且用在(通常是批处理的)$D_{tr}$上的多步梯度下降来更新GNN模型 $f_{\\theta}$。\n$$\n\\theta_1 = \\theta_0 - \\eta ▽_{\\theta_0} L^{fine}(f_{\\theta_0};D^{tr})\n$$\n其中 $ \\eta$ 学习率\n\n可见常规的预训练和finetuing是解耦的，参数$\\theta_0$ 和下游没有适应性的联系形式。\n\n为此，作者提出通过构建预训练阶段来模拟下游任务的微调过程，从而直接优化预训练模型对下游任务的快速适应性。\n\n### 新的预训练方法\n\n其实就是元学习的思想 参考上文 [Meta Learning(李宏毅)](https://coding-zuo.github.io/2021/05/09/Meta-Learning-%E6%9D%8E%E5%AE%8F%E6%AF%85/)\n\n现有$G\\in D^{pre}$ 从中采样一些子图 定义为$D^{tr}_{T_G}$ 作为模拟下游任务$T_G$的训练数据——元学习中的support sets，再采样一些子图作为$D^{te}_{T_G}$ 作为模拟的验证集——元学习中的query sets。\n$$\n\\theta_0 = argmin_{\\theta} \\sum_{G\\in D^{pre}} L^{pre}(f_{\\theta - \\alpha ▽_{\\theta}L^{pre}(f_{\\theta}; D^{tr}_{T_G})}; D^{te}_{T_G})\n$$\n$\\theta - \\alpha ▽_{\\theta}L^{pre}(f_{\\theta}; D^{tr}_{T_G})$ 相当于在$D^{tr}_{T_G}$ 预训练的测试集先进行了一次fine-tuning\n\n作者认为：因此，预培训输出$θ_0$并不是为了直接优化任何特定任务的训练或测试数据。相反，θ0通常是最佳的，因为它允许快速适应新任务。\n\n我认为：这类似元学习的思想，还可以从元知识的角度来描述。还有一个点，这个预训练数据集和下游任务相不相关呢？如果相关度不大会不会有用，如果相关会不会更好？\n\n\n\n## L2P_GNN\n\n两个特点：\n\n- 从局部和全局角度捕捉图形中的结构和属性\n- 套用MAML获得元学习的先验知识可以适应新的任务或图表\n\n### 任务实施\n\n定义每个任务的图数据随机采样得到 $T_G = (S_G,Q_G)$ , $S_G$ 为Support set ，$Q_G$ 为Query set\n\n![](/Users/zuoyuhui/Library/Application Support/typora-user-images/image-20210510173143614.png)\n\n多个任务的支持集合查询集为: $S_G =(S_G^1,S_G^2,...,S_G^k) ,Q_G =(Q_G^1,Q_G^2,...,Q_G^k)$\n\n在给定父任务和子任务的情况下，作者设计了一个节点级聚集和图级汇集的自监督基本GNN模型，分别学习节点和图的表示。其核心思想是利用无标签图数据的内在结构作为节点级和图级的自我监督。\n\n\n\n节点级：自监督预测u和v节点有边链接的目标函数\n$$\nL^{node}(\\psi;S_G^c) = \\sum_{(u,v)\\in S_G^e} -ln(\\sigma(h_u^Th_v)) -ln(\\sigma(-h_u^Th_{v'}))\n$$\n其中 $v'$ 是负采样节点，是没有和u有边的节点。\n\n图级：通过图池化获得图表达$h_G$，每个任务的支持集图表达为 $h_{S_G^c} = \\Omega(w;\\{h_u|\\forall u,\\exists v:(u,v) \\in S_G^c\\})$\n$$\nL^{graph} (w; S_G) = \\sum_{c=1}^k -log(\\sigma(h_{S_G^c}^T h_G)) -log(\\sigma(-h^T_{S_G^c}h_{G'}))\n$$\n两个级别的loss综合到一起：\n$$\nL_{T_G}(\\theta;S_G) = L^{graph}(w;S_G) + \\frac{1}{k} \\sum_{c=1}^k L^{node}(\\psi;S_G^c)\n$$\n其中$\\theta = \\{\\psi,w\\}$ 是可学习参数，就是可迁移的先验知识\n\n### 双重适应(图级和节点级)\n\n\n\n![](https://i.loli.net/2021/05/10/ahQdOwrHvFgKIxy.png)\n\n节点级：支持loss采用一个或几个梯度下降步骤，以获得子任务的适应先验 $ψ$。例如，当使用一个具有节点级学习率$α$的梯度更新时:\n$$\n\\psi' = \\psi - \\alpha \\frac{\\partial\\sum_{c=1}^k L^{node}(\\psi;S_G^c)}{\\partial\\psi}\n$$\n图级：\n$$\nw' = \\psi - \\beta \\frac{\\partial  L^{graph}(w;S_G^c)}{\\partial w}\n$$\n所有任务的更新参数过程\n$$\n\\theta \\gets \\theta - \\gamma\\frac{\\partial\\sum_{G\\in D^{pre}}L_{T_G}(\\theta';Q_G) }{\\partial \\theta}\n$$\n\n## 实验\n\n实验的主要目的：要验证有没有缩小预训练和微调的gap图级和节点级预训练策略是否奏效\n\n作者对预训练的GNN模型在下游任务微调前后（命名为model-P和model-F）进行了对比分析，并考虑了三个比较视角：model-P和model-F参数之间的中心核对齐相似性（CKA），训练损失（delta损失）和下游任务测试性能（delta RUC-AUC或Micro-F1）的变化。\n\n![](https://i.loli.net/2021/05/10/wiGa9eSAcgNy62u.png)\n\n如图所示，观察到L2P-GNN参数在微调前后的CKA相似性通常比基线的CKA相似性小，这表明L2P-GNN经历了更大的变化，以便更好地适应下游任务。\n\nCKA 是测量神经网络表示相似性的，可以对迁移学习任务进行评估，值越小越相似。\n\n此外，L2P-GNN的训练损失变化较小，说明L2P-GNN通过快速适应可以很容易地达到新任务的最优点。\n\n\n\n\n\n\n\n## 参考\n\n### GNN预训练的论文\n\nHu, W.; Liu, B.; Gomes, J.; Zitnik, M.; Liang, P.; Pande, V. S.; and Leskovec, J. 2020. Strategies for Pre-training Graph Neural Networks. In *Proceedings of ICLR*.\n\nHu, Z.; Fan, C.; Chen, T.; Chang, K.; and Sun, Y. 2019. Pre-Training Graph Neural Networks for Generic Structural Feature Extraction. *CoRR* abs/1905.13728.\n\nNavarin, N.; Tran, D. V.; and Sperduti, A. 2018. Pre-training Graph Neural Networks with Kernels. *CoRR* abs/1811.06930.\n\n### 元学习\n\nFinn, C.; Abbeel, P.; and Levine, S. 2017. Model-agnostic meta-learning for fast adaptation of deep networks. In *Pro- ceedings of ICML*, 1126–1135.\n\nLu, Y.; Fang, Y.; and Shi, C. 2020. Meta-learning on Hetero- geneous Information Networks for Cold-start Recommenda- tion. In *Proceedings of KDD*, 1563–1573.","tags":["GNN"]},{"title":"DP——最大子序和","url":"/2021/05/06/DP——最大子序和/","content":"\n# DP——最大子序和\n\nhttps://www.acwing.com/problem/content/137/\n\n输入一个长度为 n 的整数序列，从中找出一段长度不超过 m 的连续子序列，使得子序列中所有数的和最大。\n\n**注意：** 子序列的长度至少是 1。\n\n#### 输入格式\n\n第一行输入两个整数 n,m。\n\n第二行输入 n 个数，代表长度为 n 的整数序列。\n\n同一行数之间用空格隔开。\n\n#### 输出格式\n\n输出一个整数，代表该序列的最大子序和。\n\n#### 数据范围\n\n1≤n,m≤300000\n\n#### 输入样例：\n\n```\n6 4\n1 -3 5 1 -2 3\n```\n\n#### 输出样例：\n\n```\n7\n```\n\n\n\n\n\n## 解\n\n![](https://i.loli.net/2021/05/06/QHsdPGY1q7FrtpB.png)\n\n\n\n状态转移方程：集合代表的喊一声所有以i结尾的子段，如果i=3的话，那么集合可能是{1,num[i]}、{1,-3,num[i]}、{1,5,num[i]}、{num[i]} ，目标是求这些集合中的最大值，因为每个集合都有num[i]可先不考虑num[i]。\n\n所以只要考虑f[i-1]+num[i] ,和只有num[i]的集合的最大值。\n\n也就是考虑f[i-1]和0谁最大。\n\n最终的答案是所有集合的值取最大\n\n## 代码\n\nLeetCode53 不限制最大子序列长度\n\n```java\nclass Solution {\n    public int maxSubArray(int[] num) {\n        int last = 0;\n        int res = Integer.MIN_VALUE;\n        for (int i = 0; i < num.length; i++) {\n            int now = Math.max(last, 0) + num[i];\n            res = Math.max(res, now);\n            last = now;\n        }\n        return res;\n    }\n}\n```\n\n\n\nacwing 135 限制最大子序列长度\n\n不同的是，对于每一个i，要求前面长度为m这个段内，求一个最小值\n\n![](https://i.loli.net/2021/05/06/KfOS1Mzt4GxnoUd.png)\n$$\nmax\\{Sum_i - Sum_j\\} , i-m 到 i-1\n$$\n可以用一个队列来维护m个数\n\n每次i向后移动，就插入一个数同时队首出列\n\n- 用一个单调队列\n- 把没用的数删去\n- 变成单调递增的序列\n- 用$0(1)$ 把 min或max找出\n\n```java\n\npublic class Main{\n\n    void run(){\n        int n = jin.nextInt();\n        int m = jin.nextInt();\n        nums.add(0);\n        for (int i = 0 ; i < n ; i++) nums.add(jin.nextInt());\n        for (int i = 1 ; i <= n ; i++) nums.set(i, nums.get(i)+nums.get(i-1));\n\n        int res = Integer.MIN_VALUE;\n        for (int i = 1; i <= n ; i++){\n            while(!queue.isEmpty() && i - queue.peekFirst() > m) queue.removeFirst();\n\n            if (!queue.isEmpty()) res = Math.max(res, nums.get(i) - nums.get(queue.peekFirst())); // why not peekF -1 ?\n            else res = Math.max(res, nums.get(i));                                              // 差点漏掉了\n            while(!queue.isEmpty() && nums.get(i) <= nums.get(queue.peekLast())) queue.removeLast();\n            queue.offerLast(i);\n        }\n        res = Math.max(res, nums.get(n) - nums.get(queue.peekFirst()-1));\n        System.out.println(res);\n    }\n\n    List<Integer> nums = new ArrayList<>();\n    Deque<Integer> queue = new LinkedList<>();\n    private Scanner jin = new Scanner(System.in);\n    public static void main(String[] args) throws Exception {new Main().run();}\n}\n\n```\n\n\n\n\n\n\n\n\n\n\n\n","tags":["刷题"]},{"title":"海华阅读理解比赛复盘","url":"/2021/05/01/海华阅读理解比赛复盘/","content":"\n# 海华阅读理解比赛复盘\n\n比赛详情、EMA、Baseline，本文主要记录提分点和模型改进的验证\n\n参考上文 [海华中文阅读理解比赛梳理/多卡并行/transformers](https://coding-zuo.github.io/2021/04/06/%E6%B5%B7%E5%8D%8E%E4%B8%AD%E6%96%87%E9%98%85%E8%AF%BB%E7%90%86%E8%A7%A3%E6%AF%94%E8%B5%9B%E6%A2%B3%E7%90%86-%E5%A4%9A%E5%8D%A1%E5%B9%B6%E8%A1%8C-transformers/)\n\n[github](https://github.com/Coding-Zuo/MRC_multiChoice)\n\n\n\n## 数据增强\n\n数据增强的办法很多参考 https://zhuanlan.zhihu.com/p/145521255\n\n我只采用了句子乱序和数据回译，都是将增强数据和原始数据挨着放到数据集中，在训练的时候停用shuffle。(可能有其他方法：每条数据根据概率来选择性增强)，我这种可能会让数据集臃肿，质量下降。\n\n### 句子乱序\n\n没有提分，也没有降很多。\n\n原因参考：[从知觉谈中文乱序不影响阅读的原因](https://zhuanlan.zhihu.com/p/107594976)\n\n代码：https://github.com/Coding-Zuo/MRC_multiChoice/blob/main/train/data_process.py 中的data_enhancement_sentence_order\n\n### 数据回译\n\n和句子乱序一样和回译到的数据和原始数据挨着放到数据集，没有提分，可能是回译到的数据质量不好。\n\n使用的是百度API，百度限制一个账户免费200万字符，如果超了就多注册几个账户薅羊毛。\n\n代码：https://github.com/Coding-Zuo/MRC_multiChoice/blob/main/TranslateAPI.py\n\n\n\n### 在训练集上打伪标签\n\n由于时间问题，没有直接提交伪标签训练的结果，就直接模型融合。验证集有提高。\n\n用训练好的模型去inference测试集，取了模型认为有百分之85概率认为是正确答案的数据打上伪标签，加入到训练集训练。\n\n\n\n## 优化训练\n\n### EMA\n\n滑动平均exponential moving average\n\n没有提分，反而效果变差。具体原因，还在探索，可能和优化方法有关？\n\n我一直使用的都是adamw，[比较Adam 和Adamw](https://www.cnblogs.com/tfknight/p/13425532.html) [一文告诉你Adam、AdamW、Amsgrad区别和联系](https://zhuanlan.zhihu.com/p/39543160)，AdamW是在Adam+L2正则化的基础上进行改进的算法。\n\n可以和sgd搭配看看效果。(这方面因为时间问题没有尝试充足)\n\n[PyTorch指数移动平均(EMA)手册](https://blog.csdn.net/weixin_43002433/article/details/113531466)\n\n指数移动平均EMA是用于估计变量的局部均值的，它可以使变量的更新不只取决于当前时刻的数据。\n\n而是加权平均了近期一段时间内的历史数据，是的变量的更新更平滑，不易受到某次异常值的影响。\n\n\n\n### labelSmoothing\n\n精度提升不明显，但是缓解了验证集的loss上升。\n\n```python\nclass LabelSmoothingCrossEntropy(nn.Module):\n    def __init__(self, eps=0.1, reduction='mean'):\n        super(LabelSmoothingCrossEntropy, self).__init__()\n        self.eps = eps\n        self.reduction = reduction\n\n    def forward(self, output, target):\n        c = output.size()[-1]\n        log_preds = F.log_softmax(output, dim=-1)\n        if self.reduction == 'sum':\n            loss = -log_preds.sum()\n        else:\n            loss = -log_preds.sum(dim=-1)\n            if self.reduction == 'mean':\n                loss = loss.mean()\n        return loss * self.eps / c + (1 - self.eps) * F.nll_loss(log_preds, target, reduction=self.reduction)\n```\n\n\n\n### 对抗训练\n\n提升两个点以上\n\n可参考我的 [ppt](https://coding-zuo.github.io/adversary/index.html) 和以前文章\n\n主要使用了fgm和pgd两个，都有提升的效果\n\n但有时候pgd并没有提升，可能是在有些参数和加了伪标签的数据情况下，学习困难？\n\n\n\n### 早停\n\nbert的早停不太好控制，有时候一两个epoch之后还会更新，可能跟参数有关。\n\n\n\n\n\n## 模型改进\n\n### 尝试用LongFormer\n\n因为文本比较长，但因为没有时间测试而没有跑，不过已经基本调通，日后跑一跑。\n\n\n\n### 复现DUMA\n\n用co-attention 来分别处理 bert输出的文章编码和问题答案对编码，分别送到co-attention中。\n\n我的方法是分别为文章和问题答案设置一个maxlen， 多的截掉，因为我机器只能最大总长度跑到400，而数据文章又比较长，可能这也会导致学习瓶颈的出现。\n\n我的另一个实现想法但是没有时间做的是，把文章和问题答案拼在一起用sep分割送入bert，输出时只要找到sep的timesteps进行分割，对于得到的两个不等长的向量，在经过对其。送入co-attention。\n\n训练刚开始有一个比较好的提分劲头，但随着深入训练后期效果乏力。可能是因为参数没有调好？DUMA那篇论文没有复现细节。\n\n\n\n### 尝试其他比赛前排模型\n\n![](https://i.loli.net/2021/05/01/f1QIsuWtSVXCcBx.png)\n\n移植后问题：训练集准确率很低，具体问题还需探究。\n\n\n\n### 尝试在bert后加self-attention层\n\n用pool_output,投入自注意力，没有明显提升\n\n在bert后加多层线性也没有明显提升。不过可以尝试加highway network。\n\n\n\n## 模型融合\n\n组合不同参数和结构的打包模型，用argmax的方法融合了九个，达到最好的51.7分，晋级分数最终为52分，遗憾落榜。\n\n还尝试用实现vote投票来融合，并没有最终提交。\n\n以后将会尝试实现bert的stacking融合。\n\n\n\n## 遇到的难题\n\n1. bert换成roberta后始终不收敛，因为没有经验，学习率试过1e-5, 1e-6, 2e-5,和不同batch32、64、128进行组合都不收敛(浪费了很多时间)。最终发现学习率在1e-5,2e-5 ,batch 在8或16才会收敛。\n\n   并参照roberta论文附录中的参数，收敛了，但是效果没有达到预期，不过听说好多人也是用了roberta。\n\n![](https://i.loli.net/2021/05/01/7vZQHiFus6DqJI2.png)\n\n2. 调参没经验，浪费了很多时间。\n\n\n\n## 总结\n\n用了将近一个月的时间来做这个比赛，对模型训练体系、模型理解、微调下游任务、多卡并行、对抗训练。还有好多理论需要通过实践来加深理解。\n\n\n\n\n\n\n\n\n\n\n\n","tags":["DataGame"]},{"title":"阅读理解文献梳理","url":"/2021/04/29/阅读理解文献梳理/","content":"\n# 阅读理解文献梳理\n\n\n\n## 多跳QA\n\n\n\n### 模型在任务中学习的多跳推理行为。\n\nQFE (Nishida et al., 2019) regards evidence extraction as a query-focused summarization task, and reformulates the query in each hop.    将证据提取作为以查询为中心的摘要任务，并在每一跳中重构查询。—— HGN\n\nKosuke Nishida, Kyosuke Nishida, Masaaki Nagata, Atsushi Otsuka, Itsumi Saito, Hisako Asano, and Junji Tomita. 2019. Answering while summarizing: Multi-task learning for multi-hop qa with evidence extraction. In *ACL*.\n\n---\n\n DecompRC (Min et al., 2019b) decomposes a compositional question into simpler sub-questions and leverages single-hop MRC mod- els to answer the sub-questions.  将作文问题分解为更简单的子问题，并利用单跳MRC模型答复子问题—— HGN\n\nSewon Min, Victor Zhong, Luke Zettlemoyer, and Han- naneh Hajishirzi. 2019b. Multi-hop reading compre- hension through question decomposition and rescor- ing. In *ACL*.\n\n---\n\nA neural modular network is also proposed in Jiang and Bansal (2019b), where neural modules are dynamically assembled for more interpretable multi-hop rea- soning.一种神经模块网络，其中神经模块被动态地组装起来，以便更好地解释多跳推理。—— HGN\n\nYichen Jiang and Mohit Bansal. 2019b. Self- assembling modular networks for interpretable multi-hop reasoning. In *EMNLP*.\n\n----\n\n其他\n\nJifan Chen and Greg Durrett. 2019. Understanding dataset design choices for multi-hop reasoning. In *NAACL*.—— HGN\n\nSewon Min, Eric Wallace, Sameer Singh, Matt Gard- ner, Hannaneh Hajishirzi, and Luke Zettlemoyer. 2019a. Compositional questions do not necessitate multi-hop reasoning. In *ACL*.—— HGN\n\nYichen Jiang and Mohit Bansal. 2019a. Avoiding rea- soning shortcuts: Adversarial evaluation, training, and model development for multi-hop qa. In *ACL*.—— HGN\n\n-----\n\n### 与GNN相关的\n\nCoref-GRN (Dhingra et al., 2018) construct an entity graph based on co-reference reso- lution or sliding windows.基于共引用解决方案或滑动窗口构建实体图。—— HGN\n\nBhuwan Dhingra, Qiao Jin, Zhilin Yang, William W Cohen, and Ruslan Salakhutdinov. 2018. Neural models for reasoning over multiple mentions using coreference. In *NAACL*.\n\n----\n\nEntity-GCN (De Cao et al., 2019) considers three different types of edges that connect different entities in the entity graph.考虑连接实体图中不同实体的三种不同类型的边。—— HGN\n\nNicola De Cao, Wilker Aziz, and Ivan Titov. 2019. Question answering by reasoning across documents with graph convolutional networks. In *NAACL*.\n\n---\n\n**(已读)**HDE-Graph (Tu et al., 2019) enriches information in the entity graph by adding document nodes and creating interactions among documents, entities and answer candidates.通过添加文档节点并在文档、实体和候选答案之间创建交互，丰富了实体图中的信息。——HGN\n\n---\n\n**(已读)**Cognitive Graph QA employs an MRC model to predict answer spans and possible next-hop spans, and then organizes them into a cognitive graph.使用MRC模型预测答案跨度和可能的下一跳跨度，然后将它们组织到认知图中。——HGN\n\n----\n\nDFGN (Xiao et al., 2019) constructs a dynamic entity graph, where in each reasoning step irrelevant en- tities are softly masked out and a fusion module is designed to improve the interaction between the entity graph and documents.构建了一个动态实体图，在每个推理步骤中，不相关的实体被软屏蔽，并设计了一个融合模块来改善实体图与文档之间的交互性。——HGN\n\nYunxuan Xiao, Yanru Qu, Lin Qiu, Hao Zhou, Lei Li, Weinan Zhang, and Yong Yu. 2019. Dynamically fused graph network for multi-hop reasoning. In *ACL*.\n\n-----\n\n**(已读)**SAE (Tu et al., 2020) defines three types of edge in the sentence graph based on the named entities and noun phrases appearing in the question and sentences 根据问题和句子中出现的命名实体和名词短语，定义句子图中的三种边——HGN\n\n----\n\nC2F Reader (Shao et al., 2020) uses graph attention or self-attention on entity graph, and argues that this graph may not be necessary for multi-hop reasoning. 在实体图上使用图注意或自我注意，并认为该图对于多跳推理可能不是必需的。——HGN\n\nNan Shao, Yiming Cui, Ting Liu, Wang, and Guop- ing Hu Hu. 2020. Is graph structure necessary for multi-hop reasoningt. *arXiv preprint arXiv:2004.03096*.\n\n------\n\nAsai et al. (2020) proposes a new graph-based recurrent method to find evidence documents as reasoning paths, which is more focused on information retrieval.提出了一种新的基于图的递归方法来寻找证据文档作为推理路径，更侧重于信息检索。——HGN\n\nAkari Asai, Kazuma Hashimoto, Hannaneh Hajishirzi, Richard Socher, and Caiming Xiong. 2020. Learning to retrieve reasoning paths over wikipedia graph for question answering. In *ICLR*.\n\n----\n\n**(已读)**HGN 2020 提出的模型构建了一个层次图，有效地探索了不同粒度之间的关系，并使用不同的节点来执行不同的任务。\n\n\n\n## GNN\n\n### GNN结构机制\n\n- GCN\n- SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS(ICLR 2017)\n- GAT\n- GraphSage\n- MPGNN\n- HGN\n- HAN\n\n### 预训练GNN\n\nHu, W.; Liu, B.; Gomes, J.; Zitnik, M.; Liang, P.; Pande, V. S.; and Leskovec, J. 2020. Strategies for Pre-training Graph Neural Networks. In *Proceedings of ICLR*.——L2P-GNN\n\n提出了不同的策略来预训练图神经网络的节点和图级，虽然在图级需要标记的数据。\n\n----\n\nHu, Z.; Fan, C.; Chen, T.; Chang, K.; and Sun, Y. 2019. Pre-Training Graph Neural Networks for Generic Structural Feature Extraction. *CoRR* abs/1905.13728..——L2P-GNN\n\n使用三个非监督任务预先培训图形编码器，以捕获图形的不同方面。\n\n-----\n\nNavarin, N.; Tran, D. V.; and Sperduti, A. 2018. Pre-training Graph Neural Networks with Kernels. *CoRR* abs/1811.06930..——L2P-GNN\n\n利用图内核进行预培训\n\n\n\n## 元学习及应用\n\nFinn, C.; Abbeel, P.; and Levine, S. 2017. Model-agnostic meta-learning for fast adaptation of deep networks. In *Pro- ceedings of ICML*, 1126–1135.\n\nLu, Y.; Fang, Y.; and Shi, C. 2020. Meta-learning on Hetero- geneous Information Networks for Cold-start Recommenda- tion. In *Proceedings of KDD*, 1563–1573.\n\n\n\n## 预训练语言模型\n\n- ALBERT\n- Roberta\n- Bert\n- LongFormer\n\n## 对抗训练\n\n- FGM\n- PGD\n- FreeLB\n\n\n\n\n\n\n\n\n\n","tags":["GNN&nlp"]},{"title":"Hierarchical Graph Network for Multi-hop Question Answering","url":"/2021/04/29/Hierarchical-Graph-Network-for-Multi-hop-Question-Answering/","content":"\n# Hierarchical Graph Network for Multi-hop Question Answering\n\nhttps://arxiv.org/pdf/1911.03631.pdf\n\n这篇文章也是HotpotQA数据集上的关于解决多跳问答场景的，在干扰项排行榜和全维基排行榜都曾是前列。\n\n多跳QA和HotpotQA数据集 : [HotpotQA数据集：A Dataset for Diverse, Explainable Multi-hop Question Answering](https://coding-zuo.github.io/2021/03/23/HotpotQA%E6%95%B0%E6%8D%AE%E9%9B%86/)\n\n其特点是\n\n- 通过在问题、段落、句子、实体等不同粒度上构建层次图(HGN)\n- 通过HGN这种节点粒度层次可以区分，进一步进行多任务推理：段落选择、支持句预测、实体抽取、最终答案预测\n\n## 如何构图\n\n首先来介绍下作者是如何构图的。\n\n![](https://i.loli.net/2021/05/01/sux1NI4eMgf2bcz.png)\n\n段落由句子组成，每个句子包含多个实体。这个图自然是以层次结构编码的，它也激发了作者构建层次图的动机。\n\n四种节点类型：\n\n- 问题节点Q\n- 实体节点E\n- 段落节点P：对于每个段落节点，在段落中的所有句子之间添加边。\n- 句子节点S：对于每个句子节点，提取句子中的所有实体，并在段落句子节点和这些实体节点之间添加边。\n\n七种边类型：\n\n- 问题节点和定位段落节点有边\n- 问题节点和问题中的实体节点有边\n- 段落节点和段落中的句子节点有边\n- 句子节点与其链接的段落节点之间的边(超链接链接)\n- 句子节点和句子中所提取的实体节点有边\n- 段落和段落之间有边(论文是取和问题最相关的前两个段落)\n- 存在同一个段落的句子节点\n\n\n\n## 挑战与动机\n\nHotpotQA的方案一般是先用一个检索器去找到包含正确答案的段落。然后在用MRC模型去选择段落去预测答案。\n\n目前的挑战：即使通过多个段落成功地确认了推理链，如何从分散的段落中收集不同粒度级别的证据共同回答并支持事实预测，仍然是一个关键的挑战。\n\n作者认为多跳阅读推理直观的步骤：\n\n- 找到与问题相关的段落\n- 在段落中选择强有力的证据\n- 从获得的证据中查明正确答案\n\n作者也是这么实现的，并创新的采用了多个层级的粒度信息去构图推理。\n\n\n\n## HGN \n\n![](https://i.loli.net/2021/05/05/6eL2w9WqRcPdIMj.png)\n\n模型包含四个模块：图构造模块、上下文编码模块、图推理模块、多任务预测模块\n\n### 图构造模块\n\n就是构造上文的七种边四种节点，形成层级图\n\n一共要考虑两步：\n\n- 选择相关段落：\n\n  第一跳：用预训练模型加一个二分类判断段落中是否包含支撑事实，\n\n  如果返回多个段落则选择排名靠前的两个作为段落节点。\n\n  如果标题匹配没有结果，则进一步搜索段落中包含问题实体的。\n\n  如果还是搜索失败，将会从段落排序中选择排名最高的段落。\n\n  确定第一跳后：下一步就是段落中找到可以通向其他相关段落的事实和实体(不再依赖实体链接，这可能会很引入噪音，而是在第一跳段落中使用超链接来发现第二跳段落。)\n\n  \n\n- 添加表示所选段落内的句子/实体之间的连接的边。\n\n### 上下文编码模块\n\n给出构建的层次图，下一步是获得所有图节点的初始表示。首先将所有选定的段落合并到上下文C中，将其与问题Q连接起来，输入Roberta。\n\n$C = \\{c_0,c_1,...,c_{n-1}\\} \\in \\text{R}^{n\\times d } , Q =\\{q_0,q_1,...,q_{m-1}\\}\\in \\text{R}^{m\\times d}$\n\n问题Q随后是一个双向注意力层。(2017. Bidirectional attention flow for machine comprehension. *ICLR*.)\n\n在上下文表示C之上用BiLSTM，并且从BILSTM的输出中提取不同节点的表示，表示为$M∈R^{n×2d}$。\n\n在BiLSTM后通过预测开始和结束位置来得到句子和实体节点。\n\n$p_i$ 第i段落节点、$s_i$ 第i句子节点、 $e_i$ 第i个实体节点、q 问题节点 $\\in \\text{R}^d$\n$$\n\\begin{equation}\\begin{split} \n p_i &= MLP_1 ([M[P^{(i)}_{start}][d:]; M[P^{(i)}_{end}][:d] ])\\\\\n  s_i &= MLP_2 ([M[S^{(i)}_{start}][d:]; M[S^{(i)}_{end}][:d] ])\\\\\n  e_i &= MLP_3 ([M[E^{(i)}_{start}][d:]; M[E^{(i)}_{end}][:d] ])\\\\\n  q &= \\text{max-pooling}(Q)\n    \\end{split}\\end{equation}\n$$\n\n\n\n\n### 图推理模块\n\n获得层次图所需要的节点：\n\n- 段落节点：$P = \\{p_i\\}^{n_p}_{i=1} , n_p=4$   \n- 句子节点：$S = \\{s_i\\}^{n_s}_{i=1}, n_s=40$\n- 实体节点：$E = \\{e_i\\}^{n_e}_{i=1}, n_e=60$\n\n定义图的临界矩阵为$H =  \\{q,P,S,E\\} \\in \\text{R}^{g\\times d }  , g= n_p+n_s+n_e+1$\n\n 经过GAT后，得到更新过后的每个节点表示$P',S',E',q'$\n\n为了让图信息进一步提取上下文答案跨度，这里还用更新后的节点表示H‘和之前的上下文表示M，通过一个门控注意力机制，用于答案跨度的预测。\n\n具体表示为：\n$$\n\\begin{equation}\\begin{split} \n C &= Relu(MW_m) \\cdot Relu(H'W'_m)^T\\\\\n \\hat H &= Softmax(C)\\cdot H'\\\\\n G &= \\sigma([M;\\hat H]W_s) \\cdot Tanh([M;\\hat H]W_t)\n    \\end{split}\\end{equation}\n$$\n其中：$W_m \\in \\text{R}^{2d\\times 2d}$ ，$W’_m \\in \\text{R}^{2d\\times 2d}$ ，$W_s \\in \\text{R}^{4d\\times 4d}$ , $W_t\\in \\text{R}^{4d\\times 4d}$\n\n\n\n### 多任务预测模块\n\n- 基于段落节点的段落选择\n- 基于句子节点的支撑事实预测\n- 基于实体节点和上下文G表示的答案预测\n\n最终目标函数\n$$\n\\begin{equation}\\begin{split} \n \\text{L}_{joint} = \\text{L}_{start} +\\text{L}_{end} + \\lambda_1\\text{L}_{para} + \\lambda_2\\text{L}_{sent} + \\lambda_3\\text{L}_{entity} + \\lambda_4 \\text{L}_{type}\n    \\end{split}\\end{equation}\n$$\n其中$\\lambda_{1,2,3,4}$ 超参数权重\n\n$L_{type}$ 是预测答案类型的损失\n\n\n\n## 错误分析\n\n![](https://i.loli.net/2021/05/05/ephOUw7zXAcK3bH.png)\n\n作者在这分析了模型的弱点(为将来的工作提供了见解)，在dev集中随机抽样了100个答案f1为0的示例。\n\n作者总结了六类错误\n\n- Annotation批注：数据集中提供的批注不正确 \n\n  上图第一行：“Tonka”和“101只斑点狗”是在同一个十年上映的吗？数据集给的答案和实际情况不一样？这种应该是数据集错误吧， 这种错误占了9%。这种问题应该不是模型的弱点吧？\n\n- Multiple-Answers：问题可能有多个正确答案，但数据集中只提供一个答案\n\n  迈克尔·J·亨特取代了成为哪家机构管理员的律师？答案EPA是预测答案的缩写，这种问题也比较难解决，占了24%是比重最多的。\n\n- Discrete Reasoning:  这种类型的错误经常出现在“比较”题中，需要离散推理才能正确回答问题； 16%\n\n  在Mastodon和Hole这两个乐队中，哪个成员更多？ 可能是已知这两个乐队人数，要比较这两个数的大小\n\n- Commonsense & External Knowledge： 要回答这类问题，需要常识或外部知识\n\n  迷你专辑Code#01的艺人第二次延长演出的名字是什么？\n\n- Multi-hop：模型不能进行多跳推理，从错误的段落中找到最终答案 16%\n\n  这部根据5：15出现的摇滚歌剧改编的电影是谁导演的？\n\n- MRC:  模型正确地找到了支持段落和句子，但预测了错误的答案跨度。 20%\n\n  艾达·洛夫莱斯，第一位计算机程序员，在“恰尔德·拜伦”中与拜伦勋爵有什么关系？答案是他的女儿，模型回答成紧张的关系，说明模型没有完全理解问题中的关系。\n\n\n\n可以看出HGN对于阅读理解的进行鲁棒性的回答还是有所不足，面对相同答案的多样性还有进一步的改进空间。\n\n对于句子理解和推理定位还不够特别准确。\n\n\n\n\n\n\n\n\n\n","tags":["GNN&nlp"]},{"title":"二分模板","url":"/2021/04/29/二分模板/","content":"\n# 二分模板\n\nhttps://www.acwing.com/problem/content/791/\n\n二分的本质不是单调性, 单调性的题目一定可以二分, 可以二分的题目不一定有单调性\n\n二分的本质是边界\n二分法用于查找, 每次都选择答案所在的区间再次进行查找, 当区间长度为 1时, 就是答案\n\n![](https://i.loli.net/2021/04/29/Hy4vGqOtus8lQXp.png)\n\n1. 根据 check(mid)来判断 r和 l的取值范围\n2. 根据取值范围选择 mid是否有 + 1操作\n   - mid归于左边, r = mid, mid选择 不 +1\n   - mid归于右边, l = mid, mid选择 +1\n\n```java\nimport java.io.BufferedReader;\nimport java.io.IOException;\nimport java.io.InputStreamReader;\nimport java.util.Arrays;\n\npublic class 模板_二分 {\n\n    public static void main(String[] args) throws IOException {\n        BufferedReader input = new BufferedReader(new InputStreamReader(System.in));\n        int[] line1 = Arrays.asList(input.readLine().split(\" \")).stream().mapToInt(Integer::parseInt).toArray();\n        int n = line1[0];\n        int q = line1[1];\n        int[] line2 = Arrays.asList(input.readLine().split(\" \")).stream().mapToInt(Integer::parseInt).toArray();\n\n        while (q-- != 0) {\n            int target = Integer.parseInt(input.readLine());\n            // 查找左边界 用第一个模板\n            int index_l = bsearch_1(line2, 0, n - 1, target);\n            if (line2[index_l] != target) {\n                System.out.println(\"-1 -1\");\n            } else {\n                System.out.print(index_l + \" \");\n                // 查找右边界 用第二个模板\n                int index_r = bsearch_2(line2, 0, n - 1, target);\n                System.out.print(index_r + \"\\n\");\n            }\n        }\n    }\n\n    public static int bsearch_1(int[] arr, int l, int r, int target) {\n        while (l < r) {\n            int mid = l + r >> 1;\n            if (arr[mid] >= target) {\n                r = mid;\n            } else {\n                l = mid + 1;\n            }\n        }\n        return l;\n    }\n\n    public static int bsearch_2(int[] arr, int l, int r, int target) {\n        while (l < r) {\n            int mid = l + r + 1 >> 1;\n            if (arr[mid] <= target) {\n                l = mid;\n            } else {\n                r = mid - 1;\n            }\n        }\n        return l;\n    }\n\n}\n```\n\n","tags":["刷题"]},{"title":"归并排序模板","url":"/2021/04/28/归并排序模板/","content":"\n# 归并排序模板\n\n分治思想\n\n![](https://i.loli.net/2021/04/28/8g1qixHscOBTv6Q.png)\n\n1. 确定分界点：$mid = (l+r)/2$\n\n2. 先递归分成左右两边\n\n3. 将两个有序数组合并成一个有序序列——归并\n\n   使用两个指针：这个过程时间复杂度为$O(n)$\n\n![](https://i.loli.net/2021/04/28/d23pUiKgLOswDZm.png)\n\n整体时间复杂度$O(nlogn)$\n\n因为分层用了$logn$次\n\n![](https://i.loli.net/2021/04/28/WeSTDRHymJbg5KN.png)\n\n```java\nimport java.io.BufferedReader;\nimport java.io.IOException;\nimport java.io.InputStreamReader;\n\npublic class 模板_归并排序 {\n\n\n    public static void main(String[] args) throws IOException {\n        BufferedReader input = new BufferedReader(new InputStreamReader(System.in));\n        int n = Integer.parseInt(input.readLine());\n        int[] q = new int[n];\n        String[] linelist = input.readLine().split(\" \");\n        for (int i = 0; i < linelist.length; i++) {\n            q[i] = Integer.parseInt(linelist[i]);\n        }\n\n        merge_sort(q, 0, q.length - 1);\n\n        for (int i = 0; i < q.length; i++) {\n            System.out.print(q[i]);\n            System.out.print(\" \");\n        }\n\n    }\n\n\n    public static void merge_sort(int[] q, int l, int r) {\n        if (l >= r) return;\n        // 确定分界点\n        int mid = l + ((r - l) >> 1);\n        // 递归\n        merge_sort(q, l, mid);\n        merge_sort(q, mid + 1, r);\n\n        int[] tmp = new int[r - l + 1]; // 辅助数组\n        // 归并\n        int k = 0; // 表示tmp中有多少个数\n        // 两个指针\n        int i = l, j = mid + 1;\n        while (i <= mid && j <= r) {\n            if (q[i] <= q[j]) {\n                tmp[k++] = q[i++];\n            } else {\n                tmp[k++] = q[j++];\n            }\n        }\n        // 剩余\n        while (i <= mid) tmp[k++] = q[i++];\n        while (j <= r) tmp[k++] = q[j++];\n        // 放回\n        for (i = l, j = 0; i <= r; i++, j++) q[i] = tmp[j];\n    }\n}\n```","tags":["刷题"]},{"title":"Ubantu18.04安装NVIDIA驱动+cuda10.1+cuDNN+Tensorflow2.1.0","url":"/2021/04/26/Ubantu18-04安装NVIDIA驱动-cuda10-1-cuDNN-Tensorflow2-1-0/","content":"\n# Ubantu18-04安装NVIDIA驱动-cuda10-1-cuDNN-Tensorflow2-1-0\n\n注意：TensorFlow2.1 要求 你的GPU算力要达到3.5，检查自己GPU算力\n\n## 安装和卸载NVIDIA驱动\n\n首先要确保驱动已经卸载干净\n\n```\nsudo apt-get purge nvidia*\nsudo apt-get autoremove\n```\n\n检查自己GPU版本，之后到官网去下载，这种办法安装比较稳妥，其他网络安装办法有时候出错不知道咋回事。\n\n```\nlshw -numeric -C display\n```\n\n\n\n![](https://i.loli.net/2021/04/26/tDVckAHU8B7dnla.png)\n\n下载驱动网址：https://www.nvidia.cn/Download/index.aspx?lang=cn\n\n![](https://i.loli.net/2021/04/26/ruzlX3qQ6Ndat9I.png)\n\n禁用Nouveau\n\n```\nNouveau驱动禁用方法：\n\nsudo gedit /etc/modprobe.d/blacklist.conf\n或者\nsudo vim /etc/modprobe.d/blacklist.conf\n \n在最后两行添加：\n \nblacklist nouveau\noptions nouveau modeset=0     // 禁用nouveau第三方驱动，之后也不需要改回来\n \n执行\n \nsudo update -initramfs -u   // 更新内核\n```\n\n\n\n关闭lightdm\n\n\n\n```\nsudo service lightdm stop\n\n　sudo init 3 # 遇见X Server报错执行 \n\n rm -rf /tmp/.X*\n\n ./NVIDIA-Linux-x86_64-418.165.02.run #开始安装驱动 遇见continue就continue 遇见ok就ok\n```\n\n![](https://i.loli.net/2021/04/26/Wf7Imlx8PyKqtUG.png)\n\n## 安装cuda10.1\n\nhttps://tensorflow.google.cn/install/source#linux\n\n在这个网站上对好版本，版本不对可不行，全是坑 \n\nhttps://developer.nvidia.com/cuda-toolkit-archive 选择版本\n\n然后在这里下载cuda 我用的是deb的办法也是本地下载后安装的。**（我这个网络可能是不行，总是apt-get update 总是报错 所以这个方法没成功用runfile成功了。。。）参考一下吧** \n\n![](https://i.loli.net/2021/04/26/wVXLYjvD5zHTNRu.png)\n\n安装\n\n```\nsudo dpkg -i cuda-repo-ubuntu1804-10-0-local-10.0.130-410.48_1.0-1_amd64.deb\nsudo apt-key add /var/cuda-repo-<version>/7fa2af80.pub\nsudo dpkg -i cuda-repo-ubuntu1804-10-0-local-10.0.130-410.48_1.0-1_amd64.deb\nsudo apt-get update\nsudo apt-get install cuda\n```\n\n添加环境变量：\n\n打开 .bashrc\n\n sudo vim ~/.bashrc\n\n```\nexport CUDA_HOME=/usr/local/cuda \nexport PATH=$PATH:$CUDA_HOME/bin \nexport LD_LIBRARY_PATH=/usr/local/cuda-10.1/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}\n```\n\nsource ~/.bashrc\n\nnvcc -V\n\n\n\n## runfile安装cuda\n\n下载runfile\n\n![](https://i.loli.net/2021/04/26/7G8c26kofdjJQBh.png)\n\n![](https://i.loli.net/2021/04/26/LI4shCiMqcKaNQB.png)\n\n一定要取消掉driver 此处！！！，因为已经装了驱动了\n\n![](https://i.loli.net/2021/04/26/5CmNy6BrOIiDlkp.png)\n\n\n\n```python3\nsudo vim ~/.bashrc\n```\n\n\n\n我们在文件最后一行添加：\n\n```\n$ export PATH=/usr/local/cuda-10.1/bin:/usr/local/cuda-10.1/NsightCompute-2019.1${PATH:+:${PATH}}\n$ export LD_LIBRARY_PATH=/usr/local/cuda-10.1/lib64\\\n                         ${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}\n```\n\n\n\n```text\nsource ~/.bashrc\n```\n\n\n\n![](https://i.loli.net/2021/04/26/VDZRTx76oi8MeuK.png)\n\n\n\n## 安装TensorFlow2.1.0_gpu \n\n这上面虽然没写2.1.0_gpu 可是还得得装gpu版\n\n![](https://i.loli.net/2021/04/26/LNxBI3jmDrcGUVT.png)\n\n\n\n完成后 \n\nconda install cudatoolkit=10.1\n\n![](https://img2020.cnblogs.com/blog/1225390/202010/1225390-20201031135739329-731523260.png)\n\n\n\n## 安装cuDNN\n\nhttps://developer.nvidia.com/cudnn\n\n去下载对应版本，但是要登录一下\n\n解压后\n\n```\nsudo cp cuda/include/cudnn.h /usr/local/cuda/include\nsudo cp cuda/lib64/libcudnn* /usr/local/cuda/lib64\nsudo chmod a+r /usr/local/cuda/include/cudnn.h \nsudo chmod a+r /usr/local/cuda/lib64/libcudnn*\n```\n\n以配置cuDNN环境。\n\n通过\n\n```\ncat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2\n```\n\n\n\n查看cuDNN版本\n\nover\n\n\n\n\n\n\n\n","tags":["GPU"]},{"title":"快速排序模板","url":"/2021/04/26/快速排序模板/","content":"\n快速排序模板\n\n\n\n![](https://i.loli.net/2021/04/26/voAgqKV12i9Rxuz.png)\n\n1. 先确定分界点：$q[l] 、 q[(l+r)/2]、 q[r]$ 或随机\n2. 调整区间：小于等于x的在左半边，大于等于x的在右半边 (如何去调整)\n3. 递归处理左右两段\n\n## 由数据反推算法复杂度和算法内容\n\n![](https://i.loli.net/2021/05/14/i9EQsUqAYdW1rcB.png)\n\n\n\n## 实现\n\n\n\n暴力：\n\n- 声明两个数组 a[] 、b[]\n- 将$q[l~r]$ 遍历 \n- 如果 $q[i] \\le x$ 放到a[]中   \n- 如果 $q[i] \\ge x$ 放到b[]中   \n- 再将a、b数组放回q中\n\n优美：\n\n用两个指针，swap\n\n\n\n[关于JAVA中IO流类：BufferredReader的简单用法](https://blog.csdn.net/qq_42369555/article/details/82745923)\n\nbufferreader要比scanner快\n\n```java\npackage code;\n\nimport java.io.BufferedReader;\nimport java.io.IOException;\nimport java.io.InputStreamReader;\nimport java.util.Collections;\n\npublic class 快排模板 {\n\n    public static void main(String[] args) throws IOException {\n        BufferedReader input = new BufferedReader(new InputStreamReader(System.in));\n        int n = Integer.parseInt(input.readLine());\n        int[] q = new int[n];\n        String[] linelist = input.readLine().split(\" \");\n        for (int i = 0; i < linelist.length; i++) {\n            q[i] = Integer.parseInt(linelist[i]);\n        }\n\n        quick_sort(q, 0, q.length - 1);\n\n        for (int i = 0; i < q.length; i++) {\n            System.out.print(q[i]);\n            System.out.print(\" \");\n        }\n\n    }\n\n    public static void quick_sort(int[] q, int l, int r) {\n        if (l >= r) return;\n        int x = q[l];\n        int i = l - 1;\n        int j = r + 1;\n        while (i < j) {\n            do i++; while (q[i] < x);\n            do j--; while (q[j] > x);\n            if (i < j) {\n                int t = q[i];\n                q[i] = q[j];\n                q[j] = t;\n            }\n        }\n        quick_sort(q, l, j);\n        quick_sort(q, j + 1, r);\n    }\n\n\n}\n\n```\n\n\n\n\n\n\n\n","tags":["刷题"]},{"title":"DP分析——石子合并","url":"/2021/04/24/DP分析——石子合并/","content":"\n# DP分析——石子合并\n\n设有 NN 堆石子排成一排，其编号为 1，2，3，…，N。\n\n每堆石子有一定的质量，可以用一个整数来描述，现在要将这 N 堆石子合并成为一堆。\n\n每次只能合并相邻的两堆，合并的代价为这两堆石子的质量之和，合并后与这两堆石子相邻的石子将和新堆相邻，合并时由于选择的顺序不同，合并的总代价也不相同。\n\n例如有 4 堆石子分别为 `1 3 5 2`， 我们可以先合并 1、2堆，代价为 4，得到 `4 5 2`， 又合并 1，2 堆，代价为 9，得到 `9 2` ，再合并得到 11，总代价为 4+9+11=244+9+11=24；\n\n如果第二步是先合并 2，3 堆，则代价为 7，得到 `4 7`，最后一次合并代价为 11，总代价为 4+7+11=22。\n\n问题是：找出一种合理的方法，使总的代价最小，输出最小代价。\n\n#### 输入格式\n\n第一行一个数 N 表示石子的堆数 N。\n\n第二行 N 个数，表示每堆石子的质量(均不超过 1000)。\n\n#### 输出格式\n\n输出一个整数，表示最小代价。\n\n#### 数据范围\n\n1≤N≤300     1≤N≤300\n\n#### 输入样例：\n\n```\n4\n1 3 5 2\n```\n\n#### 输出样例：\n\n```\n22\n```\n\n## 解\n\n![](https://i.loli.net/2021/04/24/CqE9QcaxYBzZKRw.png)\n\n![](https://i.loli.net/2021/04/24/gPlOsK5oXFcWutE.png)\n\n\n\n```java\npublic class DP_石子合并 {\n\n    public static void main(String[] args) {\n        Scanner scanner = new Scanner(System.in);\n        int N = scanner.nextInt();\n        int[] s = new int[N + 1];  //前缀和\n        for (int i = 1; i <= N; i++) {\n            s[i] = scanner.nextInt();\n            s[i] += s[i - 1];\n        }\n        int[][] dp = new int[N + 1][N + 1];\n\n        for (int len = 2; len <= N; len++) {//先枚举区间长度\n            for (int i = 1; i + len - 1 <= N; i++) {//再枚举区间左端点\n                int j = i + len - 1; //右端点\n                dp[i][j] = 100000000;\n                for (int k = i; k < j; k++) {\n                    dp[i][j] = Math.min(dp[i][j], dp[i][k] + dp[k + 1][j] + s[j] - s[i - 1]);\n                }\n            }\n        }\n        System.out.println(dp[1][N]);\n    }\n}\n```\n\n$O(n^3)$ \n\n---\n\n# 最长公共子序列\n\n给定两个长度分别为 N 和 M 的字符串 A 和 B，求既是 A 的子序列又是 B 的子序列的字符串长度最长是多少。\n\n#### 输入格式\n\n第一行包含两个整数 N 和 M。\n\n第二行包含一个长度为 N 的字符串，表示字符串 A。\n\n第三行包含一个长度为 M 的字符串，表示字符串 B。\n\n字符串均由小写字母构成。\n\n#### 输出格式\n\n输出一个整数，表示最大长度。\n\n#### 数据范围\n\n1≤N,M≤1000       1≤N,M≤1000\n\n#### 输入样例：\n\n```\n4 5\nacbd\nabedc\n```\n\n#### 输出样例：\n\n```\n3\n```\n\n\n\n## 解\n\n最坏情况下 aaaa,aaaaa，A中所有都是由 $2^n$ 个不同子序列。\n\n![](https://i.loli.net/2021/04/24/oxH4yliYPD23LeQ.png)\n\n![](https://i.loli.net/2021/04/24/dVY9UmoHTticMPC.png)\n\n\n\n```java\npublic static void main(String[] args) {\n        Scanner scanner = new Scanner(System.in);\n        int N = scanner.nextInt();\n        int M = scanner.nextInt();\n        String strA = \" \" + scanner.next();\n        String strB = \" \" + scanner.next();\n//        char[] A = strA.toCharArray();\n//        char[] B = strB.toCharArray();\n\n        int[][] dp = new int[N + 1][M + 1];\n\n        for (int i = 1; i <= N; i++) {\n            for (int j = 1; j <= M; j++) {\n                dp[i][j] = Math.max(dp[i - 1][j], dp[i][j - 1]);\n                if (strA.charAt(i) == strB.charAt(j)) {\n                    dp[i][j] = Math.max(dp[i][j], dp[i - 1][j - 1] + 1);\n                }\n            }\n        }\n        System.out.println(dp[N][M]);\n    }\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["刷题"]},{"title":"Select, Answer and Explain-Interpretable Multi-hop Reading Comprehension over Multiple Documents","url":"/2021/04/22/Select-Answer-and-Explain-Interpretable-Multi-hop-Reading-Comprehension-over-Multiple-Documents/","content":"\n# Select, Answer and Explain: Interpretable Multi-hop Reading Comprehension over Multiple Documents\n\n\n\n## 摘要\n\n选择、回答和解释(SAE)系统解决多文档RC问题。\n\n首先主要创新，用文档分类器过滤掉与答案无关的文档，从而减少分散注意力的信息量。\n\n然后将所选择的答案相关文档输入到模型以联合预测答案和支持句子。\n\n该模型在答案预测的表征层和支持句子预测的句子层都设置了多任务学习目标，\n\n并在这两个任务之间进行了基于注意力的交互，对模型进行了优化。\n\n关键词：过滤无关文档、多任务学习、混合注意力交互\n\n![](https://i.loli.net/2021/04/22/yArGlY6zuT7eMsW.png)\n\n## 在HotpotQA中什么是gold doc\n\nHotpotQA通过为答案提供支持句来鼓励可解释的QA模型，这些支持句通常来自多个文档，如果文档包含答案或包含对答案的支持句，则称为“黄金文档”。\n\n\n\n应答文本，它可以是一段文本或“是/否”。\n\n作者从答案和支持句标签导出GOLD文档标签。我们使用 $D_i$ 表示文档 i：如果Di是黄金文档，则标记为1，否则标记为0。还将答案类型标记为以下注释之一：“Span”、“Yes”和“No”。\n\n\n\n\n\n ## 选择gold doc(过滤文档)\n\n答案预测和支持句预测的上游任务。将分类排名最靠前的文档作为预测的黄金文档 gold doc。\n\n![](https://i.loli.net/2021/04/22/EapiyjuwNbPt49l.png)\n\n做文档过滤最直接做法就是采用bert的CLS摘要向量，做交叉熵分类\n$$\n\\begin{equation}\\begin{split} \n L = -\\sum_{i=0}^n t_ilogP(D_i) + (1-t_i) log(1-P(D_i))\n    \\end{split}\\end{equation}\n$$\n$t_i$ 是 $D_i$ 的标签，n是文档数，$P(D_i)$ 是文档i在标签 $t_i$ 中的概率。\n\n这种简单的方法的缺点：单独处理每个文档，而不考虑下游多跳推理任务所必需的文档间交互和关系。\n\n为解决此问题，作者提出了一个新的模型，如图上图CLS后，加了一层多头注意力层。\n\n意在：增加对从不同文档生成的“CLS”标记的关注的动机是鼓励文档间的交互。文档间交互对于文档间的多跳推理至关重要。\n\n优化：采用了新的成对学习排序损失。还将问题从分类问题描述为两两学习排序问题，\n\n通过将文档与所有其他文档进行比较，该模型能够更好地将一小部分黄金文档与睡觉分散注意力的文档区分开来。\n\n给每个文档一共分数 $S(.)$\n\n如果 $D_i$ 是gold doc $S(D_i) = 1 $, 否则 $S(D_i) = 0$\n\n然后，标记每对输入文档：给定一对输入文档 $(D_i，D_j)$，标签 $l$设置为：\n$$\n\\begin{equation}\\begin{split} \n l_{i,j} = \n\\begin{cases}\n 1, &if\\ S(D_i) \\gt S(D_j) \\\\\n 0 , &if\\  S(D_i) \\le S(D_j)\n\\end{cases}\n    \\end{split}\\end{equation}\n$$\n还认为包含答案范围的文档对于下游任务更重要。因此，如果$D_i$是包含答案跨度的黄金文献，$S(D_i)=2$。\n\n再将MHSA输出传递给双线性层来输出每对文档的概率，双线性层基于二元交叉熵进行训练，如下所示：\n$$\n\\begin{equation}\\begin{split} \n L = - \\sum_{i=0,j=0}^n \\sum_{j\\neq i} l_{i,j} logP(D_i,D_j) + (1-l_{i,j}) log(1-P(D_i,D_j))\n    \\end{split}\\end{equation}\n$$\n相关性定义为$ R_i=􏰅\\sum_j^n(P(D_i，D_j)>0.5)$。将来自该相关性排序的前k个排序的文档作为的过滤文档。\n\n\n\n\n\n## 答案和解释\n\n模型采用多任务学习的方式进行训练，以联合预测答案和对黄金文档的支持意义。\n\n基于GNN构建多跳推理图，将上下文语句嵌入作为节点，而不是像以往的工作那样以实体作为节点，直接输出带有答案预测的支持语句。\n\n为什么不用NER因为作者认为：\n\n目前GNN在QA任务中的应用通常需要实体作为图形节点，并且通过在具有上下文信息的节点上进行消息传递来实现推理。这仅在预定义的一组目标实体可用时才有可能。否则，需要使用命名实体识别(NER)工具来提取实体，这可能会导致图推理中的冗余实体和噪声实体。如果答案不是命名实体，则需要进一步处理以定位最终答案。\n\n token-level and sentence-level 多任务学习\n\n\n\n基于一种新的混合注意池机制\n\n将GNN中使用的上下文语句嵌入归结到令牌表示上。注意力权重是根据令牌表示上的答案广度日志和自我注意输出来计算的。这种基于注意力的交互能够利用“回答”和“解释”任务之间的互补信息。\n\n\n\n### 答案预测\n\n针对bert输出的每一个$H_i$ 用两层MLP做答案起始位置预测 $L$ 为长度\n$$\n\\begin{equation}\\begin{split} \n \\hat Y &= f_{span} (H^i) \\in R^{L\\times2}\\\\\n L ^{span} &= \\frac{1}{2}(CE(\\hat Y[:,0], y^{start}) + CE(\\hat Y[:,1], y^{end}))\n    \\end{split}\\end{equation}\n$$\n其中$\\hat Y$的第一行是起始位置的逻辑，第二行是结束位置的逻辑。$y^{star}t$和 $y^{end}$ 是范围 [0，L-1] 中的开始位置和结束位置的标签。CE表示交叉熵损失函数。\n\n\n\n### 支持句预测\n\n预测输入上下文中的句子是否为答案预测的支持证据。为了实现句子级预测，我们首先获得$H_i$中每个句子的序列表示。$H_i$ 是bert的token输出。\n$$\n\\begin{equation}\\begin{split} \n S^j - H[j^s:j^e,:] \\in R^{L^j\\times d}\n    \\end{split}\\end{equation}\n$$\n$S^j$是表示语句 j 内的标记嵌入的矩阵( 这里省略了样本索引i)。 $j^s$ 和 $j^e$ 定义了开始和结束位置，$L_j$ 是语句$j$ 的长度。\n\n\n\n### 多任务\n\n答案预测任务和支持句预测任务可以相辅相成。\n\n据观察，答案预测任务总是可以帮助支持句子预测任务，因为有答案的句子总是一条证据；\n\n但反过来情况不是一样的，因为可能有多个支持句子，概率最高的句子可能不包含答案\n\n所以答案预测任务总 可以帮助支持句子预测任务，因为有答案的句子总是一个证据；\n\n反之亦然，因为可能有多个支持句子，概率最高的句子可能不包含答案。\n\n因此，为了揭示这两个互补任务之间的相互作用，提出了一种基于注意力的总结句子表示法，以引入来自回答预测的互补信息。\n\n注意力权重的计算方法如下：在Sj上用自我注意计算一部分注意力，另一部分来自答案预测任务的起始位置日志和结束位置日志的总和。\n$$\n\\begin{equation}\\begin{split} \n \\alpha^j &= \\sigma(f_{att}(S^j) + \\hat Y[j^s:j^e,0] + \\hat Y[j^s:j^e,1])\\\\\n s^j &= \\sum^{L^j}_{k=0} \\alpha^j_k S^j[k,:] \\in R^{1\\times d}\n    \\end{split}\\end{equation}\n$$\nSj是表示语句j 的标记嵌入的矩阵\n\n$f_{att}$ 是一个两层MLP输出size为1，$\\sigma$是softmax\n\n$α_j ∈ R^{L^j×1}$表示句子j的每个token上的关注度权重。\n\n### 构建GNN\n\n接下来，在语句嵌入Sj上建立GNN模型，以显式地促进对预测gold doc中所有语句的多跳推理，从而更好地利用复杂的关系信息。使用语句嵌入Sj来初始化图的节点特征。采用基于多关系图卷积网络(GCN)的消息传递策略来更新图的节点特征，并将最终的节点特征输入到MLP中，得到每个句子的分类。\n\n![](https://i.loli.net/2021/04/22/kfrJdNaDZBqyAhV.png)\n\n根据问题和句子中出现的命名实体和名词短语设计了三种类型的边：\n\n- 如果两个节点最初来自同一文档，则在这两个节点之间添加一条边(上图中的实节点)\n- 如果表示两个节点的句子在问题中都具有命名实体或名词短语(可以是不同的)，则在来自不同文档的两个节点之间添加边。(图中的虚线)\n- 如果表示两个节点的句子具有相同的命名实体或名词短语，则在来自不同文档的两个节点之间添加一条边。(图中的虚线)\n\n第一种类型的边的动机是希望GNN掌握每个文档中呈现的全局信息。\n\n第二类和第三类边，为了以更好地捕捉这种跨文档推理路径。跨文档推理是通过从问题中的实体跳到未知的桥梁实体或比较问题中两个实体的属性来实现的 。\n\n\n\n对于消息传递，使用具有门控机制的多关系GCN。\n\n假设 $h^0_j$ 表示从语句嵌入 $S_j$的初始节点嵌入，则一跳(或一层)之后的节点嵌入计算可表示为:\n$$\n\\begin{equation}\\begin{split} \n h_j^{k+1} &= act(u_j^k) \\odot g^k_j + h^k_j \\odot (1-g^k_j) \\\\\n u^k_j &= f_s(h^k_j) + \\sum_{r\\in R} \\frac{1}{|N_j^r|} \\sum_{n\\in N^r_j} f_r(h_n^k)\\\\\n g_j^k &= sigmoid (f_g([u_j^k; h^k_j])) \n    \\end{split}\\end{equation}\n$$\n\n\n其中R 是一些列边类型， $N^r_j$ 是边类型为r的 j 节点的邻居。\n\n$h^k_n$ 是节点n的第k层节点表示。\n\n$f_r、f_s、f_g$中的每一个都定义了输入节点表示上的变换，并且可以使用MLP来实现。\n\n门控$g_j^k$ 是由0和1之间的值组成的向量，用于控制来自计算的更新$u^k_j$ 或来自原始节点表示的信息。\n\n函数$act$表示非线性激活函数。\n\n最后得到每个节点的最终表示 $h_j$ 后用两层MLP 最终预测 。\n\n$\\hat y^{sp}_j = sigmoid(f_{sp}(h_j))$ \n\n\n\n除了支持句子预测任务之外，还在GNN输出之上添加了另一个任务，以说明“Yes/No”类型的问题。\n\n预测任务描述为3类(“Yes”、“No”和“span”)分类\n\n引入：\n\n$h = \\sum_j a_jh_j$\n\n$a = \\sigma(\\hat y^{sp})$\n\n$\\hat y^{ans} = f_{ans}(h)$\n\n最终loss表达为：\n$$\n\\begin{equation}\\begin{split} \n L = \\gamma L^{span} + BCE(\\hat y^{sp}, y^{sp}) + CE(\\hat y^{ans}, y^{ans})\n    \\end{split}\\end{equation}\n$$\n$BCE()$ 二元交叉熵函数\n\n为了考虑不同损失的尺度差异，在跨度损失中加入了一个权重γ。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["GNN&nlp"]},{"title":"DP分析法--01背包问题","url":"/2021/04/20/DP分析法——01背包问题/","content":"\n# DP分析法--01背包问题\n\n从集合角度来分析DP问题，DP问题的题目一般都是从有限集中求得最值的问题。\n\n![](https://i.loli.net/2021/04/20/SlgJ96RzdyGp5fw.png)\n\n[01背包问题](https://www.acwing.com/problem/content/2/)\n\n有 N 件物品和一个容量是 V 的背包。每件物品只能使用一次。\n\n第 i 件物品的体积是 $v_i$，价值是 $w_i$。\n\n求解将哪些物品装入背包，可使这些物品的总体积不超过背包容量，且总价值最大。\n输出最大价值。\n\n#### 输入格式\n\n第一行两个整数，N，V，用空格隔开，分别表示物品数量和背包容积。\n\n接下来有 N 行，每行两个整数 $v_i,w_i$，用空格隔开，分别表示第 i 件物品的体积和价值。\n\n#### 输出格式\n\n输出一个整数，表示最大价值。\n\n#### 数据范围\n\n0<N,V≤10000<N,V≤1000\n0<vi,wi≤10000<vi,wi≤1000\n\n#### 输入样例\n\n```\n4 5\n1 2\n2 4\n3 4\n4 5\n```\n\n#### 输出样例：\n\n```\n8\n```\n\n\n\n\n\n## 解\n\n最多$2^N$, 从$2^N$ 个方案里找总价值最大的方案。——有限集合的最值问题\n\n状态表示：\n\n- 选择问题一般$f(i,j)$ 第一维表示前i个物品,第二维是限制 (经验)\n\n- 集合：所有只考虑前i个物品，且总体积不超过j的选法的集合。\n- 属性：集合中每一个方案的最大价值Max\n\n状态计算：\n\n- 所有不选第i个物品的方案 $f(i-1,j)$\n- 所有选择第i个物品的方案 $f(i-1,j-v_i) + w_i$\n- $Max(f(i-1,j), f(i-1,j-v_i)+w_i)$\n\n```java\nimport java.util.Scanner;\n\npublic class Main{\n    public static void main(String[] args) throws Exception {\n        // 读入数据的代码\n        Scanner reader = new Scanner(System.in);\n        // 物品的数量为N\n        int N = reader.nextInt();\n        // 背包的容量为V\n        int V = reader.nextInt();\n        // 一个长度为N的数组，第i个元素表示第i个物品的体积；\n        int[] v = new int[N + 1] ;\n        // 一个长度为N的数组，第i个元素表示第i个物品的价值；\n        int[] w = new int[N + 1] ;\n\n        for (int i=1 ; i <= N ; i++){\n            // 接下来有 N 行，每行有两个整数:v[i],w[i]，用空格隔开，分别表示第i件物品的体积和价值\n            v[i] = reader.nextInt();\n            w[i] = reader.nextInt();\n        }\n        reader.close() ;\n\n        // 正式工作的代码\n        /*\n        定义一个二阶矩阵dp[N+1][V+1],\n        这里之所以要N+1和V+1，是因为第0行表示只能选择第0个物品的时候，即没有物品的时候\n        第0列表示背包的体积为0的时候，即不能装任何东西的时候\n\n        dp[i][j]表示在 只能选择前i个物品，背包容量为j的情况下，背包中物品的最大价值\n        对于dp[i][j]有两种情况：\n        1. 不选择当前的第i件物品/第i件物品比背包容量要大，则dp[i][j] = dp[i-1][j]\n        2. 选择当前的第i件物品（潜在要求第i件物品体积小于等于背包总容量），则能装入的物品最大价值为：\n            当前物品的价值 加上 背包剩余容量在只能选前i-1件物品的情况下的最大价值\n            dp[i][j] = dp[i-1][j-v[i]] + w[i]\n        dp[i][j]在两种情况中选择比较大的情况作为当前的最优解；\n        即：\n        if(j >= v[i]):\n            dp[i][j] = max(dp[i-1][j], dp[i-1][j-v[i]] + w[i])\n        else:\n            dp[i][j] = dp[i-1][j]\n        */\n        int[][] dp = new int[N+1][V+1];\n        dp[0][0] = 0;\n        for(int i = 1; i <= N; i++){\n            for(int j = 0; j <= V; j++){\n                if(j >= v[i]){\n                    dp[i][j] = Math.max(dp[i-1][j], dp[i-1][j-v[i]] + w[i]);\n                }else{\n                    dp[i][j] = dp[i-1][j];\n                }\n            }\n        }\n        System.out.println(dp[N][V]);\n    }\n}\n\n\n```\n\n优化后\n\n```java\nimport java.util.Scanner;\n\npublic class Main{\n    public static void main(String[] args) throws Exception {\n        // 读入数据的代码\n        Scanner reader = new Scanner(System.in);\n        // 物品的数量为N\n        int N = reader.nextInt();\n        // 背包的容量为V\n        int V = reader.nextInt();\n        // 一个长度为N的数组，第i个元素表示第i个物品的体积；\n        int[] v = new int[N + 1] ;\n        // 一个长度为N的数组，第i个元素表示第i个物品的价值；\n        int[] w = new int[N + 1] ;\n\n        for (int i=1 ; i <= N ; i++){\n            // 接下来有 N 行，每行有两个整数:v[i],w[i]，用空格隔开，分别表示第i件物品的体积和价值\n            v[i] = reader.nextInt();\n            w[i] = reader.nextInt();\n        }\n        reader.close() ;\n\n        // 正式算法的代码\n        // 将dp优化为一维数组\n        /*\n        注意，这里第二层循环的时候，还是小到大循环的话，那么\n\n        dp[i][j] = Math.max(dp[i-1][j], dp[i-1][j-v[i]] + w[i])\n        实际上变成了\n        dp[i][j] = Math.max(dp[i][j], dp[i][j-v[i]] + w[i]);\n\n        因为i-1的值已经在前面被更新过了，覆盖了\n        为了避免这个问题，所以要逆序更新，即先更新第i个，然后更新第i-1个，从而保证第i-1个不被覆盖\n\n        如果不逆序的话，输出结果为10，dp数组实际为：\n        0 0 0 0 0 0 \n        0 2 4 6 8 10\n        0 2 4 6 8 10\n        0 2 4 6 8 10\n        0 2 4 6 8 10\n        */\n        int[] dp = new int[V+1];\n        dp[0] = 0;\n        for(int i = 1; i <= N; i++){\n            for(int j = V; j >= v[i]; j--){\n                dp[j] = Math.max(dp[j], dp[j-v[i]] + w[i]);\n            }\n            // for(int j = 0; j <= V; j++){\n            //     System.out.print(dp[j]);\n            //     System.out.print(\" \");\n            // }\n            // System.out.print(\"\\n\");\n        }\n        System.out.println(dp[V]);\n    }\n}\n\n```\n\n\n\n\n\n\n\n```java\n    public static int o1bagSolutionOptimization(int[] weight, int[] value, int bagWeight) {\n        int num = weight.length;\n        int[] dp = new int[bagWeight + 1];\n        dp[0] = 0;\n        for (int i = 1; i <= num; i++) {\n            for (int j = bagWeight; j >= 1; j--) {\n                if (j >= weight[i - 1]) {\n                    dp[j] = Math.max(dp[j], dp[j - weight[i - 1]] + value[i - 1]);\n                }\n            }\n        }\n\n\n        return dp[bagWeight];\n    }\n    public static void main(String[] args) {\n        Scanner sc = new Scanner(System.in);\n        int itemsNumber = sc.nextInt();\n        int bagWeight = sc.nextInt();\n        int[][] arr = new int[itemsNumber][2];\n        int[] weight = new int[itemsNumber];\n        int[] value = new int[itemsNumber];\n        for(int i = 0; i < itemsNumber; i++) {\n            for(int j = 0; j < 2; j++) {\n                arr[i][j] = sc.nextInt();\n            }\n            weight[i] = arr[i][0];\n            value[i]=   arr[i][1];\n        }\n        System.out.println(o1bagSolutionOptimization(weight, value, bagWeight));\n    }\n\n\n```\n\n\n\n## 完全背包问题\n\n```java\npublic class 完全背包问题 {\n    // 完全背包和01背包的区别是完全背包中每个物品可以用无限次\n// 01背包：f[i][j] = max(f[i-1][j], f[i-1][j-v]+w)\n// 完全背包：f[i][j] = max(f[i-1][j], f[i][j-v]+w)\n    public static void main(String[] args) throws Exception {\n        Scanner reader = new Scanner(System.in);\n        int N = reader.nextInt();\n        int V = reader.nextInt();\n        int[] v = new int[N + 1];\n        int[] w = new int[N + 1];\n\n        for (int i = 1; i <= N; i++) {\n            v[i] = reader.nextInt();\n            w[i] = reader.nextInt();\n        }\n        reader.close();\n\n        int[] dp = new int[V + 1];\n        dp[0] = 0;\n        for (int i = 1; i <= N; i++) {\n            for (int j = 0; j <= V; j++) {\n                if (j >= v[i]) {\n                    dp[j] = Math.max(dp[j], dp[j - v[i]] + w[i]);\n                }\n            }\n        }\n        System.out.println(dp[V]);\n    }\n\n    // int nativeDp(int n,int m){\n    //     int[] f = new int[maxN];\n    //     for(int i=1;i<=n;i++){\n    //         for(int j=m;j>=v[i];j--){\n    //             for(int k=0;k*v[i]<=j;k++){\n    //                 f[j] = Math.max(f[j], f[j-k*v[i]]+k*w[i]);\n    //             }\n    //         }\n    //     }\n    // }\n}\n```\n\n\n\n\n\n","tags":["刷题"]},{"title":"LongFormer:The Long-Document Transformer","url":"/2021/04/18/LongFormer-The-Long-Document-Transformer/","content":"\n# LongFormer:The Long-Document Transformer\n\n主要记录一些Longfromer的原理和使用时的细节。\n\n## 摘要\n\n针对的问题：\n\n- 基于Transformer的模型，由于self-attention的操作，导致不能处理很长的序列。\n- self-attention的处理规模和序列长度是成二次关系的。\n\n![](https://i.loli.net/2021/04/18/3YtkrO18p2dAvmV.png)\n\n因为self-attention对于每个token都要计算打分，也就是缩放点积中的$QK^T$ 矩阵运算。\n\n这相当于对每个token之间都照顾到了注意信息。\n\n每个token代表一个小格，自注意力机制的QK都是自己，所以是个正方形。\n\n为解决这个问题，作者引入了三种具有随序列长度线性缩放的注意机制，将规模缩减成线性。\n\n分别是局部窗口注意和任务激活的全局注意力。\n\n并且还提供了LongFormer的预训练模型。\n\n定义了生成结构为Long-Forward-Encoding-Decoder(LED) \n\n\n\n\n\n## 引入&相关工作\n\n熟知的Bert等预训练模型，最大长度为512，多的就要截断，这样可能会潜在地导致重要的跨分区信息丢失问题。\n\n然而当时已有的针对解决长文本的方法，都是基于自回归语言模型的。\n\n而LongFormer是可以应用于迁移学习环境中的文档级NLP任务的。\n\n![](https://i.loli.net/2021/04/18/KNJa3dZx6fCG8eH.png)\n\n之后可能会读几篇。ltr从左到右的模型，其受益于双向语境(自回归或从左到右的语言建模被粗略地定义为在给定输入序列中的先前符号/字符的情况下估计现有符号/字符的概率分布)。\n\nspare代表模型通过稀疏性来进行优化。\n\nGenerating long se-quences with sparse transformers.其使用由BlockSparse提供的大小为8x8的块的扩展滑动窗口的形式，但没有探索预训练设置。等等\n\n\n\n## LongFormer\n\n原始Transformer的自注意力机制有$O(n^2)$ 的时间和空间内存复杂度。\n\n为了解决这个问题，作者根据指定相互关注的输入位置对的“注意模式”来稀疏完整的自我注意矩阵\n\n与full self-attention不同的是，提出的注意力模式与输入序列成线性关系，这使得它对较长的序列是有效的。\n\n### 注意力模式\n\n#### 滑动窗口 (Sliding Window)\n\n设固定窗口大小为 w，transformer层数为$l$, token的每边 $\\frac{1}{2}w$  计算复杂度为$O(n\\times w)$\n\n![](https://i.loli.net/2021/04/18/XaDokntURBWdNSe.png)\n\n作者认为：根据应用程序的不同，为每个图层使用不同的w值可能有助于在效率和模型表达能力之间取得平衡。\n\n\n\n#### 空洞滑窗(Dilated Sliding Window)\n\n类似于CNN的空洞卷积\n\n空洞尺寸 $d$ 感受野是 $l\\times d\\times w$\n\n![](https://i.loli.net/2021/04/18/SxDhujGwCVIvt2g.png)\n\n在多头注意力中，每个注意力头部计算不同的注意力分数。\n\n作者发现，每个头具有不同扩张配置设置的话效果会好：\n\n允许一些没有空洞的头部专注于局部语境，而另一些带空洞的则专注于更长的语境，从而提高了性能。\n\n\n\n#### 全局注意力(Global Attention)\n\n![](https://i.loli.net/2021/04/18/tVGNpUa3o9gIluf.png)\n\n例如对于QA，问题和文档连接在一起，允许模型通过自我关注将问题与文档进行比较。\n\n有时需要使用特殊的全局CLS作为整体的表达，所以就需要再这某些个关键点地方计算全局注意力，关注每一个token。其他的还是滑窗的形式。\n\n我们在几个预先选择的输入位置添加了“全局关注”。\n\n由于这样的记号token的数量相对于n很小，并且与n无关，因此组合的局部和全局注意的复杂度仍然是O(N)。\n\n这时，计算打分函数就可以分为两组QKV，分别是全局的$Q_g,K_g,V_g$ 和 滑窗局部的 $Q_s,K_s,V_s$\n\n昂贵的运算是矩阵乘法 $QK^T$，因为Q和K都具有n(序列长度)投影。对于LongFormer，空洞滑动窗口注意只计算固定数量$QK^T$的对角线。\n\n在实现的时候主要用到了带状乘法。还定制了特别的CUDA内核。。\n\n\n\n### 对于自回归的语言模型\n\n可以使用空洞滑动窗口注意力，并且可以跨层使用不同尺寸的窗口，效果可能更佳。\n\n对较低层使用较小的窗口大小，并在移动到较高层时增加窗口大小\n\n这允许顶层了解整个序列的较高级别表示，同时使较低层捕获本地信息。此外，它还在效率和性能之间取得平衡。\n\n(窗口大小越小，非零值越少，计算开销越小)\n\n(窗口大小越大，表示能力更丰富，通常会带来性能提升)\n\n\n\n## 实验\n\n和训练长文本的模型进行对比 ，BPC值越小越好\n\n![](https://i.loli.net/2021/04/18/Oxo2A1SCsaIeDL8.png)\n\n\n\n## 在QA上的Finetuning\n\n分别采用了我比较关注的多文档数据集 WikiHop/HotpotQA(干扰榜)/TriviaQA\n\n将问题和文档连接成一个长序列放入Longformer，最后加一个预测层。\n\n![](https://i.loli.net/2021/04/18/lqTB5cSPrD8Z3w7.png)\n\n### WikiHop\n\n数据特点：\n\n- 候选答案个数由2个到79个不等。\n\n- 文章段落数量由3段到63段不等\n\n数据集不为多跳推理链提供任何中间注释，需要模型代之以从间接答案监督中推断它们。\n\n数据预处理：\n\n将问题和答案与特殊令牌连接在一起\n\n$ [q] question [/q] [ent] candidate1 [/ent] ... [ent] candidateN [/ent] $\n\n上下文也是使用文档分隔符进行间隔\n\n$</s> context1 </s> ... </s> contextM </s>$\n\n在准备好输入数据后，从每个模型的顶层开始计算活动。获取问题和答案候选并将它们连接到尽可能多的上下文直到模型序列长度(Roberta为512，LongFormer为4,096)，在模型中运行序列，收集输出激活，并重复，直到用尽所有上下文(除了LongFormor-Large之外的所有模型，由于存储器要求，我们只包括第一个4,096长度的序列)。然后，将所有块的所有激活连接成一个长序列。在Longformer的下，使用全局注意力来关注整个问答候选序列。\n\n最终预测，对每个[ent] 附加一个线性层，输出一个logit，最后平均所有候选答案的logits。 用softmax和交叉熵得出最终答案。\n\n优化策略：\n\nAdam、Linear warmup超过200梯度更新对于最大LR，然后linear decay剩余训练。\n\n使用梯度累积最终batch达到32\n\n其他超参Dropout weight decay 都和Roberta相同。\n\n对LR[2e-5，3e-5，5e-5]和epoch[5，10，15]进行网格搜索。\n\nLR=3e-5，15个epoch是最好的Longform-Base配置。\n\n\n\n### TriviaQA\n\nTriviaQA有超过10万个问题、答案、文档。\n\n文档是维基百科文章，答案是文章中提到的命名实体。\n\n回答问题的跨度没有注释，但可以使用简单的文本匹配找到它。\n\n数据预处理：\n\n$[s] question [/s]document [/s]$\n\n在所有问题符号上都使用全局注意力。\n\n\n\n## HotpotQA\n\n使用两阶段首先确定相关段落，然后确定最终答案范围和证据。\n\n这主要是因为首先删除分散注意力的段落，可以降低最终认识和范围检测的噪声，这一点也被发现非常重要此数据集中最新的最新方法。\n\n数据预处理：\n\n$[CLS] [q] question [/q] ⟨t⟩ title1 ⟨/t⟩ sent1,1 [s] sent1,2 [s] ...⟨t⟩ title2 ⟨/t⟩ sent2,1 [s] sent2,2 [s] ...$\n\n使用全局注意力来问句标记、段落计时开始标记以及句子标记。\n\n在段落标题顶部增加了前馈层，用于预测相关段落的开始标记，以及用于预测证据句子的句子标记。\n\n在对第一阶段模型进行训练后，预测了训练集和开发集的相关段落得分。然后，保留最多5个原始得分高于预先指定的阈值(-3.0)的段落，并从上下文中删除其他段落。然后，根据得到的缩短上下文训练第二阶段模型。\n\n将跨度、问题分类、句子和段落损失结合起来，使用线性损失组合对模型进行多任务训练。\n\n使用ADAM优化器对模型进行了训练，并进行了线性warmup(1000步)和线性衰减。我们使用最小超参数调整，使用3E-5和5E-5的LR和3到7的epoch，发现LR为3E-5和5个历元的模型效果最好。\n\n![](https://i.loli.net/2021/04/19/LuOCHUx1eMPwDW9.png)\n\n","tags":["nlp"]},{"title":"Kaggle上传dataset的方法","url":"/2021/04/15/Kaggle上传dataset的方法/","content":"\n# Kaggle快速上传dataset的方法\n\n\n\n## 原理\n\n从国内上传到有cdn的地方(如GitHub), 再在kaggle的kernel上下载下来，直接上传dataset。\n\n\n\n## 方法\n\n\n\n首先需要掌握kaggle-api的使用，kaggle-api是kaggle官方提供的命令行工具，可以从命理完成比赛数据的下载、dataset下载上传，获取榜单等操作。\n\nhttps://github.com/Kaggle/kaggle-api\n\n本地安装：pip install kaggle\n\nKaggle已经安装好了，不用再安装\n\n\n\n步骤1：下载账户API json\n\nhttps://www.kaggle.com/me/account\n\n步骤2：在页面创建一个dataset\n\nhttps://www.kaggle.com/datasets\n\n步骤3：下载dataset的metadata\n\n运行：kaggle datasets metadata shopee-models\n\n步骤4：下载数据集并上传到dataset\n\n完整代码：\n\n```sh\n# 将API json文件写到这里\n!mkdir /root/.kaggle\nlines = '''{\"username\":\"写你的用户名\",\"key\":\"写你的key\"}'''\nwith open('/root/.kaggle/kaggle.json', 'w') as up:    \n\t\tup.write(lines)\n# 创建文件夹，写入dataset的metadata\n!mkdir hubmapkidneysegmentation\nlines = '''{\n\t\"id\": \"finlay/shopee-models\",\n\t\"id_no\": 122348,\n\t\"title\": \"shopee_models\",\n\t\"subtitle\": \"\",\n\t\"description\": \"\",\n\t\"keywords\": [],\n\t\"resources\": []\n}'''\nwith open('hubmapkidneysegmentation/dataset-metadata.json', 'w') as up:\n\t\tup.write(lines)\n# 下载文件，这里用axel多线程下载，直接用wget也可以的。\n!apt-get install axel\n!axel -n 12 https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b7-dcc49843.pth -o hubmapkidneysegmentation/baseline_fold0_densenet_224_epoch50.pth\n# 上传文件，这里会覆盖上传\n!kaggle datasets version -p ./hubmapkidneysegmentation -m \"Updated data fcn\"\n```\n\n","tags":["DataGame"]},{"title":"DUMA: Reading Comprehension with Transposition Thinking","url":"/2021/04/14/DUMA-Reading-Comprehension-with-Transposition-Thinking/","content":"\n# DUMA: Reading Comprehension with Transposition Thinking\n\nDUMA：DUal Multi-head Co-Attention model\n\n这是一篇针对解决多项选择任务的MRC网络结构。题目中的Transposition Think，被作者赋义为分别从文章和问题的角度来考虑对方的关注点。\n\n主要特点：\n\n- 基于预训练语言模型(得到表示编码，替代复杂的匹配网络)\n- 衔接多层co-attention(从三元组中捕捉关系)\n\n多项选择任务可以抽象为(文章P，问题q，选项a) 三元组。\n\n针对多项选择的特点多项选择MRC尤其依赖于匹配网络的设计，它被认为是有效地捕捉文章、问题和答案三元组之间的关系。(不能只考虑推理如何做的更好，还要考虑答案出现的关键位置也就是匹配网络的作用)\n\n \n\n文中总结的人在做阅读理解题时的特点：\n\n- 快速通读文章的整体内容，问题和回答选项，以建立全局印象，然后进行换角度思考过程。\n- 根据问答选项的特有信息，重新考虑文章的细节，收集问答选项的支持证据。\n- 根据文章中的特有信息，重新考虑问题和答案选项，以确定正确的选项，排除错误的选项。\n\n当人们重读文章时，他们倾向于根据对问答选项的印象提取关键信息，重读问答选项时也是如此\n\n\n\n---\n\n## DUMA\n\n多项选择问题可以定义模型需要学习一个概率分布$F(A_1,A_2,...,A_t|P,Q)$\n\n![](https://i.loli.net/2021/04/14/IE9asGiRTlLJNV2.png)\n\nEncoder 接受文本输入生成一个全局序列表达，这个过程类似人类第一次阅读整个内容以获得总体印象。\n\nDecoder则收集所有信息的答案预测以选择正确答案选项。\n\nDUMA层位于encoder和decoder之间，意在模仿人类转换思考角度的过程，从问题文章和关键词中捕捉关系信息。\n\n\n\n\n\n### Encoder\n\n作者用的是PrLMs，其将文章、问题和所有不同的候选答案拼接作为输入。\n\n$P=[p_1,p_2,..,p_m]$    ， $Q=[q_1,q_2,...,q_n]$ ,   $A=[a_1,a_2,...,a_k]$\n$$\n\\begin{equation}\\begin{split} \n E = Enc(P \\oplus Q \\oplus A )\n \\end{split}\\end{equation}\n$$\n这个输入到预训练的方式可能会遇到点问题，一般预训练语言模型比如bert都会限制一个输入的大小，如果文章过长的话，模型看不到问题和选项可能会导致训练效果不佳。可以改为 Q、A、P的形式，因为一般Q和A都比较短。\n\n$E = [e_1,e_2,...,e_{m+n+k}]$  \n\n$e_i$ 为固定维度$d_{model}$ 的向量，是各自的token。\n\n### Dual Multi-head Co-Attention\n\n使用双多头共同注意模型来计算文章和问答的attention表征。(可堆叠k层)\n\n其实就是一个多头co-attention，定义一个Q、K、V (Q不是上面的问题Q)\n\n先从E中分离出$E^P = [e^P_1,e^P_2,...,E^P_{t_p}]$、$E^{QA} = [e^{qA},e^{qA},...,E^{qA}_{t_{q_a}}]$\n\n使用两种计算attention的方法：\n\n- $E^P$ 做Query ，$E^{QA}$ 做 Key和Value\n\n- $E^{QA}$ 做Query ，$E^{P}$ 做 Key和Value\n\n$$\n\\begin{equation}\\begin{split} \n Attention(E^P,E^{QA},E^{QA}) &= softmax(\\frac{E^P(E^{QA})^T}{\\sqrt{d_k}})E^{QA}\\\\\n head_i &= Attention(E^PW^Q_i,E^{QA}W^K_i)\\\\\n MIIA(E^P, E^{QA}, E^{QA}) &= Concat(head_1,head_2,...,head_h) W^O\\\\\n MHA_1 &= MHA(E^P, E^{QA}, E^{QA}) \\\\\n MHA_2 &= MHA(E^{QA}, E^{P}, E^P) \\\\\n DUMA (E^P, E^{QA}) &= Fuse(MHA_1,MHA_2)\\\\\n    \\end{split}\\end{equation}\n$$\n\n \n\n其中$W_i^Q \\in R^{d_{model} \\times d_q}$ 、 $W_i^K \\in R^{d_{model} \\times d_k}$、  $W_i^V \\in R^{d_{model} \\times d_q}$ 、$W_i^O \\in R^{hd_v \\times d_{model}}$  : h 头数\n\n$MHA$: 多头注意力\n\n$Fuse$ 函数先使用均值池化来汇集$MHA(·)$的序列输出，然后再聚合两个池化的输出。\n\n后文实验了三种聚合方法 元素乘法  元素相加  concat\n\n表示在决定哪个是最佳答案选项之前，对所有关键信息进行混合。\n\n### Decoder\n\n$$\n\\begin{equation}\\begin{split} \n O_i &= DUMA(E^P, E^{QA_i}) \\\\\n L(A_r|P,Q) &= -log\\frac{exp(W^TO_r)}{\\sum_{i=1}^s exp(W^TO_i)}\n \\end{split}\\end{equation}\n$$\n\ns 是选项数量\n\n\n\n## Multi-choice MRC数据集\n\nDREAM and RACE\n\n![](https://i.loli.net/2021/04/14/63cBOaFhfGIgd58.png)\n\n## 实验\n\n![](https://i.loli.net/2021/04/14/3tQ1BCvzHSo9bTU.png)\n\n![](https://i.loli.net/2021/04/14/NchfAZRWxCIuQeS.png)\n\n![](https://i.loli.net/2021/04/14/d6JDXcVaTEmZPLF.png)\n\n","tags":["nlp"]},{"title":"FREELB: ENHANCED ADVERSARIAL TRAINING FOR NATURAL LANGUAGE UNDERSTANDING","url":"/2021/04/09/FREELB-ENHANCED-ADVERSARIAL-TRAINING-FOR-NATURAL-LANGUAGE-UNDERSTANDING/","content":"\n# FreeLB: Enhanced Adversarial Training For Natural Language Understanding\n\n[nlp中的对抗训练](https://coding-zuo.github.io/2021/04/07/nlp%E4%B8%AD%E7%9A%84%E5%AF%B9%E6%8A%97%E8%AE%AD%E7%BB%83-%E4%B8%8Ebert%E7%BB%93%E5%90%88/)\n\n承接上文，上文主要讲对抗训练的原理与物理意义与发展，对抗性训练是创建健壮神经网络的一种方法。在对抗性训练期间，小批次的训练样本受到对抗性扰动的污染，然后用于更新网络参数，直到得到的模型学会抵抗此类攻击，并且对模型起到了正则化的效果，提高模型泛化能力并且防止过拟合。\n\n这篇论文结合现在流行的预训练模型或transformer模型只能结合到下游任务的embedding中。\n\n提出FreeLB算法在GLUE上结合Roberta达到了当时的SOTA，是基于Transformer的自然语言理解和常识推理任务模型来做对抗。\n\n\n\n## 摘要\n\n对抗性训练可以最小化标签保留输入扰动的最大风险，已被证明对提高语言模型的泛化能力是有效的。\n\nFreeLB (Free Large-Batch)，通过在单词嵌入中添加对抗性扰动，并最小化输入样本周围不同区域内的对抗性风险，从而提高了嵌入空间的不变性。\n\n在GLUE基准上的实验表明，当仅应用于精调阶段时，它能够将BERT-BASE模型的整体测试分数从78.3提高到79.4，将Roberta-Large模型的测试分数从88.5提高到88.8。\n\n\n\n## 创新点\n\n针对PGD算法的问题：当K较小时，基于PGD的对抗性训练仍然会导致高度卷积和非线性的损失面，在更强的对手下很容易被打破，当K大时计算开销又很大。\n\n利用最近提出的“Free”训练策略在不同范数约束下用多样化的对抗样本来丰富训练数据，\n\n“Free”的对抗性训练算法在一次反向传递中同时更新模型参数和对抗性扰动。\n\n还使用将大部分对抗性更新限制在第一层，有效减少的对抗过程正反向传播总量。\n\n比PGD计算成本小，能在大规模的预训练模型上进行对抗训练。\n\n\n\n## 文本的对抗样本(对手) \n\n1. 黑盒环境下对embedding进行扰动(对手不是从样本进行攻击)\n2. 在输入中添加分散注意力的句子(人工)\n3. 用GANs将输入投影到潜在空间，并搜索接近原始的文本对手\n\n![](https://i.loli.net/2021/04/09/daKoDQkv35hwmEP.png)\n\n第二三算是一种辅助模型，数据增强的一种形式。\n\n如何在没有人工评估的情况下通过单词/字符替换来构建保留标签的对抗性示例仍然不清楚，因为每个单词/字符的含义取决于上下文。\n\n所以主要还是采用第一种进行对抗训练。\n\n因为词的输入表达有很多种，像词embedding、句子embedding和位置embedding。作者和其他对抗训练一样只干扰词embedding和拼接词的embedding。\n\n注意，基于Embedding的对手严格来说比更传统的基于文本的对手更强大，因为对手可以在单词嵌入上进行在文本域中不可能进行的操作。因为CV都是从样本层面进行扰动，这个扰动从embedding上扰动，相当于在更高级的层面，所以更强大。\n\n## FreeLB\n\n此前预训练语言模型对于下游任务已被证实很有效。\n\n作者的目标是通过在下游语言理解任务的精调过程中增强它们在嵌入空间中的鲁棒性，进一步提高这些预先训练的语言模型在下游语言理解任务上的泛化能力。\n\n由于这篇论文只对对抗性训练的效果感兴趣，而不是产生实际的对抗性示例，因此使用基于梯度的方法在输入句子的嵌入中添加范数有界的对抗性扰动。\n\n定义模型的输入One-hot向量为 $ Z=[z_1,z_2,...,z_n]$\n\n嵌入矩阵为V\n\n语言模型看成是一个 $y=f_{\\theta}(X), X=VZ$ , y是模型输出 $\\theta$是可学习参数。\n\n定义对抗扰动为 $\\delta$ \n\n新的预测输出变为 $y'=f_{\\theta}(X+\\delta)$\n\n为了保持语义，我们将δ的范数限制为较小，并假设模型的预测在扰动后不会改变。\n\n上面的定义和其他人的研究基本都是相同的，FreeLB区别在于不要求X归一化。\n\nFreeLB吸取了FreeAT和YOPO加速方法, 几乎不需要任何开销就可以获得参数的梯度。实现了与标准PGD训练模型相当的健壮性和泛化能力，只使用与自然训练相同或略多的正反向传播。\n\n### FreeAT (Free Adversarial Training): NIPS2019\n\n从FGSM到PGD，主要是优化对抗扰动的计算，虽然取得了更好的效果，但计算量也一步步增加。对于每个样本，FGSM和FGM都只用计算两次，一次是计算x的前后向，一次是计算x+r的前后向。而PGD则计算了K+1次，消耗了更多的计算资源。因此FreeAT被提了出来，在PGD的基础上进行训练速度的优化。\n\nFreeAT的思想是在对每个样本x连续重复m次训练，计算r时复用上一步的梯度，为了保证速度，整体epoch会除以m。r的更新公式为：\n$$\n\\begin{equation}\\begin{split} \n r_{t+1} = r_t + \\epsilon \\cdot sign(g)\n    \\end{split}\\end{equation}\n$$\n伪代码：\n\n```text\n初始化r=0\n对于epoch=1...N/m:\n  对于每个x:\n    对于每步m:\n      1.利用上一步的r，计算x+r的前后向，得到梯度\n      2.根据梯度更新参数\n      3.根据梯度更新r\n```\n\n缺点：FreeLB指出，FreeAT的问题在于每次的r对于当前的参数都是次优的（无法最大化loss），因为当前r是由r(t-1)和theta(t-1)计算出来的，是对于theta(t-1)的最优。\n\n代码：[https://github.com/mahyarnajibi...](https://link.zhihu.com/?target=https%3A//github.com/mahyarnajibi/FreeAdversarialTraining/blob/d70774030871fa3207e09ce8528c1b84cd690603/main_free.py%23L160)\n\n### YOPO (You Only Propagate Once): NIPS2019\n\n代码：[https://github.com/a1600012888/YOPO-You-Only-Propagate-Once](https://link.zhihu.com/?target=https%3A//github.com/a1600012888/YOPO-You-Only-Propagate-Once)\n\n可以参考[加速对抗训练——YOPO算法浅析](https://zhuanlan.zhihu.com/p/95904001)\n\n极大值原理PMP(Pontryagin's maximum principle)是optimizer的一种，它将神经网络看作动力学系统。这个方法的优点是在优化网络参数时，层之间是解藕的。通过这个思想，我们可以想到，既然扰动是加在embedding层的，为什么每次还要计算完整的前后向传播呢？\n\n基于这个想法，作者想复用后几层的梯度，假设p为定值：\n\n![[公式]](https://www.zhihu.com/equation?tex=p+%3D+%5Cnabla_%7Bg_%7B%5Ctilde%5Ctheta%7D%7D%28l%28g_%7B%5Ctilde%5Ctheta%7D%28f_0%28x_i%2Br_i%5E%7Bj%2C0%7D%2C+%5Ctheta_0%29%29%2Cy_i%29%29%5Ccdot%5Cnabla_%7Bf_0%7D%28g_%7B%5Ctilde%5Ctheta%7D%28f_0%28x_i%2Br_i%5E%7Bj%2C0%7D%2C+%5Ctheta_0%29%29%29+%5C%5C)\n\n则对r的更新就可以变为\n\n![[公式]](https://www.zhihu.com/equation?tex=r_i%5E%7Bj%2Cs%2B1%7D+%3D+r_i%5E%7Bj%2Cs%7D%2B%5Calpha_1p%5Ccdot%5Cnabla_%7Br_i%7Df_0%28x_i%2Br_i%5E%7Bj%2Cs%7D%2C%5Ctheta_0%29+%5C%5C)\n\n我们可以先写出YOPO的梯度下降版本：\n\n```text\n对于每个样本x\n初始化r(1,0)\n对于j=1,2,...,m:\n  1.根据r(j,0),计算p\n  对于s=0,1,...,n-1:\n    2.计算r(j,s+1)\n  3.另r(j+1,0)=r(j,n)\n```\n\n作者又提出了PMP版本的YOPO，并证明SGD的YOPO是PMP版的一种特殊形式。这样每次迭代r就只用到embedding的梯度就可以了。\n\nYOPO还主张在每次反向传播后，应将第一隐层的梯度作为常数，利用该常数与网络第一层的雅可比的乘积对对手进行多次额外更新，以获得强对手。\n\n### 回到FreeLB\n\n与FreeAT不同的是，YOPO从每个上升步长开始累加参数的梯度，并且只在K个内上升步长之后更新一次参数。\n$$\n\\begin{equation}\\begin{split} \n  min_{\\theta}\\mathbb{E}_{(Z,y)∼ D ,{m∼M }} [\\frac {1}{K}\\sum_{t=0}^{K-1} max_{\\delta_t\\in \\Omega_t\t}L(f_{\\theta}(x+\\delta_t),y)] \n \\end{split}\\end{equation}\n$$\n\n对比 PGD:\n$$\n\\begin{equation}\\begin{split} \n  min_{\\theta}\\mathbb{E}_{(x,y)∼ D} [max_{\\Delta x\\in \\Omega\t}L(x+\\Delta x,y;\\Theta)] \n    \\end{split}\\end{equation}\n$$\n\nFreeLB和PGD主要有两点区别：\n\n1. PGD是迭代K次r后取最后一次扰动的梯度更新参数，FreeLB是取K次迭代中的平均梯度\n2. PGD的扰动范围都在epsilon内，因为伪代码第3步将梯度归0了，每次投影都会回到以第1步x为圆心，半径是epsilon的圆内，而FreeLB每次的x都会迭代，所以r的范围更加灵活，更可能接近局部最优：\n\n![](https://i.loli.net/2021/04/10/ZMxvfdq4FXRn69S.jpg)\n\n它执行多次PGD迭代来构造对抗性实例，并在每次迭代中同时累积“free”参数梯度∇θL。\n\n伪代码：\n\n```text\n对于每个x:\n  1.通过均匀分布初始化r，梯度g为0\n  对于每步t=1...K:\n    2.根据x+r计算前后向，累计梯度g\n    3.更新r\n  4.根据g/K更新梯度\n```\n\n论文中还指出了很重要的一点，就是**对抗训练和dropout不能同时使用**，加上dropout相当于改变了网络结构，会影响r的计算。如果要用的话需要在**K步中都使用同一个mask**。\n\n![](https://i.loli.net/2021/04/10/WTh7O4Ui5YenzNM.png)\n\n\n\n\n\n## 参考文献\n\n[一文搞懂NLP中的对抗训练FGSM/FGM/PGD/FreeAT/YOPO/FreeLB/SMART](https://zhuanlan.zhihu.com/p/103593948)\n\n[对抗训练的理解，以及FGM、PGD和FreeLB的详细介绍](https://blog.csdn.net/weixin_41712499/article/details/110878322)\n\n","tags":["nlp"]},{"title":"图神经网络的对抗攻击","url":"/2021/04/08/图神经网络的对抗攻击/","content":"\n# 图神经网络的对抗攻击\n\n最近要汇报一个关于安全方面的研究。本来打算讲一些和安全擦边的关于nlp对抗训练提升模型鲁棒性的内容，正好和最近学习的阅读理解比赛相关，可以作为一个提分trick。\n\n但老师强调要和安全相关少讲过程。而nlp中的对抗样本不可以加在原始样本中，只能在embedding中加入扰动，这样就没法攻击，多数用来提升模型鲁棒性。所以就拍马研究了一下图网络的对抗攻击。\n\n刚开始了解，希望可以从中找出可以和我研究方向结合的地方。\n\n如有不对的地方还希望联系我指点一下。\n\n[nlp中的对抗训练&与bert结合](https://coding-zuo.github.io/2021/04/07/nlp%E4%B8%AD%E7%9A%84%E5%AF%B9%E6%8A%97%E8%AE%AD%E7%BB%83-%E4%B8%8Ebert%E7%BB%93%E5%90%88/)\n\n在上一篇文章中主要介绍的是对抗训练，其实是一种防御的策略，对提高模型而言FGM相当于加了一个正则项。 \n\n## 图网络攻击难点\n\n- 离散的结构/特征，难以直接利用现有的基于梯度的方法。\n\n- 对于“无法感知”的扰动如何定义。\n\n- 节点分类往往属于直推式学习，训练数据和测试数据联合使用以学习模型，这就使得攻击方法注定是与poisoning/causative attack相关，而非仅是evasion attack。\n\n\n\n\n\n\n\n\n\n\n\n## 参考文献\n\n[图对抗攻击 Graph Adversarial Attack](https://zhuanlan.zhihu.com/p/88934914)\n\n","tags":["GNN"]},{"title":"nlp中的对抗训练&与bert结合","url":"/2021/04/07/nlp中的对抗训练-与bert结合/","content":"\n#  nlp中的对抗训练学习\n\nPPT : https://coding-zuo.github.io/adversary/index.html\n\n由于深度神经网络强大的表示学习能力，在许多领域都取得了很大的成功，包括计算机视觉、自然语言处理、语音识别等。然而，在其卓越性能的背后，深度神经网络作为一个黑箱，缺乏可解释性与鲁棒性，使得它易受到对抗攻击而对抗性攻击的存在可能是深度学习模型的一个固有弱点。\n\n深度学习的对抗一般有两种含义：\n\n- 一是生成对抗网络(Generative Adversarial Network,GAN) 代表一大类先进的生成模型。(这方面我不是很了解)\n- 另一个则是跟对抗攻击、对抗样本相关的领域。(主要关心模型在小扰动下的稳健性)\n\n\n\n## 方法介绍\n\n在CV领域，我们需要通过对模型的对抗攻击和防御来增强模型的稳健型，比如在自动驾驶系统中，要防止模型因为一些随机噪声就将红灯识别为绿灯。\n\n在NLP领域，类似的对抗训练也是存在的，不过NLP中的对抗训练更多是作为一种正则化手段来提高模型的泛化能力！\n\n这使得对抗训练成为了NLP刷榜的“神器”之一，前有微软通过RoBERTa+对抗训练在[GLUE](https://gluebenchmark.com/leaderboard)上超过了原生RoBERTa。\n\n\n\n## 对抗样本\n\n要认识对抗训练，首先要了解“对抗样本”，它首先出现在论文[《Intriguing properties of neural networks》](http://https//arxiv.org/abs/1312.6199)之中。简单来说，它是指对于人类来说“看起来”几乎一样、但对于模型来说预测结果却完全不一样的样本，比如下面的经典例子：\n\n![](https://i.loli.net/2021/04/07/EizJ85fCHyX2drj.png)\n\n“对抗攻击”，其实就是想办法造出更多的对抗样本。\n\n“对抗防御”，就是想办法让模型能正确识别更多的对抗样本。\n\n所谓对抗训练，则是属于对抗防御的一种，它构造了一些对抗样本加入到原数据集中，希望增强模型对对抗样本的鲁棒性；同时，如本文开篇所提到的，在NLP中它通常还能提高模型的表现。\n\n用对抗训练的思路来提升NLP模型，有两个实现角度：\n\n1. 因为nlp的输入通常是one-hot向量，两个one-hot向量其欧式距离恒为$\\sqrt 2$ ，理论上不存在微小的扰动，不想cv图像那样可以对连续实数向量来做。比如，$\\Delta x$ 是实数向量，$x+\\Delta x$还是一个有意义的图。所以很多研究都是在embedding层上做扰动的，因为embedding层是我们自己训练的，所以不太可能出现认为的恶意对抗攻击。\n\n   ![](https://i.loli.net/2021/04/09/daTOFDIU3EtfyGs.png)\n\n2. 这种角度不知道还算不算对抗，但可以说是一种数据增强手段。如上图中下面的问题，经过缩写，添加标点，或者同义词近义词替换等等。通过辅助模型提升鲁棒性。\n\n\n\n## Min-Max\n\n对抗训练可以统一写成如下格式：\n$$\n\\begin{equation}\\begin{split} \n min_{\\theta}\\mathbb{E}_{(x,y)∼ D} [max_{\\Delta x\\in \\Omega\t}L(x+\\Delta x,y;\\Theta)] \n    \\end{split}\\end{equation}\n$$\n其中$D$ 代表训练集，x代表输入，y代表标签，θ是可学习模型参数，L(x,y;θ)是单个样本的loss，Δx是对抗扰动，Ω是扰动空间。\n\n理解为：\n\n1. $max_{\\Delta x\\in \\Omega}L(x+\\Delta x,y;\\theta)$ ，往输入x中注入扰动$\\Delta x$， 目的是希望 $ L(x+\\Delta x,y;\\theta)$ 损失越大越好，也就是让现有模型的预测出错;\n\n2. 当然$\\Delta x$ 不能太大、无约束，否则达不到“看起来几乎一样”的效果，所以$Δx$要满足一定的约束，常规的约束是$‖Δx‖≤ϵ$，其中$ϵ$是一个常数；\n\n3. 构造好对抗样本后，用$x+\\Delta x,y$作为数据去最小化loss，来更新参数$\\theta$ (梯度下降)\n4. 重复执行1.2.3步。\n\n整个对抗训练优化过程是一个max和min交替执行的过程：通过注入max损失，在梯度下降让损失变min。\n\n\n\n## 如何计算$\\Delta x$——快速梯度FGM\n\n$\\Delta x$的目的是增大Loss，而我们知道让loss减少的方法是梯度下降，那反过来，让loss增大的方法自然就是梯度上升，因此可以简单地取\n$$\n\\begin{equation}\\begin{split} \n \\Delta x &= ϵ∇_xL(x,y;θ)\\\\\n ∇_xL(x,y;θ) &= (\\frac {\\partial L }{\\partial x})\n    \\end{split}\\end{equation}\n$$\n求loss对x的梯度，然后根据梯度给Δx赋值，来实现对输入的干扰，完成干扰之后再执行常规的梯度下降。\n\n为了防止$\\Delta x$过大，通常要对 $∇xL(x,y;θ)$ 标准化，常见方式为：\n$$\n\\begin{equation}\\begin{split} \n \t\\Delta x = ϵ \\frac {∇_xL(x,y;θ)}{||∇_xL(x,y;θ)||} \\text{或} \\Delta x=  ϵsign(∇_xL(x,y;θ))\n    \\end{split}\\end{equation}\n$$\n采用右边的取扰动值的算法叫FGSM(ICLR2015)，理解为扰动是沿着梯度方向向损失值的极大值走。\n\n采用左边取扰动值的算法叫FGM(ICLR2017)，理解为在每个方向上都走相同的一步找到更好的对抗样本。\n\n有了$\\Delta x$，得到：\n$$\n\\begin{equation}\\begin{split} \n min_{\\theta}\\mathbb{E}_{(x,y)∼ D} [L(x+\\Delta x,y;\\Theta)] \n    \\end{split}\\end{equation}\n$$\n这就构成了一种对抗训练方法，被称为**Fast Gradient Method（FGM）**，它由GAN之父Goodfellow在论文[《Explaining and Harnessing Adversarial Examples》](https://arxiv.org/abs/1412.6572)首先提出。\n\n此外，对抗训练还有一种方法，叫做**Projected Gradient Descent（PGD）**，其实就是通过多迭代几步来达到让$L(x+Δx,y;θ)$更大的$Δx$（如果迭代过程中模长超过了$ϵ$，[《Towards Deep Learning Models Resistant to Adversarial Attacks》](https://arxiv.org/abs/1706.06083)。在后文....\n\n### 梯度惩罚\n\n假设已经得到对抗扰动 $\\Delta x$ ,更新 $\\theta$ 时，对 L 进行泰勒展开：\n$$\n\\begin{equation}\\begin{split} \n min_{\\theta} \\mathbb{E}_{(x,y)∼ D} [L(x+\\Delta x,y;\\theta)] &\\approx min_{\\theta} \\mathbb{E}_{(x,y)∼ D}[L(x,y;\\theta) + <∇_xL(x,y;θ), \\Delta x>] \\\\\n &= min_{\\theta} \\mathbb{E}_{(x,y)∼ D}[L(x,y;\\theta) + ∇_xL(x,y;θ) \\cdot \\Delta  x ] \\\\\n &= min_{\\theta} \\mathbb{E}_{(x,y)∼ D}[L(x,y;\\theta) + ∇_xL(x,y;θ)^T  \\Delta  x ] \n    \\end{split}\\end{equation}\n$$\n对应的 $\\theta$ 的梯度为:\n$$\n\\begin{equation}\\begin{split} \n ∇_{\\theta} L(x,y;\\theta) + ∇_{\\theta} ∇_xL(x,y;θ)^T  \\Delta  x \n    \\end{split}\\end{equation}\n$$\n代入 $ \\Delta x = ϵ∇_xL(x,y;θ)$:\n$$\n\\begin{equation}\\begin{split} \n &∇_{\\theta} L(x,y;\\theta) + ϵ ∇_{\\theta} ∇_xL(x,y;θ)^T  ∇_xL(x,y;θ)\\\\ &= ∇_{\\theta}(L(x,y;θ) + \\frac{1}{2} ϵ ||∇_xL(x,y;θ)||^2)\n    \\end{split}\\end{equation}\n$$\n这个结果表示，对输入样本施加 $ϵ∇xL(x,y;θ)$ 的对抗扰动，一定程度上等价于往loss里边加入“梯度惩罚”\n$$\n\\begin{equation}\\begin{split} \n \\frac{1}{2} ϵ ||∇_xL(x,y;θ)||^2\n    \\end{split}\\end{equation}\n$$\n\n如果对抗扰动是$ϵ‖∇xL(x,y;θ)‖$ ，那么对应的梯度惩罚项则是$ϵ‖∇xL(x,y;θ)‖$（少了个1/2，也少了个2次方）。\n\n### 几何图像\n\n事实上，关于梯度惩罚，我们有一个非常直观的几何图像。以常规的分类问题为例，假设有n个类别，那么模型相当于挖了n个坑，然后让同类的样本放到同一个坑里边去：\n\n![](https://i.loli.net/2021/04/09/xeOucXmabjkrS4A.png)\n\n梯度惩罚则说“同类样本不仅要放在同一个坑内，还要放在坑底”，这就要求每个坑的内部要长这样：\n\n![](https://i.loli.net/2021/04/09/tHylhowkCpvP2IM.png)\n\n为什么要在坑底呢？因为物理学告诉我们，坑底最稳定呀，所以就越不容易受干扰呀，这不就是对抗训练的目的么？\n\n那坑底意味着什么呢？极小值点呀，导数（梯度）为零呀，所以不就是希望‖∇xL(x,y;θ)‖‖∇xL(x,y;θ)‖越小越好么？这便是梯度惩罚的几何意义了。\n\n![](https://kexue.fm/usr/uploads/2020/03/3963498733.gif)\n\n苏神代码基于keras的：\n\n> https://github.com/bojone/keras_adversarial_training\n\n## Projected Gradient Descent (PGD)\n\n内部max的过程，本质上是一个非凹的约束优化问题，FGM解决的思路其实就是梯度上升，**那么FGM简单粗暴的“一步到位”，是不是有可能并不能走到约束内的最优点呢？**当然是有可能的。于是，一个很intuitive的改进诞生了：Madry在18年的ICLR中，提出了用Projected Gradient Descent（PGD）的方法，简单的说，就是**“小步走，多走几步”**，如果走出了扰动半径为$\\epsilon$的空间，就映射回“球面”上，以保证扰动不要过大：\n\n其中$\\mathcal{S}=\\{r\\in\\mathbb{R}^d:||r||_2 \\leq \\epsilon\\}$ 为扰动的约束空间，$\\alpha$为小步的步长。\n\n作者将这一类通过一阶梯度得到的对抗样本称之为“一阶对抗”，在实验中，作者发现，经过PGD训练过的模型，对于所有的一阶对抗都能得到一个低且集中的损失值，如下图所示：\n\n![](https://i.loli.net/2021/04/09/SosrVAW9UGYNm6T.png)\n\n我们可以看到，面对约束空间 $\\mathcal{S}$ 内随机采样的十万个扰动，PGD模型能够得到一个**非常低且集中的loss分布**，因此，在论文中，作者称PGD为**“一阶最强对抗”**。也就是说，只要能搞定PGD对抗，别的一阶对抗就不在话下了。\n\n```\n对于每个x:\n  1.计算x的前向loss、反向传播得到梯度并备份\n  对于每步t:\n      2.根据embedding矩阵的梯度计算出r，并加到当前embedding上，相当于x+r(超出范围则投影回epsilon内)\n      3.t不是最后一步: 将梯度归0，根据1的x+r计算前后向并得到梯度\n      4.t是最后一步: 恢复(1)的梯度，计算最后的x+r并将梯度累加到(1)上\n  5.将embedding恢复为(1)时的值\n  6.根据(4)的梯度对参数进行更新\n```\n\n基于PGD的对抗性训练被广泛认为是最有效的，因为它在很大程度上避免了模糊的梯度问题。它将一类对抗性训练算法转化为求解交叉熵损失的极大极小问题，该问题可以通过多次投影梯度上升步骤和随后的SGD步骤可靠地实现。\n\n\n\n## Virtual Adversarial Training\n\n除了监督训练，对抗训练还可以用在半监督任务中，尤其对于NLP任务来说，很多时候输入的无监督文本多的很，但是很难大规模地进行标注，那么就可以参考[13]中提到的Virtual Adversarial Training进行半监督训练。\n\n首先，我们抽取一个随机标准正态扰动（$d\\sim \\mathcal{N}(0, I)\\in \\mathbb{R}^d$），加到embedding上，并用KL散度计算梯度：\n\n然后，用得到的梯度，计算对抗扰动，并进行对抗训练：\n\n![](https://i.loli.net/2021/04/09/KYX3zILWf4A1Htg.png)\n\n实现方法跟FGM差不多\n\n## FreeAT & YOPO & FreeLB\n\n**优化的主要方向有两点：得到更优的扰动 & 提升训练速度**\n\n其实PGD效果不错但是它迭代多步计算开销很大，所以出现了这些针对效率上的优化，并且结合预训练语言模型。\n\n具体的就搜这些论文来看吧。\n\nFGSM: Explaining and Harnessing Adversarial Examples\n\nFGM: Adversarial Training Methods for Semi-Supervised Text Classification\n\nFreeAT: Adversarial Training for Free!\n\nYOPO: You Only Propagate Once: Accelerating Adversarial Training via Maximal Principle\n\nFreeLB: Enhanced Adversarial Training for Language Understanding\n\nSMART: Robust and Efficient Fine-Tuning for Pre-trained Natural\n\n## 参考文献\n\n[[对抗训练浅谈：意义、方法和思考（附Keras实现）](https://kexue.fm/archives/7234)]\n\n[【炼丹技巧】功守道：NLP中的对抗训练 + PyTorch实现](https://fyubang.com/2019/10/15/adversarial-train/)\n\n[NLP --- >对抗学习：从FGM, PGD到FreeLB](https://blog.csdn.net/chencas/article/details/103551852)\n\n[TAVAT: Token-Aware Virtual Adversarial Training for Language Understanding](https://arxiv.org/pdf/2004.14543v3.pdf)\n\n[Adversarial Training Methods for Semi-Supervised Text Classification](https://arxiv.org/abs/1605.07725)\n[Adversarial Text Classification原作实现](https://github.com/tensorflow/models/blob/e97e22dfcde0805379ffa25526a53835f887a860/research/adversarial_text/adversarial_losses.py)\n\n[NLP(文本)中的对抗训练](https://blog.csdn.net/ganxiwu9686/article/details/105931668)\n\n[对抗训练的理解，以及FGM、PGD和FreeLB的详细介绍](https://blog.csdn.net/weixin_41712499/article/details/110878322)\n\n","tags":["nlp"]},{"title":"数组范围内计数","url":"/2021/04/07/数组范围内计数/","content":"\n# 数组范围内计数\n\n数组为 3,2,2,3,1, 查询为（0,3,2)。\n\n意思是在数组里下标 0-3 这个范围上，有几个 2? \n\n假设给一个数组 arr，对这个数组的查询非常频繁请返回所有查询的结果。\n\n给出：arr[    ]\n\n要查多个范围：\n\n[[0,3,2],\n\n[1,4,0]]\n\n结果返回：[第一个数组结果，第二个数组结果]\n\n暴力解法直接遍历肯定不可以。\n\n## 解法\n\n一、做一个map映射，遍历一遍数组，将每个值和每个值出现的下标位置数组做成key-value\n\n在根据查询的V，在所在值的数组内做二分查找。\n\n```java\npublic static class QueryBox2 {\n        private HashMap<Integer, ArrayList<Integer>> map;\n\n        public QueryBox2(int[] arr) {\n            map = new HashMap<>();\n            for (int i = 0; i < arr.length; i++) {\n                if (!map.containsKey(arr[i])) {\n                    map.put(arr[i], new ArrayList<>());\n                }\n                map.get(arr[i]).add(i);\n            }\n        }\n\n        public int query(int L, int R, int value) {\n            if (!map.containsKey(value)) return 0;\n            ArrayList<Integer> indexArr = map.get(value);\n            // 查询<L的下标有几个\n            int a = countLess(indexArr, L);\n            // 查询<R+1的下标有几个\n            int b = countLess(indexArr, R + 1);\n            return b - a;\n        }\n\n        // 在有序数组中，用二分法数出<limit 的数有几个\n        // 也就是用二分法，找到<limit的数中最右的位置\n        private int countLess(ArrayList<Integer> arr, int limit) {\n            int L = 0;\n            int R = arr.size() - 1;\n            int mostRight = -1;\n            while (L <= R) {\n                int mid = L + ((R - L) >> 1);\n                if (arr.get(mid) < limit) {\n                    mostRight = mid;\n                    L = mid + 1;\n                } else {\n                    R = mid - 1;\n                }\n            }\n            return mostRight + 1;\n        }\n    }\n```\n\n$O(mlogn)$\n\n\n\n扩展：\n\n如果是求范围内累加和\n\n可以生成一个前缀和数组类似本题\n\n\n\n\n\n## 腾讯原题\n\n给定整数 power。给定一个数组 arr。给定一个数组 reverse。含义如下\n\narr 的长度一定是 2 的 power 次方，reverse1 每个值一定都在 0 ~ power范围。\n\n例如 power=2, ar={3,1,4,2}, reverse={0,1,0,2}\n\n针对reverse的数组中每一个值 \n\n如第一个值为0，就是对$2^0=1$ 每一个arr数组以1个数为单位逆序。\n\n如第二个值为1，就是对$2^1=2$ 对arr数组每两个数逆序\n\n任何一个在前的数字可以和任何一个在后的数组，构成一对数。可能是升序关系、相等关系或者降序关系。\n\n最后求调整完的arr数组有多少个降序对。\n\n比如 arr 开始时有如下的降序对：(3,1)、（3.2)、（4.2），一共 3 个。\n\n以2个数调整后arr由{3,1,4,2} 变成{1,3,2,4} 降序对有{3,2} ，共1个\n\n\n\n经典做法每次都reverse\n\n```java\n// originArr长度一定是2的power次方\n    // reverseArr中每一个值，都是0-power范围上的数\n    public static int[] reversePair1(int[] originArr, int[] reverseArr, int power) {\n        int[] ans = new int[reverseArr.length];\n        for (int i = 0; i < reverseArr.length; i++) {\n            // 1 << (reverseArr[i]) == r[i]的2次方\n            reverseArray(originArr, 1 << (reverseArr[i]));\n            ans[i] = countReversePair(originArr);\n        }\n        return ans;\n    }\n\n    public static void reverseArray(int[] originArr, int teamSize) {\n        if (teamSize < 2) return;\n        for (int i = 0; i < originArr.length; i += teamSize) {\n            reversePart(originArr, i, i + teamSize - 1);\n        }\n    }\n\n    public static void reversePart(int[] arr, int L, int R) {\n        while (L < R) {\n            int temp = arr[L];\n            arr[L++] = arr[R];\n            arr[R--] = temp;\n        }\n    }\n\n    public static int countReversePair(int[] originArr) {\n        int ans = 0;\n        for (int i = 0; i < originArr.length; i++) {\n            for (int j = i + 1; j < originArr.length; j++) {\n                if (originArr[i] > originArr[j]) {\n                    ans++;\n                }\n            }\n        }\n        return ans;\n    }\n```\n\n\n\n优化方案\n\n[3,2 4,5, 0,1 3,5]\n\n两个数一组：  1个逆序对，3个升序对\n\n四个数一组： 0个逆序对，8个升序对\n\n八个数一组：10个逆序对，4个升序对\n\n每个数组的逆序对数是2、4、9个一组的加和\n\n当数组进行几个数一组翻转时\n\n翻转后的逆序对和升序对数量，和翻转前的升序对和逆序对相等，数量调换了。\n\n小的数调整后数量不影响大数量调整后的数量。\n\n\n\n所以直接查2、4、8、16个 数量再交换相加。\n\n如何高效生成预处理记录\n\n输入数据状况\n\npower范围[0,20]\n\narr长度范围[1,10e7]\n\nreverse长度范围[1,10e6]\n\n```java\npublic static int[] reversePair2(int[] originArr, int[] reverseArr, int power) {\n        int[] originReverse = Arrays.copyOf(originArr, originArr.length);\n        reversePart(originReverse, 0, originReverse.length - 1);\n        int[] recordDown = new int[power + 1];\n        int[] recordUp = new int[power + 1];\n        process(originArr, 0, originArr.length - 1, power, recordDown);\n        process(originReverse, 0, originReverse.length - 1, power, recordUp);\n\n        // recordDown[i] 2的i次方个数一组的划分中，降序的数量\n        // recordUp[i] 2的i次方个数一组的划分中，升序的数量\n        int[] ans = new int[reverseArr.length];\n        for (int i = 0; i < reverseArr.length; i++) {\n            int curPower = reverseArr[i]; // =3  2的1次方、2次方、3次方 要调整\n            for (int p = 1; p <= curPower; p++) {\n                int tmp = recordDown[p];\n                recordDown[p] = recordUp[p];\n                recordUp[p] = tmp;\n            }\n            for (int p = 1; p <= power; p++) {\n                ans[i] += recordDown[p];\n            }\n        }\n        return ans;\n    }\n\n    public static void process(int[] originArr, int L, int R, int power, int[] record) {\n        if (L == R) {\n            return;\n        }\n        int mid = L + ((R - L) >> 1);\n        process(originArr, L, mid, power - 1, record);\n        process(originArr, mid + 1, R, power - 1, record);\n        record[power] += merge(originArr, L, mid, R);\n    }\n\n    public static int merge(int[] arr, int L, int m, int r) {\n        int[] help = new int[r - L + 1];\n        int i = 0;\n        int p1 = L;\n        int p2 = m + 1;\n        int ans = 0;\n        while (p1 <= m && p2 <= r) {\n            ans += arr[p1] <= arr[p2] ? arr[p1++] : arr[p2++];\n            help[i++] = arr[p1] <= arr[p2] ? arr[p1++] : arr[p2++];\n        }\n        while (p1 <= m) {\n            help[i++] = arr[p1++];\n        }\n        while (p2 <= r) {\n            help[i++] = arr[p2++];\n        }\n        for (i = 0; i < help.length; i++) {\n            arr[L + i] = help[i];\n        }\n        return ans;\n    }\n```\n\n","tags":["刷题"]},{"title":"海华中文阅读理解比赛梳理/多卡并行/transformers","url":"/2021/04/06/海华中文阅读理解比赛梳理-多卡并行-transformers/","content":"\n# 海华中文阅读理解比赛梳理\n\n文文言文古诗词现代诗词\n\n1 字词解释 2 标点符号作用 3 句子解释 4 填空 5 选择正读音 6 推理总结 7 态度情感 8 外部知识\n\n不需要先验知识的问题\n\n如一个问题能够在文档中进行匹配，回答起来就几乎不需要先验知识需要先验知识的问題\n\n1、关于语言的知识：需要词汇/语法知识,例如:习语、谚语、否定、反义词、同义词语法转换\n\n2、特定领域的知识：需要但不限于些事实上的知识，这些事实与特定领域的概念概念定义和属性，概念之间的关系\n\n3、一般世界的知识：需要有关世界如何运作的一般知识，或者被称为常识。比如百科全书中的知识\n\n这个赛题的难点是有些预训练语言模型没有学到的先验知识怎么学\n\n## 赛题概述\n\n- train 训练集提供了6313条数据数据格式是和中小学生做的阅读题一样，一篇文章有两到三个问题每个问题有两到四个答案选项。\n- validation 验证集提供了1000条数据。\n\n原始单条数据格式如下：\n\n```json\n{\n    \"ID\": \"0001\",\n    \"Content\": \"春之怀古张晓风春天必然曾经是这样的：从绿意内敛的山头，一把雪再也撑不住了，噗嗤的一声，将冷面笑成花面，一首澌澌然的歌便从云端唱到山麓，从山麓唱到低低的荒村。。。。。很多省略。\",\n    \"Questions\": [\n      {\n        \"Q_id\": \"000101\",\n        \"Question\": \"鸟又可以开始丈量天空了。”这句话的意思是   （   ）\",\n        \"Choices\": [\n          \"A．鸟又可以飞了。\",\n          \"B． 鸟又要远飞了。\",\n          \"C．鸟又可以筑巢了。\"\n        ],\n        \"Answer\": \"A\"\n      },\n      {\n        \"Q_id\": \"000102\",\n        \"Question\": \"本文写景非常含蓄，请读一读找一找哪些不在作者的笔下有所描述\",\n        \"Choices\": [\n          \"A．冰雪融化\",\n          \"B． 蝴蝶在花间飞舞\",\n          \"C．白云在空中飘\",\n          \"D．小鸟在空中自由地飞\"\n        ],\n        \"Answer\": \"C\"\n      }\n    ]\n}\n```\n\n## EDA 与预处理\n\n将原始数据每个问题抽出来以 [文章- 问题 -答案] 作为一条数据。\n\n```json\n{\n    \"Question\": \"下列对这首诗的理解和赏析，不正确的一项是\",\n    \"Choices\": [\n        \"A．作者写作此诗之时，皮日休正患病居家，闭门谢客，与外界不通音讯。\",\n        \"B．由于友人患病，原有的约会被暂时搁置，作者游春的诗篇也未能写出。\",\n        \"C．作者虽然身在书斋从事教学，但心中盼望能走进自然，领略美好春光。\",\n        \"D．尾联使用了关于沈约的典故，可以由此推测皮日休所患的疾病是目疾。\"\n    ],\n    \"Answer\": \"A\",\n    \"Q_id\": \"000101\",\n    \"Content\": \"奉和袭美抱疾杜门见寄次韵  陆龟蒙虽失春城醉上期，下帷裁遍未裁诗。因吟郢岸百亩蕙，欲采商崖三秀芝。栖野鹤笼宽使织，施山僧饭别教炊。但医沈约重瞳健，不怕江花不满枝。\"\n}\n```\n\n训练集从6313变为15421条数据，相当于有15421个问题\n\n验证集从1000变为2444条数据，相当于有2444个问题\n\n接下来看看文章的长度如何？\n\n![](https://i.loli.net/2021/04/06/UXPvh1c6CIRY54J.png)\n\n```\ncount    15421.000000\nmean      1039.781272\nstd        435.583878\nmin         38.000000\n25%        744.000000\n50%       1067.000000\n75%       1251.000000\nmax       3047.000000\nName: content_len, dtype: float64\ncount    2444.000000\nmean      927.508592\nstd       481.552693\nmin        40.000000\n25%       596.000000\n50%       938.000000\n75%      1179.500000\nmax      3047.000000\nName: content_len, dtype: float64\n```\n\n发现content文章都非常长，绝大多数都超过了512。\n\n使用预训练模型bert的话，如何训练很长的文章是是个提高的点。\n\n我的想法是bert模型一个这个提高的点、看看最近比较火的Longformer怎么做，再用几个和长度无关的模型像lstm等最后做集成。\n\n![](https://i.loli.net/2021/04/06/gBUFiwHtaK195rq.png)\n\n答案中选C的居多，点歌都选C。。。\n\n\n\n在提供的测试集中有一个特别的地方，赛方给出了文章的类型。\n\n00 现代文 11文言文 22 古诗词 33现代诗词\n\n![](https://i.loli.net/2021/04/06/ZoVXJGdhrf7wga5.png)\n\n测试集还给了难度，使用想法：\n\n可以训练一个模型预测文本的难度和类型，标注训练集，可能会有提升。\n\n\n\n接下来将标签从ABCD转成0123\n\n```python\ntrain_df['label'] = train_df['Answer'].apply(lambda x:['A','B','C','D'].index(x)) \n\ntest_df['label'] = 0\n```\n\n\n\n## Baseline\n\n### 分词器\n\n采用transformers提供的bert分词器\n\n```python\ntokenizer = BertTokenizer.from_pretrained('model') #加载bert的分词器\n```\n\n这里我试过如果要将bert改成roberta，分词器还是要采用BertTokenizer，如果用RobertaTokenizer会报错。\n\n参考[关于transformers库中不同模型的Tokenizer](https://zhuanlan.zhihu.com/p/121787628)\n\n**由于中文的特殊性不太适合采用byte级别的编码，所以大部分开源的中文Roberta预训练模型仍然采用的是单字词表，所以直接使用`BertTokenizer`读取即可，** 不需要使用`RobertaTokenizer`。\n\n\n\n### 模型部分\n\nBertForMultipleChoice https://huggingface.co/transformers/model_doc/bert.html#bertformultiplechoice\n\n把每个问题和文章的不同选项拆开拼成一个输入。如下图第一行\n\n![](https://i.loli.net/2021/04/08/sgbWnyIqdT9hcrE.png)\n\nbaseline采用transformers提供的调包，封装好的BertForMultipleChoice (多项选择任务)，它的源码：\n\n```python\nclass BertForMultipleChoice(BertPreTrainedModel):\n    def __init__(self, config):\n        super().__init__(config)\n\n        self.bert = BertModel(config)\n        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n        self.classifier = nn.Linear(config.hidden_size, 1)\n\n        self.init_weights()\n\n    \n    def forward(\n        self,\n        input_ids=None,\n        attention_mask=None,\n        token_type_ids=None,\n        position_ids=None,\n        head_mask=None,\n        inputs_embeds=None,\n        labels=None,\n    ):\n       \n        num_choices = input_ids.shape[1]\n\n        input_ids = input_ids.view(-1, input_ids.size(-1))\n        attention_mask = attention_mask.view(-1, attention_mask.size(-1)) if attention_mask is not None else None\n        token_type_ids = token_type_ids.view(-1, token_type_ids.size(-1)) if token_type_ids is not None else None\n        position_ids = position_ids.view(-1, position_ids.size(-1)) if position_ids is not None else None\n\t\t\t\t# 将bert三个输入展平 输入到bertmodel\n        outputs = self.bert(\n            input_ids,\n            attention_mask=attention_mask,\n            token_type_ids=token_type_ids,\n            position_ids=position_ids,\n            head_mask=head_mask,\n            inputs_embeds=inputs_embeds,\n        )\n\t\t\t\t# 隐层输出\n        # last_hidden_state: [32=4*batch, seq_len,768]\n        # pooler_ouput: [32=4*batch,768]\n        pooled_output = outputs[1] # CLS https://www.cnblogs.com/webbery/p/12167552.html\n        # bert_output = outputs[0] # last_hidden\n\n        pooled_output = self.dropout(pooled_output)\n        logits = self.classifier(pooled_output)\n        reshaped_logits = logits.view(-1, num_choices)\n\n        outputs = (reshaped_logits,) + outputs[2:]  # add hidden states and attention if they are here\n\n        if labels is not None:\n            loss_fct = CrossEntropyLoss()\n            loss = loss_fct(reshaped_logits, labels)\n            outputs = (loss,) + outputs\n\n        return outputs  # (loss), reshaped_logits, (hidden_states), (attentions)\n```\n\n做bert方面的模型扩展可以参考上面，其实就是BertModel加上了线性层。\n\n\n\n\n\n### 制造模型输入数据\n\n```python\nclass MyDataset(Dataset):\n    def __init__(self, dataframe):\n        self.df = dataframe\n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx): \n      #将一条数据从(文章,问题,4个选项)转成(文章,问题,选项1)、(文章,问题,选项2)...\n        label = self.df.label.values[idx]\n        question = self.df.Question.values[idx]\n        content = self.df.Content.values[idx]\n        choice = self.df.Choices.values[idx][2:-2].split('\\', \\'')\n        if len(choice) < 4: #如果选项不满四个，就补“不知道”\n            for i in range(4-len(choice)):\n                choice.append('D．不知道')\n        \n        content = [content for i in range(len(choice))]\n        pair = [question + ' ' + i[2:] for i in choice]\n        \n        return content, pair, label\n```\n\n$61536 = 15325\\times 4 + 71 \\times3+ 25\\times2 $\n\n数据将变成61536条\n\n如果用五折交叉验证： 训练集 49228 验证集12307\n\n如果Using 8 dataloader workers every process\n\n每个batch 8条数据的话  约等于每个epoch 训练集运行772次，验证集193次\n\n(这个地方不知道算的对不对)\n\n将数据做成bert需要的三种编码：\n\n```python\ndef collate_fn(data): \n  # 将文章问题选项拼在一起后，得到分词后的数字id，输出的size是(batch, n_choices, max_len)\n    input_ids, attention_mask, token_type_ids = [], [], []\n    for x in data:\n        text = tokenizer(x[1],\n                         text_pair=x[0],\n                         padding='max_length',  # 填充到使用参数max_length指定的最大长度，或者填充到模型的最大可接受输入长度(如果未提供该参数)。\n                         truncation=True,\n                         # TRUE或‘LIMEST_FIRST’：截断到使用参数max_length指定的最大长度，或者截断到模型的最大可接受输入长度(如果没有提供该参数)。这将逐个令牌截断令牌，如果提供了一对序列(或一批对)，则从该对中最长的序列中删除一个令牌。\n                         max_length=Param['max_len'],\n                         return_tensors='pt')  # 返回pytorch tensor格式\n        input_ids.append(text['input_ids'].tolist())\n        attention_mask.append(text['attention_mask'].tolist())\n        token_type_ids.append(text['token_type_ids'].tolist())\n    input_ids = torch.tensor(input_ids)\n    attention_mask = torch.tensor(attention_mask)\n    token_type_ids = torch.tensor(token_type_ids)\n    label = torch.tensor([x[-1] for x in data])\n    return input_ids, attention_mask, token_type_ids, label\n```\n\nDataLoader\n\n```python\ntrain_set = utils.MyDataset(train)\nval_set = utils.MyDataset(val)\n\n\"\"\"单卡直接写\"\"\"\ntrain_loader = DataLoader(train_set, batch_size=CFG['train_bs'], collate_fn=collate_fn, shuffle=True, num_workers=CFG['num_workers'])\nval_loader = DataLoader(val_set, batch_size=CFG['valid_bs'], collate_fn=collate_fn, shuffle=False, num_workers=CFG['num_workers'])\n\n\"\"\"多卡写法\"\"\"\n # 给每个rank对应的进程分配训练的样本索引\ntrain_sampler = DistributedSampler(train_set)\nval_sampler = DistributedSampler(val_set)\n # 将样本索引每batch_size个元素组成一个list 验证集不用\ntrain_batch_sampler = torch.utils.data.BatchSampler(train_sampler, batch_size=args.batch_size, drop_last=True)\n\n\ntrain_loader = DataLoader(train_set, batch_sampler=train_batch_sampler, pin_memory=False,\n                                  collate_fn=collate_fn, num_workers=2)\nval_loader = DataLoader(val_set, batch_size=args.batch_size, sampler=val_sampler, pin_memory=False, collate_fn=collate_fn, num_workers=2)\n```\n\nDistributedSampler/BatchSampler:\n\n[四Sampler源码](https://blog.csdn.net/m0_37400316/article/details/107210970)\n\n[（TORCH.NN.PARALLEL.DISTRIBUTEDDATAPARALLEL）时，DISTRIBUTEDSAMPLER(DATASET)用法解释](https://www.freesion.com/article/6505681767/)\n\n\n\n\n\n\n\nDataloader 中的 num_workers:\n\n加快训练进程\n为了加快训练过程，使用DataLoader类的num workers可选属性。\nnum workers属性告诉数据加载器实例要使用多少子进程来加载数据。默认情况下，num  workers值设置为0，值为0告诉加载程序在主进程内加载数据。\n这意味着训练将在主进程中按顺序工作。在训练过程中使用了一个batch，并且需要另一个batch之后，从磁盘读取批数据。现在，如果我们有一个worker进程，我们可以利用机器多个核的。这意味着在主进程准备好进行另一批处理时，下一批处理已经可以加载并准备就绪。这就是加速的来源。批处理使用其他工作进程加载，并在内存中排队。\n\n\n\n\n\n### 训练过程\n\n\n\n\n\n#### 优化配置\n\n多层不同学习率\n\n```python\nfc_para = list(map(id, model.module.classifier.parameters()))\nlstm_para = list(map(id, model.module.lstm.parameters()))\ngru_para = list(map(id, model.module.gru.parameters()))\nbase_para = filter(lambda p: id(p) not in fc_para, model.module.parameters())\nparams = [{'params': base_para},\n{'params': model.module.lstm.parameters(), 'lr': args.other_lr},\n{'params': model.module.gru.parameters(), 'lr': args.other_lr},\n{'params': model.module.classifier.parameters(), 'lr': args.fc_lr}]\nscaler = GradScaler() # 有v100的话还可以开半精度\noptimizer = AdamW(model.module.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n# criterion = nn.CrossEntropyLoss().cuda(local_rank)\ncriterion = utils.LabelSmoothingCrossEntropy().cuda(local_rank) # 标签平滑\n```\n\n\n\n#### 梯度累积\n\n由于机器显存限制，不得不用梯度累积来达到目的batch数。\n\n用多次小的 mini-batch 来模拟一个较大的 mini-batch，即：global_batch_size = batch_size*iter_size\n\nbatch size 和 learning rate 要等比例放大。但需要注意：特别大的 batch size 还需要再加上其他 trick 如 warmup 才能保证训练顺利（因为太大的初始 lr 很容易 train 出 nan）。\n\n```python\nloss = criterion(output, y) / args.accum_iter\n\nif ((step + 1) % args.accum_iter == 0) or ((step + 1) == len(train_loader)):\n    scaler.step(optimizer)\n    scaler.update()\n    scheduler.step()\n    optimizer.zero_grad()\n```\n\n苏神:[ 用时间换取效果：Keras梯度累积优化器](https://kexue.fm/archives/6794)\n\n\n\n\n\n#### loss计算与warmup\n\nwarmup顾名思义就是热身，在刚刚开始训练时以很小的学习率进行训练，使得网络熟悉数据，随着训练的进行学习率慢慢变大，到了一定程度，以设置的初始学习率进行训练，接着过了一些inter后，学习率再慢慢变小；学习率变化：上升——平稳——下降；\n\nwarm up setp（一般等于epoch*inter_per_epoch），当step小于warm up setp时，学习率等于基础学习率×(当前step/warmup_step)，由于后者是一个小于1的数值，因此在整个warm up的过程中，学习率是一个递增的过程！当warm up结束后，学习率以基础学习率进行训练，再学习率开始递减\n\n1、当网络非常容易nan时候，采用warm up进行训练，可使得网络正常训练；\n\n2、如果训练集损失很低，准确率高，但测试集损失大，准确率低，可用warm up；具体可看：https://blog.csdn.net/u011995719/article/details/77884728\n\n[[LR Scheduler]warmup](https://blog.zhujian.life/posts/f311f0.html)\n\n\n\n#### 模型保存与加载\n\n这里有个小地方要注意，因为多卡并行时model用DistributedDataParallel包装了，所以在save时不时直接的model.state_dict()，而是model.module.state_dict()。 这个问题当时困扰了我好久，模型保存完的都是没经过学习的参数。\n\n```python\nif val_acc > best_acc:\n    best_acc = val_acc\n    print(\"best:\", best_acc)\n    if distribute_utils.is_main_process():\n        torch.save(model.module.state_dict(),\n                   'spawn_adv_pgd_{}_fold_{}.pt'.format(args.model.split('/')[-1], fold))\n```\n\n\n\n\n\n\n\n\n\n## 提升点\n\n更长的文本（512、sliding window、xinet、longformer） \n\n- 滑动窗口把文章截成很多段然后取平均softmax\n- xlnet 不限制长度，时间长\n- longformer 4096 transformers有提供\n\n更好的模型（roberta、large、DUMA）\n\n- DUMA bert上再加attention\n\n更多的数据（爬虫、C3）\n\n- 先训练C3中文的有提升 但新改了规则说不让用外部数据了。\n\n比赛复盘[海华阅读理解比赛复盘]()\n\n\n\n\n\n\n\n## 遇到的问题\n\n1. 五折交叉验证有的轮次收敛有的轮次不收敛\n\n数据shuffle过，要加warmup用cosine lr，学习率往小调从2e-5调到1e-5\n\n还有一种情况是因为label不均衡造成的，每折数据不一样\n\n2. 验证集loss和acc都上涨\n\n现象很常见，原因是过拟合或者训练验证数据分布不一致造成。就是在训练后期，预测的结果趋向于极端，使少数预测错的样本主导了loss，但同时少数样本不影响整体的验证acc情况。\n\n\n\n\n\n\n\n## 可能用到的外部数据\n\n1、RACE dataset\n2、SQuAD2.0 and CoQA dataset\n3、ARC dataset\n4、DREAM dataset\n5、ChineseSquad，https://github.com/zengjunjun/ChineseSquad\n6、cmrc2018，https://github.com/ymcui/cmrc2018\n7、c3 dataset\n8、dureader dataset\n\n1、 爬取中学语文阅读理解试题（全部选项、无标注） https://github.com/sz128/ext_data_for_haihua_ai_mrc （内含网盘下载链接）\n2、C3数据：https://github.com/nlpdata/c3\n3、 开源的中文预训练语言模型：\n\nMacBERT (https://github.com/ymcui/MacBERT)\nChinese-BERT-wwm（https://github.com/ymcui/Chinese-BERT-wwm）\nChinese-ELECTRA（https://github.com/ymcui/Chinese-ELECTRA)\nALBERT-zh (https://github.com/brightmart/albert_zh)\nguwenBERT (https://github.com/Ethan-yt/guwenbert);","tags":["DataGame"]},{"title":"bfprt算法","url":"/2021/04/06/bfprt算法/","content":"\n# bfprt算法 求TopK\n\n**中位数的中位数算法** 最坏时间复杂度 $O(n)$\n\n在做topk问题时，最容易想到的就是先对所有数据进行一次排序，然后取其前k个。但问题有二：\n\n- 快排时间复杂度 $O(nlogn)$ ，但最坏时间复杂度 $O(n^2)$\n- 我们只要前k大的，而对其余的数也进行了排序，浪费了大量排序时间。\n\n除了这种方法堆排序也是一个比较好的选择，可以维护一个大小为k的堆，时间复杂度为 $O(nlogk)$\n\n## 堆排序topk\n\n- Heap是一种数据结构具有以下的特点：\n  1）**完全二叉树**；\n  2）heap中存储的值是**偏序**；\n- **Min-heap**: 父节点的值小于或等于子节点的值；\n  **Max-heap**: 父节点的值大于或等于子节点的值；\n- 一般都用数组来表示堆，i结点的父结点下标就为(i–1)/2。它的左右子结点下标分别为2 * i + 1和2 * i + 2\n- 堆中每次都删除第0个数据。为了便于重建堆，实际的操作是将最后一个数据的值赋给根结点，然后再从根结点开始进行一次从上向下的调整。\n\n```java\n# 大根堆比较器 top小\npublic  static class MaxheapComparator implements Comparator<Integer>{\n  @Override\n  public int compare(Integer o1, Integer o2){\n    return o2-o1;\n  }\n}\npublic static PriorityQueue getMinKNumsByHeap(int[] arr,int k){\n  if(k<1 || k>arr.length){\n    return null;\n  }\n  PriorityQueue<Integer> kHeap = new PriorityQueue<Integer>(k, new MaxheapComparator());\n  for(int i=0;i!=k;i++){\n    kHeap.add(arr[i]);\n  }\n  for(int i=k;i!=arr.length;i++){\n    if(arr[i]<kHeap.peek()){ // 返回第一个元素，而不从此PriorityQueue中删除一个元素。\n      kHeap.poll(); // 返回第一个元素，并从此PriorityQueue中删除一个元素。\n      kHeap.add(arr[i]);\n    }\n  }\n  return kHeap;\n}\npublic static void main(String[] args) {\n         int[] arr = { 1, 3, 2, 5, 9 };\n         // 测试普通方法\n         System.out.println(getMinKNumsByHeap(arr, 1).peek());\n         System.out.println(getMinKNumsByHeap(arr, 2).peek());\n         System.out.println(getMinKNumsByHeap(arr, 3).peek());\n         System.out.println(getMinKNumsByHeap(arr, 4).peek());\n         System.out.println(getMinKNumsByHeap(arr, 5).peek());\n     }\n```\n\n\n\n## 原理过程\n\n在快排基础上，先通过判断主元位置与k的大小使递归的规模变小。\n\n再通过修改快速排序中主元的选取方法来降低快速排序在最坏情况下的时间复杂度。\n\n- 选取主元\n\n- 以选取的主元为分界点，把小于主元的放到左边，大于主元的放到右边\n\n- 分别对左边和右边进行递归，重复上述过程\n\n  \n\n  \n\n\n\n1. 数组被划分为了 N/5 个小部分，每个部分的5个数排序需要 O(1) ，所有部分排完需要 O(N/5)=O(N)\n\n2. 取出每个小部分的中位数，一共有 N/5 个，递归调用BFPRT算法得到这些数中第 (N/5)/2 小的数（即这些数 的中位数），记为 pivot\n\n3. 以 pivot 作为比较，将整个数组划分为 <pivot , =pivot , >pivot 三个区域\n\n4. 判断第K小的数在哪个区域，如果在 = 区域则直接返回 pivot ，如果在 < 或 > 区域，则将这个区域的数递 归调用BFPRT算法\n\n5. base case ：在某次递归调用BFPRT算法时发现这个区域只有一个数，那么这个数就是我们要找的数\n\n```java\npublic static int getMinKthNum(int[] arr, int k){\n  if(arr==null || k>arr.length){\n    return Integer.MIN_VALUE;\n  }\n  int[] copyArr = Arrays.copyOf(arr, arr.length);\n  return BFPRT(copyArr, 0, arr.length-1, k-1);\n}\n// 取出每个小部分的中位数，一共有 N/5 个，递归调用BFPRT算法得到这些数中第 (N/5)/2 小的数（即这些数 的中位数），记为 pivot. 以 pivot 作为比较，将整个数组划分为 <pivot , =pivot , >pivot 三个区域\nprivate static int BFPRT(int[] arr, int begin, int end, int i){\n  if(begin==end) return arr[begin];\n  int pivot = medianOfMedians(arr, begin, end);\n  int[] pivotRange = partition(arr, begin, end, pivot);\n  if(i>= pivotRange[0] && i<=pivotRange[1]){\n    return arr[i];\n  } else if(i<pivotRange[0]){\n    return BFPRT(arr, begin, pivotRange[0]-1, i);\n  } else{\n    return BFPRT(arr, pivotRange[1]+1, end, i);\n  }\n}\n\nprivate static int[] partition(int[] arr, int begin, int end, int pivot){\n  int L= begin-1;\n  int R= end + 1;\n  int cur = begin;\n  while(cur!=R){\n    if(arr[cur]>pivot){\n      swap(arr, cur, --R);\n    } else if(arr[cur]<pivot){\n      swap(arr, cur++, ++L)\n    } else{\n      cur++;\n    }\n  }\n  return new int[]{L+1, R-1};\n}\n\nprivate static int medianOfMedians(int[] arr, int begin, int end){\n  int num = end - begin +1;\n  int offset = num % 5 ==0 ? 0 : 1;\n  int[] medians = new int[num/5 + offset];\n  for(int i=0;i<medians.length; i++){\n    int beginI = begin+i*5;\n    int endI = beginI + 4;\n    medians[i] = getMedian(arr, beginI, Math.min(endI, end));\n  }\n  return BFPRT(medians, 0, medians.length-1, medians.length/2);\n}\n\nprivate static int get Median(int[] arr, int begin, int end){\n  insertionSort(arr, begin, end);\n  int sum = end+begin;\n  int mid = (sum/2) + (sum%2);\n  return arr[mid];\n}\nprivate static void insertionSort(int[] arr, int begin, int end){\n  if (begin>=end) return;\n  for(int i=begin+1; i<=end; i++){\n    for(int j=i; j>begin; j--){\n      if(arr[j] < arr[j-1]){\n        swap(arr, j, j-1);\n      }else{\n        break;\n      }\n    }\n  }\n}\n```\n\n\n\n## 时间复杂度\n\n最坏情况下是 $O(n)$\n\n令 $T(n)$ 为所求的时间复杂度，则：\n$$\n\\begin{equation}\\begin{split} \n T(n) \\le T(\\frac {n}{5}) + T(\\frac{7n}{10}) + c\\cdot n\n    \\end{split}\\end{equation}\n$$\n\n\n- $T(\\frac n 5)$ 来自 GetPivotIndex()，n 个元素，5 个一组，共有 $⌊\\frac n5⌋$ 个中位数；\n- $T(\\frac {7n}{10})$ 来自 BFPRT()，在 $⌊\\frac n5⌋$ 个中位数中，主元 x 大于其中 $\\frac 12⋅\\frac n5=\\frac n{10}$ 的中位数，而每个中位数在其本来的 5 个数的小组中又大于或等于其中的 3 个数，所以主元 x 至少大于所有数中的 $\\frac n{10}⋅3=\\frac {3n}{10}$ 个。即划分之后，任意一边的长度至少为 $\\frac 3{10}$，在最坏情况下，每次选择都选到了 $\\frac 7{10}$ 的那一部分。\n- $c⋅n$ 来自其它操作，比如 InsertSort()，以及 GetPivotIndex() 和 Partition() 里所需的一些额外操作。\n\n设 $T(n)=t⋅n$，其中 t 为未知，它可以是一个正常数，也可以是一个关于 n 的函数，代入上式：\n\n$$ \\begin{align} t⋅n&≤\\frac {t⋅n}5+\\frac{7t⋅n}{10}+c⋅n \\tag{两边消去 n}\\\\ t&≤\\frac t 5+\\frac {7t}{10}+c \\tag{再化简}\\\\ t&≤10c \\tag{c 为一个正常数} \\end{align} $$\n\n其中 c 为一个正常数，故t也是一个正常数，即 $T(n)≤10c⋅n$，因此 $T(n)=O(n)$，至此证明结束。\n\n接下来我们再来探讨下 BFPRT 算法为何选 5 作为分组主元，而不是 2, 3, 7, 9 呢？\n\n首先排除偶数，对于偶数我们很难取舍其中位数，而奇数很容易。再者对于 3 而言，会有 $T(n)≤T(\\frac n 3)+T(\\frac {2n}3)+c⋅n$，它本身还是操作了 n 个元素，与以 5 为主元的 $\\frac {9n}{10}$ 相比，其复杂度并没有减少。对于 7，9，... 而言，上式中的 10c，其整体都会增加，所以与 5 相比，5 更适合。\n\n\n\n\n\n\n\n\n\n","tags":["刷题"]},{"title":"RoBERTa & Albert","url":"/2021/04/05/RoBERTa-Albert/","content":"\n# RoBERTa & Albert\n\n2021年了，bert的改进体也越来越多，Roberta和Albert是比较出名的两个改进体。\n\nRoberta主要针对bert的预训练任务如NSP，mask进行改进。并且扩大了batchsize和使用更长的序列训练，这两点可能在长文本竞赛上有作用。\n\nAlbert主要针对bert参数量太大，训练慢来进行改进。引入了跨层参数共享，embedding解绑分解，取消dropout和添加SOP预训练任务。\n\n\n\n## RoBERTa\n\n1. 使用更大的batch在更大的数据集上对Bert进行深度训练\n2. 不再使用NSP(Next Sentence Prediction)任务\n3. 使用更长的序列进行训练\n4. 动态改变训练数据的MASK模式\n\n\n\n### 静态Masking vs 动态Masking\n\n- 静态Masking:在数据预处理期间Mask矩阵就已经生成好了，每个样本只会进行一次随机Mask，每个epoch都是相同的。\n- 修改版静态Masking: 在预处理时将数据拷贝10份，每一份拷贝都采用不同的Mask，也就是说，同样的一句话有十种不同的mask 方式，然后每份数据都训练N/10个epoch\n- 动态Masking:每次向模型输入一个序列时，都会生成一种新的Mask方式，即不在预处理的时候进行mask，而是在向模型提供输入时动态生成Mask。\n\n![](https://i.loli.net/2021/04/05/zFrQXsCIgc98pu3.png)\n\n### 取消NSP任务\n\nRoBERTa 实验了 4 种方法：\n\n- SEGMENT-PAIR + NSP：输入包含两部分，每个部分是来自同一文档或者不同文档的 segment （segment 是连续的多个句子），这两个 segment 的 token 总数少于 512 。预训练包含 MLM 任务和 NSP 任务。这是原始 BERT 的做法\n- SENTENCE-PAIR + NSP：输入也是包含两部分，每个部分是来自同一个文档或者不同文档的单个句子，这两个句子的 token 总数少于 512 。由于这些输入明显少于 512 个 tokens，因此增加 batch size 的大小，以使 tokens 总数保持与 SEGMENT-PAIR + NSP 相似。预训练包含 MLM 任务和 NSP 任务\n- FULL-SENTENCES：输入只有一部分（而不是两部分），来自同一个文档或者不同文档的连续多个句子，token 总数不超过 512 。输入可能跨越文档边界，如果跨文档，则在上一个文档末尾添加标志文档边界的 token 。预训练不包含 NSP 任务\n- DOC-SENTENCES：输入只有一部分（而不是两部分），输入的构造类似于 FULL-SENTENCES，只是不需要跨越文档边界，其输入来自同一个文档的连续句子，token 总数不超过 512 。在文档末尾附近采样的输入可以短于 512 个 tokens， 因此在这些情况下动态增加 batch size 大小以达到与 FULL-SENTENCES 相同的 tokens 总数。预训练不包含 NSP 任务\n\n![](https://i.loli.net/2021/04/05/TqvNDS2WIXHBnAl.png)\n\n\n\n### 扩大Batch Size\n\n公认的因素：降低batch size会显著降低实验效果，具体可参考BERT，XLNet目录的相关Issue。\n\nRoberta 作者也证实了这一点。\n\n![](https://i.loli.net/2021/04/05/jRdWv3gEVMlLk14.png)\n\n其中，bsz 是 Batch Size；steps 是训练步数（为了保证 bsz*steps 近似相同，所以大 bsz 必定对应小 steps）；lr 是学习率；ppl 是困惑度，越小越好；最后两项是不同任务的准确率。\n\n### 文本编码\n\n- 基于 char-level ：原始 BERT 的方式，它通过对输入文本进行启发式的词干化之后处理得到。\n- 基于 bytes-level：与 char-level 的区别在于bytes-level 使用 bytes 而不是 unicode 字符作为 sub-word 的基本单位，因此可以编码任何输入文本而不会引入 UNKOWN 标记。\n\n\n\n\n\n## Albert\n\n最近在 NLP 领域的研究趋势是使用越来越大的模型，以获得更好的性能。ALBERT 的研究表明，无脑堆叠模型参数可能导致效果降低\n\n在论文中，作者做了一个有趣的实验\n\n> 如果更大的模型可以带来更好的性能，为什么不将最大的 BERT 模型 (BERT-large) 的隐含层单元增加一倍，从 1024 个单元增加到 2048 个单元呢？\n\n他们称之为 \"BERT-xlarge\"。令人惊讶的是，无论是在语言建模任务还是阅读理解测试（RACE）中，这个更大的模型的表现都不如 BERT-large\n\n![](https://i.loli.net/2021/04/05/5kJfDmlt8xiUFCv.png)\n\n\n\n### 概述\n\nALBERT 利用了参数共享、矩阵分解等技术大大减少了模型参数，用 SOP（Sentence Order Prediction） Loss 取代 NSP（Next Sentence Prediction） Loss 提升了下游任务的表现。但是 ALBERT 的层数并未减少，因此**推理时间（Inference Time）还是没有得到改进**。不过参数减少的确使得训练变快，同时 ALBERT 可以扩展到比 BERT 更大的模型（ALBERT-xxlarge），因此能得到更好的表现\n\n具体的创新部分有三个：\n\n1. embedding 层参数因式分解\n2. 跨层参数共享\n3. 将 NSP 任务改为 SOP 任务\n\n#### Factorized Embedding Parameterization\n\n原始的 BERT 模型以及各种依据 Transformer 的预训连语言模型都有一个共同特点，即 E=H，其中 E 指的是 Embedding Dimension，H 指的是 Hidden Dimension。这就会导致一个问题，当提升 Hidden Dimension 时，Embedding Dimension 也需要提升，最终会导致参数量呈平方级的增加。\n\n所以 ALBERT 的作者将 **E 和 H 进行解绑**，具体的操作就是**在 Embedding 后面加入一个矩阵进行维度变换**。E 的维度是不变的，如果 H 增大了，我们只需要在 E 后面进行一个升维操作即可\n\n![](https://i.loli.net/2021/04/05/8FjUN5XrKWAqvsP.png)\n\n所以，ALBERT 不直接将原本的 one-hot 向量映射到 hidden space size of H，而是分解成两个矩阵，原本参数数量为 V∗H，V 表示的是 Vocab Size。分解成两步则减少为 V∗E+E∗H，当 H 的值很大时，这样的做法能够大幅降低参数数量\n\n> V∗H=30000∗768=23,040,000\n>\n> V∗E+E∗H=30000∗256+256∗768=7,876,608\n>\n> 举个例子，当 V 为 30000，H 为 768，E 为 256 时，参数量从 2300 万降低到 780 万\n\n通过因式分解 Embedding 的实验可以看出，对于参数不共享的版本，随着 E 的增大，效果是不断提升的。但是参数共享的版本似乎不是这样，E 最大并不是效果最好。同时也能发现参数共享对于效果可能带来 1-2 个点的下降\n\n![](https://i.loli.net/2021/04/05/5W9ytZiukCfdLmQ.png)\n\n```python\ndef __init__(self):\n  self.emb = nn.Embedding(vocab_size, 128)\n  self.fc = nn.Linear(128, 1024)\ndef forward(self, x):\n  x = self.emb(x)\n  x = self.fc(x) # [batch_size, seq_len, 1024]\n```\n\n\n\n#### Cross-Layer Parameter Sharing\n\n传统 Transformer 的每一层参数都是独立的，包括各层的 self-attention、全连接。这样就导致层数增加时，参数量也会明显上升。之前有工作试过单独将 self-attention 或者全连接层进行共享，都取得了一些效果。ALBERT 作者尝试将所有层的参数进行共享，相当于只学习第一层的参数，并在剩下的所有层中重用该层的参数，而不是每个层都学习不同的参数\n\n![](https://i.loli.net/2021/04/05/zOjWTLiGyaXMvnq.png)\n\n使用参数共享提升了模型 的稳定性，曲线更平滑了。\n\nBERT-base 和 ALBERT 使用相同的层数以及 768 个隐藏单元，结果 BERT-base 共有 1.1 亿个参数，而 ALBERT 只有 3100 万个参数。通过实验发现，feed-forward 层的参数共享会对精度产生比较大的影响；共享注意力参数的影响是最小的\n\n![](https://i.loli.net/2021/04/05/V3Tf6EhcAiuXder.png)\n\n```python\n# 参数共享例子\ndef __init__(self):\n    self.enc_layer = TransformerEncoder()\ndef forward(self, x):\n    for _ in range(12):\n        x = self.enc_layer(x)\n# 参数不共享例子        \ndef __init__(self):\n    self.enc_layer1 = TransformerEncoder()\n    self.enc_layer2 = TransformerEncoder()\n    ....\n    self.enc_layer12 = TransformerEncoder()\ndef forward(self, x):\n    x = self.enc_layer1(x)\n    x = self.enc_layer2(x)\n    ....\n    x = self.enc_layer12(x)\n# 分组参数共享\ndef __init__(self):\n    self.enc_layer1 = TransformerEncoder()\n    self.enc_layer2 = TransformerEncoder()\ndef forward(self, x):\n    for i in range(11):\n      enc_inputs = self.encoder_layer(enc_inputs)\n    x = self.enc_layer2(x)\n```\n\n#### Sentence-Order Prediciton (SOP)\n\n**BERT** 引入了一个叫做**下一个句子预测**的二分类问题。这是专门为提高使用句子对，如 \"自然语言推理\" 的下游任务的性能而创建的。但是像 RoBERTa 和 XLNet 这样的论文已经阐明了 NSP 的无效性，并且发现它对下游任务的影响是不可靠的\n\n因此，ALBERT 提出了另一个任务 —— **句子顺序预测**。关键思想是：\n\n- 从同一个文档中取两个连续的句子作为一个正样本\n- 交换这两个句子的顺序，并使用它作为一个负样本\n\n![](https://i.loli.net/2021/04/05/XHDghABQW6Y2Fdf.png)\n\n![](https://i.loli.net/2021/04/05/K7vIQg5C2GthUda.png)\n\n#### Adding Data & Remove Dropout\n\n以上 ALBERT 都是使用跟 BERT 相同的训练数据。但是增加训练数据或许可以提升模型的表现，于是 ALBERT 加上 STORIES Dataset 后总共训练了 157G 的数据。另外，训练到 1M 步的时候，模型还没有对训练集 Overfit，所以作者直接把 Dropout 移除，最终在 MLM 验证集上的效果得到了大幅提升\n\n![](https://i.loli.net/2021/04/05/8u3sZJXQ4EFcn2C.png)\n\n\n\n#### Conclusion\n\n刚开始看这篇文章是很惊喜的，因为它直接把同等量级的 BERT 缩小了 10 + 倍，让普通用户有了运行可能。但是仔细看了实验后才发现参数量的减小是需要付出代价的\n\n![](https://i.loli.net/2021/04/05/U37dpafWzxT4lqD.png)\n\n需要注意的是，Speedup 是训练时间而不是 Inference 时间。Inference 时间并未得到改善，因为即使是使用了共享参数机制，还是得跑完 12 层 Encoder，故 Inference 时间跟 BERT 是差不多的\n\n实验用的参数如下\n\n![](https://i.loli.net/2021/04/05/svcV1HRtMd7jxX8.png)\n\n可以得出的结论是：\n\n1. 在相同的训练时间下，ALBERT 得到的效果确实比 BERT 好\n2. 在相同的 Inference 时间下，ALBERT base 和 large 的效果都没有 BERT 好，而且差了 2-3 个点，作者在最后也提到了会继续寻找提高速度的方法（Sparse attention 和 Block attention）\n\n另外，结合 **Universal Transformer** 可以想到的是，在训练和 Inference 阶段可以动态地调整 Transformer 层数（告别 12、24、48 的配置）。同时可以想办法去避免纯参数共享带来的效果下降，毕竟 Transformer 中越深层学到的任务相关信息越多，可以改进 Transformer 模块，加入记忆单元、每层个性化的 Embedding\n\n\n\n\n\n\n\n","tags":["nlp"]},{"title":"Heterogeneous Graph Neural Network","url":"/2021/03/30/Heterogeneous-Graph-Neural-Network/","content":"\n# Heterogeneous Graph Neural Network\n\n\n\n## 摘要\n\n挑战：不仅是因为需要合并由多种类型的节点和边组成的异质结构(图)信息，而且还因为需要考虑与每个节点相关联的异质属性或内容(例如，文字或图像)。\n\n方法：C1引入了一种带重启的随机游走策略，对每个节点的固定大小的强相关异构邻居进行采样，并根据节点类型对它们进行分组。\n\n接下来，设计一个包含两个模块的神经网络体系结构，用来聚合那些采样的相邻节点的特征信息。\n\n第一个模块C2：对异构内容的“深度”特征交互进行编码，并为每个节点生成内容Embedding。\n\n第二个模块C3：聚合不同相邻组(类型)的内容(属性)嵌入，并通过考虑不同组的影响来进一步组合它们，以获得最终的节点嵌入。\n\nHetGNN用途：在边链接预测、推荐、节点分类和聚类以及归纳节点分类和聚类等各种图挖掘任务\n\n\n\n## 异质图\n\n![](https://i.loli.net/2021/03/30/BAJN9XrwndLE5zW.png)\n\n学术图中，\n\n关系：作者与论文(写作)、论文与论文(引文)、论文与期刊(出版)\n\n此外，该图中的节点携带属性 如作者有id属性、文本有论文摘要属性。\n\n## 挑战\n\n![](https://i.loli.net/2021/03/30/a74yHiAdxeXI1jn.png)\n\n- 1：现有的GNN大多只聚合直接（一阶）相邻节点的特征信息，特征传播过程可能会削弱远邻节点的影响。此外，“中心”节点的嵌入生成受到弱相关邻居（“噪声”邻居）的影响，“冷启动”节点的嵌入由于邻居信息有限而没有得到充分的表示。因此，挑战1是：如何为HetG中的每个节点采样与嵌入生成密切相关的异构邻居。如上图C1。(信息聚合考虑的信息不够多)\n\n  方法：基于重启策略的随机游走，采样固定大小强相关异构邻居，并根据节点类型进行分组。\n\n- 2：HETG中的一个节点可以携带非结构化的异构内容。如上图C2，type1有属性＋文本，type2有属性+图片。因此挑战2是：如何设计节点内容编码器来解决HetG中不同节点的内容异构性。(异构属性信息如何嵌入)\n\n  方法：聚合模块1，用RNN对异构内容的“深层”特征交互进行编码，得到每个节点的内容嵌入。\n\n- 3：不同类型的邻居对HetG中节点嵌入的贡献不同。目前的GNN主要集中在齐次图上，没有考虑节点类型的影响。因此，挑战3是：如何通过考虑不同节点类型的影响来聚合异构邻居的特征信息，如图上图C3。(不同类型节点如何聚合)\n\n  方法：聚合模块2，利用另一个RNN聚合不同邻域组的内容嵌入，并进一步通过注意力机制进行组合，以度量异构节点类型的不同影响，并获得最终的节点嵌入。\n\n\n\n和其他模型对比\n\n![](https://i.loli.net/2021/03/30/a5wPN1Uc8hnB9Tu.png)\n\n## C-HetG\n\n内容关联异质图\n\n定义为有多种类型的节点V和边E的图。$G=(V，E，O_V，R_E)$。\n\n$O_V$ 和 $R_E$ 分别表示对象类型的集合和关系类型的集合。\n\n此外，每个节点与不同种类的内容相关联(例如，属性、文本或图像)。\n\n\n\n## 基于重启策略的随机游走 C1\n\n和GAT/GCN采样一阶邻居不一样。他们不能聚合多种类型节点的信息，并且采样信息不完整。\n\nHetGNN用这个方法采样。\n\nStep1：采样固定大小长度的随机游走路径$RWR(v)$ 。以概率p决定是走到当前节点还是返回上一节点。 v是起始节点，$RWR(v)$ 中不同类型节点的数量受到限制，以确保可以采样所有节点类型。\n\nStep2:：对不同类型的邻居进行分组。对于每个节点类型t，根据频率从 $RWR(v)$ 中选择前kt个节点，并将它们作为节点v的t型相关邻居的集合。\n\n保证了手机每个节点都有所有类型邻居的信息，并且对相同类型的邻居进行分组，以便后续任务。\n\n\n\n## 异质内容编码 C2\n\n![](https://i.loli.net/2021/03/30/O34hFWBto5xnsYT.png)\n\n对于第二个挑战，设计此模块去提取图中的异质内容$C_v$ ,编码为固定大小的embedding。\n\n定义$C_v$ 中的第i个特征表达为 $x_i \\in R^{d_f\\times 1}$\n\n$x_i$ 可以根据不同类型的内容采用不同的技术进行预训练。例如，可以利用Par2Vec来预先训练文本内容，或者使用CNNs来预先训练图像内容。 下面的 $FC_{\\theta_x}$ 就代表不同的特征转换器，参数为$\\theta_x$。\n\n采用双向LSTM学习深度特征：\n$$\n\\begin{equation}\\begin{split} \n    f_1(v) =\\frac {\\sum_{i\\in C_v}[\\overrightarrow{LSTM}\\{FC_{\\theta_x}(x_i) \\} \\oplus \\overleftarrow{LSTM} \\{ FC_{\\theta_x}(x_i)  \\}]}{ |C_v|}\n    \\end{split}\\end{equation}\n$$\n\n\n$\\oplus$ 链接操作。LSTM公式：\n$$\n\\begin{equation}\\begin{split} \n z_i &= \\sigma (U_zFC_{\\theta_x}(x_i) + W_zh_{i-1} + b_z) \\\\\n  f_i &= \\sigma (U_fFC_{\\theta_x}(x_i) + W_fh_{i-1} + b_z) \\\\\n   o_i &= \\sigma (U_oFC_{\\theta_x}(x_i) + W_oh_{i-1} + b_z) \\\\\n   \\tilde c_i &= tanh(U_cFC_{\\theta_x}(x_i)+ W_ch_{i-1} + b_c)\\\\\n   c_i &= f_i \\circ c_{i-1} + z_i \\circ \\tilde c_i\\\\\n   h_i &= tanh(c_i) \\circ o_i\n \\end{split}\\end{equation}\n$$\n\n## 聚合异构邻居 C3\n\n包含两个步骤：\n\n- 同类邻居聚合\n- 类型邻居聚合\n\n### 同类型聚合\n\n![](https://i.loli.net/2021/03/30/uh5zVmLsHNKiMyf.png)\n\n使用随机游走对每个节点的不同节点类型的固定大小邻居进行采样后。\n\n将$v∈V$ 的t类型抽样邻居集表示为$N_t(v)$\n\n经过上面的内容嵌入后变为$ v' \\in N_t(v)$ \n\n然后使用神经网络$f_2^t$ 来聚合得到的内容嵌入。\n\n聚合嵌入公式为：\n$$\n\\begin{equation}\\begin{split} \n f_2^t(v) = AGG_{v'\\in N_t(v)}^t \\{ f_1(v')\\}\n    \\end{split}\\end{equation}\n$$\n还是使用的Bi-LSTM：\n$$\n\\begin{equation}\\begin{split} \n f_2^t(v) =\\frac {\\sum_{v'\\in N_{t(v)}}[\\overrightarrow{LSTM}\\{f_1(v') \\} \\oplus \\overleftarrow{LSTM} \\{ f_1(v')  \\}]}{ |N_{t(v)}|}\n    \\end{split}\\end{equation}\n$$\n使用Bi-LSTM来聚集所有t型邻居的内容嵌入，并使用所有隐藏状态的平均值来表示一般的聚集嵌入。我们使用不同的Bi-LSTM来区分邻居聚合的不同节点类型。Bi-LSTM对无序邻域集进行操作，该集合的灵感来自于GraphSAGE\n\n### 类型邻居聚合\n\n![](https://i.loli.net/2021/03/30/4yp3YDo8l7JhSAc.png)\n\n上一步为节点v生成$|O_v|$ 聚集嵌入 (图中的节点类型集)。\n\n为了将这些基于类型的邻居嵌入与v的内容嵌入相结合，采用了注意机制。\n\n其动机是不同类型的邻居将对v的最终表示做出不同的贡献。因此，输出嵌入被表示为：\n$$\n\\begin{equation}\\begin{split} \n \\epsilon_v = a^{v,v} f_1(v) + \\sum_{t\\in O_v} \\alpha^{v,t} f_2^t(v)\n    \\end{split}\\end{equation}\n$$\n$\\epsilon_v \\in \\Re^{d\\times 1}$  , d 是嵌入维度\n\n$f_1(v)$ 是获得v的内容嵌入\n\n$f_2^t(v)$ 是类型聚合嵌入\n\n$\\alpha^{v,*}$  表示不同嵌入的重要性\n\n定义：$F(v) =\\{ f_1(v) \\bigcup (f_2^t(v) ,t\\in O_v)\\}$\n$$\n\\begin{equation}\\begin{split} \n \\alpha^{v,i} = \\frac{ exp \\{LeakyReLU(u^T[f_i\\oplus f_1(v)])\\}}{\\sum_{f_j\\in F(v)} exp\\{ LeakyReLU(u^T[f_j\\oplus f_1(v)]) \\}}\n    \\end{split}\\end{equation}\n$$\n\n\n## \n\n\n\n\n\n\n\n\n\n## HetGNN\n\n![](https://i.loli.net/2021/03/30/FKu5qcMT1AahHlk.png)\n\n四个组成部分\n\n- 采样异质邻居\n- 编码节点的异质内容\n- 聚合异质邻居\n- 制定目标函数，设计训练过程。\n\n\n\n\n\n\n\n","tags":["GNN"]},{"title":"Cognitive Graph for Multi-Hop Reading Comprehension at Scale(ACL2019)","url":"/2021/03/27/Cognitive-Graph-for-Multi-Hop-Reading-Comprehension-at-Scale-ACL2019/","content":"\n# Cognitive Graph for Multi-Hop Reading Comprehension at Scale(ACL2019)\n\nppt : https://coding-zuo.github.io/CogQA_RevealJS/ \n\n## 认知图谱\n\n知识图谱+认知推理+逻辑表达。\n认知图谱依据人类认知的双加工理论，动态构建带有上下文信息的知识图谱并进行推理。\n认知图谱可以被解释为“基于原始文本数据，针对特定问题情境，使用强大的机器学习模型动态构建的，节点带有上下文语义信息的知识图谱”。\n\n**认知图谱和知识图谱的区别？**\n认知图谱是包含知识图谱的相关技术的。知识图谱的任务主要是包括知识图谱的表示、构建和存储。这些是构建知识库的过程。认知推理的底层是知识推理，而知识图谱目的是完善知识。面向知识图谱的认知推理可以基于已有的知识推理出新的知识，或者发现错误矛盾的知识。认知图谱是为了解决复杂理解问题或少样本知识图谱推理问题如歧义问题、链接困难、关系的冗余与组合爆炸等。认知推理其实更具有人脑特性，相对更动态一些，可以基于知识感知来调整推理，也可以基于推理来调整知识和感知。交叉了认知科学对人类知识的总结，有助于划分和处理知识图谱的相关问题。\n\n认知图谱主要有三方面创新，分别对应人类认知智能的三个方面：\n\n1.（长期记忆）直接存储带索引的文本数据，使用信息检索算法代替知识图谱的显式边来访问相关知识。\n\n2.（系统1推理）图谱依据查询动态、多步构建，实体节点通过相关实体识别模型产生。\n\n3.（系统2推理）图中节点产生的同时拥有上下文信息的隐表示，可通过图神经网络等模型进行可解释的关系推理。\n\n本质上，认知图谱的改进思路是减少图谱构建时的信息损失(两元一谓)，将信息处理压力转移给检索和自然语言理解算法，同时保留图结构进行可解释关系推理。\n\n![](https://i.loli.net/2021/03/27/2mdSVkFas3NlWhQ.png)\n\n\n\n\n\n## 摘要\n\n- 提出新的多跳QA框架CogQA\n- 基于双过程理论System1:隐式提取，System2:显式推理\n- 可以给出答案的解释路径\n- 基于Bert和GNN处理HotpotQA数据集\n- 评估指标F1 score\n\n## Introduction\n\n现在的单段阅读理解机器已经超过人了，像SQuAD。但要跨过机器阅读理解和人阅读理解的鸿沟还很难。\n\n主要有三个主要挑战：\n\n- 理解能力：如对抗性测试所揭示的那样，单段问答模型倾向于在与问题匹配的意义中寻找答案，这不涉及复杂的推理。因此多跳阅读是要克服的。\n- 可解释性：显式推理路径能够验证逻辑严格性，对质量保证系统的可靠性至关重要。数据集中给出的是无序的句子级别的解释，但我们人可以通过逻辑一步一步给出有序的、实体级别的解释。\n- 大规模的(时间成本)：任何QA系统都要处理大规模的知识。现在已有的DrQA是通过预检索来减少规模到几个段落的范围。这个框架是单段阅读和多段阅读的结合，但和人脑中大量记忆和知识而言是一种折中的做法。时间成本不会随着段落增加而增加。\n\n### 两个系统的工作\n\n**隐式提取System1**：模仿大脑通过隐式注意提取相关信息，是直觉和无意识的系统。\n从段落中提取与问题相关的实体和答案日期，并对其语义信息进行编码。\n\n![](https://i.loli.net/2021/03/27/jY967V5RuPvpgm8.jpg)\n\n如上图，系统一从段落和语义信息中提取问题相关的实体和答案候选。\n\n**显式推理System2**：在System1基础上进行有意识的的可控的推理。\n\n系统一根据提出的问题提供给系统二资源，系统二根据信息进行深度推理，挖掘相关信息。两个系统协作，迭代的给出快慢思考。\n\n在信息一提出出的信息图上，搜集线索。并且指导系统一更好的提取下一跳实体。\n\n迭代直到所有可能的答案都被找到，再由系统二推理出最终答案。\n\n![](https://i.loli.net/2021/03/27/lO9sy8hDARqk3uI.jpg)\n\n\n\n`系统1(system 1)负责经验性的直觉判断，这一黑盒过程提取重要信息，并动态构建认知图谱；系统2(system 2)则在图上进行关系推理，由于认知图谱保留了实体节点上语义信息的隐表示，所以在符号逻辑之外，比如图神经网络等深度学习模型也可以大显身手。`\n\n![](https://i.loli.net/2021/03/27/SPXlQ4nOkLcpARH.jpg)\n\n这块有一个缺点，GCN在有节点新加入的时候要重新训练图模型？这个要等我研究研究源码\n\n前沿节点(frontier node)有两种:\n\n- 新添加的节点\n- 图中新添加边的节点(需重新访问)\n\n\n系统1在线索和问题Q的指导下读取para[x]，提取跨度并生成语义向量sem[x，Q，clues]。同时，系统2更新隐藏表示X，并为任何后继节点y准备线索clues[y，G]。基于X进行最终预测。\n\n算法流程\n1.提取在问题Q中提到的实体作为认知图的初始化，并且标记为前沿节点。\n2.重复下面过程直到21(在每一步中，我们访问一个前沿节点x)\n3.从前沿节点中跳出一个节点x\n4.从前沿节点收集线索clues[x,G],例如线索可以是提及x的句子。(线索句可以是提到的x的句子)\n5.在词库W中找到包含x的段落para[x]\n6.system1生成语义向量sem[x,Q,clues],初始化X[x]\n7.如果x是一个hop节点\n8.system1在para[x]中找到hop和answer的局部\n9.遍历hop内容，每个内容为y\n10.如果内容y不在G内并且y在词库W内\n11.用y创建一个新的hop节点\n12.如果y属于G，并且x和y的边不在图内\n13.在图中添加x和y的连线\n14.让节点y作为一个前沿节点\n15.循环结束\n16.答案部分，每个答案是y\n17.添加一个新的答案节点y和edge(x,y)到G中\n18.循环结束\n19.x过程结束\n20.用System2更新隐含X的表示\n21.直到G中没有前沿节点或G足够大；\n22.返回答案节点中概率最大的节点作为最终答案。\n\n关于可解释性，认知图谱有显式的路径，除了简单的路径，认知图还可以清楚地显示联合或循环推理过程。\n在这些过程中，可能会带来关于答案的新线索。\n\n尺度可伸缩性，框架理论上是可伸缩的，因为引用所有段落的唯一操作是通过标题索引访问哪些段落。\n\n对于多跳问题，传统的检索-抽取框架可能会牺牲后续模型的潜力，因为距离问题多跳的段落可能共享的常用词很少，与问题的语义关系也很小，导致检索失败。然而，这些段落可以通过在我们的框架中使用线索迭代展开来发现。\n\n## 实施方案\n\n![](https://i.loli.net/2021/03/27/A7W8mvJ1z2sioSc.jpg)\n\n### System1\n系统1的作用，在线索clues和问题Q的指导下提取spans并生成语义向量sem[x,Q,clus]。\nclues是前置节点段落的句子，从文中直接提取原始句子，这样做方便BERT训练。\n\n![](https://i.loli.net/2021/03/27/A7W8mvJ1z2sioSc.jpg)\n\nBert的输入句子分为A和B两部分：\n$$\n    \\begin{equation}\\begin{split} \n    A:[CLE]Question[SEP]clues[x,G][SEP]B:Para[x]\n    \\end{split}\\end{equation}\n$$\n\n\\[CLE\\]:放在每个句子的第一位，classification用于下游分类任务。\n为什么用CLS？因为self-attention，[CLS]的output含有整句话的完整信息。在每个词的时候，对自己这个词的评分会很大。用无意义的CLS可以公平的反应整个句子的特征。\n\\[SEP\\]:separator分隔连接token序列的符号。\n\n![](https://i.loli.net/2021/03/27/7ROBPrVjkQfH91s.jpg)\n\n$$\n    \\begin{equation}\\begin{split} \n    P^{start}_{ans}[i]=\\frac{e^{S_{ans} \\cdot T_i}}{\\sum_je^{S_{ans}\\cdot T_j}}\n    \\end{split}\\end{equation}\n$$\n\n$S_{hop}$、$E_{hop}$、$S_{ans}$、$E_{ans}$ :可学习的参数，用来预测目标span。\n$T\\in R^{L\\times H}$:是bert的输出向量,L是输入序列长度，H是隐层维度。\n$P^{start}_{ans}[i]$:是第i个输入token到ans范围内开始位置的概率。\n\n\n\n\n\n我们只聚焦topK开始的概率${start_k}$,对于每个k的结束位置$end_k$:\n$$\n    \\begin{equation}\\begin{split} \n    end_k = argmax_{start_k\\leq j\\leq start_k + maxL }P^{end}_{ans}[j]\n    \\end{split}\\end{equation}\n$$\nmaxL：是最大概率的span长度。\n$P^{end}_{ans}[j]$:是第j个输入token到ans范围内结束位置的概率。\n\n文章说是这么区分下一跳和答案的：\n答案和下一跳协议具有不同的属性。答案提取在很大程度上依赖于问题所指示的字符。例如，“纽约市”比“2019”更有可能是WHERE问题的答案，而下一跳实体通常是其描述与问题中的语句相匹配的实体。\n\n为了识别不相关的段落，利用在§3.4.1中引入负抽样进行训练，系统1生成负阈值。在顶部\nk个跨度，起始概率小于负阈值将被丢弃。因为对第0个token[CLS]进行预训练以合成\n用于下一句预测的所有输入标记任务Pstart[0]充当ANS这是我们实施过程中的一个阈值。\n\n### System2\n系统2，更新隐藏表示X，并为任何后继节点y准备clues[y，G]。基于X输出最终预测结果。\n\n第一个功能是为前沿节点准备clues[x，G]，我们将其实现为收集提到x的x个前置节点的原始语句。\n第二个功能是更新隐含表示X，这是系统2的核心功能。隐含表示$X∈R^{n×H}$代表G中所有n个实体的理解。要完全理解实体x与问题q之间的关系，仅仅分析语义sem[x，Q，clues]是不够的。由于图结构的归纳偏差，GNN已被提出用于对图进行深入学习，特别是关系推理。\n\n$$\n    \\begin{equation}\\begin{split} \n    \\Delta = \\sigma((AD^{-1})^T\\sigma(XW_1))\n    \\end{split}\\end{equation}\n$$\n$$\n    \\begin{equation}\\begin{split} \n    X’=\\sigma(XW_2+\\Delta)\n    \\end{split}\\end{equation}\n$$\n$W_1,W_2 \\in R^{H\\times H}$:权重矩阵\n$\\sigma(XW_1)$ 左乘$(AD^{-1})^T$(列归一化A):可以解释为局部化光谱过滤.\n在访问边界节点x的迭代步骤中，其隐藏表示X[x]按照公式(4)(5)更新。\n在实验中发现“异步更新”在性能上没有明显的差别，在G最终确定后，将所有节点的X一起分多步更新，效率更高，在实践中被采用。\n\n\n\n### 训练细节\n\n模型采用负采样，在训练集的段落中预先提取下一跳hop和answer span。\n对于每个para[x]和问题Q有下面这种字典数据。\n$$\n    \\begin{equation}\\begin{split} \n    D[x,Q] = \\{(y_1,start_1,end_1),...,(y_n,start_n,end_n)\\}\n    \\end{split}\\end{equation}\n$$\n$start_i$和$end_i$ 是在para[x] 中根据一个实体或者答案$y_i$模糊匹配出来的。\n\n### 任务1：Span Extraction\n\n基于$D[x,Q]$，得到$P^{start}_{ans}$,$P^{end}_{ans}$,$P^{start}_{hop}$,$P^{end}_{hop}$\n在每个段落中最多出现一个$answer(y,start,end)$\n因此，定义一个one-hot向量$g_{ans}^{start}$ ，其中$g_{ans}^{start}[start]=1$。然而，一个段落中可能出现多个不同的ans next-hop spans，因此$g_{hop}^{start_i}[start]=1/k$ ，其中k是下一跳跨度的数量。\n\n为了能够区分不相关的段落，在G中预先增加了不相关的negative-hop节点。\n\n### 任务2：预测答案节点\n\n\n\n\n\n## 实验\n\n### 数据集\n\n使用HotpotQA的全维基设置来构建实验。基于维基百科文档中的第一段图，众包收集了112,779个问题，其中84%的问题需要多跳推理。数据被分成训练集(90,564个问题)、发展集(7,405个问题)和测试集(7,405个问题)。开发和测试集中的所有问题都是困难的多跳案例。\n\n \n\n## 总结&展望\n系统2的推理如何实现？现在的方法（如图神经网络）虽然使用关系边作为归纳偏置，却仍然无法执行可控、可解释、鲁棒的符号计算。系统1如何为现有的神经-符号计算方法提供可行前续工作？\n\n文本库应该如何预处理或预训练，才能有助于访问相关知识的检索？\n\n另辟蹊径？本文介绍的认知图谱是基于认知科学的双通道理论，是否还存在其他支撑理论？或者直接构建一个符号推理和深度学习相结合的新型学习架构？\n\n如何与人类记忆机理相结合？人类记忆机理包括长期记忆和短期记忆，但其工作模式和工作机理并不清楚。长期记忆可能存储的是一个记忆模型，记忆模型不再是一个概念的网络，而是一个计算模型的网络。\n\n认知图谱如何与外界反馈相结合是一个全新的问题。当然这里可以考虑通过反馈强化学习来实现，但具体方法和实现模式还需要深入探讨。\n\n## 参考文献\n[浅谈多跳阅读理解](https://zhuanlan.zhihu.com/p/133483274)\n[BERT的[CLS]有什么用](https://www.pianshen.com/article/5232700066/)\n[从Word Embedding到Bert模型—自然语言处理中的预训练技术发展史](https://zhuanlan.zhihu.com/p/49271699)\n[从知识图谱到认知图谱：历史、发展与展望](http://toutiao.secjia.com/knowledge-map-to-cognitive-map-0820/)\n[图神经网络及其在知识图谱中的应用](https://zhuanlan.zhihu.com/p/208697908?utm_source=wechat_timeline)\n[还在用[CLS]？从BERT得到最强句子Embedding的打开方式！](http://www.360doc.com/content/20/1227/10/7673502_953710193.shtml)\n\n\n\n\n\n","tags":["GNN&nlp"]},{"title":"Multi-hop Reading Comprehension across Multiple Documents by Reasoning over Heterogeneous Graphs","url":"/2021/03/27/Multi-hop-Reading-Comprehension-across-Multiple-Documents-by-Reasoning-over-Heterogeneous-Graphs/","content":"\n# Multi-hop Reading Comprehension across Multiple Documents by Reasoning over Heterogeneous Graphs\n\n\n\n京东出品19年采用异质图网络的一篇多跳阅读理解，这篇是在WikiHopQA数据集上，在没有使用预训练语言模型的情况下第一次超过人类表现。20年还有一篇在HotpotQA上的，过两天准备也读一读。前一阵子用京东在线客服和智能语音客服的时候，感觉效果不错，果然发现这两篇文章。\n\n先说一下WikiHopQA\n\n训练集43,738个样本，开发集5129个。候选答案个数2-79个之间，平均19.8个。文档数3-63个，平均13.7篇。每篇文档的字数4-2046字，平均100.4个字。该数据集的难度在于，要从多篇文章中找相关文档，还要依据多篇文章做推理。推理跳数的增加，与问题的相关性越来越小，统计距离较远，非参数化的检索方法如传统的TF-IDF，无法搜索到最终答案所在的上下文。如下图：\n\n![](https://i.loli.net/2021/03/27/IrqT6k5tdo9Az37.png)\n\n每个样本包含字段：dict_keys(['answer', 'id', 'candidates', 'query', 'supports'])\n\n目前主要做法有三种思路：构造推理链，一般用RNN网络进行链式推理；从网络模型角度改进；构造graph，利用GCN，GAT等方法在图上推理。\n\n和HotpotQA一样都是属于多跳阅读理解数据集。针对一个问题给出多个支撑文档，来做推理。可看之前的文章[HotpotQA数据集](https://coding-zuo.github.io/2021/03/23/HotpotQA%E6%95%B0%E6%8D%AE%E9%9B%86/)\n\n不同的是，WikiHopQA给出了候选答案，可以看成是多项选择题。\n\n\n\n\n\n## 创新点\n\n提出Heterogeneous Document-Entity  graph (HDE graph) ，可以从候选答案、文档和实体中，聚合不同级别的信息粒度。\n\n使得不同类型的节点之间能够进行丰富的信息交互，从而便于精确的推理。不同类型的节点与不同类型的边相连，以突出查询、文档和候选之间呈现的各种结构信息。\n\n\n\n## 如何设计\n\n![](https://i.loli.net/2021/03/28/disz9JgGEIf5u1C.png)\n\n数据集提供的是候选答案、问题和一系列文档。分布作为输入，分别表示为：$C_q, q(s,r,?), S_q $\n\n其中，$q(s,r,?)$  内分别表示为主体、关系和位置客体。任务是预测查询的正确答案$a^*$。\n\n首先将这些输入文字，映射成词向量，分别为 $X_q\\in R^{l_q\\times d}$ 、$X_s^i\\in R^{l_s^i\\times d}$ 其中i为第i个词、  $, X_c^j\\in R^{l_c^j\\times d}$  其中j为第j个词。\n\n$l$ 为每段文字长度 ，d为词向量维度。\n\n这就是上图中的最下面一层。\n\n--------\n\n再往上一层encoder采用的是双向GRU，分别对C/q/S 的上下文信息进行编码。\n\n编码后的维度是  $ H_q\\in R^{l_q\\times h}$  、 $H_s^i\\in R^{l_s^i\\times h}$ 、 $H_c^j\\in R^{l_c^j\\times h}$   其中h是RNN输出维度。\n\n再观察上图，发现在encoder上面一层，Documents上面和其他两个地方不同，中间加了一个实体提取。\n\n是作者发现有些通过查询query和候选答案C，在文档中提取被提及的实体。提取到每个mentions的开始位置和结束位置。\n\n每一次提及都被视为一个实体Entiry。第i个文档提出的实体表示为 $H_s^i, M\\in R^{l_m\\times h}$   , $l_m$ 是实体长度。\n\n------\n\n再向上一层，是co-attention协同注意力机制，特意读了下协同注意力DCN那篇文章[协同注意力和自注意力的区别(DCN+)](https://coding-zuo.github.io/2021/03/25/%E5%8D%8F%E5%90%8C%E6%B3%A8%E6%84%8F%E5%8A%9B%E5%92%8C%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E7%9A%84%E5%8C%BA%E5%88%AB/)\n\n用到这个任务上其实就是一个协同每两个特征来提取新特征。\n\n通俗上讲，Q和S 相互co-attention就是带着问题看文章，读完文章看问题。C和Q做带着选项看问题。\n\n拿RNN输出的问题序列$H_q \\in R^{l_q\\times h}$ 和文档$H_s^i\\in R^{l_s^i\\times h}$为例计算过程如下：\n$$\n\\begin{equation}\\begin{split} \n    A^i_{qs} = H_s^i(H_q)^T  \\in R^{l_s^i\\times l_q}\n    \\end{split}\\end{equation}\n$$\n得到查询和每个字的点积打分。\n\n为简化起见，在后面的上下文中，我们使用上标i，它表示对第i个文档的操作。\n$$\n\\begin{equation}\\begin{split} \n    C_q &= softmax(A_{qs}^T)H_s \\in R^{l_q\\times h}\\\\\n    C_s &= softmax(A_{qs})H_q \\in R^{l_s\\times h}\n    \\end{split}\\end{equation}\n$$\n进一步使用GRU ,f 对共同参与的文档上下文进行编码\n$$\n\\begin{equation}\\begin{split} \n    D_s = f(softmax(A_{qs})C_q)\\in R^{l_s\\times h}\n    \\end{split}\\end{equation}\n$$\n最终拼接\n$$\n\\begin{equation}\\begin{split} \n   S_{ca} =[C_s;D_s] \\in R^{l_s\\times 2h}\n    \\end{split}\\end{equation}\n$$\n同样的co-attention应用在query和候选，query和实体得到 $C_{CA},E_{ca}$ 。\n\n注意，作者不在查询和对应于查询主题的实体之间共同关注，因为查询主题已经是查询的一部分。为了保持维度的一致性，应用了一个具有tanh激活函数的单层多感知器(MLP)，将查询主题实体的维数增加到2h。\n\n这个查询主题query subject到底是什么我有点疑问。\n\n-----\n\n再往上是一个自注意力池化。\n\n当co-attention产生文档的查询感知上下文表示时，自关注集合被设计为通过选择重要的查询感知信息将顺序上下文表示转换为固定维度的非顺序特征向量。\n$$\n\\begin{equation}\\begin{split} \n    a_s&=softmax(MLP(S_ca))\\in R^{l_s\\times 1}\\\\\n    s_{sa}&= a_s^TS_{ca} \\in R^{1\\times 2h}\n    \\end{split}\\end{equation}\n$$\n\n\n同样，对每个实体和候选，可得到  $c_{sa}, e_{sa}$  。\n\n------\n\n再接下来就是构建异质图了。\n\n![](https://i.loli.net/2021/03/28/AtPhugd79czJ3k2.png)\n\n\n\n一共三种类型的节点，绿色是文档节点、蓝色是实体节点、黄色是候选答案节点。\n\n七种建边规则：\n\n- 文档节点和候选节点：如果候选节点在文档中出现时建立一条边。\n- 文档节点和实体节点：如果实体节点从这个文档中提取出来建立一条边。\n- 候选节点和实体节点：如果实体节点被候选答案提及建立一条边。\n- 两个实体节点之间：如果他们在同一个文档中被提取时建立一条边。\n- 两个实体节点之间: 如果他们被相同的候选或问题提及，且实体在不同的文档中时建立一条边。\n- 所有的候选节点相互连接\n- 不满足以上条件的不进行相连。\n\n## HGN传播聚合机制\n\n信息传递\n$$\n\\begin{equation}\\begin{split} \n    z_i^k = \\sum_{r\\in R} \\frac{1}{|N_i^r|} \\sum_{j\\in N_i^r} f_r(h_j^k)\n    \\end{split}\\end{equation}\n$$\n\n\n其中R 是所有边的类型\n\n$N_i^r$ 是 第i个节点边类型是r的邻居集合\n\n$h_j^k$ 是第j个邻居节点的第k层表达\n\n$h_j^0$ 是self-attention的输出\n\n$f_r$ 是MLP\n\n$z_i^k$ 是第i个节点第k层的局和信息\n\n可以与变换更新后的节点i：\n$$\n\\begin{equation}\\begin{split} \n    u_i^k = f_s(h_i^k) + z_i^k\n    \\end{split}\\end{equation}\n$$\n$f_s$ :MLP\n\n为了解决多层GNN的过平滑问题，作者采用了加门控的方式。\n$$\n\\begin{equation}\\begin{split} \n    g_i^k &= sigmoid(f_g([u_i^k;h_i^k]))\\\\\n    h_i^{h+1} &= tanh(u_i^k)\\odot g_i^k + h_i^k \\odot (1-g_i^k)\n    \\end{split}\\end{equation}\n$$\n$\\odot$ :element-wise product = element-wise multiplication = Hadamard product\n\n含义：两个矩阵对应位置元素进行乘积\n\n以上的$f$ 都是单层MLP 输出维度为2h\n\n## 最终预测\n\n使用候选节点和与候选提及相对应的实体节点的最终节点表示来计算分类分数：\n$$\n\\begin{equation}\\begin{split} \n    a = f_C(H^C)+ACC_{max}(f_E(H^E))\n    \\end{split}\\end{equation}\n$$\n$H^C \\in R^{C\\times 2h}$ , C是候选数量\n\n$H^M \\in R^{M\\times 2h}$ , M是节点数量\n\n$f_C,f_E$ 两层MLP\n\n$ACC_{max}$ :是对属于同一候选者的实体的分数取最大值的操作。\n\n隐含层大小为输入维的一半，输出维数为1，我们将可预测节点和实体节点的得分直接相加，作为多个候选者的最终得分。因此，输出分数向量$a∈r^{c×1}$给出了所有候选的分布。由于任务是多类分类，采用交叉熵损失作为训练目标，以a和标签作为输入。\n\n\n\n## 实验\n\n![](https://i.loli.net/2021/03/28/ZMIraibAGWv9VL8.png)\n\n\n\n![](https://i.loli.net/2021/03/28/3JDMT6lNtiWIBQf.png)\n\n\n\n\n\n\n\n\n\n","tags":["GNN&nlp"]},{"title":"Pytorch多GPU并行实例","url":"/2021/03/27/Pytorch多GPU并行实例/","content":"\n# Pytorch Train_Multi_GPU\n\nhttps://pytorch.org/tutorials/intermediate/ddp_tutorial.html\n\n两种方式：\n\n- DataParallel（DP）：Parameter Server模式，一张卡位reducer，实现也超级简单，一行代码。\n- DistributedDataParallel（DDP）：All-Reduce模式，本意是用来分布式训练，但是也可用于单机多卡。\n\n最后还有一个pycharm远程服务器的配置，还有如何在pycharm里配置run参数为：\n\n```\npython -m torch.distributed.launch --nproc_per_node=4 --use_env train_multi_gpu_using_launch.py\n```\n\n这个行运行命令是用DistributedDataParallel时的，指定的运行参数。具体介绍在后面写。\n\n\n\n### DataParallel vs DistributedDataParallel\n\n- 如果模型太大而无法容纳在单个GPU上，则必须使用 **model parallel** 将其拆分到多个GPU中。 DistributedDataParallel与模型并行工作； DataParallel目前不提供。\n\n- DataParallel是单进程、多线程的，只能在单机上工作，而DistributedDataParallel是多进程的，既可用于单机，也可用于多机。即使在一台机器上，DataParallel通常也比DistributedDataParallel慢，这是因为线程间的GIL争用、每次迭代复制模型以及分散输入和收集输出带来的额外开销。\n\n- DistributedDataParallel适用于模型并行；DataParallel目前不能。当DDP与模型并行相结合时，每个DDP进程使用模型并行，所有进程共同使用数据并行。\n\n\n\n## 单机多卡理论基础\n\n- 按照并行方式来分：模型并行 vs 数据并行\n- 按照更新方式来分：同步更新 vs 异步更新\n- 按照算法来分：Parameter Server算法 vs AllReduce算法\n\n### 常见的多GPU使用 \n\n![jz0tf9.png](https://i.loli.net/2021/03/27/stRfpYBavhDPwnu.png)\n\n模型并行，将网络不同模块放到不同GPU上去运行。训练速度无提升，但可让非常大的模型分布在多块gpu。\n\n![](https://i.loli.net/2021/03/27/syT1vPiIwEMUYXF.png)\n\n数据并行，将数据和模型同时放到多个GPU，同时进行正向传播和反向传播，并行输入样本进行训练， 相当于加大了batchsize，训练速度也加快了。\n\n\n\n### 数据如何在不同设备间进行分配\n\n\n\n\n\n### 误差梯度如何在不同设备间通信\n\n\n\n\n\n\n\n\n### 多GPU训练常用启动方式\n\n- [torch.distributed.lauch](https://pytorch.org/docs/stable/distributed.html?highlight=distributed#module-torch.distributed.launch) : 代码量少，启动速度快。如果开始训练后，手动强制终止程序，有小概率会出现进程没有杀掉的情况。\n- torch.multiprocessing: 拥有更好的控制和灵活性\n\n## DataParallel\n\nhttps://pytorch.org/tutorials/beginner/blitz/data_parallel_tutorial.html\n\n\n\n\n\n## DistributedDataParallel（DDP）\n\nDistributedDataParallel（DDP）在module级别实现数据并行性。它使用[torch.distributed](https://link.zhihu.com/?target=https%3A//pytorch.org/tutorials/intermediate/dist_tuto.html)包communication collectives来同步梯度，参数和缓冲区。并行性在单个进程内部和跨进程均有用。在一个进程中，DDP将input module 复制到device_ids指定的设备，相应地按batch维度分别扔进模型，并将输出收集到output_device，这与[DataParallel](https://link.zhihu.com/?target=https%3A//pytorch.org/tutorials/beginner/blitz/data_parallel_tutorial.html)相似。\n\n### 处理速度不同步时\n\n在DDP中，Model, forward method 和 differentiation of the outputs是分布式的同步点。期望不同的过程以相同的顺序到达同步点，并在大致相同的时间进入每个同步点。否则，快速流程可能会提早到达，并在等待时超时。因此，用户负责进程之间的工作负载分配。有时，由于例如网络延迟，资源争用，不可预测的工作量峰值，不可避免地会出现不同步的处理速度。为了避免在这些情况下超时，请确保在调用[init_process_group](https://link.zhihu.com/?target=https%3A//pytorch.org/docs/stable/distributed.html%23torch.distributed.init_process_group)时传递足够大`timeout`value\n\n\n\n\n\n\n\n\n\n## 常见报错\n\nsubprocess.CalledProcessError: Command ‘[’/home/labpos/anaconda3/envs/idr/bin/python’, ‘-u’, ‘main_distribute.py’, ‘–local_rank=1’]’ returned non-zero exit status 1.\n\n这个错出现是前面有代码写的不对，可以先在DistributedDataParallel 中加入find_unused_parameters=True。试试，一般不是分布式部分的错，是前面哪里写的不对。很可能是data_loader哪里仔细检查一下。\n\n\n\n验证集loss和acc都上涨\n\n验证集loss上升，acc也上升这种现象很常见，原因是过拟合或者训练验证数据分布不一致导致，就是在训练后期，预测的结果趋向于极端，使少数预测错的样本主导了loss，但同时少数样本不影响整体的验证acc情况。\n\n问一下，这时如果设置早停，是不是以loss最小早停合理点？以前见过用准确率设置早停的。假设交叉熵损失，训练与验证集分布大概一致的条件下\n\n答：准确率比较好\n\n## 遇到问题\n\nloss下降但最终效果不好，得到的模型结果像是只在四分之一数据做训练后的效果。\n\n\n\n\n\n## 参考文献\n\n[PyTorch分布式训练简介](https://blog.csdn.net/baidu_19518247/article/details/89635181)\n\n[Pytorch多机多卡分布式训练](https://zhuanlan.zhihu.com/p/68717029)\n\n[【分布式训练】单机多卡的正确打开方式（三）：PyTorch](https://zhuanlan.zhihu.com/p/74792767)\n\n[PyTorch 24.单机多卡的理论基础](https://zhuanlan.zhihu.com/p/158886284)\n\n[【分布式训练】单机多卡的正确打开方式（三）：PyTorch](https://zhuanlan.zhihu.com/p/74792767)\n\n[PyTorch 20.GPU训练](https://zhuanlan.zhihu.com/p/158375254)\n\n[pytorch 分布式训练 distributed parallel 笔记](https://blog.csdn.net/m0_38008956/article/details/86559432)\n\n[Pytorch 分布式训练](https://zhuanlan.zhihu.com/p/76638962)\n\n[Pycharm：运行、调试pytorch分布式训练代码](https://blog.csdn.net/lxb206/article/details/114293060)\n\n[如何在pycharm中运行/调试torch分布式训练](https://zhuanlan.zhihu.com/p/144815822)\n\n[pytorch 分布式训练 distributed parallel 笔记](https://blog.csdn.net/m0_38008956/article/details/86559432?utm_medium=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7EBlogCommendFromMachineLearnPai2%7Edefault-1.control&dist_request_id=&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7EBlogCommendFromMachineLearnPai2%7Edefault-1.control)\n\n","tags":["DataGame"]},{"title":"协同注意力和自注意力的区别(DCN+)","url":"/2021/03/25/协同注意力和自注意力的区别/","content":"\n# 协同注意力和自注意力的区别(DCN+)\n\n读阅读理解QA的论文发现co-attention没见过，self-attention和attention又忘得差不多了。\n\n就先读了一下DCN和DCN+的论文\n\nDYNAMIC COATTENTION NETWORKS FOR QUESTION ANSWERING\n\nDCN+: MIXED OBJECTIVE AND DEEP RESIDUAL COATTENTION FOR QUESTION ANSWERING+\n\n注意力机制有很多种变形，这里我只考虑最近接触可能会用的。\n\n- soft&hard attention\n- key-value pair attention\n- self-attention\n- Multi-head attention\n- co-attention\n\n## attention\n\n注意力机制就是计算机模仿人的注意力，对信息分配一个权重，对关注的信息分配较大的权重，不重要的信息反之。\n\n例如，我们的视觉系统倾向于关注图像中辅助判断的部分信息，并忽略掉不相关的信息。同样，在涉及语言或视觉的问题中，输入的某些部分可能会比其他部分对决策更有帮助。例如，在翻译和总结任务中，输入序列中只有某些单词可能与预测下一个单词相关。同样，在image-caption问题中，输入图像中只有某些区域可能与生成caption的下一个单词更相关.\n\n### soft和hard的区别\n\nSoft attention是一种全局的attention，其中权重被softly地放在源图像所有区域\n\nHard attention一次关注图像的一个区域，采用0-1编码，时间花费较少，但是不可微分，所以需要更复杂的技术来进行训练\n\n在机器学习中soft 常常表示可微分，比如sigmoid和softmax机制，而hard常常表示不可微分\n\nsoft hard attention机制是在图像生成标题任务中被提出的，其原始任务如下:\n\n![](https://i.loli.net/2021/03/25/4bCNYj5f6kQcIXt.png)\n\n上面是soft 下面是hard，我们可以看到，soft的权重是每次被放置在整张图像上，注重强调的部分（越白）的数值越接近1，越黑越接近0\n\n下面的一排非黑即白，白色区域为1，黑色区域为0。\n\n\n\n现在主流用soft比较多，其主要步骤有两个：\n\n针对输入$X=[x_1,x_2...x_3]$ (提取对象)\n\n- 1计算输入信息熵的注意力分布\n- 2根据注意力分布计算输入信息的加权平均\n\n### 计算注意力分布\n\n给定一个和任务相关的查询向量q，用注意力变量$z \\in [1,N]$ 表示被选择信息的索引位置，即 z=i，表示选择了第i个输入信息。\n\n其中查询向量q可以是动态生成的，也可以是可学习的参数。\n\n#### Soft-attention计算分布\n\n在给定输入信息x的查询变量q下，选择第i个输入信息的概率。\n$$\n\\begin{equation}\\begin{split} \n\\alpha_i &= p(z=i|x,q) \\\\\n&= softmax(s(x_i,q))\n\\end{split}\\end{equation}\n$$\n其中$\\alpha_i$ 为注意力分布，$s(x_i,q)$ 为打分函数。\n\n常用的打分函数:\n\n- 加性模型: $s(x_i,q) = v^Ttanh(Wx_i+Vq)$\n- 双线性：$s(x_i,q)=x_i^TWq$\n- 点积：$s(x_i,q)=x_i^Tq$\n- 缩放点积:$s(x_i,q)= \\frac{x_i^Tq}{d^{\\frac{1}{2}}}$\n\n#### 加权平均\n\n$$\n\\begin{equation}\\begin{split} \natt(X,q) &= \\sum_{i=1}^N \\alpha_i x_i \\\\\n&=E_{z\\sim p(z|X,q)}[X]\n\\end{split}\\end{equation}\n$$\n\n\n\n\n\n![](https://i.loli.net/2021/03/25/XrtYUMNH8J1KvLP.png)\n\n\n\n\n\n#### key-value pair attention\n\n其实就是输入信息是(k,v)键值对形式。$(K,V)=[(k_1,v_1),(k_2,v_2),...,(k_n,v_n)]$\n\n其中键用来计算注意力分布$\\alpha_i$，值用来计算聚合信息\n\n当K=V时，键值对注意力=柔性注意力\n\n![](https://i.loli.net/2021/03/25/hWkdyl3TGVjsRY4.png)\n\n如上图，计算注意力分布\n$$\n\\begin{equation}\\begin{split} \n\\alpha_i &= \\frac{exp(s(k_i,q))}{\\sum_{j=1}^Nexp(s(k_j,q))} \\\\\natt((K,V),q) &= \\sum_{i=1}^N \\alpha_iv_i \\\\\n&=\\frac{exp(s(k_i,q))}{\\sum_{j=1}^Nexp(s(k_j,q))} v_i\n\\end{split}\\end{equation}\n$$\n\n\n#### self-attention \n\n查询向量q、键向量k、值向量v ， 都等于输入向量序列。\n\n可参考下面的多头自注意力\n\n#### multi-head self attention\n\n查询向量Q、键向量K、值向量V ， 都等于输入向量序列的线性表示。\n\n假设输入序列 $X=[x_1,x_2,...,x_n]\\in R^{d_1\\times R}$，输出的是$H=[h_1,h_2,...,h_n]\\in R^{d_2\\times R}$\n\n$$Q = W_qX \\in d_3\\times N$$\n\n$$K = W_kX \\in d_3\\times N$$\n\n$$V = W_vX \\in d_2\\times N$$\n$$\n\\begin{equation}\\begin{split} \n\\hat h_i &= att((K,V),q_i) = \\sum_{j=1}^N \\alpha_{ij} v_j \\\\\n&= \\sum_{j=1}^N softmax(s(k_j,q_i))v_j\n\\end{split}\\end{equation}\n$$\n其中$i,j\\in[1,N]$ 为输出和输入的向量序列位置\n\nTransformer里用的是上面的缩放点积打分函数s\n\n\n\n![](https://i.loli.net/2021/03/25/OGKUbvgx9jY4PiS.png)\n\n如果在encoder-decoder架构中\n\nattention一般用在encoder和decoder之间做衔接的部分\n\nself-attention 一般在块内部\n\n比如在翻译任务中，Sourse和Target内部通常用self-attention提取特征，两者之间用attention\n\n\n\n\n\n\n\n## DCN\n\nCo-attention 共同注意力机制就从DCN讲起，DCN是一个QA模型，为了解决然而，问答场景中单次通过的性质，对于不正确答案的局部最大值恢复的问题。它首先融合了问题和文档的共同依赖表示，以便集中于两 者的相关部分。然后，动态指向解码器迭代潜在的答案跨度，该迭代过程使模型能够从对应于不正确答案的初始局部最大值中恢复。这个是论文的话，其实不是coattention来恢复的，是动态指向解码器。\n\n其实就是因为一段内容里可能多多个正确答案，但是我们在模型输出的时候选的是最大概率的开始和结尾，DCN用一种迭代的方式，以找到局部极值概率点来当做答案。\n\n![](https://i.loli.net/2021/03/25/jx5iEAS3KZlwpb9.png)\n\n所以，co-attention就是带着问题去阅读，融合问题和文档的特征调整的attention机制。\n\n\n\nDynamic Decoder \n\n![](https://i.loli.net/2021/03/25/Kkg8E5pAJLVbZyu.png)\n\nHMN\n\n![](https://i.loli.net/2021/03/25/thIAcEHed1ZWpwv.png)\n\n![](https://i.loli.net/2021/03/25/SsvJj6t3iaP4DRm.png)\n\n\n\nmax运算计算张量第一维上的最大值。第一个maxout层和最后一个maxout层的输出之间存在高速连接。\n\n### DCN+\n\n![](https://i.loli.net/2021/03/25/V7nA6PkYDpLh5Ka.png)\n\n","tags":["nlp"]},{"title":"字符串无序匹配","url":"/2021/03/25/字符串无序匹配/","content":"\n给定长度为 m 的字符串 aim，以及一个长度为 n 的字符串 str 问能否在 str 中找到一个长度为 m 的连续子串，使得这个子串刚好由 aim 的 m 个字符组成，顺序无所谓返回任意满足条件的一个子串的起始位置，未找到返回-1。\n\n思路：\n\n找到一个串和aim排序对比\n\n```java\npublic static void main(String[] args) {\n        Scanner input = new Scanner(System.in);\n        while (input.hasNext()) {\n            String aim = input.next();\n            String str = input.next();\n            int m = aim.length();\n            int i = 0;\n            int j = m - 1;\n            char[] charAim = aim.toCharArray();\n            Arrays.sort(charAim);\n            int flag = 0;\n            while (j != m) {\n                char[] sub = str.substring(i, j + 1).toCharArray();\n                Arrays.sort(sub);\n                flag = 0;\n                for (int k = 0; k < sub.length; k++) {\n                    if (sub[k] != charAim[k]) {\n                        flag = 1;\n                        break;\n                    }\n                }\n                if (flag == 1) {\n                    i++;\n                    j++;\n                    continue;\n                } else {\n                    System.out.println(\"true\");\n                    break;\n                }\n            }\n            if (flag == 1) System.out.println(\"false\");\n        }\n    }\n```\n\n面试上写这个暴力算法没有分 O(n^3*logN)\n\n优化O(N*M):\n\n```java\npublic boolean isTY(char[] str, int L, char[] aim) {\n        // 0-255 统计数组\n        // 'a' 97\n        // count[97] ++;\n        int[] count = new int[256];\n        for (int i = 0; i < aim.length; i++) {\n            count[aim[i]]++;\n        }\n        //count 中含有0-255\n        for (int i = 0; i < str.length; i++) {\n            if (count[str[i]] == 0) {\n                return false;\n            }\n            count[str[i]]--;\n        }\n        return true;\n    }\n\n    public int containExactly2(String a, String b) {\n        if (a == null || b == null || a.length() < b.length()) {\n            return -1;\n        }\n        char[] str = a.toCharArray();\n        char[] aim = b.toCharArray();\n        for (int L = 0; L <= str.length - aim.length; L++) {\n            if (isTY(str, L, aim)) {\n                return L;\n            }\n        }\n        return -1;\n    }\n\n```\n\n一共有N-M个要判断匹配的串，要遍历M个长度\n\n\n\n最后优化:O(n)\n\n先把目标字符串做成一个字典表。\n\n出现了的字符做成一个计数字典\n\n没有出现的就认为是0\n\n遍历输入字符串的时候\n\n让滑动窗口内的计数减减，多的可以记成负数\n\n每次从窗口右边进来的我都减\n\n从窗口左边画出的我都加一\n\n最终遍历完看无效的负数点有没有来判断有没有同源异构\n\n```java\npublic int containExactly(String a, String b) {\n        if (a == null || b == null || a.length() < b.length()) {\n            return -1;\n        }\n        char[] str = a.toCharArray();\n        char[] aim = b.toCharArray();\n        int[] count = new int[256];\n        for (int i = 0; i < aim.length; i++) {\n            count[aim[i]]++;\n        }\n        int M = aim.length;\n        int inValidTimes = 0;\n        int R = 0;\n        // 先让窗口用于M个字符\n        for (; R < M; R++) {\n            if (count[str[R]]-- <= 0) {\n                inValidTimes++;\n            }\n        }\n        // 如果第一个是同源异构词\n        if (inValidTimes == 0) {\n            return R - M;\n        }\n        // 窗口滑动\n        for (; R < str.length; R++) {\n            if (inValidTimes == 0) {\n                return R - M;\n            }\n            // 0[0..M-1]M\n            // [1..M]\n            // [2...M+1]\n            if (count[str[R]]-- <= 0) {\n                inValidTimes++;\n            }\n            if (count[str[R - M]]++ < 0) {\n                inValidTimes--;\n            }\n        }\n        return inValidTimes == 0 ? R - M : -1;\n    }\n\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["刷题"]},{"title":"已知后序序列构建二叉搜索树","url":"/2021/03/24/已知后序序列构建二叉搜索树/","content":"\n# 已知后序序列构建二叉搜索树\n\n思路：\n\n[2,4,3,6,8,7,5]\n\n最后一个是根节点，从后往前找，第一个比根小的数是左子树的根，根前面的数是右子树的根。\n\n就变成了子问题，已知他们的根，怎么构建左子树和右子树\n\n时间复杂度$O(N^2)$\n\n优化用二分法，找比根小的节点，一直找到无法二分。就可以找到有序的部分。遍历行为替换成二分。\n\n```java\npublic class PosArrayToBST {\n\n    public static class Node {\n        public int value;\n        public Node left;\n        public Node right;\n\n        public Node(int v) {\n            value = v;\n        }\n    }\n\n    public static Node posArrayToBST1(int[] posArr) {\n        return process1(posArr, 0, posArr.length - 1);\n    }\n\n    public static Node process1(int[] posArr, int L, int R) {\n        if (L > R) return null;\n        Node head = new Node(posArr[R]);\n        if (L == R) return head;\n        int M = L - 1; // 为了全部是全左或全右子树\n        for (int i = L; i < R; i++) {\n            if (posArr[i] < posArr[R]) {\n                M = i;\n            }\n        }\n        head.left = process1(posArr, L, M);\n        head.right = process1(posArr, M + 1, R - 1);\n        return head;\n    }\n\n    public static Node process2(int[] posArr, int L, int R) {\n        Node head = new Node(posArr[R]);\n        if (L == R) return head;\n        int M = -1;\n        for (int i = L; i < R; i++) {\n            if (posArr[i] < posArr[R]) {\n                M = i;\n            }\n        }\n\n        if (M == -1) {\n            head.right = process1(posArr, L, R - 1);\n        } else if (M == R - 1) {\n            head.left = process2(posArr, L, R - 1)\n        } else {\n            head.left = process1(posArr, L, M);\n            head.right = process1(posArr, M + 1, R - 1);\n        }\n\n        return head;\n    }\n\n    public static Node process3(int[] posArr, int L, int R) {\n        if (L > R) return null;\n        Node head = new Node(posArr[R]);\n        if (L == R) return head;\n        int M = L - 1;\n        int left = L;\n        int right = R - 1;\n        while (left <= right) {\n            int mid = left + ((right - left) >> 1);\n            if (posArr[mid] < posArr[R]) {\n                M = mid;\n                left = mid + 1;\n            } else {\n                right = mid - 1;\n            }\n        }\n        head.left = process2(posArr, L, M);\n        head.right = process2(posArr, M + 1, R - 1);\n        return head;\n    }\n\n}\n```\n\n","tags":["刷题"]},{"title":"HotpotQA数据集","url":"/2021/03/23/HotpotQA数据集/","content":"\n# HotpotQA数据集：A Dataset for Diverse, Explainable Multi-hop Question Answering\n\n\n\n官方地址：https://hotpotqa.github.io/index.html\n\n为解决当前QA数据集不能训练系统回答复杂问题和提供可解释的答案问题而提出。\n\n## 摘要\n\nHotpotQA基于113k(十一万三千)个维基百科问答对，有四个特点：\n\n- 问题需要对多个支持文档进行查找和推理才能回答\n- 问题是多样的，不受任何预先存在的知识库或知识模式的限制\n- 提供句子级别的推理所需的事实支持，允许QA系统在强有力的监督下进行推理和解释预测\n- 提供了一种新型的拟事实比较问题来测试QA系统提取相关事实和进行必要比较的能力。\n\n[![6HJiz6.png](https://z3.ax1x.com/2021/03/23/6HJiz6.png)](https://imgtu.com/i/6HJiz6)\n\n所构建的多跳问答数据集样式\n\n## 贡献\n\n\n\n### 构建维基百科超链接图\n\n使用整个英文维基百科做为语料库。\n\n- 维基百科文章中的超链接通常自然地涉及上下文中的两个(已经消除歧义的)实体之间的关系，这可能被用来促进多跳推理。\n- 每篇文章的第一段通常包含许多可以有意义地查询的信息。\n\n基于这些观察，我们从所有维基百科文章的第一段中提取了所有的超链接。用这些超链接，构建了一个有向图G，edge(a,b) 表示超链接从文章的第一段a 到 文章b。\n\n\n\n\n\n### 生成候选段落对\n\n为了生成用于与超连接图G的多跳问题回答的有意义的段落对，引入了一个桥梁实体“bridge entity”。\n\n比如问题是：when was the singer and songwriter of Radiohead born？\n\n为了回答这个问题，我们需要推理出 “singer and songwriter of Radiohead”是“Thom Yorke”\n\n在从文章中计算出他的生日。“Thom Yorke”就是桥梁实体。\n\n对于G中的edge(a,b)。桥梁实体通常是链接a和文档b的桥梁\n\n也就是说打开维基百科，第一段全是超链接的段就是a，超链接上面的名字通常是桥梁实体，链接过去的文章就是b。\n\n文章b通常确定a和b之间共享上下文的主题，但并不是所有文章b都适合收集多跳问题。例如，像国家这样的实体在维基百科中经常被提及，但与所有传入链接不一定有太多共同之处。\n\n\n\n### 比较问题\n\n收集了新一种类型的多跳问题----比较问题。\n\n其主要思想是，比较来自同一类别的两个实体通常会产生有趣的多跳问题\n\n例如：Who has played for more NBA teams, Michael Jordan or Kobe Bryant?\n\n还在比较问题中引入了是/否问题子集。\n\n回答这些问题通常需要算术比较，例如比较给定的出生日期的年龄。\n\n\n\n### 收集支持事实\n\n为了增强问答系统的可解释性，我们希望它们在生成答案时输出一组得出答案所需的支持事实。\n\n这些佐证事实可以作为关注哪些判决的有力监督。此外，现在可以通过将预测的支持事实与基础事实进行比较来检验模型的解释能力。\n\n\n\n\n\n## 处理和基准设置\n\n[![6HdD61.png](https://z3.ax1x.com/2021/03/23/6HdD61.png)](https://imgtu.com/i/6HdD61)\n\ntrain_easy: 单跳问题 18089 个。\n\ntrain_medium: 56,814个，占多跳示例的60% ,是baseline可以回答正确的问题。\n\n把难的问题分为四个子集：\n\ntrain_hard: 15661个\n\ndev : 7405个\n\ntest-distractor ：7405个\n\ntest-fullwiki : 7405个\n\nTest-distractor 和 Test-fullwiki 是两个基线，官网上的两个表单。\n\n### Distractor\n\n用tfidf检索8个段落作为干扰项，混合两个gold段落(用来收集问题和答案) shuffle构成干扰设置。()\n\n### Fullwiki\n\n要求模型回答所有维基百科文章的第一段(没有指定黄金段落)来充分测试模型定位相关事实以及对它们进行推理的能力。\n\n(真正的野外推理)\n\n两个test不能同时用，答案会泄露。\n\n\n\n## 数据集分析\n\n分析数据集中涵盖的问题类型、答案类型和多跳推理类型。\n\n### 问题类型\n\n![](https://i.loli.net/2021/03/24/LvZhegMF8RwVDUA.png)\n\n### 答案类型\n\n![](https://i.loli.net/2021/03/24/fliA8Zm65y9NdEB.png)\n\n### 推理类型\n\n![](https://i.loli.net/2021/03/24/yTm2pasAt6hJL75.png)\n\n","tags":["nlp"]},{"title":"Spatial-Temporal Graph Convolutional Network for Video-based Person Re-identification(CVPR2020)","url":"/2021/03/23/Spatial-Temporal-Graph-Convolutional-Network-for-Video-based-Person-Re-identification-CVPR2020/","content":"\nSpatial-Temporal Graph Convolutional Network for Video-based Person Re-identification(CVPR2020)\n===============================================================================================\n我做的ppt：https://coding-zuo.github.io/re-id-ppt/index.html\n\n行人重识别\n----------\n\n行人重识别（Person\nRe-identification），简称为ReID，是利用计算机视觉技术判断图像或者视频序列中是否存在特定行人的技术。广泛被认为是一个图像检索的子问题。给定一个监控行人图像，检索跨设备下的该行人图像。\n\n方法分为以下几类： \n- 基于表征学习的ReID方法 \n- 基于度量学习的ReID方法 \n- 基于局部特征的ReID方法 \n- 基于视频序列的ReID方法 \n- 基于GAN造图的ReID方法\n\n本文基于视频序列的ReID方法\n--------------------------\n\n通常单帧图像的信息是有限的，因此有很多工作集中在利用视频序列来进行行人重识别方法的研究（本篇论文就是）。基于视频序列的方法最主要的不同点就是这类方法不仅考虑了图像的内容信息，还考虑了帧与帧之间的运动信息等。\n\n### CNN&RNN\n\n利用CNN来提取图像的空间特征，而基于视频序列的方法主要思想是利用CNN\n来提取空间特征的同时利用RNN来提取时序特征。\n![](https://pic4.zhimg.com/v2-d01de4281c4079b3fd25e58a0351c27f_r.jpg \"Title\")\n\nRNN在Re-ID任务中对时间信息的建模效果有限，或者由于其复杂的结构而难以训练。\n\n### AMOC\n\n累计运动背景网络(Accumulative motion context network,\nAMOC)。AMOC输入的包括原始的图像序列和提取的光流序列。通常提取光流信息需要用到传统的光流提取算法，但是这些算法计算耗时，并且无法与深度学习网络兼容。\n![](https://pic3.zhimg.com/v2-9ed4efb7e67f29891e9ca0bda0729a6a_r.jpg \"Title\")\n\n光流法是非常耗时的，并且光流对于遮挡和噪声来说不够健壮。\n\n### temporal pooling & spatial-temporal attenttion\n\n论文：这些方法没有充分考虑人体各部分在不同帧之间的时间关系，效果有限。\n\n### 瓶颈问题\n\n方向的存在挑战： \n- 不同下摄像头造成行人外观的巨大变化； \n- 目标遮挡（Occlusion）导致部分特征丢失； \n- 不同的 View Illumination导致同一目标的特征差异； \n- 不同目标衣服颜色近似、特征近似导致区分度下降；\n\n论文解决挑战：\n1.仅使用外观特征不足以区分，但它们的身体结构信息是不同的。利用序列中各部分之间的时空关系可以缓解这些问题。\n\n2.当边界框不完美，或者存在噪声或遮挡时，基于外观的要素可能效果较差，并且基于图像的re-ID在这种情况下可能不能很好地工作。\n\n论文方法解决：显式地利用不同帧之间补丁的时间关系，以缓解遮挡和不对准问题。\n具体地说，通过连接不同帧的所有块来构建图来建模时间关系，目的是提供不同块之间的互补信息，从而缓解拥塞和错位问题。另一方面，我们还考虑了帧内的结构信息，通过为视频中的每一帧构造补丁图来提供互补的外观信息。\n\n3.基于图像的识别最具挑战性的难点之一是如何区分视觉上相似的身份，而大多数基于图像的方法只能依赖于提取细粒度的外观特征。\n\n在基于视频的人Re-ID中，相同身份的结构信息(例如形状信息)将更加完整和精确，因为每个视频具有许多帧，这些帧可能覆盖更多的视图和姿势。Structural\nGCN Module\n\n### Spatial-Temporal Graph Convolutional Network\n\n《Person re-identification with deep similarity-guided graph neural\nnetwork》2018 《Learning context graph for person search》2019 《Videos\nas space-time region graphs》2018 --- 视频分类\n\n论文：它们忽略了帧内或帧间不同身体部位之间的关系，是基于图像的，不考虑时间关系。\n\n《Adaptive graph representation learning for video person\nre-identification》2019---------引入图神经网络，利用姿态对齐连接和特征相似性连接实现相关区域特征之间的上下文交互。此外，该方法连接了所有帧的不同部分的特征，不对每帧身体部分的空间关系进行建模，忽略了帧内的结构信息。\n\n创新点、贡献\n------------\n\n（1）利用GCN来模拟人体不同部位在一帧内和帧间的潜在关系，为人们提供更具鉴别力和鲁棒性的信息\n（2）提出了时空GCN框架来联合建模视频层的整体斑块关系和帧级的单个帧的结构信息，该框架可以学习斑块之间的区分和鲁棒的时空关系，从而促进基于视频的Re-ID。\n\n模型设计\n--------\n\n设计了3个分支 \n- 上部分支是用于从相邻帧上的斑块中提取时间线索的时间分支 \n- 中间分支是通过对空间关系建模来提取人体结构信息的空间分支 \n- 底层分支是提取行人外观特征的全局分支。\n\n![-w1414](https://i.loli.net/2021/03/23/BC3YgrzAhbtFqHW.png)\n\n-   首先把每一帧放到CNN中，得到Fi ∈ Rh×w×c，F ={F1,F2,...,FT}，T为帧数。\n-   再把没个feature map Fi水平切分成P个patch，pi = 1,...,N。\n-   patch数量N为T\\*P，把每个P做平均池化后得到patch特征向量为xi ∈ Rc, i =\n    1,...,N.\n\n用GCN去学习patches之间的关系。 G(V,E)有N个节点，vi ∈ V,eij = (vi,vj) ∈\nE. 每个patches就是图中的节点，边e代表他们之间的关系。 A ∈ RN×N\n是这个图的邻接矩阵。 ![-w621](https://i.loli.net/2021/03/23/jKIY7PWqREQ8Dpm.png)\n\n![-w406](https://i.loli.net/2021/03/23/kdoSKRwTjizyW2A.png)\n这个式子，表示两个patch的关系，φ表示原始面要素的对称变换，φ =\nwx。w是可通过反向传播学习的d×d维权重。\n这个变换的意义是：它允许我们自适应地选择和学习帧内或跨不同帧的不同补丁的相关性，结合其他节点的信息。\n\n归一化 神经网络一般对输入数据的规模很敏感。\n对于亲和力矩阵的每一行，所有边值(即连接到面片i的边)的总和应为1。\n邻接矩阵的每个元素都应该是非负的，系数应该在(0，1)的范围内。\n![-w394](https://i.loli.net/2021/03/23/g96qEtu8sfFAjBy.png)\n接着给邻接矩阵加上单位矩阵\n![-w171](https://i.loli.net/2021/03/23/O7au8z49APyMwfb.png)\n这么做是因为将来GCN拿邻接矩阵A和权重相乘，意味着对于每个节点，我们把这个节点的所有邻接节点的feature向量加了起来，但没有加自己这个点。\n之后，使用re-normalization技巧来近似图-拉普拉斯：\n![-w210](https://i.loli.net/2021/03/23/xA5hYeUioD4M1G8.png)\n邻接矩阵乘以度矩阵减小数据规模，度矩阵也反应了一些节点信息。 \n### Temporal branch\n作用：使用不同帧的所有补丁来构建图，其目的是捕捉跨帧的补丁之间的互补信息。\n方法：使用GCN捕获pathches时域关系，构建M层GCN\n![-w289](https://i.loli.net/2021/03/23/AECcOzH2sY3fBFm.png)\nXm是第m层隐层特征，X0是通过CNN获得的特征patch。 Wm是被学习的参数矩阵。\n每层图卷积后跟一个nomalization层用和LeakyRelu\n![-w421](https://i.loli.net/2021/03/23/8zmZVbWfaovcIJO.png) 最后使用Max\npooling作用于Xm 最后得到 ft ∈ R1×dm 是时域GCN特征，dm设置为2048\n\n#### Structural GCN Module(spatial relations branch)\n\n作用：提供额外的辨别性信息，以加强重新识别系统。\n方法：使用GCN捕获不同patch的空间关系。然后，对视频中各帧的GCN特征进行融合，得到视频中的内在结构特征。\nGis (Vis , Eis ), Vis = {xi,1 , xi,2 , . . . , xi,P }\n下标i表示第i帧，并且每个帧被分成P个patch\n![-w511](https://i.loli.net/2021/03/23/HADw5CYgLnSaZsb.png)\n\n独立地利用每一帧的块之间的关系来捕获视频序列中的结构信息。我们将GCNs的所有输出特征聚合在一起，形成视频的结构特征。\n![-w318](https://i.loli.net/2021/03/23/maljbhcMGAX5fNJ.png)\n邻接矩阵公式和上面介绍的一样。k为第i帧上的第k层图卷积。 Wik ∈ Rdk ×dk\n输出的经过Max pooling降维后的特征矩阵为：XiK ∈ RP ×256\n最后，将视频的特征连接起来，最后的特征表示为fs。\n\n### Global branch\n全局分支提取每个视频的全局外观特征。\n\n### loss function \nbatch hard triplet和softmax cross-entropy Ltriplet\nand Lsoftmax \n### Triplet loss \nTriplet loss学到的是一个好的embedding，相似的图像在embedding空间里是相近的，可以判断是否是同一个人脸。\\[3\\]\n\nTriplet loos 需要三份数据(可以从一个batch中选择):Anchor、Positive、Positive\n- 其中Anchor表示当前数据，Positive是跟A相同人的数据，Positive是不同人的数据。\n- 当前向量、同一人不同向量、不同人不同向量\n- 将一个图像经过特征提取后是一个向量，让这个向量和postive更近更好，让这个向量和negative越远越好。\n![](media/16070719577662/16093032756806.jpg)\n\n目的：让A和P非常接近，A与N尽可能远离\n公式：$ \\lVert f(A)-f(P)\\rVert^2 \\le \\lVert f(A)-f(N)\\rVert^2 $ 其中f表示通过网络进行编码。\n是否会存在问题？如果f把所有的输入都编码成0，依然成立。\n\n那么，这个目标就改为: $\\lVert f(A)-f(P)\\rVert^2 - \\lVert f(A)-f(N)\\rVert^2 + a \\le 0$ \n其中a是margin间隔，表示d(A,P)和d(A,N)相差多少。\n\n\n\n同类之间的距离至少要比不同类距离要少多少。\nTriplet loss:\n$$\n\\begin{equation}\\begin{split} \n    L(A,P,N) = max(\\lVert f(A)-f(P)\\rVert^2-\\lVert f(A)-f(N)\\rVert^2 +a,0)\n    \\end{split}\\end{equation}\n$$\n但是对于约束条件:$d(A,P)+a \\le d(A,N)$ 理论上都是A与P很近，A与N较远。\n实际中用的最多的是hard negative方法，也就是在选择样本的时候，让$d(A,P)\\approx d(A,N)$ 这样给网络一些挑战，才能激励它学习。\n\n- 在同一个人P的特征中找最不像的距离最大的P。\n- 在不同人N的特征中找最像的距离最小的N。\n\n![](https://i.loli.net/2021/03/23/J4kSqvmjgdhYc5i.png) \n![](https://i.loli.net/2021/03/23/7gEZUoy6LNbaAXt.png)\n\n\n\n论文在三个分支上分别计算loss加在一起。\n![-w499](https://i.loli.net/2021/03/23/EoyTcBunLpFNRHM.png)\n\n三个分支输出的特征 fglobal , ft, fs。 fall = \\[fglobal, ft, fs\\]\n把fall放到softmax cross-entropy loss\n![-w373](https://i.loli.net/2021/03/23/1RiZHSQ4TF2pYUc.png)\n\n实验\n----\n\n### 数据集 \nDukeMTMC-VideoReID和MARS，是两个行人重识别的数据集。 \n\n- MARS有1261个身份id，的17503个tracklet和3,248个distractor序列。 \n- DukeMTMC-VideoReID 有1812个身份id，4832个tracklets\n\n评估协议：累积匹配特性曲线（CMC）和平均精度（map）来评价提出的模型的性能。\n\n### 细节(复现用)\nCNN模型用的是在imagenet预训练后的ResNet50，并且最后一层必输设为1。\n采用受限随机采样策略从每个视频中随机采样T=8帧。\n把图片resize为256x128并且随机水平翻转。 模型训练800轮。\n初始化学习率为0.0003，每200轮缩小十倍\nAdam优化器、16个身份为一个batch每个身份有四个追踪器tracklet,16 × 4 × 8 =\n512 images。\n\nTGCN有3层、SGCN有2层 把每个feature map水平切分的P为4\n\n为什么SGCN、TGCN选P=4 当Patch的数量太多时，Patch太小包含不了足够的信息。\n相反，当Patch的数量太少时，Patch可能会忽略细微但有区别的线索。\n\n### 代码\n![](https://i.loli.net/2021/03/23/Zv1cF3AXMJfzTsP.png)\n![](https://z3.ax1x.com/2021/03/23/6TfXSf.png)\n\n### 性能对比\n\n#### 纵向对比其他模型性能\n\n![-w712](https://i.loli.net/2021/03/23/dJQOKyHc9DUM7Tj.png)\n\n![-w694](https://i.loli.net/2021/03/23/C6UKZeWf3dBoYaS.png)\n现有的基于注意力的方法(包括STA、GLTR)独立地处理不同区域和帧，并且它们没有充分考虑补丁之间的内在关系。\nM3D,3D卷积运算计算量大，并且对空间不对准很敏感。 Wu et\nal. 对比这个图方法的模型，在两个数据集都优于他。\n\n#### 向内对比，三分支搭配性能\n![-w732](media/16070719577662/16072629848124.jpg)\n\n提出的方法综合考虑了人体不同部位在同一帧内和不同帧之间的潜在关系，可以提供更具区分性和鲁棒性的信息，并且能够进行端到端的训练。这些实验结果验证了该方法的优越性。\n\n主要创新点：考虑了人体不同部位在同一帧内和不同帧之间的潜在关系。\n\n#### 向内对比，替换GCN为全连接层性能\n![-w655](https://i.loli.net/2021/03/23/AlkZ4XIGOm8hioB.png) 证明了图卷积的必要性。\n\n结论\n----\n\n1.利用斑块间的时间关系缓解遮挡问题，利用斑块间的空间关系区分外观相似的歧义样本的有效性。\n2.提出STGCN模型\nSGCN:空间分支通过建模各帧面片之间的关系来学习人体的结构信息。\nTGCN:时态分支通过对不同帧之间的斑块的时态关系进行建模，可以缓解遮挡问题。\n\n未来方向，问题\n--------------\n\n加深层数会使模型效果不好，两层图卷积叫深度？浅层GCN不能有效地将节点信息传播到整个数据图。这个是GCN的过平滑的通病，还没有解决这个问题。\n\n如下图表现的一样。 ![-w645](https://i.loli.net/2021/03/23/so8cnV4RIBm3dMf.png)\n\n我个人觉得这篇论文，在GCN的结构上是可以改进的。是不是可以考虑残差思想来改进GCN网络结构，或者引入其他结构来优化？\n而且论文代码暂时未开放，模型的复杂度到底如何，还需进一步看看。\n\n## 参考文献\n\n[1][基于深度学习的行人重识别研究综述](https://zhuanlan.zhihu.com/p/31921944)\n[2][基于深度学习的person re-identification综述 Deep Learning for Person Re-identification: A Survey and Outlook](https://blog.csdn.net/rytyy/article/details/105232594)\n[3][Triplet-Loss原理及其实现、应用](https://blog.csdn.net/u013082989/article/details/83537370)\n[4][如何通俗的解释交叉熵与相对熵?](https://www.zhihu.com/question/41252833)\n[5][卷积神经网络系列之softmax，softmax loss和cross entropy的讲解](https://blog.csdn.net/u014380165/article/details/77284921)\n[6][卷积神经网络系列之softmax loss对输入的求导推导](https://blog.csdn.net/u014380165/article/details/79632950)\n[7][中山大学提出行人重识别新方法和史上最大数据集SYSU-30k，已开源！](https://zhuanlan.zhihu.com/p/329077441)\n[8][基于视频的行人再识别（1）：从认识Mars数据集开始](https://blog.csdn.net/qq_34132310/article/details/83869605)\n\n[CVPR 2020 | 旷视研究院提出新方法，优化解决遮挡行人重识别问题](https://mp.weixin.qq.com/s/EhAeaA68Ek27EptkTfZiBQ)\n[目标检测中mAP的计算方法](https://zhuanlan.zhihu.com/p/94597205)\n[视觉算法的工业部署及落地方面的技术知识，怎么学？](https://www.zhihu.com/question/428800593)","tags":["GNN&cv"]},{"title":"LeetCode470随机函数返回等概率的值","url":"/2021/03/23/随机函数返回等概率的值/","content":"\n# LeetCode470随机函数返回等概率的值\n\n\n\n![](https://i.loli.net/2021/03/23/jdgCOPBTVRs5W9U.png)\n\n问题描述：\n\n1. 给定一个随机函数f，等概率返回1~5中的一个数字，\n   这是唯一可以是使用的随机机制，如何实现等概率\n   返回1~7中的一个数字。\n2. 给定一个随机函数f，等概率返回a~b中的一个字母，\n   这是唯一可以是使用的随机机制，如何实现等概率\n   返回a~d中的一个数字。\n\n这种做法一般考虑用二进制的方法，等概率的返回0和1。\n\n如有一个等概率返回12345的函数f\n\nf':如果是1和2返回0，4或5返回1，如果是3重新调用f'。\n\n用0和1拼出一个数这样就可以实现等概率。\n\n只有两个二进制位，可以等概率返回0到3。00、01、10、11\n\n三个二进制位，可以等概率返回0到7。000，001，010，011，100，101，110，111\n\nLeetcode:\n\n```java\nclass Solution extends SolBase {\n    public int rand10() {\n        int ans = 0;\n        do {\n            ans = (rand01() << 3) + (rand01() << 2) + (rand01() << 1) + rand01();\n//        } while (ans == 15 || ans == 14 || ans == 13 || ans == 12 || ans == 11 || ans == 10);\n        } while (ans > 9);\n        return ans + 1;\n    }\n\n\n    public int rand01() {\n        int ans = 0;\n        do {\n            ans = rand7();\n        } while (ans == 4);\n        return ans < 4 ? 0 : 1;\n    }\n }\n```\n\n通用：\n\n```java\npublic class RandomBox {\n\n    //13 - 17\n    // 13+ [0,4]\n    public int random() {\n        return min + (int) (Math.random() * (max - min + 1));\n    }\n\n    public int rand01(int min, int max) {\n        int size = max - min + 1;\n        // size是奇数还是偶数\n        boolean odd = (size & 1) != 0;\n        int mid = size / 2;\n        int ans = 0;\n        do {\n            ans = random() - min;\n        } while (odd && ans == mid);\n        return ans < mid ? 0 : 1;\n    }\n\n    public int rand(int min, int max, int from, int to) {\n        if (from == to) {\n            return from;\n        }\n        // 3-9\n        // 0-6\n        int range = to - from;\n        int num = 1;\n        //求0-range需要几个2进制位\n        while ((1 << num) - 1 < range) {\n            num++;\n        }\n\n        int ans = 0;\n        do {\n            ans = 0;\n            for (int i = 0; i < num; i++) {\n                ans |= (rand01(min, max) << i);\n            }\n        } while (ans > range);\n        return ans + from;\n    }\n\n}\n\n```\n\n再一题：\n\n给一个随机函数f，以p概率返回0，以1-p概率返回1\n\n这是唯一可以用的随机机制，如何实现等概率返回0和1 \n\n思路：\n\n如果连续两次返回00或11 重新选取，如果返回01取为0，如果返回10取为1\n\n```java\n public int f() {\n \t\t\treturn Math.random() < 0.92 ? 0 : 1;\n }\n\n public int g() {\n     int first = 0;\n     do {\n         first = f();\n     } while (first == f());\n     return first;\n  }\n```\n\n","tags":["刷题"]},{"title":"HopRetriever:Retrieve Hops over Wikipedia to Answer Complex Questions(AAAI2020)","url":"/2021/03/22/HopRetriever-Retrieve-Hops-over-Wikipedia-to-Answer-Complex-Questions-AAAI2020/","content":"\n# HopRetriever:Retrieve Hops over Wikipedia to Answer Complex Questions(AAAI2020)\nhttps://arxiv.org/abs/2012.15534\n\n## 摘要\n\n- 大型文本语料库中收集支持证据对于开放领域问答(QA)是一个巨大的挑战。\n- 本文方法：\n  - 将hop定义为**超链接**和**出站链接文档**的组合\n  - 超链接编码成**提及嵌入**，相当于在上下文被提及的结构知识，表示出站链接实体建模。\n  - 出站链接文档编码成**文档嵌入**，相当于非结构化的知识。\n- 使用Hotpot数据集，该数据集文章我在这里写过[TODO]\n\nme:想要更好的检索，光用匹配一种检索方式不好，可以结合相关语义信息同时进行检索，会更准确。\n\n那么难点就是如何找到相关部分提取语义信息用于检索。\n\n\n\n## 介绍\n\n多跳问答任务需要从多个支持文档中搜集分散的证据，来提取答案。最近主流方法是将多跳证据收集视为迭代文档检索问题。\n\n在开放域下，多跳QA的一个关键部分是从整个知识源中检索证据路径，分解成几个单步文档检索。\n\n另一part是在基于知识库KB下，并尝试像虚拟结构化知识库(KB)那样遍历文本数据，专注于提到的实体。\n\n如这篇文章关于认知图谱的[TODO]我也写过。\n\n\n\n作者认为，线索收集可以分为两种\n\n- 实体介绍性文档内的信息丰富非结构的事实，关注非结构实体知识。\n- 实体本身之间的结构化和隐式关系，关注结构化实体知识。\n\n![](https://z3.ax1x.com/2021/03/22/6TmCef.png)\n\n\n\n结构性知识是指提及关系。可能是对应的Q1从一篇文章中提及的。Q1的左边好像是文章\n\n非结构性知识是指知识库之类外来知识。可能是对应Q2从知识库得来。Q2的左边好像是个知识库\n\n回答一个复杂的问题需要结合上面两种知识，我觉得对啊，就像问人一个问题，我已有的知识可能不够，我通过搜索引擎搜到一些知识来补充我回答这个问题的能力。\n\n本文作者要考虑的问题是，基于什么证据可以跳到第二个文档进行进一步检索。\n\nQ1是基于文档匹配\"directed by\"来找到下一个跳，从而可以有充足的证据。\n\nQ2问题更复杂一点，有三首歌被提及，只有其中一首是相关问题的，像上面那种关系不足以去在三者中做选择。这就需要通过和实体相关的无结构知识才能找到答案。\n\n---\n\n### 出发点\n\n所以作者认为，为了在Wikipedia中收集足够的支持证据，有必要同时考虑实体之间的关系结构和隐藏在介绍性文档中的非结构化知识。\n\n当应答过程遵循“顺藤摸瓜”的模式时，隐含的实体层次关系使得检索更加高效。但是，当关系链失败时，文档中的那些非结构化事实就会登台。\n\n本文研究如何将结构化知识和非结构化知识结合起来，共同为证据收集做出贡献。\n\n### 定义hop\n\n定义hop为超链接和相应出站链接文档的组合，后面要将两种embedding结合为hop。\n\n维基百科中的超链接暗示一个实体的介绍性文档如何提及其他一些内容\n\n而出站链接文档存储所有非结构化的事实和事件，这使得一跳包含关系证据和拟事实证据，以供将来检索。\n\n\n\n### HopRetriever思路\n\n对于维基百科文档中提到的每个实体，我们将其周围的文本上下文编码到提及嵌入中，以表示隐含的结构化知识。\n\n对于文档中非结构化知识的表示，与以往的工作一样，使用BERT对文档文本进行编码，条件是原始问题。\n\n对于每个步骤检索，从一个文档(实体)到另一个文档(实体)的跳跃可以从两个角度收集证据：\n\n- 当前文档是如何提到另一个文档。\n\n- 在另一实体的介绍性文件中隐藏了哪些事实\n\n\n\n## 相关工作\n\n### 文档级推理\n\n这种方法在不知道先前检索到的证据文档的情况下独立地查找证据文档，当证据文档中的一个与原始问题有少量语义关系时，可能会导致检索失败。\n\n为避免这个问题有些人提出引入多步检索器，实现对多个证据文件的重复检索。\n\n最近2020年一个PathRetriver，是沿着文本图的出站链接检索文档路径的。利用文档的图结构，减少了每一步检索过程中文档的搜索空间，这比以往的迭代检索器要小得多。(这个可以看看是不是用图网络来对出站非结构关系知识进行学习的) \n\nHopRetriever和他的最大不同是多考虑了，在文章之间的结构化和多值关系。\n\n\n\n### 以实体为中心的推理\n\n大多数QA都是以实体为中心进行推理的。通过实体提及来收集证据。\n\n代表一个是认知图谱那篇，一个是Differentiable Reasoning over a Virtual Knowledge Base(*ICLR 2020,*)(这个可以安排读一读)\n\n作者认为他们的问题是，当问题不是“顺藤摸瓜”时，提及本身不能为跳过哪个实体提供足够的推理证据。\n\n我感觉不太认可，认知图谱那篇同样是用bert来提取下一跳hop，可以是相同语境下的一些线索啊，不是一定提及本身啊。可能bert学的没那么强大？\n\n\n\n### 对问题分解\n\n建议将一个复杂的问题分解为几个更简单的子问题，并在每个步骤进行单跳QA。\n\n问题分解的挑战是确保每个子问题收集真正必要的证据。\n\n如果结构化关系建立失败，可能不会建立出一个可推理的子问题，用于进一步跳跃。\n\n\n\n## 方法细节\n\n这块公式参数细节比较多，一点一点梳理。\n\n### 任务定义\n\n开放域的多跳问答一般分为两个模型：\n\n- 检索模型 $D_q=Retriever(q,K)$ : 用来从大范围知识源K中收集很多证据。$D_q$ 应包含回答多跳问题所需的多个文档。\n- 阅读模型 $a=Reader(q,D_q)$ : 将$D_q$和q中的所有文本事实连接在一起，并馈送到答案提取模型阅读器中，以获得答案a\n\n每个维基百科页面对应一个实体 $e_i$\n附有介绍性的文档尾 $d_i$ ，如果在$D_i$中存在链接到$e_j$的锚点。就定义一个提及关系 $m_{i,j} = e_i \\rightharpoonup^{d_i} e_j$ 。\n\n知识源的定义为$K=\\{D,E,M\\}$\n\nM 是 提及关系$m_{i,j}$的集合\n\nE 是 实体$e_i$的集合\n\nD 是 附加文档$d_i$的集合\n\n论文的任务只是检索模型，且$D_q$ 是迭代得到的。在每个检索步骤，通过不仅检查包含在中的非结构化事实，而且还检查在最新选择的文档中对其的提及来获取文档。为了实现这一点，将非结构化的文本事实和提及分别编码，然后在一跳内将它们一起表示。当通过维基百科进行检索时，HopRetriever使用跃点hop作为匹配对象。\n\n![]( https://z3.ax1x.com/2021/03/23/6T4MDg.png)\n\n\n\n### Hop 如何Embedding\n\n$$\n\\begin{equation}\\begin{split} \n    hop_{i,j} = 提及关系的比重 \\cdot 提及Embedding的线性表示(结构化知识) + 外部文档关系的比重 \\cdot 外部文档Embedding的线性表示(非结构化知识)\n\\end{split}\\end{equation}\n$$\n\n\n\nMention Embedding提及嵌入(结构化实体关系)\n\n就是把包含entity的文档fed给bert，并且添加两个[MARKER] tokens选第一个被marker的作为mention embeding。\n\n如果文中没有直接提到entity，就用一个可学习的向量$m_p$表示\n$$\n\\begin{equation}\\begin{split} \n    m_{i,j}=\n    \\begin{cases}\n    BERT_{[M-j]}(q;d_i), &if\\ m_{i,j}\\in M\\\\\n    m_p, &if\\  otherwise\n    \\end{cases}\n\\end{split}\\end{equation}\n$$\n\n\n![](https://z3.ax1x.com/2021/03/23/6Tvkyd.png)\n\n\n\nDocument Embedding\n\n将$d_j$中的文本事实(与q拼接)送入BERT，将关于实体$e_j$的非结构化知识编码为文档嵌入$u_j$，并将[cls]的输出表示作为文档嵌入向量：\n$$\n\\begin{equation}\\begin{split} \n    u_j = BERT_{[CLS]}(q;d_j)\n\\end{split}\\end{equation}\n$$\n\n\nKnowledge fusion\n\n总体过程为，h为检索的历史向量。\n$$\n\\begin{equation}\\begin{split} \n    a_m &= hW_km{i,j}\\\\\n    a_u &= hW_ku_j \\\\\n    \\{w_m,w_u\\} &= softmax(\\{a_m, a_u\\})\\\\\n    hop_{i,j} &= w_m\\cdot W_vm_{i,j} + w_u\\cdot W_uu_j\n\\end{split}\\end{equation}\n$$\n\n\n![](https://z3.ax1x.com/2021/03/23/6TvonA.png)\n\n在第t步选择的$d_j$ 的概率计算为\n$$\n\\begin{equation}\\begin{split} \n    p(d_j) = sigmoid(h_t^Thop_{i,j})\n\\end{split}\\end{equation}\n$$\n\n\n### 细粒度句子级检索\n\n一个文档不可能所有的句子都是答案所必须的，指出必须的那些支持句子，对于明确推理线索是必须的。\n\n计算一个句子是不是留下采用以下公式：\n$$\n\\begin{equation}\\begin{split} \n    s_{i,l} &= BERT_{[SM-l]}(q;d_i) \\\\\n    p(s_i, l) &= sigmoid(h_tW_s,s_{i,l})\n\\end{split}\\end{equation}\n$$\n\n\n大于0.5定义为支持句。\n\n\n\n\n\n### 目标函数\n\n序列预测模型就是上面的RNN图，在t步下的目标函数为\n$$\nlogp(d_j) + \\sum_{\\hat d_j \\in D, \\hat d_j\\neq d_j}log(1-p(s_{s_i,l}))\n$$\n辅助支持句的预测任务，在第t步目标函数为\n$$\n\\sum_{l\\in L_i}logp(s_{i,l}) + \\sum_{l\\in L_i}log(1-p(s_{i,l}))\n$$\n\n\n## 实验\n\n数据集采用 HotpotQA [我要写TODO] 0564 个问答对。主要关注 fullwiki 部分。支持文档分散在 5M 的维基百科中。 \n\n实验包括三个部分：\n\n- 初步检索。基于 TF-IDF 选取前 500 个文档，作为初始文档。\n- 支持文档检索和支持句子预测。迭代检索初始文档。\n- 答案提取。通过 BERT 获取答案。\n\n作者还采用了一种基于 BERT 的神经排序器，获取更精确的前 500 个文档。同时，使用 ELECTRA （ELECTRA: Pre-training Text Encoders as Discrimi- nators Rather Than Generators. In *International Conference on Learning Representations*.）代替 BERT 进行答案获取。结果作为 HopRetriever-plus。这也体现了更好的初步检索的重要性。\n\n\n\n不同类型问题的embedding权重，结构和非结构\n\n![](https://z3.ax1x.com/2021/03/23/67PbrD.png)\n\n不同case的权重\n\n[![67iaQK.png](https://z3.ax1x.com/2021/03/23/67iaQK.png)](https://imgtu.com/i/67iaQK)\n\ncase3 当没有提及时，非结构化的文档embedding发挥主要作用\n\n\n\n\n\n## 结论\n\nHopRetriever 能够将结构性知识和非结构性知识进行结合，确定比较好的跃点hop。同时，跃点迭代模型能够一步步寻找下一个跃点，最终确定答案实体。除此之外，初步文档检索也是十分重要的内容，文章采用的神经排序器效果不错，值得后面继续研究。\n\n\n\n## 参考文献\n\n[HopRetriever: Retrieve Hops over Wikipedia to Answer Complex Questions 论文阅读笔记]([https://www.bluestragglers.com/kgqa-%e8%ae%ba%e6%96%87%e9%98%85%e8%af%bb%e7%ac%94%e8%ae%b0%ef%bc%88%e5%8d%81%e4%ba%8c%ef%bc%89/](https://www.bluestragglers.com/kgqa-论文阅读笔记（十二）/))\n\n\n\n","tags":["GNN&nlp"]},{"title":"LeetCode面试17_21直方图装水","url":"/2021/03/22/LeetCode面试17-21直方图装水/","content":"\n# 直方图装水\n\n![](https://i.loli.net/2021/03/22/UJAq2P9xl7D1VWa.png)\n\n\n\n## 思路\n\n- 如果用程序来描述直方图高度的话不好描述\n- 问题可以想成，每个数组下标下当前列中可以放多少水\n- 每个横坐标下的最大存水量=min(当前的左边最大高度，当前右边的最大高度)\n- 如果我当前高度比左右两边最大值都大，那么我横坐标上肯定没水\n- 当前i水量=min{max左，max右} - arr[i] > 0 ? 当前i水量 ： 0\n- 总的存水量=每个横坐标上能存水量的加和\n- 第0个和最后一个就肯定无水\n\n## 优化\n\n普通方法，像上面的思路，到每个i位置都会向左向右遍历一个最大值，复杂度有点高。\n\n技巧：预处理数组，为的是不用每次都遍历去求最大最小值,用的时候直接取\n\n比如原始数组为[3,1,6,7,2,4,3]\n\n从左到右，从右到左，正反遍历此数组，如果当前数比之前的数小就取之前的值作为当前值，当前数比钱已给数大就还选本来的值。\n\n从左到右遍历后为[3,3,6,7,7,7,7]\n\n从右到左遍历后为[7,7,7,7,4,4,3]\n\n以空间换时间，还不是最优\n\n技巧二：(最优)\n\n声明两个指针，L和R。因为数组两端点不会有水L=1,R=N-2。\n\n再声明两变量，LMax：L扫过的部分的最大值，RMax：R扫过的部分最大值。初值为LMax=arr[0],RMax=arr[N-1]\n\n此时就可以计算出L和R当前所能存水的最大值。因为R左边最大值肯定大于等于LMax，L右边最大值肯定大于等于RMax\n\n当LMax大于RMax时，R处的值可求 \n\n当RMax大于LMax事，L处的值可求\n\n相等事，LR可同时求算\n\nRMax和LMax随遍历进行更新。\n\n```java\nclass Solution {\n    public static int water1(int[] arr) {\n        if (arr == null && arr.length < 2) {\n            return 0;\n        }\n        int N = arr.length;\n        int water = 0;\n        for (int i = 0; i < N; i++) {\n            int leftMax = Integer.MIN_VALUE;\n            for (int j = 0; j < i; j++) {\n                leftMax = Math.max(leftMax, arr[j]);\n            }\n            int rightMax = Integer.MIN_VALUE;\n            for (int j = i + 1; j < N; j++) {\n                rightMax = Math.max(rightMax, arr[j]);\n            }\n            water += Math.max(Math.min(leftMax, rightMax) - arr[i], 0);\n        }\n        return water;\n    }\n\n    public static int water2(int[] arr) {\n        if (arr == null && arr.length < 2) {\n            return 0;\n        }\n        int N = arr.length;\n        int water = 0;\n        int left = Integer.MIN_VALUE;\n        int[] leftMaxs = new int[N];\n        for (int i = 0; i < N; i++) {\n            leftMaxs[i] = Math.max(leftMaxs[i - 1], arr[i]);\n        }\n        int[] rightMaxs = new int[N];\n        rightMaxs[N - 1] = Integer.MIN_VALUE;\n        for (int i = N - 1; i >= 9; i--) {\n            rightMaxs[i] = Math.max(rightMaxs[i + 1], arr[i]);\n        }\n        int warter = 0;\n        for (int i = 0; i < N; i++) {\n            warter += Math.max(Math.min(leftMaxs[i-1], rightMaxs[i+1]) - arr[i], 0);\n        }\n\n        return water;\n    }\n    public static int water3(int arr[]) {\n          if (arr == null && arr.length < 2) {\n              return 0;\n          }\n          int N = arr.length;\n          int L = 1;\n          int R = N - 2;\n          int leftMax = arr[0];\n          int rightMax = arr[N - 1];\n          int water = 0;\n          while (L <= R) {\n              if (leftMax <= rightMax) {\n                  water += Math.max(0, leftMax - arr[L]);\n                  leftMax = Math.max(leftMax, arr[L++]);\n              } else {\n                  water += Math.max(0, rightMax - arr[R]);\n                  rightMax = Math.max(rightMax, arr[R--]);\n              }\n          }\n     }\n}\n```\n\n\n\n","tags":["刷题"]},{"title":"阅读理解数据集综述","url":"/2021/03/22/阅读理解数据集综述/","content":"\n# 阅读理解数据集综述\n\n## 1. 阅读理解任务定义\n\n阅读理解任务可以被当作是一个有监督学习问题，具体来说，该任务可 以详细描述为:给定一个数据集 T，其中 T 的每一个样本都以下的三元组来表示:\n$$\nT = {(P_i, Q_i, A_i)}_{i=1}^n\n$$\n其中，$P_i$ 代表第 $i$ 个样本中的文章片段，$Q_i$ 代表第 $i$ 个样本中的问题，$A_i$  代表第 $i$  个样本中根据文章和问题所回答的答案。阅读理解的任务是通过学习得到一个预测函数 $f$ ，使得我们能够通过给定的 $P_i$  与 $Q_i$  来预测出 $A_i$ :\n$$\nf(P_i, Q_i) \\to A_i\n$$\n通俗来讲，阅读理解任务就是通过给定一个文章片段，给定一个问题，要求计算机能够通过文章片段与问题来获得答案。\n\n## 2. 阅读理解任务类型\n\n阅读理解有多种类型，其划分的一个主要依据是根据答案的类型进行划分，这么区分的主要原因在于答案的不同使得模型输出层，损失函数，评估方式等发生很大变化。\n\n目前来看，阅读理解任务根据具体答案形式的不同可以大致区分为以下四类:\n\n- **填空式阅读理解。**\n\n  填空式阅读理解有一个很明显的特点：答案往往是一个单词而非句子。填空式阅读理解任务可以描述为:给定一段文章片段与一个问题，要求机器根据文章片段与问题来推理出合理的答案， 且答案往往是文章片段的某个词。\n\n  填空式阅读理解在阅读理解发展的早 期起到了至关重要的作用，现在已经退出主流数据集了，具体典型的数据集 有:CNN&Daily Mail，Who did What等数据集。\n\n- **抽取式阅读理解。**\n\n  抽取式阅读理解任务可以描述为:给定一段文章片 段，给定一个问题，要求机器根据该问题从文章片段中找出一个连续的片段作为答案。\n\n  考虑到输出问题，此类问题又转化为预测答案的开始与结束的两 个位置 $pos_{start}$ 与 $pos_{end}$ 。此时，问题就转化成为一个分类问题，答案可以用篇章词片段表示为 $[ pos_{start} , pos_{end} ]$ 。\n\n  在过去两年中，此类数据集一直是学术界的主流数据集，极大的推动了阅读理解领域的发展，其中最典型的数据集包括 SQuAD，MS Marco，NewsQA，TriviaQA等数据集。\n\n- **多选式阅读理解。**\n\n  多选式阅读理解任务可以描述为：给定一段文章片段，给定一个问题，给定多个选项，要求机器根据文章片段与问题从答案选项中选择一个最合适的答案。\n\n  通过将阅读理解问题转化为分类问题可以更准 确的评估机器对语言的理解能力，这也是此类数据集强于抽取式数据集的一 大原因。\n\n  此类数据集是目前研究人员研究的热点之一，代表性的数据集有 RACE，CLOTH等。\n\n- **生成式阅读理解。**\n\n  生成式阅读理解任务可以描述为：给定一段文章片 段，给定一个问题，要求机器基于文章片段与问题生成一个合适的答案，该答案不局限于文章中存在的词语，而是自由生成的。\n\n  此类型的阅读理解任务 更适合实际生活场景，但是由于生成的句子无法做准确评估，因此一直无法 成为业界的主流数据集。代表性的数据集有 NARRATIVEQA，CoQA等。\n\n\n\n## 3. 阅读理解任务的评估方式\n\n| 任务类型       | 评估方法           |\n| -------------- | ------------------ |\n| 填空式阅读理解 | 准确率(Accuracy)   |\n| 抽取式阅读理解 | EM(完全匹配值)，F1 |\n| 多选式阅读理解 | 准确率(Accuracy)   |\n| 生成式阅读理解 | BLEU，ROUGE        |\n\n对于抽取式阅读理解任务，由于答案通常为一个片段，一般同时采用两\n种评估方式:\n\n- 完全匹配值(Exact Match，EM)。该指标用来判定预测的答案与给 定的答案是否完全相同，即预测的开始位置 $pos^{pred}_{start}$ 与终止位置 $pos^{pred}_{end}$ 是否与真实值相同，其计算公式下：\n  $$\n  EM = \\begin{cases} 1, & pos^{pred}_{start} == pos^{real}_{start}  \\, and \\, pos^{pred}_{end} == pos^{real}_{end} \\\\ 0, & otherwise \\end{cases}\n  $$\n\n- F1 值。该指标主要评估预测的答案片段与正确答案的重合率，其计 算公式如下所示：\n  $$\n  F1 = \\frac{2 \\times Precision \\times Recall}{Precision + Recall}\n  $$\n\n## 4. 现有数据集分类\n\n本节汇集了当前大多数的阅读理解数据集，并对其进行简单描述\n\n### 1. 填空式阅读理解\n\n考虑到这部分其实已经几乎没人在搞了，因此就不做详细描述了。\n\n| 数据集            | 语言    | 状态             |\n| ----------------- | ------- | ---------------- |\n| MCTest [1]        | English | 过时，不推荐研究 |\n| CNN/Daily Mail[2] | English | 过时，不推荐研究 |\n| CBT[3]            | English | 过时，不推荐研究 |\n| Quasar-S[4]       | English | 过时，不推荐研究 |\n\n- CNN&Daily Mail： 最具代表的数据聚集，数据来源于CNN 和 Daily Mail。\n- CBT：数据来源于儿童读物。\n\n### 2. 抽取式阅读理解\n\nhttps://www.leiphone.com/news/201903/QcmBwrYSo8QyWXRb.html\n\n| 数据集                                                       | 语言        | 状态                                 |\n| ------------------------------------------------------------ | ----------- | ------------------------------------ |\n| [SQuAD 1.0](https://rajpurkar.github.io/SQuAD-explorer/) [5] | English     | 过时                                 |\n| [**SQuAD 2.0**](https://rajpurkar.github.io/SQuAD-explorer/) [6] | **English** | **热点**                             |\n| [**DuReader**](https://zhuanlan.zhihu.com/p/36415104)        | **Chinese** | **热点**                             |\n| [**MS MARCO**](https://zhuanlan.zhihu.com/p/53525750)        | **English** | **非研究热点，但跟搜索引擎紧密结合** |\n| [CoQA](https://zhuanlan.zhihu.com/p/43050014) [9]            | English     | 热点，接替SQuAD                      |\n| [TriviaQA](http://nlp.cs.washington.edu/triviaqa/) [10]      | English     | 热点                                 |\n| [HotpotQA](https://hotpotqa.github.io/) [11]                 | English     | 热点                                 |\n| Quasar-T [4]                                                 | English     | 非研究热点                           |\n| SearchQA[12]                                                 | English     | 非研究热点                           |\n| [CMRC 2018](https://hfl-rc.github.io/cmrc2018/open_challenge/) | Chinese     | 研究热点                             |\n| [CMRC 2019](https://hfl-rc.github.io/cmrc2019/)              | Chinese     | 热点                                 |\n| [NewsQA](https://www.microsoft.com/en-us/research/project/newsqa-dataset/) [13] | English     | 有点意思                             |\n| [QuAC](http://quac.ai/) [14]                                 | English     | 非热点                               |\n\n- SQuAD 1.0：来源于维基百科，给定 context 于 question， 从 context 中截取一个片段，该片段作为答案。 是一个典型的抽取式问题。\n- SQuAD 2.0：在 SQuAD 1.0 的基础上新增超过5万无法回答的问题。这要求模型不仅要在能够在问题可回答时给出答案，还要判断哪些问题是阅读文本中没有材料支持的，并拒绝回答这些问题。\n- DuReader： 中文阅读理解数据集，应该是国内最棒的阅读理解数据集。它的格式跟 下面的 MS MARCO 相似。DuReader中的问题和文档均来自百度搜索和百度知道。答案是人为产生的，而不是原始上下文中的片段。DuReader之所以与众不同，是因为它提供了新的问题类型，例如yes、no和opinion。与事实性问题相比，这些问题有时需要对文档的多个部分进行汇总。\n- MS MARCO：， 很工业化的数据集，来自Bing 用户查询，因此跟搜索引擎技术紧密相连，十分适合学习。为了克服以前的数据集的弱点，它具有四个主要功能。首先，所有问题都是从真实用户查询中收集的；其次，对于每个问题，使用Bing搜索引擎搜索10个相关文档作为上下文；第三，人为这些问题标注了答案，因此它们不仅限于上下文范围，还需要更多的推理和总结；第四，每个问题有多个答案，有时甚至冲突，这使得机器选择正确的答案更具挑战性。MS MARCO使MRC数据集更接近真实世界。\n- CoQA：， 对话式阅读理解数据集，这跟现实生活又近了一步，是现在研究的热点。CoQA包含约8000轮对话，问题的答案有五种类型，分别为Yes、No、Unknown，文章中的一个span和生成式答案。当根据文章和之前的对话信息无法回答当前问题时，答案为Unknown。该数据集不仅提供答案，而且给出了答案的依据，每一种类型的答案的依据都是文章中的一个span。\n\n- TriviaQA：。该数据集构造问答对，然后从维基百科等页面中寻找对应的论据。最终通过上述方式构造了约65,000个“问题-答案-论据”三元组，通过这种方式构造的数据集比SQuAD更接近实际使用场景。对比SQuAD数据集，其主要集中于是推理方面的问题，并且实验证明一些在SQuAD上表现良好的模型在TriviaQA上并不能获得理想的结果。\n- HotpotQA：研究基于多个信息内容的多步推理，然后回答问题。这意味着答案并不仅仅来源于单一文档。\n- Quasar-T：不建议深入研究。\n- SearchQA：作者构建该数据集的目的是构建能反映检索系统噪声的阅读理解数据集，作者通爬取 Jeopardy 上的问题，然后将问题作为query 在Google 上检索，获得 answer snippets。 该数据集是通过程序生成的，因此噪声不可避免的比较高，因此不建议深入研究。\n- NewsQA：该数据集是从CNN新闻网站上构造的，构造方法与SQuAD一致。\n\n- QuAC： 对话式阅读理解数据集。\n\n### 3. 多选式阅读理解\n\n| 数据集                                                       | 语言    | 状态             |\n| ------------------------------------------------------------ | ------- | ---------------- |\n| [RACE](http://www.qizhexie.com//data/RACE_leaderboard) [15]  | English | 热点，可研究     |\n| [CLOTH](http://www.qizhexie.com/data/CLOTH_leaderboard) [16] | English | 一般，已解决     |\n| [ARC](https://allenai.org/data/arc) [17]                     | English | 一般，不推荐     |\n| Who did What [18]                                            | English | 过时，不推荐研究 |\n| [OpenBookQA](https://leaderboard.allenai.org/open_book_qa/submissions/public) [19] | English | 一般，不推荐     |\n| [CommonsenseQA](https://www.tau-nlp.org/commonsenseqa)  [20] | English | 一般，不推荐     |\n| [COSMOS QA](https://wilburone.github.io/cosmos/) [21]        | English | 一般             |\n\n- RACE： RACE 取自于中国中高考阅读理解题型，我个人认为这是目前最能体现阅读理解能力的数据集之一，十分值得研究。\n- CLOTH：来自中文中高考完形填空题型，相较于RACE， CLOTH 天然的适合 BERT 这种 AE 模型来填词，因此 CLOTH 可以说是已经被解决了，准确率比人高。\n- ARC：ARC 取自中学生考试中的科学问题，并进一步分为ARC-Challenge 于 ARC-Easy 两个子集，共包含大约8000个问题，此外，该数据集中提供与该任务相关的包含14M科学事实的语料库用来回答这些问题。\n- OpenBookQA：包含大约6000个问题，每个问题包括四个选项，此外，与ARC数据集相似，该数据集也提供了参考语料库，包含1326个事实，每个问题期望结合语料库中的某一个事实来得到答案。此外，还需要结合一些常识知识。如何准确的利用参考语料库与常识知识成为了该数据集的主要问题之一。\n- CommonsenseQA：来自于ConceptNet，其包含大约12000个需要结合背景知识的问题。在该数据集中，标注者根据ConceptNet中的实体概念来自由构造问题，来使问题包含人类所具有的、但难以在网络资源中检索到的背景知识，故回答问题需要利用问题、候选答案，以及仅仅使用检索策略无法检索到的背景知识。\n- COSMOS QA：包含35600个需要常识阅读理解的问题，其专注于解决需要跨越上下文、而不是定位指定片段的推理问题。\n\n### 4. 生成式阅读理解\n\n生成式阅读理解目前还没有热起来的趋势，相关的数据集也没有进入主流视野，个人不建议做这方面的研究。 这一大原因在于文本生成作为单一的任务迟迟得不到突破，至少目前为止（2020年），看不到突破的影子，个人觉得还需要一些时间。\n\n### 5. 其他\n\n其他还有一些数据集，如bAbi，LAMBADA， SCT，MCScript，NarrativeQA，DuoRC，CliCR 等，水平有限，累了，就不做赘述了。\n\n## 最后\n\n本文总结了大多数的数据集，但是并没有对数据集进行详细描述，一来是因为工作量比较大，二来是觉得没有必要。 一般做阅读理解紧跟几个主流数据集就行，太多数据集反而会乱了自身阵脚。\n\n## Reference\n\n### 1. 博客参考\n\n[赛尔笔记 | 机器阅读理解简述](https://zhuanlan.zhihu.com/p/111410698)\n\n[RCPapers](https://github.com/thunlp/RCPapers)\n\n### 2. 填空式阅读理解\n\n[1] (MCTest) **MCTest: A Challenge Dataset for the Open-Domain Machine Comprehension of Text.** Matthew Richardson, Christopher J.C. Burges, and Erin Renshaw. EMNLP 2013. [paper](http://www.aclweb.org/anthology/D13-1020).\n\n[2] (CNN/Daily Mail) **Teaching Machines to Read and Comprehend.** Hermann, Karl Moritz, Tomas Kocisky, Edward Grefenstette, Lasse Espeholt, Will Kay, Mustafa Suleyman, and Phil Blunsom. NIPS 2015. [paper](https://papers.nips.cc/paper/5945-teaching-machines-to-read-and-comprehend.pdf)\n\n[3] (CBT) **The Goldilocks Principle: Reading Children's Books with Explicit Memory Representations.** Felix Hill, Antoine Bordes, Sumit Chopra, and Jason Weston. arXiv preprint arXiv:1511.02301 (2015). [paper](https://arxiv.org/pdf/1511.02301)\n\n[4] (Quasar) **Quasar: Datasets for Question Answering by Search and Reading.** Bhuwan Dhingra, Kathryn Mazaitis, and William W. Cohen. arXiv preprint arXiv:1707.03904 (2017). [paper](https://arxiv.org/pdf/1707.03904)\n\n### 3. 抽取式阅读理解\n\n[5 ]  (SQuAD 1.0) **SQuAD: 100,000+ Questions for Machine Comprehension of Text.** Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. EMNLP 2016. [paper](https://aclweb.org/anthology/D16-1264)\n\n[6] (SQuAD 2.0) **Know What You Don't Know: Unanswerable Questions for SQuAD.** Pranav Rajpurkar, Robin Jia, and Percy Liang. ACL 2018. [paper](http://aclweb.org/anthology/P18-2124)\n\n[7] (DuReader) **DuReader: a Chinese Machine Reading Comprehension Dataset from Real-world Applications.** Wei He, Kai Liu, Yajuan Lyu, Shiqi Zhao, Xinyan Xiao, Yuan Liu, Yizhong Wang, Hua Wu, Qiaoqiao She, Xuan Liu, Tian Wu, and Haifeng Wang. ACL 2018 Workshop. [paper](https://arxiv.org/abs/1711.05073)\n\n[8]  (MS MARCO) **MS MARCO: A Human Generated MAchine Reading COmprehension Dataset.** Tri Nguyen, Mir Rosenberg, Xia Song, Jianfeng Gao, Saurabh Tiwary, Rangan Majumder, and Li Deng.  arXiv preprint arXiv:1611.09268 (2016). [paper](https://arxiv.org/pdf/1611.09268)\n\n[9] (CoQA) **CoQA: A Conversational Question Answering Challenge.** Siva Reddy, Danqi Chen, and Christopher D. Manning. arXiv preprint arXiv:1808.07042 (2018). [paper](https://arxiv.org/pdf/1808.07042)\n\n[10] (TriviaQA) **TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension.** Mandar Joshi, Eunsol Choi, Daniel S. Weld, Luke Zettlemoyer. arXiv preprint arXiv:1705.03551 (2017). [paper](https://arxiv.org/pdf/1705.03551)\n\n[11] (HotpotQA) **HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question Answering**. Yang Z , Qi P , Zhang S , et al. . 2018.[paper](https://arxiv.org/abs/1809.09600v1)\n\n[12] (SearchQA) **SearchQA: A New Q&A Dataset Augmented with Context from a Search Engine.** Matthew Dunn, Levent Sagun, Mike Higgins, V. Ugur Guney, Volkan Cirik, and Kyunghyun Cho. arXiv preprint arXiv:1704.05179 (2017). [paper](https://arxiv.org/pdf/1704.05179)\n\n[13] (NewsQA) **NewsQA: A Machine Comprehension Dataset.** Adam Trischler, Tong Wang, Xingdi Yuan, Justin Harris, Alessandro Sordoni, Philip Bachman, and Kaheer Suleman. arXiv preprint arXiv:1611.09830 (2016). [paper](https://arxiv.org/pdf/1611.09830)\n\n[14] (QuAC) **QuAC : Question Answering in Context.** Eunsol Choi, He He, Mohit Iyyer, Mark Yatskar, Wen-tau Yih, Yejin Choi, Percy Liang, and  Luke Zettlemoyer. arXiv preprint arXiv:1808.07036 (2018). [paper](https://arxiv.org/pdf/1808.07036)\n\n### 3.  多选式阅读理解\n\n[15] (RACE) **RACE: Large-scale ReAding Comprehension Dataset From Examinations.** Guokun Lai, Qizhe Xie, Hanxiao Liu, Yiming Yang, and Eduard Hovy. EMNLP 2017. [paper](http://aclweb.org/anthology/D17-1082)\n\n[16] (CLOTH) **Large-scale Cloze Test Dataset Created by Teachers.** Qizhe Xie, Guokun Lai, Zihang Dai, and Eduard Hovy. EMNLP 2018. [paper](https://arxiv.org/pdf/1711.03225)\n\n[17] (ARC) **Think you have Solved Question Answering?Try ARC, the AI2 Reasoning Challenge.** Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot,Ashish Sabharwal, Carissa Schoenick, and Oyvind Tafjord. arXiv preprint arXiv:1803.05457 (2018). [paper](https://arxiv.org/pdf/1803.05457)\n\n[18] (Who did What) **Who did What: A Large-Scale Person-Centered Cloze Dataset** Takeshi Onishi, Hai Wang, Mohit Bansal, Kevin Gimpel, and David McAllester. EMNLP 2016. [paper](https://aclweb.org/anthology/D16-1241)\n\n[19] (OpenBookQA) Mihaylov T, Clark P, Khot T, et al. Can a suit of armor conduct electricity? a new dataset for open book question answering[J].  2018. [paper](https://arxiv.org/abs/1809.02789)\n\n[20] Talmor A, Herzig J, Lourie N, et al. Commonsenseqa: A question answering challenge targeting commonsense knowledge[J]. 2018. [paper](https://arxiv.org/abs/1811.00937)\n\n[21] Huang L, Bras R L, Bhagavatula C, et al. Cosmos QA: Machine reading comprehension with contextual commonsense reasoning[J]. arXiv, 2019. [paper](https://arxiv.org/abs/1909.00277)\n\n### 其他\n\n[22] (bAbi) **Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks.** Jason Weston, Antoine Bordes, Sumit Chopra, Alexander M. Rush, Bart van Merriënboer, Armand Joulin, and Tomas Mikolov. arXiv preprint arXiv:1502.05698 (2015). [paper](https://arxiv.org/pdf/1502.05698)\n\n[23] (LAMBADA) **The LAMBADA Dataset:Word Prediction Requiring a Broad Discourse Context.** Denis Paperno, Germ ́an Kruszewski, Angeliki Lazaridou, Quan Ngoc Pham, Raffaella Bernardi, Sandro Pezzelle, Marco Baroni, Gemma Boleda, and Raquel Fern ́andez. ACL 2016. [paper](https://www.aclweb.org/anthology/P16-1144)\n\n[24] (SCT) **LSDSem 2017 Shared Task: The Story Cloze Test.** Nasrin Mostafazadeh, Michael Roth, Annie Louis,Nathanael Chambers, and James F. Allen. ACL 2017 workshop. [paper](http://aclweb.org/anthology/W17-0906)\n\n[25] (MCScript) **MCScript: A Novel Dataset for Assessing Machine Comprehension Using Script Knowledge.** Simon Ostermann, Ashutosh Modi, Michael Roth, Stefan Thater, and Manfred Pinkal. arXiv preprint arXiv:1803.05223.  [paper](https://arxiv.org/pdf/1803.05223.pdf)\n\n[26] (NarrativeQA) **The NarrativeQA Reading Comprehension Challenge**.\nTomáš Kočiský, Jonathan Schwarz, Phil Blunsom, Chris Dyer, Karl Moritz Hermann, Gábor Melis, and Edward Grefenstette. TACL 2018. [paper](http://aclweb.org/anthology/Q18-1023)\n\n[27] (DuoRC) **DuoRC: Towards Complex Language Understanding with Paraphrased Reading Comprehension.** Amrita Saha, Rahul Aralikatte, Mitesh M. Khapra, and Karthik Sankaranarayanan. ACL 2018. [paper](http://aclweb.org/anthology/P18-1156)\n\n[28] (CliCR) **CliCR: a Dataset of Clinical Case Reports for Machine Reading Comprehension.** Simon Suster and Walter Daelemans. NAACL 2018. [paper](http://aclweb.org/anthology/N18-1140) ","tags":["nlp"]},{"title":"High-Order Information Matters Learning Relation and Topology for Occluded Person Re-Identification(CVPR2020)(泛读)","url":"/2021/01/29/16088026276866/","content":"# High-Order Information Matters: Learning Relation and Topology for Occluded Person Re-Identification(CVPR2020)(泛读)\n\nhttps://arxiv.org/abs/2003.08177\n## 解决方案\n主要解决遮蔽现象。\n整体思路可以再各种跟验证相关的任务中去套用。\n\n\n针对遮蔽数据集Occluded-DukeMTMC\n提出三阶段模型：\n- 关键点局部特征提取 (关键点数据集或者关键点识别模型)\n- 图卷积融合关键点特征\n- 基于图匹配的方式来计算相似度并训练模型\n完成特征提取，重点解决遮蔽问题。\n\n![](https://i.loli.net/2021/03/22/pGFgesWTlOBR7fH.png)\n关键点可以学习人体走路运动的先验知识。\n\n1、关键点局部特征提取 \n关键点数据集或者关键点识别模型\n\n2、图卷积融合贯机电特征\n传统算法是点与点进行匹配，但当两个图像遮蔽位置不一致时，就没法进行对比关键点。\n图卷积就会好好利用未被遮挡的区域。\n\n3、基于图匹配的方式来计算相似度并训练模型\n匹配图像中哪些能用哪些不能用，能用的该怎么用，不能用的该怎么减少。\n计算U匹配矩阵(13x13)关键点。\n\n![](https://i.loli.net/2021/03/22/JxhiZMtfjGT2w1c.png)\n\n### 第一阶段S(关键点局部特征提取)\n根据CNN提取到feature map和十三个关键点的信息。\nlocal是十三个关键点信息。\nglobal是feature map(global average pooling得到)\n![-w417](https://i.loli.net/2021/03/22/82pZIRDka5mWf6B.png)\n热度图是关键点乘以feature map\n选择一个pose estimation模型即可，得到的是各个关键点的热度图信息，通过热度图得到原始特征图的局部信息。\n![](https://i.loli.net/2021/03/22/RexpiASI2hQcVBK.png)\n用feature map和关键点信息相乘，相当于在特征图中把信息画出来。\n得到一共十四个特征+global\n把local和global都进行训练，添加多个损失。\n\n### 第二阶段R(如何利用各个点的特征，用图卷积局部特征关系整合)\n![](https://i.loli.net/2021/03/22/3axhY2EUwpvDzSW.png)\n做特征的整合，得到的还是local和global，是一个有了相互关系的拓扑结构，相当于一个attention机制。\n将得到的邻接矩阵A来指导每个关键点特征如何跟其他关键点特征进行计算，并且A矩阵也要进行学习。\n\n如何利用好局部特征？加入关系\n先初始化邻接矩阵来进行图卷积，邻接矩阵在学习过程中更新，综合利用各关键点直接的信息。\n\n如何才能更好的针对每个输入利用不同的局部特征？没有边的就不用\n\n和整体差异越大的，越离群。\n利用差异特征来学习邻居矩阵A\n有了A就能开始图卷积了，用他来指导如何利用不同关键点的特征进行组合，最终再与输入的局部特征进行整合。\n\n![](https://i.loli.net/2021/03/22/ILAd2y5hYOR6vbt.png)\n$K=13$ 13个关键点\n$V_l^{in}$ 关键点特征向量 $batch*13*2048$\n$V_g^{in}$ 全局特征向量   $1*13*2048$\nrepeat调整向量大小把$1*13*2048$变成$batch*13*2048$后做减法\n然后经过abs绝对值、bn层、fc层后得到一个$K*K$的矩阵$A^{adp}$。\n用学习到的$A^{adp}$和邻接矩阵A做乘法。$A'=A^{adp}*A$\n之后在用$V_l^{in}$和上面相乘得到的结果当成$V_l^{in}*A'$相当于图卷积过程。\n再将本身特征$V_l^{in}$和图卷积后的关系特征相加。\n再concat全局特征向量$V_g^{in}$得到输出\n\n\n\n\n\n\n\n\n\n\n\n### 第三阶段T(图匹配，相似度计算)\n\n输入两张图像(经过了前两阶段后的结果)\n\nGraph Matching 计算一个14X14的相似度矩阵U，对一下关键点。表示两个图之间的关系。\n![-w454](https://i.loli.net/2021/03/22/WkqcwQo9avTXibR.png)\n进入了新的验证损失函数。\n就是sigmoid(emb1,emb2)的结果。\n\n![](https://i.loli.net/2021/03/22/s2ZIxedCYqESvk7.png)\n输入两个编码后的特征向量。\n先经过fc+relu提取下特征，再进行图匹配得出相似度矩阵U。\n然后是一个交叉cross的过程，分别交叉来得到个子匹配的特征结果。知道了哪里该匹配哪里不该，再进过fc+relu得到最终特征。\n\n## 参考文献\n[这篇的旷世推文](https://mp.weixin.qq.com/s/EhAeaA68Ek27EptkTfZiBQ)\n[【CVPR2020】：High-Order Information Matters: Learning Relation and Topology for Occluded Person Re-Ide](https://blog.csdn.net/baidu_41617231/article/details/107421943)\n[【唐宇迪】CVPR2020最新行人重识别论文解读](https://www.bilibili.com/video/BV1764y1c7jZ?p=3)\n[图解行人重识别论文系列](https://www.bilibili.com/video/BV13W411K7jM?from=search&seid=5052861388779194545)","tags":["GNN&cv"]},{"title":"天池赛题:天猫重复购学习笔记(我的EDA模板)","url":"/2021/01/29/16080066587381/","content":"highlight_shrink:\n---\n\n# 天池赛题:天猫重复购学习笔记(我的EDA模板)\n\n字段解释都在:[这里](https://tianchi.aliyun.com/competition/entrance/231576/information)\n代码在GitHub:[这里](https://github.com/Coding-Zuo/DataGame/tree/main/tianchi/%E5%A4%A9%E7%8C%AB%E7%94%A8%E6%88%B7%E9%87%8D%E5%A4%8D%E8%B4%AD)\n- 复购率 = 重复购买用户数量/用户样本数量\n- 复购率 = 重复购买行为次数(或 交易次数)/用户样本数量\n\n[TOC]\n\n## EDA步骤\n\n### 1.看数据类型、数量、样例\n无疑是一些pd.read_csv(_)和data.info()、data.head()。大致看一看\n查看是否有单一值变量\n\n```python\n#查看训练集测试集中特征属性只有一值的特征\ntrain_one_value = [col for col in train.columns if train[col].nunique() <= 1]\ntest_one_value = [col for col in test.columns if test[col].nunique() <= 1]\nprint('one value featrues in train:',train_one_value)\nprint('one value featrues in test: ',test_one_value)\n```\n\n### 2.区分类别变量和连续变量\n一般类别变量的处理和连续型变量的处理不一样\n类别型可能会encode，看一些数量分布。\n连续型可能会看一看核分布。\n\n```python\n#区分类别特征与连续特征\ndef split_features(df,colnums,nums=30):\n    label_features={}\n    continue_features={}\n    for key in colnums:\n        nunique=df[key].nunique()\n        if np.issubdtype(df[key][0],np.int) and nunique<=nums:\n            label_features.update({key:nunique})\n        elif np.issubdtype(df[key][0],np.float) and nunique<=nums:\n            label_features.update({key:nunique})\n        else:\n            continue_features.update({key:nunique})\n    print(label_features)\n    #return label_features,continue_features\n\nuser_info_colnums=user_info.columns.values\nuser_log_colnums=user_log.columns.values\ntrain_colnums=train.columns.values\nlable_nunique_maxnums=20\nprint('user_info:')\nsplit_features(user_info,colnums=user_info_colnums,nums=lable_nunique_maxnums)\nprint('user_log :')\nsplit_features(user_log,colnums=user_log_colnums,nums=lable_nunique_maxnums)\nprint('train :')\nsplit_features(train,colnums=train_colnums,nums=lable_nunique_maxnums)\n```\n可知 \nuser_info:\n{'age_range': 9, 'gender': 3}\nuser_log :\n{'action_type': 4}\ntrain :\n{'label': 2}\n\n### 3.看是否有缺失值\n\n| 插补方法      | 说明                                                         | 优点                             | 缺点                                   | 使用环境         |\n| ------------- | :----------------------------------------------------------- | -------------------------------- | -------------------------------------- | ---------------- |\n| 类均值插补    | 数值型：均值。<br/>非数值型：众数（出现频率最高的值）值比较稳定性；低估资料变异 | 简单易行：被插补的值比较稳定     | 不能反映缺失值的变异性；低估资料变异   | 低缺失率首选     |\n| 类随机插补    | 聚类填充；使用所有可能的值填充；组合完整化方法               | 能体现数据变异性                 | 依赖于观测值                           | 低缺失率         |\n| 回归插补      | 基于完整的数据集，建立回归方程（模型）                       | 方差估计好                       | 稳定性依赖于辅助变量，抽样误差不易控制 | 变量间的相关性强 |\n| Em 插补       | 通过观测数据的边际分布可以对未知参数进行极大似然估计         | 利用充分，考虑了缺失值的不确定性 | 计算复杂                               | 高缺失率         |\n| 多重插补 MCMC | 估计出持插补的值，然后加上不同的噪声，形成多组可选插补值     | 利用充分，考虑了缺失值的不确定性 | 计算复杂                               | 高缺失率首选     |\n\n\n\n```python\n# 有时0代表缺失值，对于缺失值严重的一般删除处理\n# 缺失值较少一般三种：\n#统计量填充：连续值推荐用中位数，离散值：用众数，不能用均值和中位数\n#特殊值填充：正常范围内取值\n#不处理：xgb、lgb对缺失值不太敏感，算法本身有一套缺失值处理方法\ndef missing_value_rate(data,col_name):\n    rate_list = {}\n    for col in col_name:\n        rate = (data.shape[0]-data[col].count())/data.shape[0]\n#         na_zero_num = data[data[col].isna() | (data[data[col]==0])].count()\n        lable_foamt = 'rate:{}'.format(rate)\n        rate_list[col]=lable_foamt\n    return rate_list\n```\n\n```python\nprint('age_range:',user_info[user_info['age_range'].isna() | (user_info['age_range']==0)].count())\nprint()\nprint('gender:',user_info[user_info['gender'].isna() | (user_info['gender']==0)].count())\nmissing_value_rate(user_info,user_info.columns)\n```\n\n### 4.观察数据分布、不均衡样本\n不均衡样本，可采用\n\n- 随机欠采样\n- 随机过采样\n- 基于聚类的过采样\n- SMOTE算法\n- 基于数据清洗的SMOTE\n\n首先describe()看一看。\n#### 正负样本分布\n```python\nlabel_gp = train.groupby('label')['user_id'].count()\nprint('正负样本数量:',label_gp)\n```\n\n```python\nfig = plt.figure()\n# 样本分布不均匀 可采用负样本过采样技术，训练多个模型后求平均或者调整模型的损失函数样本比例的权重\nax = plt.subplot(1,2,1)\nlabels = [0,1]\nsizes = [label_gp[0],label_gp[1]]\nexplode = (0,0)\nplt.pie(sizes,explode=explode,labels=labels,autopct='%1.1f%%',shadow=False,startangle=150)\n\nplt.subplot(1,2,2)\nsns.countplot(train['label'])\nplt.show()  \n```\n![-w355](https://i.loli.net/2021/03/22/VuwAyesYqEUKkib.png)\n\n\n\n#### 对店铺的分析\n\n```python\n#top5销量店铺\ntrain.merchant_id.value_counts().head()\ntrain_data_merchant = train.copy()\ntrain_data_merchant['TOP5']=train_data_merchant['merchant_id'].map(lambda x:1 if x in [4044,3828,4173,1102,4976] else 0)\ntrain_data_merchant = train_data_merchant[train_data_merchant['TOP5']==1]\nplt.figure(figsize=(8,6))\nplt.title('Merchant vs Label')\nsax = sns.countplot('merchant_id',hue='label',data=train_data_merchant)\n```\n对比一下top5店铺回购的比例，可看出不同店铺复购率不同，可能与店铺售卖商品和运营有关。\n![-w507](https://i.loli.net/2021/03/22/6brYGId4tyvh2js.png)\n\n```python\n# 查看店铺的复购分布\nmerchant_repeat_buy = [rate for rate in train.groupby(['merchant_id'])['label'].mean() if rate<=1 and rate>0]\n\nplt.figure(figsize=(8,4))\n\nimport scipy.stats as stats\nax = plt.subplot(1,2,1)\nsns.distplot(merchant_repeat_buy,fit=stats.norm)\nax = plt.subplot(1,2,2)\nres = stats.probplot(merchant_repeat_buy,plot=plt)\n```\n不同店铺有不同的复购率，在0到0.3之间。\n![-w495](https://i.loli.net/2021/03/22/YfWSRQaX3x8wdGh.png)\n\n#### 对用户方面的分析\n通过user_id/age_range/gender等方面\n\n```python\n# 对用户分析\nuser_repeat_buy = [\n    rate for rate in train.groupby(['user_id'])['label'].mean()\n    if rate <=1 and rate>0\n]\n\nplt.figure(figsize=(8,6))\nax = plt.subplot(1,2,1)\nsns.distplot(user_repeat_buy,fit=stats.norm)\nax = plt.subplot(1,2,2)\nres = stats.probplot(user_repeat_buy,plot=plt)\n```\n看出进六个月用户复购概率很小，基本为一次买主\n![-w509](https://i.loli.net/2021/03/22/8ve2dRhlVkCXaxI.png)\n\n```python\n# 用户性别分析\ntrain_user_info =train.merge(user_info,on=['user_id'],how='left')\n\nplt.figure(figsize=(8,8))\nplt.title('Gender vs label')\nax = sns.countplot('gender',hue='label',data=train_user_info)\nfor p in ax.patches:\n    height = p.get_height()\n```\n![-w519](https://i.loli.net/2021/03/22/OARdpIU5tBqMGjy.png)\n```python\n# 不同性别对用户的复购率不同\nrepeat_buy = [rate for rate in train_user_info.groupby(['gender'])['label'].mean()]\n\nplt.figure(figsize=(8,4))\nax = plt.subplot(1,2,1)\nsns.distplot(repeat_buy,fit=stats.norm)\n\nax = plt.subplot(1,2,2)\nres = stats.probplot(repeat_buy,plot=plt) \n```\nprobplot主要是直观的表示观测与预测值之间的差异。一般我们所取得数量性状数据都为正态分布数据。预测的线是一条从原点出发的45度角的虚线，事件观测值是实心点。\n偏离线越大，则两个数据集来自具有不同分布的群体的结论的证据就越大。\n![-w494](https://i.loli.net/2021/03/22/Y2xQn74AGUZTHsl.png)\n\n```python\n# 对用户年龄分析\nplt.figure(figsize=(8,8))\nplt.title('Age vs label')\nax = sns.countplot('age_range',hue='label',data = train_user_info)\n```\n![-w514](https://i.loli.net/2021/03/22/cwrPBGtfKVZbJRC.png)\n```python\n# 用户年龄复购的分布\n# 不同年龄段对用户的复购率不同\nrepeat_buy = [rate for rate in train_user_info.groupby(['age_range'])['label'].mean()]\n\nplt.figure(figsize=(8,4))\n\nax = plt.subplot(1,2,1)\nsns.distplot(repeat_buy,fit=stats.norm)\nax = plt.subplot(1,2,2)\nres = stats.probplot(repeat_buy,plot=plt)\n```\n![-w499](https://i.loli.net/2021/03/22/jkeTh1aUYZq9ELH.png)\n\n### 5.对比训练集和测试集分布\n\n```python\n\n```\n### 6.探查重要影响因素\n\n```python\ncolormap = plt.cm.viridis\nplt.figure(figsize=(14,12))\nplt.title('Pearson Correaltion of Feature',y=1.05,size=15)\nsns.heatmap(train_user_info.astype(float).corr(),linewidths=0.1,vmax=1.0,square=True,cmap=colormap,linecolor='white',annot=True)\n```\n\n## 特征工程\n类别型特征的转换：决策树等少数模型能直接处理字符串形式的输入。\n逻辑回归、svm等需类别型特征处理成数值型特征后才能工作。\n现在比赛基本上都是lightgbm和xgb这些GDBT比较有优势，所以也不用怎么做。了解一些处理方法。\n\n- 序号编码\n- 独热编码\n- 二进制编码\n\n\n### 特征组合\n1、离散特征可两两组合成高阶组合特征，高维组合特征处理的目的是提高复杂关系的拟合能力。\n如： 语言：中文、英文\n    剧集类型：电影电视剧\n    可组合成：中文电影、中文电视剧、英文电影、英文电视剧\n当引入ID特征时，通常要降维。以推荐为例。通常有：\n\n| 是否点击 | uid=1,item=1 | uid=2,item=2 | .... | uid=n,item=n |\n| -------- | ------------ | ------------ | ---- | ------------ |\n| 0        | 1            | 0            | ...  | 0            |\n| 1        | 0            | 1            | ...  | 0            |\n\n\n\n当uid有10000个，item有10000个时有100000000一般可采用SVD分解降低参数，还可以增加参数的迭代拟合数量，防止过拟合。\n\n\n\n2、决策树组合特征：\n![](https://i.loli.net/2021/03/22/RB9qlWDKb3try6c.png)\n\n\n​    \n## 模型训练\n## 模型验证\n## 特征优化\n\n## EDA代码技巧罗列(方便快速拷贝)\n\n### 画字段测试集和训练集数量对比饼图\n\n```python\n#画字段测试集和训练集数量对比饼图\ndef pie_category(train,test):\n    plt.figure(figsize=[9,7])\n    train.value_counts().plot.pie()\n    print(\"train:\",Counter(train))  \n    print(\"test:\",Counter(test))  \n\npie_category(train.XINGBIE,test.XINGBIE)\n```\n### 选择Dataframe数据集中的某几列\n\n```python\n#选择Dataframe数据集中的某几列\nfrom sklearn.base import BaseEstimator,TransformerMixin\n\nclass DataFrameSelector(BaseEstimator,TransformerMixin):\n    def __init__(self,attribute_names):\n        self.attribute_names = attribute_names\n    def fit(self,X,y=None):\n        return self\n    def transform(self,X):\n        return X[self.attribute_names]\n        \nlianxu_train = DataFrameSelector(column_lianxu).transform(train)\nlianxu_test =  DataFrameSelector(column_lianxu).transform(test)\n```\n### 多列KDE分布\n\n```python\n# 多列KDE分布\ndist_cols = 3\ndist_rows = len(column_lianxu)\nplt.figure(figsize=(4 * dist_cols, 4 * dist_rows))\n\nlianxu_train = DataFrameSelector(column_lianxu).transform(train)\nlianxu_test =  DataFrameSelector(column_lianxu).transform(test)\n\ni = 1\nfor col in column_lianxu:\n    ax = plt.subplot(dist_rows, dist_cols, i)\n    ax = sns.kdeplot(lianxu_train[col], color=\"Red\", shade=True)\n    ax = sns.kdeplot(lianxu_test[col], color=\"Blue\", shade=True)\n    ax.set_xlabel(col)\n    ax.set_ylabel(\"Frequency\")\n    ax = ax.legend([\"train\", \"test\"])\n\n    i += 1\nplt.show()\n```\n### 包库常用设置拷贝\n```python\n# 包库常用设置拷贝\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport lightgbm as lgb\nfrom scipy import stats\nimport matplotlib\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split\nimport gc\nimport warnings\nfrom collections import Counter\nwarnings.filterwarnings(\"ignore\")\nimport matplotlib.pyplot as plt\nplt.rcParams.update({'figure.max_open_warning': 0})\npd.set_option('expand_frame_repr', False) #数据超过总宽度后，是否折叠显示\npd.set_option('display.width', 100) #数据显示总宽度\npd.set_option('max_rows', 100) #显示最多行数，超出该数以省略号表示\npd.set_option('max_columns', 100) #显示最多列数，超出该数以省略号表示\npd.set_option('max_colwidth', 16) #设置单列的宽度，用字符个数表示，单个数据长度超出该数时以省略号表示\npd.set_option('large_repr', 'truncate') #数据超过设置显示最大行列数时，带省略号显示/若是info则是统计信息显示\npd.set_option('show_dimensions', True) #当数据带省略号显示时，是否在最后显示数据的维度\n\nsns.set_style(\"whitegrid\")\nmatplotlib.rcParams['font.sans-serif'] = ['SimHei']\nmatplotlib.rcParams['font.family']='sans-serif' \nmatplotlib.rcParams['axes.unicode_minus'] = False\nmatplotlib.fontsize='20'\n```\n### 查看类别特征是否测试集类别有不在训练集的\n\n```python\n#查看类别特征是否测试集类别有不在训练集的\ntest_outof_train=[]\nfor key in label_features:\n    test_unique=test_df[key].unique().tolist()\n    train_unique=train_df[key].unique().tolist()\n    for index in test_unique:\n        if index not in train_unique:\n            test_outof_train.append(key)\n            break\ntest_outof_train\n```\n### 类别特征分布\n```python\n# 类别特征分布\ndef show_label_features_distribution(df1,df2,Y=None):\n    df1=df1.value_counts().sort_index()\n    df2=df2.value_counts().sort_index()\n    df=pd.concat([df1,df2],axis=1)\n    feature_name=df.columns[0]\n    df.columns=['train','test'] \n    df.plot.bar(title=feature_name)\n    print(feature_name,'\\n',df)\n\nfor key in label_features:q\n    show_label_features_distribution(train_df[key],test_df[key])\n```\n### 连续特征分布\n```python\n# 连续特征分布\ndef show_continue_features_distribution(df1,df2):\n    feature_name=df1.name\n    g = sns.kdeplot(df1.values, color=\"Red\", shade = True)\n    g = sns.kdeplot(df2.values, ax =g, color=\"Green\", shade= True)\n    g.set_xlabel(feature_name)\n    g.set_ylabel(\"Frequency\")\n    g = g.legend([\"train\",\"test\"])\n    plt.show()\n    describe=pd.concat([df1.describe(),df2.describe()],axis=1)\n    describe.columns=[f'train {feature_name}',f'test {feature_name}']\n    print(describe)\n\nfor key in continue_featues:\n    show_continue_features_distribution(train_df[key],test_df[key])\n```\n### 清理缓存\n```python\ndef clear_mem():\n    %reset -f out\n    %reset -f in\n    gc.collect()\n```\n## 参考文献\n[matplotlib 知识点11：绘制饼图（pie 函数精讲）](https://www.cnblogs.com/biyoulin/p/9565350.html)\n[决策树中的类别特征问题（关于label encode还是one-hot的讨论）](https://blog.csdn.net/m0_37870649/article/details/104551969)\n[kaggle编码categorical feature总结](https://zhuanlan.zhihu.com/p/40231966)\n[TF-IDF算法介绍及实现](https://blog.csdn.net/asialee_bird/article/details/81486700)\n[Python中的TfidfVectorizer参数解析](https://blog.csdn.net/laobai1015/article/details/80451371)\n[关于target encoding与count encoding](https://blog.csdn.net/ssswill/article/details/90271293)","tags":["DataGame"]}]