<!DOCTYPE html><html lang="zh-CN" data-theme="dark"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Prompt tuning 基础 | Coding-Zuo</title><meta name="keywords" content="Active Learning"><meta name="author" content="Coding-Zuo"><meta name="copyright" content="Coding-Zuo"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#0d0d0d"><meta name="description" content="[TOC] Prompt tuning调研基本介绍在海量数据上预训练 PLM，将其调整为下游任务，这已经成为NLP的典型范式（Fine tuning&#x2F;微调&#x2F;精调）。传统上，它通过特定任务的监督，优化PLM的所有参数。 然而，随着 PLM 参数的持续增长，全参数微调对于典型的范式和模型存储都变得难以承受。为了弥补这一缺陷，人们提出了许多参数高效的 tuning 方法，这些方法只调整几个参数，而保持大">
<meta property="og:type" content="article">
<meta property="og:title" content="Prompt tuning 基础">
<meta property="og:url" content="http://example.com/2022/02/21/Prompt-tuning-%E5%9F%BA%E7%A1%80/index.html">
<meta property="og:site_name" content="Coding-Zuo">
<meta property="og:description" content="[TOC] Prompt tuning调研基本介绍在海量数据上预训练 PLM，将其调整为下游任务，这已经成为NLP的典型范式（Fine tuning&#x2F;微调&#x2F;精调）。传统上，它通过特定任务的监督，优化PLM的所有参数。 然而，随着 PLM 参数的持续增长，全参数微调对于典型的范式和模型存储都变得难以承受。为了弥补这一缺陷，人们提出了许多参数高效的 tuning 方法，这些方法只调整几个参数，而保持大">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://s4.ax1x.com/2022/02/21/HX2kHP.png">
<meta property="article:published_time" content="2022-02-21T02:08:56.000Z">
<meta property="article:modified_time" content="2022-02-21T02:10:21.631Z">
<meta property="article:author" content="Coding-Zuo">
<meta property="article:tag" content="Active Learning">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://s4.ax1x.com/2022/02/21/HX2kHP.png"><link rel="shortcut icon" href="https://i.loli.net/2021/03/22/reFlcYOnP3dSuJX.png"><link rel="canonical" href="http://example.com/2022/02/21/Prompt-tuning-%E5%9F%BA%E7%A1%80/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.json","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-02-21 10:10:21'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
          const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
          const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
          const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

          if (t === undefined) {
            if (isLightMode) activateLightMode()
            else if (isDarkMode) activateDarkMode()
            else if (isNotSpecified || hasNoSupport) {
              const now = new Date()
              const hour = now.getHours()
              const isNight = hour <= 6 || hour >= 18
              isNight ? activateDarkMode() : activateLightMode()
            }
            window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
              if (saveToLocal.get('theme') === undefined) {
                e.matches ? activateDarkMode() : activateLightMode()
              }
            })
          } else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const fontSizeVal = saveToLocal.get('global-font-size')
    if (fontSizeVal !== undefined) {
      document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
    }
    })(window)</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/sviptzk/HexoStaticFile@latest/Hexo/css/footer.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css"><meta name="generator" content="Hexo 5.3.0"><link rel="alternate" href="/atom.xml" title="Coding-Zuo" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="https://i.loli.net/2021/03/22/YP2oqk7lOAfceTD.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">137</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">17</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https:www.baidu.com"><i class="fa-fw fas fa-heart"></i><span> 我的简历</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 清单</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/%E9%9F%B3%E4%B9%90"><i class="fa-fw /music/"></i><span> 0</span></a></li><li><a class="site-page child" href="/%E7%94%B5%E5%BD%B1"><i class="fa-fw /movies/"></i><span> 1</span></a></li><li><a class="site-page child" href="/%E7%85%A7%E7%89%87"><i class="fa-fw /Gallery/"></i><span> 2</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://s4.ax1x.com/2022/02/21/HX2kHP.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Coding-Zuo</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https:www.baidu.com"><i class="fa-fw fas fa-heart"></i><span> 我的简历</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 清单</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/%E9%9F%B3%E4%B9%90"><i class="fa-fw /music/"></i><span> 0</span></a></li><li><a class="site-page child" href="/%E7%94%B5%E5%BD%B1"><i class="fa-fw /movies/"></i><span> 1</span></a></li><li><a class="site-page child" href="/%E7%85%A7%E7%89%87"><i class="fa-fw /Gallery/"></i><span> 2</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Prompt tuning 基础</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-02-21T02:08:56.000Z" title="发表于 2022-02-21 10:08:56">2022-02-21</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-02-21T02:10:21.631Z" title="更新于 2022-02-21 10:10:21">2022-02-21</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Prompt tuning 基础"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>[TOC]</p>
<h1 id="Prompt-tuning调研"><a href="#Prompt-tuning调研" class="headerlink" title="Prompt tuning调研"></a>Prompt tuning调研</h1><h2 id="基本介绍"><a href="#基本介绍" class="headerlink" title="基本介绍"></a>基本介绍</h2><p>在海量数据上预训练 PLM，将其调整为下游任务，这已经成为NLP的典型范式（Fine tuning/微调/精调）。传统上，它通过特定任务的监督，优化PLM的所有参数。</p>
<p>然而，随着 PLM 参数的持续增长，全参数微调对于典型的范式和模型存储都变得难以承受。为了弥补这一缺陷，人们提出了许多参数高效的 tuning 方法，这些方法只调整几个参数，而保持大部分PLM参数的冻结。</p>
<p>在这些具有参数效率的微调变体中，Prompt Tuning 得到了广泛的关注，这是由 GPT-3 激发的。 它通过在输入文本之前给每个任务预留一个文本提示，并让 PLM 直接生成答案，从而展示了显著的【少样本】与【跨任务/domain迁移】性能。</p>
<p>Prompt 的突然兴起，主要是因为学者们把任务扩展到了NLU，之前大部分是做生成和信息抽取，而在统一了方法之后，<strong>现在可以做分类任务和匹配任务了，同时在少样本甚至全样本，能追上微调的效果</strong>。</p>
<p>Prompt的思想：<strong>设计不同的输入形态，激发语言模型的潜力，得到任务相关的输出，从而避免微调模式带来的灾难性遗忘问题</strong>。引用刘鹏飞博士放在<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/395115779">博客</a>里的图：</p>
<p><img src="https://s4.ax1x.com/2022/02/18/H7YIdU.png" alt=""></p>
<p>Prompt兴起之前做NLP任务的大致流程，即”Pre-train, Fine-tune”，如上图，可看做是由预训练模型（PLM）迁就下游任务。Prompt的模式大致可以归纳成”Pre-train, Prompt, and Predict”。在该模式中，可看成由下游任务迁就 PLM，下游任务被重新调整成类似预训练任务的形式。例如，MLM（Masked Language Model），在文本情感分类任务中，对于”I love this movie”这句输入，可以在后面加上Prompt：”the movie is <em>_</em>“，组成如下这样一句话：</p>
<blockquote>
<p>I love this movie, the movie is <em>_</em></p>
</blockquote>
<p>然后让 PLM 用表示情感的答案（例如”great”、”terrible”等）做完形填空，最后再将该答案转换为情感分类的标签。这样一来，我们就可以通过构造合适的【模板】，控制模型的输出空间，从而训练 PLM 来解决各种各样的下游任务。</p>
<p>Prompt 更严谨的定义如下：</p>
<blockquote>
<p>Prompt is the technique of <strong>making better use of the knowledge</strong> from the pre-trained model by <strong>adding additional texts to the input</strong>.</p>
<p>Prompt 是一种<strong>为了更好的使用预训练语言模型的知识</strong>，采用在输入段<strong>添加额外的文本</strong>的技术。</p>
</blockquote>
<ul>
<li>目的：更好挖掘预训练语言模型的能力</li>
<li>手段：在输入端添加文本，即重新定义任务（task reformulation）</li>
</ul>
<h2 id="Prompt-优势是什么"><a href="#Prompt-优势是什么" class="headerlink" title="Prompt 优势是什么"></a>Prompt 优势是什么</h2><p>从四个角度进行分析：Level 1. Prompt Learning 角度；Level 2. Prompt Learning 和 Fine-tuning 的区别；Level 3. 现代 NLP 历史；Level 4. 超越NLP</p>
<h3 id="Level-1-Prompt-tuning-使得所有的NLP任务成为一个语言模型的问题"><a href="#Level-1-Prompt-tuning-使得所有的NLP任务成为一个语言模型的问题" class="headerlink" title="Level 1. Prompt tuning 使得所有的NLP任务成为一个语言模型的问题"></a>Level 1. Prompt tuning 使得所有的NLP任务成为一个语言模型的问题</h3><ul>
<li><p>Prompt tuning 可以将所有的任务归化为预训练语言模型的任务</p>
</li>
<li><p>避免了预训练和Fine tuning 之间的gap，几乎所有 NLP 任务都可以直接使用，不需要训练数据。</p>
</li>
<li><p>更少的调整参数、提升参数效率</p>
</li>
<li><p>在少样本的数据集上，能取得超过微调的效果，未来也有希望在全方位超过微调。</p>
</li>
<li><p>使得所有的任务在方法上变得一致，在<strong>多任务、多领域场景下使得迁移学习变得更加自然且容易</strong>，如下图：</p>
<p><img src="https://s4.ax1x.com/2022/02/19/HH79mR.png" alt=""></p>
<p>左边是传统的 Model Tuning(Fine tuning) 的范式：对于不同的任务，都需要将整个预训练语言模型进行精调，每个任务都有自己的一整套参数。右边是Prompt Tuning，对于不同的任务，仅需要插入不同的prompt 参数，每个任务都单独训练Prompt 参s数，不训练预训练语言模型，这样子可以大大缩短训练时间，也极大的提升了模型的使用率。</p>
</li>
</ul>
<h3 id="Level-2-Prompt-tuning-和-Fine-tuning-的范式区别"><a href="#Level-2-Prompt-tuning-和-Fine-tuning-的范式区别" class="headerlink" title="Level 2. Prompt tuning 和 Fine tuning 的范式区别"></a>Level 2. Prompt tuning 和 Fine tuning 的范式区别</h3><ul>
<li>Fine tuning 是使得预训练语言模型<strong>适配下游任务</strong></li>
<li>Prompting 是将下游任务进行任务重定义，使得其利用预训练语言模型的能力，即<strong>适配语言模型</strong></li>
</ul>
<h3 id="Level-3-现代-NLP-第四范式"><a href="#Level-3-现代-NLP-第四范式" class="headerlink" title="Level 3. 现代 NLP 第四范式"></a>Level 3. 现代 NLP 第四范式</h3><p>Prompting 方法是现在NLP的第四范式。其中现在NLP的发展史包含</p>
<ol>
<li>Feature Engineering：即使用文本特征，例如词性，长度等，在使用机器学习的方法进行模型训练。（无预训练语言模型）</li>
<li>Architecture Engineering：在W2V基础上，利用深度模型，加上固定的embedding。（有固定预训练embedding，但与下游任务无直接关系）</li>
<li>Objective Engineering：在bert 的基础上，使用动态的embedding，在加上Fine tuning。（有预训练语言模型，但与下游任务有gap）</li>
<li>Prompt Engineering：直接利用与训练语言模型辅以特定的prompt。（有预训练语言模型，但与下游任务无gap）</li>
</ol>
<p>我们可以发现，在四个范式中，预训练语言模型，和下游任务之间的距离，变得越来越近，直到最后Prompt Learning是直接完全利用LM的能力。</p>
<p><img src="https://s4.ax1x.com/2022/02/19/HH5YeP.png" alt=""></p>
<h3 id="Level-4-超越NLP的角度"><a href="#Level-4-超越NLP的角度" class="headerlink" title="Level 4. 超越NLP的角度"></a>Level 4. 超越NLP的角度</h3><p>Prompt 可以作为连接多模态的一个契机，例如 CLIP 模型，连接了文本和图片。相信在未来，可以连接声音和视频，这是一个广大的待探索的领域。</p>
<p><img src="https://s4.ax1x.com/2022/02/19/HHIAfg.png" alt=""></p>
<h2 id="Prompt-的工作流"><a href="#Prompt-的工作流" class="headerlink" title="Prompt 的工作流"></a>Prompt 的工作流</h2><p>Prompt 的工作流包含以下4部分：</p>
<ol>
<li>Prompt 模版（Template）的构造</li>
<li>Prompt 答案空间映射（Verbalizer）的构造</li>
<li>文本代入template，并且使用预训练语言模型进行预测</li>
<li>将预测的结果映射回label。</li>
</ol>
<p>具体的步骤如下图，接下来将一步步进行拆解分析。</p>
<p><img src="https://s4.ax1x.com/2022/02/19/HHqT3T.png" alt=""></p>
<h3 id="Step-1-prompt-construction【Template】"><a href="#Step-1-prompt-construction【Template】" class="headerlink" title="Step 1: prompt construction【Template】"></a>Step 1: prompt construction【Template】</h3><p>首先我们需要构建一个模版Template，模版的作用是将输入和输出进行重新构造，变成一个新的带有mask slots的文本，具体如下：</p>
<ul>
<li>定义一个模版，包含了2处代填入的slots：[x] 和 [z]</li>
<li>将 [x] 用输入文本代入</li>
</ul>
<p>例如：</p>
<ul>
<li>输入：x = 我喜欢这个电影。</li>
<li>模版：[x] 总而言之，它是一个 [z] 电影。</li>
<li>代入（Prompt）：我喜欢这个电影。总而言之，它是一个[z]电影。</li>
</ul>
<p><img src="https://s4.ax1x.com/2022/02/19/HHvnoj.png" alt=""></p>
<p>以上介绍的为离散的Prompt（手工构造Prompt），这浪费人力并且往往是次优的性能。目前普遍采用的是连续的Prompt 将Prompt 向量化进行调优，在经典工作中将会涉及此类工作。</p>
<h3 id="Step-2-answer-construction【Verbalizer】"><a href="#Step-2-answer-construction【Verbalizer】" class="headerlink" title="Step 2: answer construction【Verbalizer】"></a>Step 2: answer construction【Verbalizer】</h3><p>对于我们构造的prompt，我们需要知道我们的预测词和我们的label 之间的关系，并且我们也不可能让 z 是任意词，这边我们就需要一个映射函数（mapping function）将输出的词与label进行映射。</p>
<p>例如，输出的 label 有两个，一个【是】 ，一个【不是】 ，我们可以限定，【是】这个预测词是<code>fantastic</code> 对应 ，【不是】则对应  <code>boring</code>  。</p>
<p><img src="https://s4.ax1x.com/2022/02/19/HHxy3q.png" alt=""></p>
<h3 id="Step-3-answer-prediction【Prediction】"><a href="#Step-3-answer-prediction【Prediction】" class="headerlink" title="Step 3: answer prediction【Prediction】"></a>Step 3: answer prediction【Prediction】</h3><p>选择<a href="https://link.zhihu.com/?target=https%3A//huggingface.co/docs/transformers/model_summary">合适的预训练语言模型</a>，然后进行mask slots [z] 的预测。例如下图，得到了结果 <code>fantastic</code>, 我们需要将其代入 [z] 中。</p>
<p><img src="https://s4.ax1x.com/2022/02/19/HHx4UJ.png" alt=""></p>
<h3 id="Step-4-answer-label-mapping【Mapping】"><a href="#Step-4-answer-label-mapping【Mapping】" class="headerlink" title="Step 4: answer-label mapping【Mapping】"></a>Step 4: answer-label mapping【Mapping】</h3><p>第四步骤，对于得到的 <code>answer</code>，我们需要使用 <code>Verbalizer</code> 将其映射回原本的label。</p>
<p>例如：fantastic 映射回 label：</p>
<p><img src="https://s4.ax1x.com/2022/02/19/HHzEVg.png" alt=""></p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p><img src="https://s4.ax1x.com/2022/02/19/HHz8ZF.png" alt=""></p>
<h2 id="经典工作与方法（持续更新…）"><a href="#经典工作与方法（持续更新…）" class="headerlink" title="经典工作与方法（持续更新…）"></a>经典工作与方法（持续更新…）</h2><h3 id="Parameter-Efficient-Transfer-Learning-for-NLP-（ICML-2019-2019-2-2"><a href="#Parameter-Efficient-Transfer-Learning-for-NLP-（ICML-2019-2019-2-2" class="headerlink" title="Parameter-Efficient Transfer Learning for NLP （ICML 2019) -2019.2.2"></a>Parameter-Efficient Transfer Learning for NLP （ICML 2019) -2019.2.2</h3><ul>
<li>motivation: 将 adapter 加入到 transformer 中，在针对某个下游任务微调时，改变的仅仅是 adapter 的参数。</li>
<li>method:<img src="https://s4.ax1x.com/2022/02/19/HbATTP.png" alt=""></li>
</ul>
<h3 id="Language-Models-as-Knowledge-Bases-ACL-2019-2019-9-3"><a href="#Language-Models-as-Knowledge-Bases-ACL-2019-2019-9-3" class="headerlink" title="Language Models as Knowledge Bases?  (ACL 2019) -2019.9.3"></a>Language Models as Knowledge Bases?  (ACL 2019) -2019.9.3</h3><ul>
<li><p>motivation : 语言模型可以作为关系知识的潜在表示形式，对预先训练的现成语言模型（例如 ELMo 和 BERT）中已经存在的关系知识提取。在 kownledge-base complete 任务上利用语言模型预测的分数，完成知识提取，相比 elmo 等模型表现要好。需要人工标注 query 也就是模板。 </p>
</li>
<li><p>method:</p>
<p><img src="https://s4.ax1x.com/2022/02/19/HbeN7R.png" alt=""></p>
</li>
</ul>
<h3 id="Exploiting-Cloze-Questions-for-Few-Shot-Text-Classification-and-Natural-Language-Inference-EACL-2021-2020-1-21"><a href="#Exploiting-Cloze-Questions-for-Few-Shot-Text-Classification-and-Natural-Language-Inference-EACL-2021-2020-1-21" class="headerlink" title="Exploiting Cloze Questions for Few Shot Text Classification and Natural Language Inference (EACL 2021) - 2020.1.21"></a>Exploiting Cloze Questions for Few Shot Text Classification and Natural Language Inference (EACL 2021) - 2020.1.21</h3><ul>
<li><p>motivation:  如何用较小的预训练模型充分发挥预训练模型作为语言模型的作用，做 few shot learning，做法是分类转化为完形填空 </p>
</li>
<li><p>method:</p>
<p><img src="https://s4.ax1x.com/2022/02/19/HbmPb9.png" alt=""></p>
</li>
</ul>
<h3 id="It’s-Not-Just-Size-That-Matters-Small-Language-Models-Are-Also-Few-Shot-Learners-NAACL-2021-2020-9-15"><a href="#It’s-Not-Just-Size-That-Matters-Small-Language-Models-Are-Also-Few-Shot-Learners-NAACL-2021-2020-9-15" class="headerlink" title="It’s Not Just Size That Matters: Small Language Models Are Also Few-Shot Learners (NAACL 2021) -2020.9.15"></a>It’s Not Just Size That Matters: Small Language Models Are Also Few-Shot Learners (NAACL 2021) -2020.9.15</h3><ul>
<li>motivation: 解决 label mask 预测多 token 问题。</li>
<li>method: 选择分数最高的一个 token 为基准计算，替代多个 token 完形填空的分数计算</li>
</ul>
<h3 id="Parameter-Efficient-Transfer-Learning-with-Diff-Pruning-2020-12-14"><a href="#Parameter-Efficient-Transfer-Learning-with-Diff-Pruning-2020-12-14" class="headerlink" title="Parameter-Efficient Transfer Learning with Diff Pruning -2020.12.14"></a>Parameter-Efficient Transfer Learning with Diff Pruning -2020.12.14</h3><ul>
<li>motivation : adapter 的延续，将原来的参数上增加新参数（L0 正则约束稀疏性）</li>
</ul>
<h3 id="Prefix-Tuning-Optimizing-Continuous-Prompts-for-Generation-ACL-2021-2021-1-1"><a href="#Prefix-Tuning-Optimizing-Continuous-Prompts-for-Generation-ACL-2021-2021-1-1" class="headerlink" title="Prefix-Tuning: Optimizing Continuous Prompts for Generation (ACL 2021) -2021.1.1"></a>Prefix-Tuning: Optimizing Continuous Prompts for Generation (ACL 2021) -2021.1.1</h3><ul>
<li><p>motivation : 提出了 Prefix-Tuning，一种轻量级 fintune 替代方法，用于对 NLG 任务进行微调，在使语言模型参数冻结的同时，去优化一个参数量少的 continuous task-specific vector（称为 prefix），用词表中的词初始化较好，并且和类别相关。在大多数任务上比 finetune 好。  </p>
</li>
<li><p>method: 根据不同的模型结构定义了不同的 Prompt 拼接方式，在 GPT 类的自回归模型上采用 [PREFIX, x, y]，在 T5 类的 encoder-decoder 模型上采用 [PREFIX, x, PREFIX’, y]。</p>
<ol>
<li><p>把预训练大模型 freeze 住，因为大模型参数量大，精调起来效率低，毕竟 prompt 的出现就是要解决大模型少样本的适配。</p>
</li>
<li><p>直接优化 Prompt 参数不太稳定，加了个更大的 MLP，训练完只保存 MLP 变换后的参数就行了。</p>
</li>
<li>实验证实只加到 embedding 上的效果不太好，因此作者在每层都加了 prompt 的参数，改动较大。</li>
</ol>
</li>
</ul>
<h3 id="PADA-A-Prompt-based-Autoregressive-Approach-for-Adaptation-to-Unseen-Domains-2021-2-24"><a href="#PADA-A-Prompt-based-Autoregressive-Approach-for-Adaptation-to-Unseen-Domains-2021-2-24" class="headerlink" title="PADA: A Prompt-based Autoregressive Approach for Adaptation to Unseen Domains  -2021.2.24"></a>PADA: A Prompt-based Autoregressive Approach for Adaptation to Unseen Domains  -2021.2.24</h3><ul>
<li>motivation: 利用 t5 的 embedding，选择领域的代表关键词（利用互信息），然后进行领域迁移（挖掘领域共现关键）</li>
</ul>
<h3 id="GPT-Understands-Too-2021-3-18"><a href="#GPT-Understands-Too-2021-3-18" class="headerlink" title="GPT Understands, Too  -2021.3.18"></a>GPT Understands, Too  -2021.3.18</h3><ul>
<li><p>motivation: P-tuning 重新审视了关于模版的定义，放弃了“模版由自然语言构成”这一常规要求，从而将模版的构建转化为连续参数优化问题，虽然简单，但却有效。</p>
<p><img src="https://s4.ax1x.com/2022/02/19/Hbnowj.png" alt=""></p>
</li>
</ul>
<h3 id="KnowPrompt-Knowledge-aware-Prompt-tuning-with-Synergistic-Optimization-for-Relation-Extraction-2021-4-15"><a href="#KnowPrompt-Knowledge-aware-Prompt-tuning-with-Synergistic-Optimization-for-Relation-Extraction-2021-4-15" class="headerlink" title="KnowPrompt: Knowledge-aware Prompt-tuning with Synergistic Optimization for Relation Extraction  -2021.4.15"></a>KnowPrompt: Knowledge-aware Prompt-tuning with Synergistic Optimization for Relation Extraction  -2021.4.15</h3><ul>
<li><p>motivation: 融入外部知识（实体，关系）的 embedding 当做参数，将关系分类设置成模板，采用 MASK 的方式训练，同时增 KE 的 loss 。</p>
<p><img src="https://s4.ax1x.com/2022/02/19/HbuN7j.png" alt=""></p>
</li>
</ul>
<h3 id="The-Power-of-Scale-for-Parameter-Efficient-Prompt-Tuning-2021-4-18"><a href="#The-Power-of-Scale-for-Parameter-Efficient-Prompt-Tuning-2021-4-18" class="headerlink" title="The Power of Scale for Parameter-Efficient Prompt Tuning  (2021.4.18)"></a>The Power of Scale for Parameter-Efficient Prompt Tuning  (2021.4.18)</h3><ul>
<li><p>motivation: 对 prefix tuning 的进一步简化 : prefix tuning 会训练所有与 prefix prompt 相关的层。而这篇文章 : 针对每个下游任务，只调输入文本前面的一些 tokens (soft prompt)。另外，这篇文章还提出了 Prompt Ensembling。</p>
</li>
<li><p>method: 总体上 Prompt Tuning 与 P-Tuning （ P-tuning-GPT Understands, Too） 较为相似。但 Prompt Tuning 的 prompt 参数全部置于左侧，并且论文将注意力集中在了冻结模型权重的一系列实验上，更好的验证了 prompt 的效果。初始化prompt: sampled vocab：从 5000 个 T5 字典最常用的 token 中提取。</p>
<p>class label：从任务 label 对应的 token 中提取。由于任务 label 通常数量较少，当任务 label 不够满足 prompt 参数长度时，使用 sampled vocab 进行填充。当一个 label 存在 multi-token 时，取其平均值。简单的 ensemble 能提升 prompt-tuning 的效果。</p>
<p><img src="https://s4.ax1x.com/2022/02/19/HbuLEd.png" alt=""></p>
</li>
</ul>
<h3 id="Multimodal-Few-Shot-Learning-with-Frozen-Language-Model-2021-7-3"><a href="#Multimodal-Few-Shot-Learning-with-Frozen-Language-Model-2021-7-3" class="headerlink" title="Multimodal Few-Shot Learning with Frozen Language Model -2021.7.3"></a>Multimodal Few-Shot Learning with Frozen Language Model -2021.7.3</h3><ul>
<li><p>motivation: 如何使用冻结参数的语言模型进行多模态任务</p>
</li>
<li><p>method: 冻结 LM 参数，只调输出以及视觉的 Vision Encoder（图中粉色部分）。LM 使用的是自回归的语言模型。视觉编码器基于 NF-ResNet-50，但是在视觉编码器之上套了一层线性映射，让其变成 Vision Prefix，类似于 Prefix Tuning [1] 的 Prefix (不过这里的 Prefix 是可以训练的)。这样，Image 就可以转变成 LM 可以理解的形式。</p>
<p><img src="https://s4.ax1x.com/2022/02/19/HbQx81.png" alt=""></p>
</li>
</ul>
<h3 id="Knowledgeable-Prompt-tuning-Incorporating-Knowledge-into-Prompt-Verbalizer-for-Text-Classification-2021-8-4"><a href="#Knowledgeable-Prompt-tuning-Incorporating-Knowledge-into-Prompt-Verbalizer-for-Text-Classification-2021-8-4" class="headerlink" title="Knowledgeable Prompt-tuning: Incorporating Knowledge into Prompt Verbalizer for Text Classification  (2021.8.4)"></a>Knowledgeable Prompt-tuning: Incorporating Knowledge into Prompt Verbalizer for Text Classification  (2021.8.4)</h3><ul>
<li>motivation: 对标签词进行扩展，相当于引入外部知识。</li>
</ul>
<h3 id="Finetuned-Language-Models-Are-Zero-Shot-Learners-2021-9-3"><a href="#Finetuned-Language-Models-Are-Zero-Shot-Learners-2021-9-3" class="headerlink" title="Finetuned Language Models Are Zero-Shot Learners -2021.9.3"></a>Finetuned Language Models Are Zero-Shot Learners -2021.9.3</h3><ul>
<li><p>motivation: 简称FLAN， 另称 : Instruction Tuning。改善语言模型的 zero-shot 学习的能力。</p>
</li>
<li><p>method：作者先收集整理了一系列任务集合(task cluster)，每个任务集合包含若干特定的数据集，有 NLU，也有 NLG，之后的 instruction tuning 就是在若干 task clusters 上训练的。tuning 方法有点像 GPT-3 的那种 prompting, 但是又有区别：</p>
<p><img src="https://s4.ax1x.com/2022/02/19/Hb1ly6.png" alt=""></p>
<p><img src="https://s4.ax1x.com/2022/02/19/HbM2f1.png" alt=""></p>
</li>
</ul>
<p>众所周知，GPT-3 不做进一步地精调，只是在 inference 时候，在开头提供一些 examples (instructions) 和 prompt，称作 in-context learning；但是这篇工作是要做精调的，把类似的 instruction 作为 tuning 时候的训练数据。</p>
<p>GPT-3 是单任务的，而这篇工作在 tuning 阶段使用多任务，每个任务都人工设计了一个 instruction template，把 template 填充之后就变成了 tuning 时候用的训练 examples。tuning 完成之后，把模型用于全新的 (unseen) 任务进行 inference, 这一次，不用 instructions (GPT-3), 就能达到很好的效果。</p>
<h3 id="PPT-Pre-trained-Prompt-Tuning-for-Few-shot-Learning-2021-9-9"><a href="#PPT-Pre-trained-Prompt-Tuning-for-Few-shot-Learning-2021-9-9" class="headerlink" title="PPT: Pre-trained Prompt Tuning for Few-shot Learning -2021.9.9"></a>PPT: Pre-trained Prompt Tuning for Few-shot Learning -2021.9.9</h3><ul>
<li>motivation: 通过预训练将 prompt tuning 用于下游任务，提供好的初始化 prompt，使得效果更稳定</li>
</ul>
<h3 id="Multitask-Prompted-Training-Enables-Zero-Shot-Task-Generalization-（EMNLP-2021）-2021-9-15"><a href="#Multitask-Prompted-Training-Enables-Zero-Shot-Task-Generalization-（EMNLP-2021）-2021-9-15" class="headerlink" title="Multitask Prompted Training Enables Zero-Shot Task Generalization （EMNLP 2021） -2021.9.15"></a>Multitask Prompted Training Enables Zero-Shot Task Generalization （EMNLP 2021） -2021.9.15</h3><ul>
<li><p>motivation: 大模型具有很好的零样本泛化能力 (zero-shot generalization)，这取决于它隐式的多任务学习机制(也就是 GPT-3 的那种外循环机制)。那么能不能通过显式的多任务学习机制 (即带有 prompt engineering) 来激发大模型的零样本泛化能力呢？</p>
</li>
<li><p>粗暴、协作：多任务数据集达 171 个，Prompt 达 1939 个，模型也是超大的（T5, 11B）。和 FLAN 工作整体相似，区别是增加了任务和 prompt 数量，减小了模型参数，效果超过 FLAN，证明了多任务 prompt 学习能使模型更加鲁棒、泛化能力更强。</p>
<p><img src="https://s4.ax1x.com/2022/02/19/HbQIg0.png" alt=""></p>
</li>
</ul>
<h3 id="P-Tuning-v2-Prompt-Tuning-Can-Be-Comparable-to-Finetuning-Universally-Across-Scales-and-Tasks-2021-10-14"><a href="#P-Tuning-v2-Prompt-Tuning-Can-Be-Comparable-to-Finetuning-Universally-Across-Scales-and-Tasks-2021-10-14" class="headerlink" title="P-Tuning v2: Prompt Tuning Can Be Comparable to Finetuning Universally Across Scales and Tasks  -2021.10.14"></a>P-Tuning v2: Prompt Tuning Can Be Comparable to Finetuning Universally Across Scales and Tasks  -2021.10.14</h3><ul>
<li><p>motivation: 之前的 soft prompt (google) 和 P-tuning 只对大模型有效，而且也仅仅用于解决一些简单的 NLU 任务。因此这个工作主要是扩展之前的 P-Tuning：适配小模型，适配复杂的 NLU 任务 (如序列标注等)。</p>
</li>
<li><p>method: 其实比起 P-tuning 或者 Google 的 soft prompt 的方式，这个更类似于 prefix tuning, 即和 prefix prompt 相关联的一系列层都能调。</p>
<p><img src="https://s4.ax1x.com/2022/02/19/Hb3S0O.png" alt=""></p>
<p>另外几点考虑是：</p>
<p>去掉了重参数化：比如 prefix tuning [1] 中的 MLP 以及 P-tuning 中的 LSTM，都不要了，因为这东西对效果提升不大。</p>
<p>多任务学习：这个挺有必要的，一方面可以减小 prompt 随机初始化的压力，另一方面可以更好地搞到跨任务/数据集的知识。</p>
<p>不用 verbalizer 了 : 其实对于复杂的 NLU 任务来说，verbalizer 的设计很不直观，那么就返璞归真，沿用原始的 [CLS]/token (hidden state) + MLP 就好。</p>
</li>
</ul>
<h3 id="SPoT-Better-Frozen-Model-Adaptation-through-Soft-Prompt-Transfer-2021-10-15"><a href="#SPoT-Better-Frozen-Model-Adaptation-through-Soft-Prompt-Transfer-2021-10-15" class="headerlink" title="SPoT: Better Frozen Model Adaptation through Soft Prompt Transfer  -2021.10.15"></a>SPoT: Better Frozen Model Adaptation through Soft Prompt Transfer  -2021.10.15</h3><ul>
<li><p>motivation: 还是为了增强模型在不同任务上的泛化性能，不过是基于 Prompt Tuning。换句话说：Transfer Learning + Prompt Tuning.</p>
</li>
<li><p>method:  Task-Agnostic Approach : 先使用 multi-task training 得到一个 soft prompt, 用其作为目标任务的初始化。Task-Specific Approach : 为了进一步提高效率，作者做了一个 prompt library. 先在一系列源任务上进行学习，取早期的 embedding 作为键，相应的最优 soft prompt 作为值。当我们需要解决目标任务时，把目标任务的早期 embedding 作为 query，与库中的键计算余弦相似度，从而检索到相应的值 (soft prompt) 作为初始化，再对 target prompt 进行进一步的优化。</p>
<p><img src="https://s4.ax1x.com/2022/02/19/Hb3nHS.png" alt=""></p>
</li>
</ul>
<h3 id="ZeroPrompt-Scaling-Prompt-Based-Pretraining-to-1-000-Tasks-Improves-Zero-Shot-Generalization-2022-1-18"><a href="#ZeroPrompt-Scaling-Prompt-Based-Pretraining-to-1-000-Tasks-Improves-Zero-Shot-Generalization-2022-1-18" class="headerlink" title="ZeroPrompt: Scaling Prompt-Based Pretraining to 1,000 Tasks Improves Zero-Shot Generalization -2022 1.18"></a>ZeroPrompt: Scaling Prompt-Based Pretraining to 1,000 Tasks Improves Zero-Shot Generalization -2022 1.18</h3><ul>
<li><p>motivation : 继FLAN和T0之后，ZeroPrompt[9]实现了大规模多任务学习在中文领域“零的突破”。ZeroPrompt来自于XLNet作者杨植麟团队，共收集了1000个中文任务数据，整个测试任务上平均只相差4.7个点，而在部分测试任务上Zero-shot性能比有监督fine tuning还要好。</p>
</li>
<li><p>ZeroPrompt虽然数据规模庞大，但也证明一点：<strong>任务数据规模的拓展是模型缩放的一种有效替代手段,任务数量极大的情况下，模型大小对性能的影响很小</strong>。正如下图所示：随着多任务训练任务的增加，不同大小模型之间的Zero-shot性能趋近一致。</p>
<p><img src="https://s4.ax1x.com/2022/02/19/HbY6RH.png" alt=""></p>
</li>
</ul>
</article><div class="post-reward"><div class="reward-button button--animated"><i class="fas fa-qrcode"></i> 打赏</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="https://i.loli.net/2021/03/22/HzNFBbkvZ2QMOKV.jpg" target="_blank"><img class="post-qr-code-img" src="https://i.loli.net/2021/03/22/HzNFBbkvZ2QMOKV.jpg" alt="wechat"/></a><div class="post-qr-code-desc">wechat</div></li><li class="reward-item"><a href="https://i.loli.net/2021/03/22/wMGegPYTAXx9cJo.jpg" target="_blank"><img class="post-qr-code-img" src="https://i.loli.net/2021/03/22/wMGegPYTAXx9cJo.jpg" alt="alipay"/></a><div class="post-qr-code-desc">alipay</div></li></ul></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="gitalk-container"></div></div></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/2022/02/21/Auto-Encoding-Variational-Bayes/"><img class="next-cover" src="https://s4.ax1x.com/2022/02/21/HXgjAK.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Auto-Encoding Variational Bayes</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span> 相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2022/02/21/A-Survey-of-Active-Learning-for-Text-Classification-Using-Deep-Neural-Networks/" title="A Survey of Active Learning for Text Classification Using Deep Neural Networks"><img class="cover" src="https://s4.ax1x.com/2022/02/21/HXgKw6.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-02-21</div><div class="title">A Survey of Active Learning for Text Classification Using Deep Neural Networks</div></div></a></div><div><a href="/2022/02/21/Auto-Encoding-Variational-Bayes/" title="Auto-Encoding Variational Bayes"><img class="cover" src="https://s4.ax1x.com/2022/02/21/HXgjAK.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-02-21</div><div class="title">Auto-Encoding Variational Bayes</div></div></a></div></div></div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Coding-Zuo</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2022/02/21/Prompt-tuning-%E5%9F%BA%E7%A1%80/">http://example.com/2022/02/21/Prompt-tuning-%E5%9F%BA%E7%A1%80/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://example.com" target="_blank">Coding-Zuo</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Active-Learning/">Active Learning</a></div><div class="post_share"><div class="addthis_inline_share_toolbox"></div><script src="//s7.addthis.com/js/300/addthis_widget.js#pubid=null" async="async"></script></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Prompt-tuning%E8%B0%83%E7%A0%94"><span class="toc-number">1.</span> <span class="toc-text">Prompt tuning调研</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E4%BB%8B%E7%BB%8D"><span class="toc-number">1.1.</span> <span class="toc-text">基本介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Prompt-%E4%BC%98%E5%8A%BF%E6%98%AF%E4%BB%80%E4%B9%88"><span class="toc-number">1.2.</span> <span class="toc-text">Prompt 优势是什么</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Level-1-Prompt-tuning-%E4%BD%BF%E5%BE%97%E6%89%80%E6%9C%89%E7%9A%84NLP%E4%BB%BB%E5%8A%A1%E6%88%90%E4%B8%BA%E4%B8%80%E4%B8%AA%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%97%AE%E9%A2%98"><span class="toc-number">1.2.1.</span> <span class="toc-text">Level 1. Prompt tuning 使得所有的NLP任务成为一个语言模型的问题</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Level-2-Prompt-tuning-%E5%92%8C-Fine-tuning-%E7%9A%84%E8%8C%83%E5%BC%8F%E5%8C%BA%E5%88%AB"><span class="toc-number">1.2.2.</span> <span class="toc-text">Level 2. Prompt tuning 和 Fine tuning 的范式区别</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Level-3-%E7%8E%B0%E4%BB%A3-NLP-%E7%AC%AC%E5%9B%9B%E8%8C%83%E5%BC%8F"><span class="toc-number">1.2.3.</span> <span class="toc-text">Level 3. 现代 NLP 第四范式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Level-4-%E8%B6%85%E8%B6%8ANLP%E7%9A%84%E8%A7%92%E5%BA%A6"><span class="toc-number">1.2.4.</span> <span class="toc-text">Level 4. 超越NLP的角度</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Prompt-%E7%9A%84%E5%B7%A5%E4%BD%9C%E6%B5%81"><span class="toc-number">1.3.</span> <span class="toc-text">Prompt 的工作流</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Step-1-prompt-construction%E3%80%90Template%E3%80%91"><span class="toc-number">1.3.1.</span> <span class="toc-text">Step 1: prompt construction【Template】</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Step-2-answer-construction%E3%80%90Verbalizer%E3%80%91"><span class="toc-number">1.3.2.</span> <span class="toc-text">Step 2: answer construction【Verbalizer】</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Step-3-answer-prediction%E3%80%90Prediction%E3%80%91"><span class="toc-number">1.3.3.</span> <span class="toc-text">Step 3: answer prediction【Prediction】</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Step-4-answer-label-mapping%E3%80%90Mapping%E3%80%91"><span class="toc-number">1.3.4.</span> <span class="toc-text">Step 4: answer-label mapping【Mapping】</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">1.3.5.</span> <span class="toc-text">总结</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%8F%E5%85%B8%E5%B7%A5%E4%BD%9C%E4%B8%8E%E6%96%B9%E6%B3%95%EF%BC%88%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0%E2%80%A6%EF%BC%89"><span class="toc-number">1.4.</span> <span class="toc-text">经典工作与方法（持续更新…）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Parameter-Efficient-Transfer-Learning-for-NLP-%EF%BC%88ICML-2019-2019-2-2"><span class="toc-number">1.4.1.</span> <span class="toc-text">Parameter-Efficient Transfer Learning for NLP （ICML 2019) -2019.2.2</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Language-Models-as-Knowledge-Bases-ACL-2019-2019-9-3"><span class="toc-number">1.4.2.</span> <span class="toc-text">Language Models as Knowledge Bases?  (ACL 2019) -2019.9.3</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Exploiting-Cloze-Questions-for-Few-Shot-Text-Classification-and-Natural-Language-Inference-EACL-2021-2020-1-21"><span class="toc-number">1.4.3.</span> <span class="toc-text">Exploiting Cloze Questions for Few Shot Text Classification and Natural Language Inference (EACL 2021) - 2020.1.21</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#It%E2%80%99s-Not-Just-Size-That-Matters-Small-Language-Models-Are-Also-Few-Shot-Learners-NAACL-2021-2020-9-15"><span class="toc-number">1.4.4.</span> <span class="toc-text">It’s Not Just Size That Matters: Small Language Models Are Also Few-Shot Learners (NAACL 2021) -2020.9.15</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Parameter-Efficient-Transfer-Learning-with-Diff-Pruning-2020-12-14"><span class="toc-number">1.4.5.</span> <span class="toc-text">Parameter-Efficient Transfer Learning with Diff Pruning -2020.12.14</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Prefix-Tuning-Optimizing-Continuous-Prompts-for-Generation-ACL-2021-2021-1-1"><span class="toc-number">1.4.6.</span> <span class="toc-text">Prefix-Tuning: Optimizing Continuous Prompts for Generation (ACL 2021) -2021.1.1</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#PADA-A-Prompt-based-Autoregressive-Approach-for-Adaptation-to-Unseen-Domains-2021-2-24"><span class="toc-number">1.4.7.</span> <span class="toc-text">PADA: A Prompt-based Autoregressive Approach for Adaptation to Unseen Domains  -2021.2.24</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#GPT-Understands-Too-2021-3-18"><span class="toc-number">1.4.8.</span> <span class="toc-text">GPT Understands, Too  -2021.3.18</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#KnowPrompt-Knowledge-aware-Prompt-tuning-with-Synergistic-Optimization-for-Relation-Extraction-2021-4-15"><span class="toc-number">1.4.9.</span> <span class="toc-text">KnowPrompt: Knowledge-aware Prompt-tuning with Synergistic Optimization for Relation Extraction  -2021.4.15</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#The-Power-of-Scale-for-Parameter-Efficient-Prompt-Tuning-2021-4-18"><span class="toc-number">1.4.10.</span> <span class="toc-text">The Power of Scale for Parameter-Efficient Prompt Tuning  (2021.4.18)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Multimodal-Few-Shot-Learning-with-Frozen-Language-Model-2021-7-3"><span class="toc-number">1.4.11.</span> <span class="toc-text">Multimodal Few-Shot Learning with Frozen Language Model -2021.7.3</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Knowledgeable-Prompt-tuning-Incorporating-Knowledge-into-Prompt-Verbalizer-for-Text-Classification-2021-8-4"><span class="toc-number">1.4.12.</span> <span class="toc-text">Knowledgeable Prompt-tuning: Incorporating Knowledge into Prompt Verbalizer for Text Classification  (2021.8.4)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Finetuned-Language-Models-Are-Zero-Shot-Learners-2021-9-3"><span class="toc-number">1.4.13.</span> <span class="toc-text">Finetuned Language Models Are Zero-Shot Learners -2021.9.3</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#PPT-Pre-trained-Prompt-Tuning-for-Few-shot-Learning-2021-9-9"><span class="toc-number">1.4.14.</span> <span class="toc-text">PPT: Pre-trained Prompt Tuning for Few-shot Learning -2021.9.9</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Multitask-Prompted-Training-Enables-Zero-Shot-Task-Generalization-%EF%BC%88EMNLP-2021%EF%BC%89-2021-9-15"><span class="toc-number">1.4.15.</span> <span class="toc-text">Multitask Prompted Training Enables Zero-Shot Task Generalization （EMNLP 2021） -2021.9.15</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#P-Tuning-v2-Prompt-Tuning-Can-Be-Comparable-to-Finetuning-Universally-Across-Scales-and-Tasks-2021-10-14"><span class="toc-number">1.4.16.</span> <span class="toc-text">P-Tuning v2: Prompt Tuning Can Be Comparable to Finetuning Universally Across Scales and Tasks  -2021.10.14</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#SPoT-Better-Frozen-Model-Adaptation-through-Soft-Prompt-Transfer-2021-10-15"><span class="toc-number">1.4.17.</span> <span class="toc-text">SPoT: Better Frozen Model Adaptation through Soft Prompt Transfer  -2021.10.15</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#ZeroPrompt-Scaling-Prompt-Based-Pretraining-to-1-000-Tasks-Improves-Zero-Shot-Generalization-2022-1-18"><span class="toc-number">1.4.18.</span> <span class="toc-text">ZeroPrompt: Scaling Prompt-Based Pretraining to 1,000 Tasks Improves Zero-Shot Generalization -2022 1.18</span></a></li></ol></li></ol></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2022 By Coding-Zuo</div><div class="footer_custom_text">Hi, welcome to my BLOG</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font-plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    loader: {
      source: {
        '[tex]/amsCd': '[tex]/amscd'
      }
    },
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        addClass: [200,() => {
          document.querySelectorAll('mjx-container:not([display=\'true\']').forEach( node => {
            const target = node.parentNode
            if (!target.classList.contains('has-jax')) {
              target.classList.add('mathjax-overflow')
            }
          })
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><script>if (document.getElementsByClassName('mermaid').length) {
  if (window.mermaidJsLoad) mermaid.init()
  else {
    getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(() => {
      window.mermaidJsLoad = true
      mermaid.initialize({
        theme: 'default',
      })
      false && mermaid.init()
    })
  }
}</script><script>function addGitalkSource () {
  const ele = document.createElement('link')
  ele.rel = 'stylesheet'
  ele.href= 'https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css'
  document.getElementsByTagName('head')[0].appendChild(ele)
}

function loadGitalk () {
  function initGitalk () {
    var gitalk = new Gitalk(Object.assign({
      clientID: 'd652112bf81876e00118',
      clientSecret: 'a5abed418c7cc2736af5b4d0cbd7ff97d460a5b3',
      repo: 'Coding-Zuo.github.io',
      owner: 'Coding-Zuo',
      admin: ['Coding-Zuo'],
      id: 'd8ff38c03256bb4a68c01c1ab0f70159',
      language: 'zh-CN',
      perPage: 10,
      distractionFreeMode: false,
      pagerDirection: 'last',
      createIssueManually: false,
      updateCountCallback: commentCount
    },null))

    gitalk.render('gitalk-container')
  }

  if (typeof Gitalk === 'function') initGitalk()
  else {
    addGitalkSource()
    getScript('https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.js').then(initGitalk)
  }
}

function commentCount(n){
  let isCommentCount = document.querySelector('#post-meta .gitalk-comment-count')
  if (isCommentCount) {
    isCommentCount.innerHTML= n
  }
}

if ('Gitalk' === 'Gitalk' || !true) {
  if (true) btf.loadComment(document.getElementById('gitalk-container'), loadGitalk)
  else loadGitalk()
} else {
  function loadOtherComment () {
    loadGitalk()
  }
}</script></div><script src="/js/custom.js"></script><script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script><script defer="defer" id="fluttering_ribbon" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-fluttering-ribbon.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script src="//code.tidio.co/mak6nokafytw9mgrsuzglwzfxiy3fpdl.js" async="async"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>